cite_key,title,authors,year,Downloaded,Relevancy,Relevancy Justification,Insights,TL;DR,Summary,Research Question,Methodology,Key Findings,Primary Outcomes,Limitations,Conclusion,Research Gaps,Future Work,Implementation Insights,url,DOI,Tags,pkg_Papers,pkg_Authors,pkg_Published Year,pkg_Journal,pkg_DOI,pkg_Conclusion,pkg_Implementation Insights,pkg_Insights,pkg_Key Findings,pkg_Limitations,pkg_Methodology,pkg_Primary Outcomes,pkg_Reproducibility,pkg_Research Question,pkg_Summary,pkg_TL;DR,pkg_Tags,match_score,match_type
abdallah_2021,Towards a GML-Enabled Knowledge Graph Platform,"Hussein Abdallah, Essam Mansour",2021,Yes,HIGH,"This paper is highly relevant as it proposes KGNet, a platform for on-demand graph machine learning (GML) as a service on top of RDF engines. This directly addresses the HDM project's need for integrating machine learning with knowledge graphs to enable intelligent reasoning over personal data. The focus on scalability, automated model training, and a GML-enabled query language (SPARQLML) provides a strong architectural blueprint for the HDM system.","The paper introduces KGNet, a platform that automates the training of GML models on knowledge graphs by using task-specific subgraphs. This approach improves scalability and accuracy for tasks like node classification and link prediction. It also proposes SPARQLML, a SPARQL-like query language that allows users to query and perform inference over KGs using the trained GML models.","This vision paper proposes KGNet, a platform that provides on-demand graph machine learning (GML) as a service on top of RDF engines. It aims to bridge the gap between GML frameworks and RDF data stores by automating the training of GML models on task-specific subgraphs of a knowledge graph. The platform introduces SPARQLML, a GML-enabled query language, to allow for querying and inferencing over KGs using the trained models, thereby improving scalability, accuracy, and accessibility of GML on knowledge graphs.","How can we seamlessly integrate graph machine learning (GML) models with RDF engines to enable scalable, on-demand training and querying of knowledge graphs for various prediction tasks?","The paper proposes the KGNet platform, which consists of two main components: GML-as-a-service (GMLaaS) and SPARQLML as a Service. GMLaaS automates the GML training pipeline by using a meta-sampling approach to extract task-specific subgraphs, selecting the optimal GML method based on budget constraints, and managing the trained models. SPARQLML as a Service provides a query interface that allows users to train, delete, and query GML models using a SPARQL-like syntax.","The experimental evaluation shows that training GML models on task-specific subgraphs identified by KGNet's meta-sampling approach significantly reduces training time and memory usage while maintaining comparable or even improved accuracy compared to training on the entire knowledge graph. For instance, on the DBLP dataset, KGNet achieved up to an 11% improvement in accuracy with at least a 22% reduction in memory and 27% reduction in training time.","The primary outcome is the proposal of the KGNet platform, a vision for a fully-fledged GML-enabled knowledge graph platform. The paper outlines the architecture, key components, and research challenges, and provides a proof-of-concept evaluation that demonstrates the feasibility and benefits of the proposed approach.","The paper is a vision paper, so the implementation is a prototype and not a fully mature system. The query optimization for SPARQLML is still an open research problem. The meta-sampling approach has been evaluated on a limited number of scenarios.","The integration of GML frameworks with RDF engines is a critical step towards building scalable and intelligent knowledge graph applications. By automating the GML pipeline and providing a high-level query language, platforms like KGNet can significantly lower the barrier for data scientists and developers to apply advanced machine learning techniques to knowledge graphs.","The paper identifies several research gaps, including the need for more advanced meta-sampling techniques, better methods for SPARQLML query optimization, and the development of comprehensive benchmarks for evaluating GML-enabled KG engines. There is also a need for more seamless integration between GML models and RDF engines to avoid the use of UDFs.","Future work includes developing more sophisticated meta-sampling approaches, creating advanced query optimization techniques for SPARQLML, and building comprehensive benchmarks to evaluate the performance of GML-enabled KG platforms. There is also an opportunity to explore the use of KGNet in various application domains beyond the ones presented in the paper.","The paper provides valuable insights into the architecture of a GML-enabled KG platform. The use of a meta-sampler to extract task-specific subgraphs is a key technique for improving scalability. The KGMeta graph, which stores metadata about trained models, is a clever way to enable seamless integration and query optimization. The proposed SPARQLML language provides a user-friendly interface for interacting with the system.",https://doi.org/10.1145/3447772,10.1145/3447772,"Knowledge Graph, Graph Machine Learning, GML, SPARQL, RDF, GNN, AI, Heterogeneous, Integration, Semantic","architecture, data-integration, gml, graph-platforms, heterogeneous-data, knowledge-graph, schema-management",,,,,,,,,,,,,,,,,,,
aburasheed_2023b,Building Contextual Knowledge Graphs for Personalized Learning Recommendations Using Text Mining and Semantic Graph Completion,"Hasan Abu-Rasheed, Mareike Dornhöfer, Christian Weber, Gábor Kismihók, Ulrike Buchmann, Madjid Fathi",2023,Yes,HIGH,"This paper is highly relevant as it directly addresses the transformation of hierarchical learning object data models into knowledge graphs using text mining and semantic graph completion. This aligns with the HDM project's focus on heterogeneous data integration and building schemas for diverse data, as it demonstrates a method for converting structured but inflexible data into a semantically rich knowledge graph. The emphasis on personalized recommendations also aligns with the HDM's goal of user-centric systems.","Transforms hierarchical learning object data models into knowledge graphs using custom text mining pipelines to extract semantic relations, achieving semantically comparable results to domain expert definitions with improved graph communities and betweenness centrality.","This paper addresses the transformation of hierarchical learning object (LO) data models into knowledge graphs to enable more sophisticated, context-aware learning recommendations. The research uses custom text mining pipelines to extract semantic relations between learning object elements and transforms hierarchical data models into knowledge graph models. The approach enables progression from basic ""remembering-level"" learning objectives to higher-order application and analysis objectives by representing learning contexts more comprehensively through knowledge graphs, addressing limitations in traditional hierarchical learning models.",How can hierarchical learning object data models be transformed into contextual knowledge graphs to enable more sophisticated context-aware personalized learning recommendations?,Custom text mining pipelines for semantic relation extraction; transformation from hierarchical data models to knowledge graph models; quality-control metrics and semantic similarity comparisons for evaluation; graph structure analysis using communities and betweenness centrality.,Knowledge graph relations semantically comparable to domain expert definitions; improved representation of learning object contexts; increased graph communities and betweenness centrality; successful transformation from hierarchical to graph-based learning models.,"The primary outcome is a demonstrated methodology for transforming hierarchical learning object data models into contextual knowledge graphs, enabling more sophisticated context-aware personalized learning recommendations. The paper shows that the resulting KG relations are semantically comparable to domain expert definitions and improve graph communities and betweenness centrality.",Limited evaluation on specific learning domains; dependency on quality of input hierarchical data models; computational complexity considerations for large-scale learning object datasets.,Successfully demonstrates transformation of hierarchical learning models into contextual knowledge graphs that enable progression from basic to higher-order learning objectives.,"The paper implicitly points to the need for: (1) broader evaluation across diverse educational domains and learning contexts, (2) investigation into scalability for very large learning object repositories, and (3) development of adaptive context modeling for dynamic learning environments.","Future work includes expanding evaluation to diverse educational domains and learning contexts, investigating scalability for large learning object repositories, and developing adaptive context modeling for dynamic learning environments.",Provides practical framework for implementing context-aware educational recommendation systems using knowledge graphs; demonstrates effective transformation from hierarchical to semantic learning models for HDM educational applications.,https://ieeexplore.ieee.org/document/10260850/,10.1109/ICALT58122.2023.00040,"Contextual Knowledge Graphs, Personalized Learning, Educational Technology, Semantic Graph Completion, Learning Object Modeling","data-integration, educational-technology, knowledge-graph, personalized-learning, recommendation-systems, semantic-completion, text-mining",Building Contextual Knowledge Graphs for Personalized Learning Recommendations Using Text Mining and Semantic Graph Completion,"Abu-Rasheed Hasan, Dornhöfer Mareike, Weber Christian, Kismihók Gábor, Buchmann Ulrike, Fathi Madjid",2023,reference-manager,10.1109/icalt58122.2023.00016,,"The implementation uses a text-mining pipeline (TMP) to extract semantic relations and build a knowledge graph (KG) from hierarchical learning object (LO) data. The KG increases LO connectivity, enabling better contextualization. TMP performance depends on LO metadata quality. Multilingualism introduces repetitive content concerns. Future work aims to improve robustness against sparse data.",,,,"Quantitative evaluation using network metrics (e.g., Average Degree Centrality, Clustering Coefficient, Betweenness Centrality) to assess KG structure.",,,"How can a semantic approach for knowledge graph completion, using a text mining pipeline for relation extraction, enhance the contextual representation and connectivity of learning objects for personalized learning systems?","The paper aims to enhance contextual representation of learning objects (LOs) for personalized learning by using a text mining pipeline (TMP) and semantic similarity calculations. Using expert-curated OER data, the methodology involves semantic relation extraction and knowledge graph (KG) construction. Results show improved LO connectivity and meaningful semantic relations, supporting better contextual learning.","The research goal is to enhance personalized learning by improving the contextual representation of learning objects (LOs) using a semantic knowledge graph (KG) constructed via a text-mining pipeline (TMP); results show the KG increases semantic connectivity among LOs, supporting richer learning contexts.",,1.000,exact_title
abusalih_2023,"Healthcare knowledge graph construction: A systematic review of the state-of-the-art, open issues, and opportunities","Bilal Abu-Salih, Muhammad AL-Qurishi, Mohammed Alweshah, Mohammad AL-Smadi, Reem Alfayez, Heba Saadeh",2023,Yes,HIGH,"This paper is highly relevant to the HDM project as it provides a comprehensive systematic review of healthcare knowledge graph construction. The challenges identified, such as data heterogeneity, knowledge interoperability, and the need for robust evaluation, are directly applicable to the development of a personal knowledge graph for HDM. The proposed taxonomy and discussion of open issues offer a valuable roadmap for designing and implementing a high-quality, reliable PKG.","The paper's key insight is the urgent need for a more systematic and standardized approach to constructing healthcare knowledge graphs. It reveals that many existing methods are ad-hoc and lack rigorous evaluation, which compromises the quality and reliability of the resulting KGs. The authors emphasize the importance of addressing data heterogeneity, ensuring data quality, and incorporating temporal dynamics to build effective healthcare KGs.","This paper provides the first comprehensive systematic review of healthcare knowledge graph (KG) construction. It introduces a new taxonomy for the field, critically evaluates state-of-the-art techniques, and discusses open issues and future research opportunities. The authors highlight the inadequacy of many existing approaches and call for more rigorous methodologies to ensure the quality and robustness of healthcare KGs.","What is the current state-of-the-art in healthcare knowledge graph construction, what are the main challenges and open issues, and what are the opportunities for future research?","The authors conducted a systematic literature review following the PRISMA framework. They analyzed 101 papers published between 2018 and 2022, focusing on KG construction methodologies in various healthcare domains. Based on this analysis, they developed a taxonomy for healthcare KG construction and critically evaluated the existing techniques.","The study found that many healthcare KG construction approaches are ad-hoc and lack proper evaluation. Key challenges include handling data heterogeneity, ensuring data quality and privacy, achieving knowledge interoperability, and modeling the temporal nature of healthcare data. The paper also highlights a lack of publicly available healthcare KGs, which hinders research and development in the field.","The primary outcome is a comprehensive survey that provides a bird's-eye view of healthcare KG construction. It includes a novel taxonomy, an in-depth analysis of the state-of-the-art, and a discussion of open issues and future directions, serving as a valuable resource for researchers and practitioners.","The review is limited to papers published within a specific timeframe (2018-2022). The analysis is based on the information provided in the papers, and the authors note that many studies did not fully disclose their methodologies, which could affect the completeness of the review.","The construction of high-quality, robust, and interoperable healthcare knowledge graphs is crucial for advancing data-driven healthcare. This requires a shift from ad-hoc approaches to more systematic and standardized methodologies that address the unique challenges of the healthcare domain.","The paper identifies several research gaps, including the need for advanced techniques for integrating heterogeneous data sources, better methods for ensuring data quality and privacy, more effective approaches for knowledge interoperability, and the development of dynamic KGs that can capture the temporal aspects of healthcare data.","Future research should focus on developing sophisticated data collection and aggregation techniques, promoting semantic expansion and interoperability, establishing standardized KG construction and evaluation methodologies, and addressing data quality and privacy issues through advanced NLP and deep learning algorithms.","The paper offers valuable implementation insights, such as the importance of following a structured construction process, the need to integrate data from diverse sources to create a holistic view, and the necessity of rigorous evaluation to ensure the quality of the KG. The proposed taxonomy can be used as a practical guide for building healthcare KGs.",,,"Healthcare, Knowledge Graph, Systematic Review, Data Integration, Semantic Web, Ontology, Machine Learning","data-integration, healthcare-informatics, healthcare-knowledge-graphs, heterogeneous-data, ontology-management, semantic-interoperability, systematic-review",,,,,,,,,,,,,,,,,,,
abusalih_2024,A systematic literature review of knowledge graph construction and application in education,"Bilal Abu-Salih, Salihah Alotaibi",2024,Yes,HIGH,"This paper provides a comprehensive systematic review of knowledge graph construction and applications in education. While the domain is education, the identified challenges and methodologies are highly relevant to the HDM project. The paper discusses challenges like data heterogeneity, lack of standardization, limited interoperability, and scalability, which are all core issues the HDM project aims to address. The structured review of KG construction techniques and applications provides valuable patterns and anti-patterns that can inform the design of the HDM's own data integration and knowledge representation architecture.","The key insight is that while KGs show immense promise in education, the field suffers from a lack of standardization, poor interoperability, and inadequate evaluation techniques. Many KG construction approaches are ad-hoc and not well-documented, hindering reproducibility and progress. This mirrors challenges in other domains and underscores the need for rigorous, systematic methodologies for building KGs, a core principle of the HDM project.","A systematic review of 120 papers reveals that Knowledge Graphs are increasingly used in education for personalized learning, curriculum design, and semantic search, but progress is hampered by a lack of standardization, poor data integration, and weak evaluation methods.","This paper conducts a systematic literature review (SLR) of 120 articles published between 2019 and 2023 on the construction and application of Knowledge Graphs (KGs) in education. It categorizes applications into five main domains: Adaptive and Personalised Learning, Curriculum Design and Planning, Concept Mapping and Visualization, Semantic Search and Question Answering, and miscellaneous applications. The review highlights the growing interest in using KGs to enhance educational experiences but also identifies significant limitations in the current state-of-the-art, including a lack of standardization, poor interoperability, sparse data, scalability issues, and inadequate evaluation techniques. The paper calls for more rigorous and standardized methodologies to advance the field.","What are the state-of-the-art methodologies for Knowledge Graph construction in education, what are their primary applications, and what are the key limitations and research gaps in the current literature?","The authors conducted a Systematic Literature Review (SLR) following the PRISMA framework. They searched multiple academic databases (Elsevier, ACM, MDPI, IEEE Xplore, Google Scholar) for papers published between 2019 and 2023. An initial set of 565 records was screened, and after a full-text eligibility assessment, 120 papers were included in the final review. The paper then synthesizes the findings from these papers, categorizing them by application domain and analyzing their methodologies, resources, and limitations.","The review found a rapidly growing interest in using KGs in education. The primary applications are in personalized learning, curriculum design, and semantic search. However, the study also identified major weaknesses in the existing research: (1) Lack of standardization in KG schemas and ontologies. (2) Limited interoperability between different educational KGs. (3) Many KGs are built on sparse and incomplete data. (4) Scalability is a major, often unaddressed, challenge. (5) Evaluation methods are often poor and subjective, lacking rigor. (6) Privacy and security are not well-studied.","The primary outcome is a comprehensive survey that maps the landscape of KG construction and application in education. It provides a structured overview of the state-of-the-art, a clear summary of the limitations and challenges, and a set of future research directions.","The paper itself identifies the limitations of the reviewed works. The authors of the survey note that their review is based on the information provided in the papers, and many studies did not fully disclose their methodologies. The review is also limited to papers published within a specific timeframe (2019-2023).","Knowledge Graphs have the potential to revolutionize education by enabling personalized, data-driven learning experiences. However, to realize this potential, the field needs to move beyond ad-hoc approaches and adopt more rigorous, standardized, and collaborative methodologies for KG construction, evaluation, and maintenance.",The paper explicitly identifies several research gaps: the need for standardized ontologies for education; methods for better data integration and handling of semantic heterogeneity; scalable KG construction and maintenance techniques; robust and objective evaluation metrics; and research into privacy-preserving techniques for educational KGs. The integration of LLMs with educational KGs is also highlighted as a key area for future research.,"Future work should focus on addressing the identified research gaps. This includes developing common ontologies for education, creating benchmarks and standardized evaluation metrics, exploring the use of LLMs for automated KG construction and maintenance, and designing privacy-preserving architectures for educational KGs.","The paper provides valuable implementation insights by highlighting common pitfalls to avoid. Key takeaways for the HDM project include: (1) The importance of adopting a standardized, ontology-driven approach from the outset. (2) The need to plan for scalability and real-time updates. (3) The necessity of developing a rigorous evaluation framework. (4) The critical importance of addressing privacy and security concerns when dealing with personal (student) data. The detailed tables summarizing various approaches also serve as a useful reference for specific techniques.",https://doi.org/10.1016/j.heliyon.2024.e25383,10.1016/j.heliyon.2024.e25383,"data-integration, educational-technology, knowledge-graph, ontology, personalized-learning, semantic-web, survey, systematic-literature-review",A systematic literature review of knowledge graph construction and application in education,"Abu-Salih Bilal, Alotaibi Salihah",2024,reference-manager,10.1016/j.heliyon.2024.e25383,,"The paper provides the first comprehensive overview of Knowledge Graph (KG) construction and application in education, analyzing methodologies, strengths, and weaknesses. It highlights research gaps, such as data quality, scalability, biases, and evaluation challenges. New insights include the growing trend in educational KG research and the need for improved frameworks and evaluation metrics.",,,,Systematic Literature Review (SLR): A structured review of research articles focused on KG (Knowledge Graph) construction in education.,,,"What are the recent methodologies for constructing knowledge graphs in education, what are their strengths and limitations, and how do these approaches impact key educational domains such as adaptive learning, curriculum design, concept mapping, semantic search, and question answering?","This paper presents the first comprehensive systematic literature review (SLR) of knowledge graph (KG) construction and application in education. Using the PRISMA model, 120 studies were analyzed across five domains. The study highlights KG methodologies, strengths, weaknesses, and research gaps, offering recommendations for future work.","The research goal is to systematically review recent knowledge graph (KG) construction methods in education, using a PRISMA-based approach, and the principal finding is a comprehensive analysis of current methodologies, their strengths and weaknesses, and identification of research gaps for future exploration.",,1.000,exact_title
aho_2023,A human digital twin for the M‑Machine,"Pertti Saariluoma, Mari Myllylä, Antero Karvonen, Mika Luimula, Jami Aho",2023,Yes,MEDIUM,"This paper's focus on Human Digital Twins (HDTs) and cognitive mimetics is relevant to the HDM project's goal of creating a system that understands and augments human cognitive processes. While the paper is more conceptual, it provides a strong theoretical foundation for modeling human-technology interaction, which is central to the HDM's purpose. The discussion of how to model human information processing and intentionality can inform the design of the HDM's user model and its interaction paradigms.","The key insight of the paper is the necessity of shifting design focus from purely technical artifacts to a more holistic view that includes modeling human actions and intentions. The authors argue that Human Digital Twins, which are computational models of human interaction with technology, are essential tools for designing the intelligent systems of the future. They introduce ""cognitive mimetics"" as a method for imitating human information processing to create more effective and human-centered AI.","This paper introduces the concept of a Human Digital Twin (HDT) as a computational model of human actions involved in interacting with technical artifacts. The authors argue that as technology becomes more intelligent, designers must focus on modeling human interaction to create effective and human-centered systems. Using Minsky's M-Machine as a general model, they explore the conceptual foundations of HDTs, their design principles, and their role as a tool for designing future intelligent technologies.",How can we construct Human Digital Twins (HDTs) to effectively model human interaction with intelligent technologies and guide the design of future human-centered AI systems?,The paper uses a conceptual engineering approach. The authors define and elaborate on the concepts of Human Digital Twins and cognitive mimetics. They use Marvin Minsky's M-Machine as an abstract conceptual model to analyze the general properties of HDTs and their design. They also introduce the Ideal-Exception-Correction (IEC) model as a practical example of an HDT for process control tasks.,"The paper establishes that HDTs are a crucial tool for designing the next generation of intelligent technologies. It demonstrates that by modeling human information processing and intentionality, designers can create more holistic and effective systems. The use of the M-Machine as a general model allows for the analysis of HDT properties at an abstract level, applicable to any specific technology.","The primary outcome is a conceptual framework for Human Digital Twins. The paper defines the key components of an HDT (the user, the machine, and the Human Interaction Point), introduces the concept of cognitive mimetics, and proposes the IEC model as a concrete example of an HDT.","The paper is largely theoretical and does not present a concrete, implemented HDT for a real-world system beyond the conceptual IEC model. The discussion on the practical implementation of HDTs is limited, and the paper does not address the technical challenges of building such complex models in detail.","The design of future intelligent systems must be holistic, considering not just the technology itself but also how humans interact with it. Human Digital Twins, based on the principles of cognitive mimetics, provide a powerful conceptual tool for achieving this human-centered design approach.","The paper highlights the need for more research into the practical construction of HDTs. It also points to the challenge of integrating different types of models (e.g., causal models for machines and intentional models for humans) within a single HDT framework.",Future work should focus on developing practical methodologies and tools for building HDTs for specific application domains. There is also a need to explore how to integrate various cognitive architectures (like ACT-R and GOMS) into HDT models to better capture the complexities of human information processing.,"The paper provides valuable insights for implementation by breaking down the concept of an HDT into its core components: the user model, the machine model (M-Machine), and the Human Interaction Point (HIP). The IEC model serves as a practical example of how to model human control processes, offering a template for designing HDTs for similar tasks.",https://doi.org/10.1007/s44163-024-00164-x,10.1007/s44163-024-00164-x,"Human Digital Twin, Cognitive Mimetics, Human-Computer Interaction, AI Design, User Modeling, M-Machine, Design Science","behavioral-modeling, cognitive-computing, data-integration, digital-twins, human-modeling, knowledge-representation, personal-data",A human digital twin for the M-Machine,"Saariluoma Pertti, Myllylä Mari, Karvonen Antero, Luimula Mika, Aho Jami",2024,reference-manager,10.1007/s44163-024-00164-x,,,,,,Designing an interaction design process model using Minsky’s M-Machine as an example to model human-AI design processes.,,,"How can human information-processing limitations, intentions, and user roles be modeled to improve the design and usability of technical artifacts, such as paper machines, through frameworks like the IEC model and HDTs?","The paper investigates how cognitive mimetics, focusing on information processes, can unify human and machine thinking. Using simulation and protocol analysis, it develops the IEC model to represent operators’ mental processes in paper manufacturing. Findings show the model helps interpret operator actions, though it lacks comprehensive detail.",The research goal is to generalize the IEC model for modeling human-technology interaction; the approach uses cognitive mimetics and empirical analysis of operator thinking; the principal finding is that the IEC model effectively captures the logic of human actions in technical process control.,,1.000,exact_title
ai_2025,Zep: A Temporal Knowledge Graph Architecture for Agent Memory,Preston Rasmussen Zep AI,2025,Yes,HIGH,Contains relevant concepts applicable to HDM systems,"Core component ""Graphiti"" - temporally-aware knowledge graph engine that dynamically synthesizes unstructured conversational and structured business data while maintaining historical relationships.",Temporal knowledge graph architecture that outperforms existing memory systems,"This paper presents Zep, a temporal knowledge graph architecture for AI agent memory that addresses limitations of static document retrieval in RAG frameworks by enabling dynamic knowledge integration from diverse sources including ongoing conversations and business data.",How can temporal knowledge graphs improve AI agent memory for enterprise applications requiring dynamic knowledge integration?,"Core component: ""Graphiti"" - temporally-aware knowledge graph engine; dynamically synthesizes unstructured conversational and structured business data; maintains historical relationships.",Outperforms MemGPT in Deep Memory Retrieval benchmark (94.8% vs 93.4%); 18.5% accuracy improvement in LongMemEval benchmark; 90% reduction in response latency.,"Enhanced cross-session information synthesis, improved long-term context maintenance, effective for enterprise AI applications.",Not explicitly stated in the abstract.,Demonstrates significant advancement in temporal knowledge graph applications for AI agent memory and enterprise knowledge integration.,Limitations of static document retrieval in RAG frameworks; need for dynamic knowledge integration in enterprise AI.,"Enhanced cross-session information synthesis, improved long-term context maintenance, effective for enterprise AI applications.",Provides practical implementation of temporal knowledge graphs for AI agent memory with focus on dynamic data synthesis and historical relationship maintenance.,https://arxiv.org/abs/2501.13956,10.48550/arXiv.2501.13956,"ai, integration, knowledge-graph, llm, machine-learning, memory, semantic, survey, temporal",ZEP: A Temporal Knowledge Graph Architecture for Agent Memory,"Rasmussen Preston, Paliychuk Pavlo, Beauvais Travis, Ryan Jack, Chalef Daniel",2025,reference-manager,,,,,,Results with Graphiti and Zep represent only initial advances; further research is needed.,,,,"How can knowledge graphs be leveraged to enhance LLM-agent memory retrieval systems, specifically through the integration of multiple search methods, reranking, and context construction, and what are the implications for accuracy, scalability, and evaluation within business-oriented and production environments?","The paper investigates Zep, a graph-based memory retrieval system for LLM agents. Using a multi-step search, rerank, and construct methodology, Zep outperforms existing baselines and MemGPT on Deep Memory Retrieval benchmarks. The study highlights Zep’s accuracy, scalability, and the need for better memory benchmarks and ontology integration.","The paper’s research goal is to improve LLM memory using a graph-based approach (Zep) that combines semantic and episodic memory; the key method is a configurable graph search API retrieving relevant nodes and edges, and the principal finding is that Zep achieves state-of-the-art accuracy and latency on memory benchmarks.",,1.000,exact_title
ain_2024,Learner Modeling and Recommendation of Learning Resources using Personal Knowledge Graphs,"Qurat Ul Ain, Rawaa Alatrash, Mohamed Amine Chatti, Shoeb Joarder, Paul Arthur Meteng Kamdem, Clara Siepmann",2024,Yes,HIGH,"This paper is highly relevant as it directly implements and evaluates a Personal Knowledge Graph (PKG) system for a practical application (education). It addresses key HDM themes like user-in-the-loop control, semantic modeling, and personalized recommendations. The use of a scrutable, user-controlled PKG to drive recommendations is a core concept for the HDM project.","The key insight is that giving learners direct control over their knowledge model (by marking concepts they ""Did Not Understand"") significantly improves their satisfaction and intention to use a recommender system. This user-in-the-loop approach, creating a scrutable PKG, is more impactful on user perception than minor differences in algorithmic accuracy.","This paper presents an educational recommender system where students build their own Personal Knowledge Graphs (PKGs) by flagging concepts they don't understand. This PKG-based approach, which gives users control over their data model, was perceived as more accurate, novel, diverse, and useful than a traditional content-based system.","This paper proposes an educational recommender system that empowers students by allowing them to construct their own Personal Knowledge Graphs (PKGs). Students interact with learning materials and explicitly mark concepts they ""Did Not Understand"" (DNU). These DNU concepts form the basis of their PKG, which is then used to generate personalized recommendations for external learning resources (YouTube videos, Wikipedia articles). The system was evaluated through offline experiments and an online user study (N=31), comparing the PKG-based approach to a traditional content-based one. The results showed that while the content-based approach had slightly higher precision, the PKG-based approach was perceived more positively by users across several metrics, including accuracy, novelty, diversity, usefulness, and overall satisfaction. The authors conclude that user control over the learner model is a key factor in the acceptance and perceived quality of educational recommender systems.","How can we effectively leverage Personal Knowledge Graphs (PKGs) to model students' knowledge and recommend learning resources in a MOOC environment, and what is the impact of this approach on system accuracy and user perception?","The authors developed a PKG-based recommender system within their CourseMapper MOOC platform. Key components include: 1) A concept extraction pipeline using SingleRank and DBpedia Spotlight. 2) A user interface allowing students to mark concepts as ""Did Not Understand"" (DNU). 3) A learner model built from the student's PKG, using SBERT for concept embeddings and a modified LightGCN to incorporate graph structure. 4) A recommendation engine that computes cosine similarity between the learner model and candidate resources from YouTube and Wikipedia. The system was evaluated in an online user study (N=31) comparing four variants (PKG-based vs. content-based, each with keyphrase vs. document-level analysis) using quantitative metrics (Precision@k, MRR, MAP) and a qualitative user survey (ResQue framework).","The user study found that: (1) The PKG-based recommendation approach was perceived by users as more accurate, novel, diverse, and useful than the content-based approach. (2) Users were more satisfied with the PKG-based system and had a higher intention to use it. (3) Giving users control over their learner model (by marking DNU concepts) was a major contributor to their satisfaction. (4) Offline, the keyphrase-based variants achieved higher semantic similarity scores, but online, the document-based variants had slightly better ranking accuracy (MRR/MAP), highlighting the discrepancy between offline metrics and user perception.","The primary outcome is a novel, user-centric educational recommender system that demonstrates the practical benefits of using scrutable Personal Knowledge Graphs. The study also provides a set of validated findings on the importance of user control in personalized learning environments.","The authors acknowledge several limitations: (1) The concept extraction process was sometimes imprecise, leading to irrelevant concepts being included in the PKG. (2) The YouTube API's query length limit restricted the number of DNU concepts that could be used for candidate retrieval. (3) The user study was conducted with a relatively small sample size (N=31) from a single university course, which may limit the generalizability of the findings.","The paper concludes that a PKG-based approach, which gives students control over their own learner model, is a promising direction for building more effective and engaging educational recommender systems. The increased user satisfaction and perceived quality of the recommendations highlight the importance of transparency and scrutability in personalized learning environments.","The paper points to the need for improved concept extraction pipelines to create more accurate PKGs. It also highlights the need for further research into how to best balance global (all DNU concepts) and local (current slide's concepts) context when generating recommendations. Finally, it suggests investigating other user-centric evaluation metrics beyond the ResQue framework, such as trust and confidence.",Future work will focus on: (1) Improving the accuracy of the concept extraction pipeline. (2) Refining the recommendation algorithm to better handle the trade-off between global and local context. (3) Conducting larger-scale user studies to further validate the findings and explore other user-centric metrics like transparency and trust.,The paper provides a clear architectural blueprint for a PKG-based recommender system. Key implementation insights include: (1) The use of SBERT for generating semantic embeddings of concepts and documents. (2) The application of a GCN (LightGCN) to enrich concept embeddings with graph-structural information. (3) The design of a user interface that allows for explicit user feedback (marking DNU concepts). (4) The use of the ResQue framework for a comprehensive user-centric evaluation.,https://dl.acm.org/doi/10.1145/3636555.3636881,10.1145/3636555.3636881,"educational-recommender-system, ers, gcn, learner-modeling, open-learner-model, personal-knowledge-graph, sbert, scrutability, semantic-similarity, user-control, user-study",Personal Knowledge Graphs,"Balog Krisztian, Kenter Tom",2019,reference-manager,10.1145/3341981.3344241,,,,,"Lack of large, open datasets for PKGs, making evaluation difficult.",,,,"How can personal knowledge graphs be effectively defined, represented, implemented, and integrated with external sources, considering their unique properties, challenges, and the need for structured, user-centric knowledge distinct from general knowledge graphs?",,"The research goal is to define personal knowledge graphs (PKGs), distinguish them from general knowledge graphs, and outline a research agenda; the approach involves identifying key properties, challenges, and open questions; the principal finding is that PKGs require new methods for evaluation, implementation, and representation due to their personal and dynamic nature.","Personal knowledge graphs, knowledge representation, personal information management",0.900,fuzzy_title
akroyd_2021,Universal Digital Twin - A Dynamic Knowledge Graph,"Jethro Akroyd, Sebastian Mosbach, Amit Bhave, Markus Kraft",2021,Yes,SUPER,"This paper is of super relevancy because it introduces a dynamic knowledge graph approach for digital twins, which is a core concept for the HDM project. The paper's focus on interoperability, real-time data integration, and the use of ontologies and agents aligns perfectly with the HDM's architectural goals. The concepts of a ""base world"" and ""parallel worlds"" for scenario analysis are directly applicable to the HDM's need to model and simulate personal data.","The key insight is that a dynamic knowledge graph, implemented with Semantic Web technologies, provides a robust and scalable foundation for creating a ""Universal Digital Twin."" This architecture, composed of ontologies, instances, and autonomous agents, can handle heterogeneous, cross-domain data while ensuring it remains connected, discoverable, and queryable.","The paper proposes a dynamic knowledge graph architecture for creating digital twins, demonstrating its ability to integrate diverse data sources, support real-time updates via computational agents, and enable complex scenario analysis through ""parallel worlds.""","This paper introduces a dynamic knowledge-graph approach for digital twins, arguing it is well-suited for realizing a Universal Digital Twin. The implementation uses Semantic Web technologies, with concepts and instances defined by ontologies, and computational agents that update the graph. This design is inherently distributed, supports cross-domain interoperability, and ensures data is connected, portable, discoverable, and queryable via a uniform interface. The paper introduces the notions of a ""base world"" for real-world representation maintained by real-time data agents, and ""parallel worlds"" for exploring alternative scenarios without affecting the base world. Use cases demonstrate the graph's ability to handle geospatial and chemical data, control experiments, and perform cross-domain simulations and scenario analysis.","How can a comprehensive, interoperable, and dynamic digital twin be implemented to support complex, cross-domain decision-making, such as in urban planning and energy system decarbonization?","The paper proposes a dynamic knowledge graph architecture implemented using Semantic Web technologies (ontologies, RDF, SPARQL). The system, called the World Avatar, uses autonomous computational agents to continuously update the knowledge graph with real-time data and perform simulations. The methodology is demonstrated through several use cases, including the J-Park Simulator for an eco-industrial park, the Cities Knowledge Graph for urban planning, and a project to create a digital twin of the UK for energy system analysis.","The dynamic knowledge graph approach is a viable and powerful method for implementing a Universal Digital Twin. It successfully integrates heterogeneous data from different domains (e.g., weather, shipping, chemistry, urban planning) and scales from atomic to national levels. The use of agents allows the digital twin to remain up-to-date and self-consistent. The ""parallel worlds"" concept provides a robust framework for what-if scenario analysis.","The primary outcome is the World Avatar project itself, a proof-of-concept for a dynamic knowledge graph-based digital twin. The paper also presents a clear architectural framework and a set of design principles for building such systems.",The paper acknowledges that the implementation of a full Universal Digital Twin is still a significant challenge. The suggestion of scenarios and the alignment of goals for complex problems are identified as open research questions. The performance and scalability of the underlying triple stores for industry-scale applications remain a challenge.,"A dynamic knowledge graph built with Semantic Web technologies provides a powerful and suitable foundation for implementing a comprehensive, interoperable digital twin. This approach can support complex, data-driven decision-making for large-scale systems like national infrastructure and energy grids.","The paper highlights the need for research on how to automatically suggest beneficial scenarios for analysis and how to ensure the goals of the digital twin align with societal goals, especially when goals conflict.","Future work includes extending the knowledge-graph-based digital twin of the UK to support the decarbonization of the energy landscape, incorporating more data sources (e.g., biomass, solar, wind), and further developing methods for goal alignment and automated scenario suggestion.","Key implementation insights include: the use of a distributed architecture with SPARQL endpoints for uniform data access; the use of autonomous agents to update the knowledge graph; the separation of the ""base world"" from ""parallel worlds"" for scenario analysis; and the use of ontologies to ensure semantic interoperability across different domains.",https://doi.org/10.17863/cam.32260,10.17863/CAM.32260,"agents, ai, data-integration, digital-twin, dynamic-knowledge-graph, energy-systems, federated, healthcare, interoperability, knowledge-graph, llm, machine-learning, medicine-access, memory, ontology, scenario-analysis, sdg, semantic, semantic-web, smart-cities, survey, temporal",,,,,,,,,,,,,,,,,,,
alatrash_2024,Transparent Learner Knowledge State Modeling using Personal Knowledge Graphs and Graph Neural Networks,"Rawaa Alatrash, Mohamed Amine Chatti, Qurat Ul Ain, Shoeb Joarder",2024,Yes,HIGH,"This paper is highly relevant as it demonstrates a novel approach combining Personal Knowledge Graphs and Graph Neural Networks for transparent learner modeling, directly aligning with HDM's goals of user-involved, interpretable knowledge representation.","Combines Personal Knowledge Graphs, Graph Convolutional Networks, and transformer sentence encoders to construct transparent learner models that explicitly involve learners in modeling their knowledge state through 'Did Not Understand' concept marking in MOOC platforms",Novel approach integrating PKGs and GNNs for transparent learner knowledge state modeling with explicit learner involvement in knowledge representation,"This paper presents a novel approach that combines Personal Knowledge Graphs, Graph Convolutional Networks, and transformer sentence encoders to construct transparent learner models for educational applications. The research explicitly involves learners in modeling their knowledge state by enabling them to mark concepts as 'Did Not Understand' in MOOC platforms, creating more interpretable and user-controlled knowledge representations. The approach addresses the need for transparency in AI-driven educational systems while maintaining effective predictive capabilities for personalized learning recommendations.",How can personal knowledge graphs and graph neural networks be combined to create transparent learner knowledge state models that actively involve learners in the knowledge representation process?,Integration of Personal Knowledge Graphs with Graph Convolutional Networks; transformer sentence encoder implementation; MOOC platform integration with 'Did Not Understand' concept marking; transparent learner modeling framework development,Demonstrated successful integration of PKGs and GNNs for learner modeling; achieved transparent knowledge state representation with active learner involvement; provided interpretable framework for educational recommendation systems,,Limited evaluation details available from conference abstract; focus on specific MOOC platform may limit generalizability; computational complexity considerations for real-time deployment not characterized,Successfully demonstrates feasibility of transparent learner modeling using PKGs and GNNs with active learner participation in knowledge state representation,,Expand evaluation to diverse educational platforms and contexts; investigate scalability for large-scale MOOC deployments; develop automated knowledge concept extraction methods,Emphasizes transparency and user involvement in AI-driven educational systems; provides practical framework for interpretable learner modeling using PKGs and GNNs for HDM educational applications,https://dl.acm.org/doi/10.1145/3627043.3659545,10.1145/3627043.3659545,"educational-technology, graph-neural-networks, learner-modeling, personal-knowledge-graph, transparent-ai",Personal Knowledge Graphs,"Balog Krisztian, Kenter Tom",2019,reference-manager,10.1145/3341981.3344241,,"Implementation Insights highlight several open challenges for Personal Knowledge Graphs (PKGs): ensuring secure integration with external services, managing storage across devices and cloud, handling offline scenarios, and maintaining privacy. Continuous, two-way synchronization and user involvement in resolving conflicting information are also emphasized as key issues.",,,,"Evaluation using large-scale, open datasets like Wikidata, DBpedia, and Freebase; synthetic data may be used as an alternative due to privacy and data availability challenges.",,,"How can personal knowledge graphs be effectively defined, represented, implemented, and integrated with external sources, considering their unique properties, challenges, and the need for structured, user-centric knowledge distinct from general knowledge graphs?","The paper defines personal knowledge graphs (PKGs) as structured, user-centered knowledge graphs and explores their unique challenges compared to general knowledge graphs. It identifies key research questions, discusses evaluation and implementation issues, and concludes that PKGs require dedicated research due to their distinct properties and integration needs.","The research goal is to define personal knowledge graphs (PKGs), distinguish them from general knowledge graphs, and propose a research agenda; the approach involves identifying key properties, challenges, and research questions; the principal finding is that PKGs require new solutions for evaluation, implementation, and representation due to their unique personal context.",,0.900,fuzzy_title
aldughayfiq_2023,Capturing Semantic Relationships in Electronic Health Records Using Knowledge Graphs: An Implementation Using MIMIC III Dataset and GraphDB,"Bader Aldughayfiq, Farzeen Ashfaq, N. Z. Jhanjhi, Mamoona Humayun",2023,Yes,SUPER,"This paper is of super relevancy because it provides a detailed, end-to-end implementation of constructing a knowledge graph from a complex, real-world Electronic Health Record (EHR) dataset (MIMIC-III). This directly addresses the HDM project's core challenge of integrating heterogeneous personal health data. The methodology, which covers ontology development, RDF mapping, and graph database implementation (GraphDB), offers a practical and validated blueprint for the HDM's data ingestion and representation layer. The paper's focus on using the KG to enable more efficient and accurate data analysis for patient outcomes is a primary goal of the HDM.","The key insight is that a knowledge graph-based approach provides a more efficient and intuitive way to analyze complex, heterogeneous EHR data compared to traditional relational databases. By creating a semantic layer (ontology) and representing the data as a graph, it becomes possible to easily query complex relationships and visualize connections that are difficult to see in a tabular format, ultimately enabling more comprehensive and holistic data analysis for better clinical decision-making.","The paper demonstrates how to build a knowledge graph from a large EHR dataset (MIMIC-III) to capture complex patient data relationships, enabling faster and more accurate analysis than traditional databases.","This study presents a methodology for constructing a knowledge graph from the MIMIC-III EHR dataset. The authors first develop an OWL ontology using Protégé to define the entities and relationships within the data. They then use Ontotext Refine to map the raw CSV data into RDF triples based on this ontology. The resulting knowledge graph is loaded into GraphDB, where SPARQL is used for querying and analysis. The authors demonstrate through sample queries that this approach can effectively capture semantic relationships, enabling more efficient and accurate analysis of patient data to identify trends and risk factors. They also show that their graph-based approach outperforms a traditional MySQL database in query execution time for similar tasks.",Can a knowledge graph created using the MIMIC III dataset and GraphDB effectively capture semantic relationships within EHRs and enable more efficient and accurate data analysis?,"The methodology involves a four-step process: 1. **Ontology Development**: An OWL ontology was created using Protégé to define the classes (e.g., Patient, Admission, Diagnosis) and properties of the EHR domain. 2. **Data Processing & RDF Mapping**: The MIMIC-III dataset (in CSV format) was processed using Ontotext Refine to map the data to the created ontology, generating RDF triples. 3. **Graph Representation**: The RDF triples were loaded into GraphDB to construct the knowledge graph. 4. **Querying and Analysis**: SPARQL queries were used to retrieve and analyze information from the graph, with use cases focused on identifying patient cohorts and risk factors. The performance was compared to a traditional MySQL database setup.","Knowledge graphs can effectively capture and represent the complex semantic relationships within large, heterogeneous EHR datasets. The graph-based approach allows for more efficient and intuitive data analysis compared to traditional relational databases. SPARQL queries on the GraphDB implementation were significantly faster (e.g., 0.11s vs. 1.33s for a sample query) than equivalent SQL queries on MySQL. The visual nature of the graph also enhances data exploration.","The primary outcome is a practical, implemented framework for converting a complex EHR dataset (MIMIC-III) into a queryable knowledge graph. This includes the developed ontology, the RDF mapping process, and a demonstration of its analytical capabilities through SPARQL queries.",The study acknowledges several limitations: the query performance evaluation was preliminary and used a limited set of sample queries. The ontology's clinical validity was not rigorously evaluated by external experts. The interoperability of the created KG with external standard vocabularies like SNOMED CT and LOINC was identified as a next step and not yet implemented. The study also focused on a single data repository.,"The study concludes that knowledge graphs are a powerful and effective tool for integrating and analyzing complex EHR data. By representing the data semantically, KGs enable more efficient, accurate, and comprehensive analysis, which can provide valuable insights for clinical decision-making and ultimately improve patient outcomes. The framework presented provides a foundation for further research and development in this area.","The paper identifies the need for more comprehensive and tailored ontologies for EHR data, more rigorous clinical validation of such KGs, and better methods for ensuring interoperability with standard medical vocabularies. It also points to the need to explore new research questions and expand the KG to include other data types like patient-generated data and genomics.","Future work plans include: 1. Linking the ontology to standard external vocabularies (SNOMED CT, LOINC) to improve interoperability. 2. Expanding the knowledge graph to include patient-generated data, genetic data, and socioeconomic determinants of health. 3. Applying machine learning algorithms on the knowledge graph to detect new risk factors and predict patient outcomes.","Key implementation insights include: the use of a standard pipeline (Ontology -> RDF Mapping -> Graph DB) for KG construction; the use of specific tools like Protégé for ontology editing, Ontotext Refine for RDF mapping, and GraphDB for storage and querying; the demonstration of significant query performance improvements of a graph database over a relational database for complex relationship-based queries. The paper provides a clear, step-by-step guide that can be followed to implement a similar system.",https://doi.org/10.3390/healthcare11121762,10.3390/healthcare11121762,"ai, digital-twin, healthcare, heterogeneous, integration, knowledge-graph, machine-learning, ontology, personal, privacy, semantic, survey, temporal",Capturing Semantic Relationships in Electronic Health Records Using Knowledge Graphs: An Implementation Using MIMIC III Dataset and GraphDB,"Aldughayfiq Bader, Ashfaq Farzeen, Jhanjhi N. Z., Humayun Mamoona",2023,reference-manager,10.3390/healthcare11121762,,,,,,Ontology development using Protégé to define entities and relationships in EHR data.,,,"How can the development and application of knowledge graphs using semantic technologies improve the analysis, integration, and clinical utility of heterogeneous electronic health record (EHR) data, particularly from the MIMIC III dataset, to enhance patient outcomes and healthcare quality?","The paper investigates whether knowledge graphs built from the MIMIC III dataset using GraphDB can effectively capture semantic relationships in electronic health records (EHRs). Using ontology mapping, RDF conversion, and SPARQL queries, the study finds that knowledge graphs improve EHR analysis and patient outcomes, though research gaps remain.","The research goal is to improve EHR data analysis by creating a knowledge graph from the MIMIC III dataset using ontology mapping and GraphDB; the approach enables efficient, accurate analysis, and the principal finding is that knowledge graphs effectively capture semantic relationships, supporting better clinical decision-making and patient outcomes.",No information available,1.000,exact_title
ammar_2021,Using a Personal Health Library–Enabled mHealth Recommender System for Self-Management of Diabetes Among Underserved Populations: Use Case for Knowledge Graphs and Linked Data,"Nariman Ammar, James E Bailey, Robert L Davis, Arash Shaban-Nejad",2021,Yes,SUPER,"This paper is of super relevancy as it proposes a Personal Health Library (PHL), which is conceptually identical to a Personal Knowledge Graph (PKG), and builds it on the decentralized Solid platform. This directly addresses the HDM project's core architectural principles of user data ownership, privacy, and heterogeneous data integration. The detailed use case for diabetes self-management provides a concrete example of the type of application the HDM aims to enable.","The key insight is the necessity of a patient-centric data model (the PHL/PKG) that gives users true ownership and control over their health data. The paper emphasizes that integrating data from various sources (EHRs, Observations of Daily Living, Social Determinants of Health) into a unified, semantically rich KG is essential for enabling personalized and effective mHealth interventions. The use of Solid for decentralization is a critical architectural choice.","The paper proposes a Personal Health Library (PHL) built on the decentralized Solid platform, using knowledge graphs to integrate diverse health data and deliver personalized recommendations for diabetes self-management.","This paper details the implementation of a mobile health (mHealth) intervention for diabetes self-management, powered by a Personal Health Library (PHL). The PHL, built on the decentralized Solid platform, acts as a secure, patient-controlled repository for integrating heterogeneous health data (EHRs, Observations of Daily Living, Social Determinants of Health). By representing this data as a Personal Knowledge Graph (PKG), the system can deliver tailored recommendations to users via an mHealth app, empowering them to take a more active role in their healthcare. The paper outlines the architecture, identifies key patient requirements, and presents a use case to demonstrate the system's functionality.","How can a Personal Health Library (PHL), incorporating both digital health data and contextual knowledge, be implemented to deliver tailored recommendations for improving self-care behaviors in diabetic adults?","The methodology involves: (1) A thematic assessment of patient requirements from literature. (2) The design of a PHL architecture using the Solid platform for decentralization and privacy. (3) The use of Semantic Web technologies (RDF, ontologies) to create a Personal Knowledge Graph (PKG) for each user. (4) The development of a prototype mHealth recommender system that queries the PKG to provide personalized interventions. (5) The paper also outlines plans for a formative evaluation and a pragmatic clinical trial.","The paper primarily presents a framework and a prototype design. The key ""finding"" is the successful conceptualization and architectural design of a PHL-enabled mHealth system that meets identified patient requirements for data ownership, integration, and privacy. It demonstrates the feasibility of using Solid and KGs to build such a system.","The primary outcome is the proposed PHL framework and the initial prototype design of the mHealth recommender system for diabetes self-management. It provides a comprehensive blueprint for building patient-centric, KG-powered health applications.","The paper itself is a proposal and initial design. The system has not yet undergone the planned formative evaluation or clinical trial. The practical challenges of large-scale deployment, user adoption, and the clinical effectiveness of the recommendations are not yet evaluated.","A Personal Health Library (PHL) built on a decentralized platform like Solid provides a powerful foundation for patient-centered care. By giving patients control over their integrated health data and using knowledge graphs to derive insights, such systems can empower patients and support clinicians in delivering more effective, personalized interventions.","The paper itself is a response to the gap in patient-centric data management. It implicitly points to the need for more research into: (1) large-scale clinical validation of such systems, (2) user-centered design methodologies for PHL interfaces, and (3) scalable methods for dynamic knowledge discovery and integration within personal health contexts.","The authors state that future work will focus on the full implementation of the end-to-end framework, including text summarization and knowledge mapping features. Crucially, they plan to conduct the formative evaluation and the pragmatic clinical trial to assess the usability and effectiveness of the intervention.","Key implementation insights include: (1) The use of the Solid platform for decentralized data storage and access control. (2) The representation of patient data as a Personal Knowledge Graph (PKG) using RDF and ontologies. (3) The separation of data from applications, allowing different apps to securely access the user's PHL. (4) The use of a RESTful API and SPARQL for querying the PKG. (5) The integration of various data sources, including EHRs, Observations of Daily Living (ODLs), and Social Determinants of Health (SDoH).",https://doi.org/10.2196/24738,10.2196/24738,"ai, children, federated, healthcare, heterogeneous, integration, knowledge-graph, machine-learning, ontology, pediatric, personal, privacy, semantic",Using a Personal Health Library–Enabled mHealth Recommender System for Self-Management of Diabetes Among Underserved Populations: Use Case for Knowledge Graphs and Linked Data,"Ammar Nariman, Bailey James E, Davis Robert L, Shaban-Nejad Arash",2021,reference-manager,10.2196/24738,,,,,,"User-centered design and formative evaluation: Iterative feedback from focus groups (patients, caregivers, clinicians, health education professionals) to assess usability, clinical, and educational content.",,,"How can a Personal Health Library (PHL) leveraging semantic technologies and federated Linked Data querying be designed and evaluated to integrate, manage, and support dynamic knowledge discovery from patient data while addressing usability, clinical, and educational requirements?","The paper aims to enhance physicians’ understanding of treatment recommendations’ applicability using the PHL platform, which leverages semantic technologies and Linked Open Data. Through user-centered design and formative evaluation, the study finds that PHL empowers patients and providers, supports knowledge sharing, and enables third-party application development.","The research goal is to help physicians understand the applicability of treatment recommendations by using the PHL platform, which leverages Linked Open Data, semantic annotations, and technologies like SPARQL and Solid; the principal finding is that these tools enable effective pattern discovery and knowledge capture for clinical practice.",,1.000,exact_title
amofa_2024,Blockchain-secure patient Digital Twin in healthcare using smart contracts,"Sandro Amofa, Qi Xia, Hu Xia, Isaac Amankona Obiri, Bonsu Adjei-Arthur, Jingcong Yang, Jianbin Gao",2024,Yes,SUPER,"This paper is of super relevancy as it directly addresses the security, privacy, and data management challenges of personal Digital Twins, which are core to the HDM project. The proposed architecture, which uses blockchain for data integrity and smart contracts for automated, policy-based access control, provides a robust framework for building a trustworthy, patient-centric system. This aligns perfectly with the HDM's focus on secure, heterogeneous data integration and user data ownership.","The key insight is that smart contracts can be used to automate and enforce access control policies for a patient's Digital Twin, creating a secure and programmable layer for managing sensitive health data. This approach, combined with a novel signcryption scheme (mIBSC) optimized for blockchain, provides a practical solution for ensuring data provenance, privacy, and integrity in a distributed healthcare ecosystem.","The paper proposes a blockchain-secured patient Digital Twin that uses smart contracts to automate and control access to the twin, ensuring data privacy and integrity through a novel cryptographic scheme.","This paper presents a framework for a blockchain-secured patient Digital Twin. The system uses smart contracts on the Ethereum blockchain to automate and mediate access to the Digital Twin, which is constructed from various data sources like Electronic Medical Records (EMRs) and Personal Health Records (PHRs). The authors propose a mathematical model for the Digital Twin and a novel Multi-receiver Identity-Based Signcryption (mIBSC) scheme to secure the data with a constant ciphertext size suitable for blockchain storage. The research addresses four key areas: access control, interaction, privacy, and security, and evaluates the proposed system in terms of network latency, smart contract execution costs, and data storage costs.","How can a patient's Digital Twin be secured using blockchain and smart contracts to guarantee access control, privacy, and data provenance, while automating its updates and interactions?","The methodology involves designing a three-layer architecture (Device, Blockchain, Application) and using the Ethereum blockchain with smart contracts to manage the Digital Twin. A novel Multi-receiver Identity-Based Signcryption (mIBSC) scheme is proposed to secure the data. The system's performance is evaluated based on latency, smart contract execution times, and storage costs.","The research demonstrates the feasibility of a blockchain-secured Digital Twin framework. The use of smart contracts provides a robust mechanism for automated, policy-based access control. The proposed mIBSC scheme is shown to be efficient for blockchain applications due to its constant-size ciphertext.","The primary outcome is the proposed framework for a blockchain-secure patient Digital Twin, which includes the system architecture, the smart contract design for access control and data management, and the custom mIBSC cryptographic scheme.","The evaluation is based on a prototype and does not involve a large-scale, real-world deployment with actual patient data. The paper focuses on the technical framework and does not deeply explore the ethical or legal implications of such a system.","The paper concludes that a blockchain-based Digital Twin, secured by smart contracts and appropriate cryptography, is a viable and powerful approach for managing patient health data securely and privately. This automated framework can improve data sharing, facilitate personalized medicine, and give patients more control over their health information.","The paper identifies a gap in the literature regarding robust security and privacy solutions for patient Digital Twins. It also highlights the need for cryptographic schemes that are efficient enough for practical blockchain implementation (e.g., constant ciphertext size).","Future work could involve applying the framework to a wider range of healthcare use cases, further optimizing the performance and scalability of the system, and conducting real-world clinical trials to validate its effectiveness.","Key implementation insights include: (1) The use of smart contracts to codify and automate access control policies. (2) The design of a multi-layered architecture that separates data sources, the blockchain layer, and applications. (3) The application of a custom signcryption scheme (mIBSC) tailored for the constraints of a blockchain environment. (4) The concept of representing the Digital Twin itself as a construct of interacting smart contracts.",https://doi.org/10.1371/journal.pone.0286120,10.1371/journal.pone.0286120,"ai, digital-twin, healthcare, heterogeneous, integration, llm, machine-learning, personal, privacy, semantic, survey",Blockchain-secure patient Digital Twin in healthcare using smart contracts,"Amofa Sandro, Xia Qi, Xia Hu, Obiri Isaac Amankona, Adjei-Arthur Bonsu, Yang Jingcong, Gao Jianbin",2024,reference-manager,10.1371/journal.pone.0286120,,,,,,"Multi-receiver Identity-Based Signcryption (mIBSC): Uses four algorithms (Setup, Extract, Signcrypt, Designcrypt) to securely share data with multiple receivers.",,,"How can a blockchain-secure patient digital twin using smart contracts ensure secure, private, and efficient personal health data sharing and access control in healthcare systems?","The paper investigates digital twin technology in healthcare, aiming to enhance secure patient data sharing. It introduces a mathematical model for patient Digital Twins and proposes a novel Multi-receiver Identity-Based Signcryption (mIBSC) scheme. Using blockchain and smart contracts, the study demonstrates improved security, privacy, and efficient data management.","The paper's main objective is to enable secure, privacy-preserving patient data sharing in healthcare using a blockchain-secure digital twin; it employs smart contracts and multi-receiver identity-based signcryption (mIBSC), and demonstrates reduced communication/computation costs and improved data integrity compared to existing frameworks.",No information available,1.000,exact_title
anderson_2016,Mind the Gap: Two Dissociable Mechanisms of Temporal Processing in the Auditory System,"Lucy A. Anderson, Jennifer F. Linden",2016,Yes,LOW,"This paper is of low relevancy. While it deals with ""temporal processing,"" it does so at a neurophysiological level (millisecond-scale auditory perception in mice), which is not applicable to the HDM project's focus on temporal knowledge graphs, heterogeneous data integration, or system architecture.","The key insight is that the brain's ability to process rapid sounds may rely on two distinct channels: one for detecting sound onsets and another for sound offsets. Deficits in temporal hearing, such as difficulty detecting brief gaps in noise, could stem from a specific failure in the offset-detection channel rather than a general 'sluggishness' of the auditory system.","The paper shows that difficulty in hearing brief gaps in noise can be caused by a specific problem in the brain's ability to process the *end* of a sound, not the beginning, suggesting separate brain circuits for 'on' and 'off' sound detection.","This study uses a mouse model with auditory processing deficits to investigate the neural basis of gap-in-noise detection. Through extracellular recordings in the auditory thalamus, the researchers found that these mice have a specific deficit in neural sensitivity to brief gaps, which is linked to reduced neural responses to sound offsets, while responses to sound onsets and other rapidly changing sounds remain normal. They propose a model with two separate channels—one for sound onsets and one for offsets—and show that weakening the offset channel in the model replicates their experimental findings. This suggests that gap-detection deficits can arise from a specific impairment of the sound-offset-sensitive channel, revealing a dissociation in how the brain processes the beginning and end of sounds.","What is the neural mechanism underlying deficits in auditory temporal processing, specifically the detection of brief gaps in noise?","The study used a mouse model of gap-detection deficits (ectopic BXSB/MpJ-Yaa mice). They performed in-vivo extracellular recordings from three subdivisions of the auditory thalamus in anesthetized mice. They presented various auditory stimuli, including gap-in-noise stimuli and click trains, and developed a phenomenological model to test their hypothesis about dissociable onset and offset channels.","The study found that: (1) Ectopic mice have a deficit in thalamic sensitivity to brief gaps in noise, specific to certain auditory pathways. (2) This deficit is not due to a general loss of temporal acuity, as responses to other rapid stimuli are normal. (3) The deficit is specifically linked to reduced neural activity following sound *offsets*, not onsets. (4) In control mice, offset-responsive neurons are exceptionally sensitive to brief gaps, and this sensitivity is lost in ectopic mice.",The primary outcome is the experimental evidence and a supporting computational model demonstrating the existence of two dissociable mechanisms for auditory temporal processing (onset-sensitive and offset-sensitive). It shows that deficits in gap detection can arise specifically from impairment of the offset-sensitive channel.,"The study was conducted on anesthetized mice, which might affect neural responses. The model is phenomenological and not a detailed, physiologically realistic model of the auditory pathway. The link between the cortical ectopias and the thalamic deficit is correlational, and the causal mechanism remains unclear.","The brain has separate mechanisms for processing the start and end of sounds. Deficits in auditory temporal acuity, like the inability to detect brief gaps in noise, can be caused by a specific problem with the brain's 'sound-off' detectors, rather than a general slowdown in auditory processing.","The paper points to the need to understand the precise origin of the offset-response deficit (e.g., brainstem, thalamus, or cortical feedback). The causal relationship between the cortical ectopias and the thalamic deficit is also an open research question.",Future work should focus on further experiments to explore the origin of the offset-response deficit and its relationship to the cortical ectopias.,"This paper is from a fundamental neuroscience domain and has no direct implementation insights for building software, data systems, or knowledge graphs. The concepts are too low-level and biological to be applicable to the HDM project.",https://doi.org/10.1523/jneurosci.1652-15.2016,10.1523/JNEUROSCI.1652-15.2016,"auditory-processing, mouse-model, neuroscience, temporal, thalamus",Mind the Gap: Two Dissociable Mechanisms of Temporal Processing in the Auditory System,"Anderson Lucy A., Linden Jennifer F.",2016,reference-manager,10.1523/jneurosci.1652-15.2016,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
anokhin_2024,AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents,"Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev",2024,Yes,SUPER,"This paper is of super relevancy because it proposes a novel architecture, AriGraph, for an LLM agent to build a dynamic world model by integrating semantic and episodic memory into a knowledge graph. This directly addresses the HDM project's need for a system that can learn from a user's experiences over time and structure that knowledge for reasoning and planning. The concept of an agent actively constructing its own KG from observations is a core principle for the HDM.","The key insight is that integrating both semantic (factual) and episodic (experiential) memory into a unified, dynamic knowledge graph allows an LLM agent to build a structured world model from scratch. This structured memory significantly outperforms unstructured memory representations (like RAG or summarization) in complex, interactive environments that require long-term reasoning and planning.","An LLM agent can learn a structured world model by building a knowledge graph that combines factual knowledge with personal experiences, enabling it to solve complex tasks more effectively than agents with unstructured memory.","This paper introduces AriGraph, a novel method where an LLM-based agent, named Ariadne, constructs and updates a memory graph that integrates both semantic (factual) and episodic (experiential) memories as it interacts with an environment. This approach is designed to overcome the limitations of unstructured memory in current LLM agents, which hinders complex reasoning and planning. The AriGraph architecture allows the agent to build a structured world model from scratch, which is shown to significantly outperform other memory methods (like full history, summarization, and RAG) and RL baselines in complex text-based games.","Can LLM-based agents learn a useful structured world model from scratch via interaction with an environment, and does this structured knowledge representation improve the retrieval of relevant facts and enable effective exploration?","The authors developed the AriGraph framework, where an LLM agent (Ariadne) extracts semantic triplets from textual observations to build a semantic KG. Episodic memory is captured by linking these triplets to the specific observation (episodic vertex) in which they occurred. The agent uses this memory graph for planning and decision-making in interactive environments (TextWorld, NetHack). The performance was evaluated against various memory baselines (full history, RAG, summarization, etc.) and RL agents.","The AriGraph agent (Ariadne) markedly outperforms other memory methods and strong RL baselines in complex interactive tasks. The structured memory enables the agent to effectively learn from its interactions, build a coherent world model, and solve tasks that are difficult even for human players. The approach also shows competitive performance on static multi-hop Q&A tasks.","The primary outcome is the AriGraph framework itself, a novel memory architecture that demonstrates how to effectively integrate semantic and episodic memory in a knowledge graph for LLM agents. The paper also presents the Ariadne agent as a proof-of-concept for this architecture.","The current approach is focused on text-based environments. The scalability of the graph construction and retrieval for very large, long-term interactions is not fully evaluated. The paper also notes that the quality of the graph construction depends on the capability of the LLM backbone.","The paper concludes that a knowledge graph world model that integrates both semantic and episodic memory is a powerful approach for building more capable LLM agents. This structured memory representation is crucial for enabling effective reasoning, planning, and exploration in complex, partially observable environments.",The paper implicitly points to the need for extending this approach to multi-modal environments (beyond text). It also highlights the need for more sophisticated graph search and retrieval methods for even larger and more complex memory graphs.,"The authors state that future work can focus on incorporating multi-modal observations, procedural memories (skills), and more advanced graph search methods into the AriGraph framework.",Key implementation insights include: (1) The dual structure of the memory graph with semantic vertices/edges and episodic vertices/edges. (2) The process of continuously updating the graph by extracting triplets from new observations and removing outdated knowledge. (3) The two-stage retrieval process (semantic search followed by episodic search) to find relevant information. (4) The use of hyperedges to connect multiple semantic triplets to a single episodic event.,https://arxiv.org/abs/2407.04363,10.48550/arXiv.2407.04363,"agent, ai, episodic-memory, knowledge-graph, llm, memory, reasoning, semantic-memory, temporal",,,,,,,,,,,,,,,,,,,
anzia_2018,Multimodal joint learning for personal knowledge base construction from Twitter-based lifelogs,"Yen An-Zia, Huang Hen-Hsenb, Chen Hsin-Hsia",2018,Yes,LOW,"This paper is of low relevancy. While it addresses personal knowledge base construction, its focus on extracting general life events (e.g., dining, visiting places) from Twitter is not aligned with the HDM project's core focus on integrating complex, heterogeneous personal data for deep, longitudinal analysis. The NLP methods for short, informal text are only a small part of the HDM's data integration challenge.","The key insight is that multimodal information (text and images) from social media can be jointly learned to detect and extract personal life events, even when they are expressed implicitly. This is useful for constructing a personal knowledge base from user-generated content.",The paper proposes a system to automatically extract personal life events from Twitter posts (text and images) to build a personal knowledge base for individuals.,"This paper presents a multimodal joint learning approach to extract personal life events from Twitter data (tweets and images). The system aims to identify both explicit and implicit life events, extract their components (subject, predicate, object, time), and map them to a structured personal knowledge base. The authors collected and annotated a dataset from 18 Twitter users and show that their system is effective in extracting these events, which could be used for applications like memory recall.",How can we leverage both visual and textual information from social media (Twitter) to automatically extract personal life events and construct a personal knowledge base for individuals?,"The authors propose a two-stage system. The first stage uses a multimodal joint learning neural network (BiLSTM) to detect if a tweet contains a life event and to recognize explicit and implicit event predicates. The second stage uses a BiLSTM-CRF model to extract the subject, object, and time for each event and performs frame semantic parsing to generate structured quadruples. The model is trained and evaluated on a custom-annotated dataset of tweets from 18 users.",The multimodal joint learning approach is effective for life event extraction from tweets. The model achieves high performance in detecting whether a tweet contains a life event and can recognize both explicit and implicit events. Visual information from images provides complementary cues that improve the recognition of implicit life events.,The primary outcome is a comprehensive system for extracting personal life events from Twitter data and constructing a personal knowledge base. The authors also released the annotated lifelog dataset.,"The dataset is limited to 18 Twitter users and is primarily in Chinese, which may limit generalizability. The system's performance is dependent on the quality of the underlying NLP tools (e.g., POS tagger) and the image captioning API. The mapping from natural language predicates to KB relations can be ambiguous.",The paper concludes that a multimodal joint learning approach is effective for extracting personal life events from social media data. The constructed personal knowledge bases are expected to be useful for applications like memory recall and living assistance.,"The paper highlights the challenge of handling the ambiguity in mapping natural language predicates to knowledge base relations. It also implicitly points to the need for more robust methods for handling noisy, informal user-generated text.","Future work could involve improving the accuracy of the event extraction, expanding the system to other social media platforms and languages, and developing more advanced applications on top of the constructed personal knowledge bases.","The two-stage architecture, separating event detection/predicate recognition from argument extraction, is a practical design pattern. The use of a multimodal approach, combining text and image features, is a key insight for handling social media data. The application of joint learning for related tasks is shown to be effective.",https://doi.org/10.1016/j.ipm.2019.102148,10.1016/j.ipm.2019.102148,"event-extraction, lifelogging, multimodal-learning, nlp, personal-knowledge-base, social-media, twitter",Multimodal joint learning for personal knowledge base construction from Twitter-based lifelogs,"Yen An-Zi, Huang Hen-Hsen, Chen Hsin-Hsi",2020,reference-manager,10.1016/j.ipm.2019.102148,,"The system performs similarly for users with many or few tweets, showing robustness even with limited data. Multimodal-MTL-BiLSTM achieves the best results across tasks. Explicit and implicit life events are both well captured, with users expressing locations explicitly and actions implicitly. Head word matching improves evaluation accuracy.",,,,"Joint learning approach: Used for life event detection, explicit life event recognition, and implicit life event recognition, comparing unimodal (text only) and multimodal (text and image) models.",,,How can life events be effectively extracted from tweets and represented as knowledge base facts using frame semantics to enable knowledge-based question answering and personal memory recall?,The paper aims to extract life events from tweets using frame semantics and convert natural language into knowledge base facts. The methodology involves multi-stage models for event detection and semantic parsing. Results show strong annotation agreement and effective extraction performance. The research enables applications like memory recall and living assistance.,The research goal is to extract life events from tweets and represent them as frame semantics and knowledge base facts; the approach involves a system for life event extraction and personal knowledge base construction; results show strong annotation agreement and F-scores up to 0.8594 for explicit subjects.,,1.000,exact_title
asprino_2022,Uncovering Values: Detecting Latent Moral Content from Natural Language with Explainable and Non-Trained Methods,"Luigi Asprino, Luana Bulla, Stefano De Giorgis, Aldo Gangemi, Ludovica Marinucci, Misael Mongiovi",2022,Yes,MEDIUM,"This paper is relevant because it explores using knowledge graphs for semantic extraction of nuanced concepts like moral values from text. This is applicable to the HDM project's goal of understanding a user's personal context, values, and sentiments from their data (e.g., journals, notes). While not directly about heterogeneous data integration, the explainable, frame-based approach could inform how the HDM system models and reasons about a user's personal worldview.","The key insight is that explainable, non-trained methods can achieve considerable performance in detecting complex, latent content like moral values, offering a transparent alternative to black-box supervised models.","This paper presents two approaches for detecting moral attitudes from natural language: a frame-based symbolic value detector using knowledge graphs and a zero-shot machine learning model without prior moral value training. The methods are tested on a corpus of tweets annotated according to Moral Foundation Theory, demonstrating that both can achieve considerable performance without the need for prior training.","This paper presents two approaches for detecting moral attitudes from natural language: a frame-based symbolic value detector using knowledge graphs and a zero-shot machine learning model without prior moral value training. The methods are tested on a corpus of tweets annotated according to Moral Foundation Theory, demonstrating that both can achieve considerable performance without the need for prior training.","How can moral attitudes be rapidly extracted from natural language to understand social interaction dynamics and individual cognitive dimensions, using explainable and non-trained methods?","The paper develops and compares two methods: (1) a frame-based symbolic value detector using knowledge graphs (FRED, Framester, ValueNet) and (2) a zero-shot machine learning model (BART-large fine-tuned on NLI and emotion detection). Both are tested on the Moral Foundation Twitter Corpus (MFTC).",Both the zero-shot and frame-based approaches achieve considerable performance (around 45% F1 score) without requiring prior training on moral value detection tasks. The frame-based approach offers the advantage of explainability by tracking the triggers for value detection.,"The development of two novel, non-trained methods for detecting moral content in text, demonstrating the feasibility of using both neural and symbolic approaches for this task.","The evaluation is limited to Twitter data, which has a fragmented syntax. The performance could be improved. The frame-based detector's performance can be affected by the quality of the knowledge graph generated from the input text.","The paper demonstrates the potential for using unsupervised, domain-independent methods to extract nuanced semantic meaning, like moral values, from natural language. It shows that both zero-shot and knowledge-graph-based approaches are viable alternatives to traditional supervised methods.",The paper doesn't explore combining the strengths of both the neural and symbolic approaches in a more integrated way. The evaluation is on a single dataset and could be expanded to other text types.,"Future work could explore the automatic discovery of knowledge patterns and their mappings, potentially drawing from research in analogical reasoning. They also mention the possibility of developing a run-time version of the pattern application mechanism.","The use of Framester and ValueNet provides a practical example of leveraging existing semantic web resources for a specific NLP task. The frame-based approach offers a transparent and explainable alternative to black-box models, which is a valuable consideration for systems like HDM where user trust is important.",https://aclanthology.org/2022.deelio-1.4/,10.18653/v1/2022.deelio-1.4,"explainable-ai, knowledge-graph, moral-values, natural-language-processing, semantic-extraction, zero-shot-learning",Uncovering Values: Detecting Latent Moral Content from Natural Language with Explainable and Non-Trained Methods,"Asprino Luigi, De Giorgis Stefano, Gangemi Aldo, Bulla Luana, Marinucci Ludovica, Mongiovì Misael",2022,reference-manager,,,"The paper presents two novel, non-trained methods—zero-shot learning and a frame-based unsupervised approach—to detect latent moral content in text using Moral Foundation Theory. Key insights include enhanced explainability, domain independence, and future plans to refine models for better handling complex moral values and sentence structures.",,,,"Unsupervised frame-based approach: Uses knowledge graphs for exploring latent moral and semantic content, including disambiguation of lexical units, frame evocation, and knowledge integration.",,,"How can unsupervised, frame-based methods leveraging knowledge graphs and Moral Foundation Theory be used to transparently and effectively detect latent moral values in natural language, particularly in Twitter data, without relying on predefined term sets or supervised training?","The paper aims to detect latent moral content in natural language using two domain-independent, unsupervised methods: a frame-based approach using knowledge graphs and a zero-shot model based on Natural Language Inference. Tested on the Moral Foundation Twitter Corpus, both methods achieved strong results without prior training, supporting explainability and versatility.","The research goal is to detect latent moral values in natural language using a frame-based symbolic value detector and a zero-shot learning approach; both unsupervised, domain-independent methods achieve notable results on the Moral Foundation Twitter Corpus without prior training, demonstrating explainability and versatility.",,1.000,exact_title
asprino_2023,Knowledge Graph Construction with a Façade: A Unified Method to Access Heterogeneous Data Sources on the Web,"Luigi Asprino, Enrico Daga, Aldo Gangemi, Paul Mulholland",2023,Yes,SUPER,"This paper is of super relevancy to the HDM project. It directly addresses the core challenge of integrating heterogeneous data sources by proposing Facade-X, a unified meta-model for accessing and transforming diverse data formats (CSV, JSON, XML, etc.) into RDF. This approach, implemented in the SPARQL Anything tool, provides a practical and scalable solution for the HDM's data ingestion pipeline, allowing seamless integration of personal data from various sources into a personal knowledge graph.","The key insight is that it's possible to decouple the structural transformation of data from the semantic mapping by using a unified meta-model (Facade-X) as a 'façade'. This allows KG engineers to interact with heterogeneous data sources using only their existing expertise in RDF and SPARQL, significantly simplifying the KGC process and reducing the complexity of data processing pipelines.","This paper introduces Facade-X, a meta-model for constructing knowledge graphs from heterogeneous data sources on the Web. Implemented in a system called SPARQL Anything, this approach provides a unified method for accessing and transforming various data formats (like CSV, JSON, and XML) into RDF. By acting as a 'façade', the meta-model simplifies the knowledge graph construction process, allowing developers to use SPARQL for both data inspection and transformation, thus streamlining data integration.",How can we create a unified and simplified method for knowledge graph construction that allows KG engineers to access and transform heterogeneous data sources on the Web using their existing expertise in RDF and SPARQL?,"The paper proposes Facade-X, a meta-model based on a set of structural design patterns (containment, ordering, key-values, typing) that can represent data from any format expressible in BNF syntax and relational databases. This meta-model is implemented in SPARQL Anything, a system that uses a virtual SPARQL endpoint to transform non-RDF data into RDF on the fly, making it queryable with standard SPARQL.","The Facade-X meta-model is proven to be generic enough to cover a wide range of structured data formats. The SPARQL Anything implementation demonstrates a significant reduction in the cognitive complexity of mappings compared to state-of-the-art tools like RML and ShExML. Performance evaluations show that the approach is viable, with a triple-filtering strategy offering significant improvements.","The primary outcome is a novel, theoretically sound, and practically implemented approach to knowledge graph construction that simplifies the integration of heterogeneous data. This includes the Facade-X meta-model and the SPARQL Anything tool, which provides a unified interface for querying diverse data formats as RDF.","The performance of the naive implementation can be slow, although the triple-filtering strategy shows significant improvements. The approach relies on the 'façade engineer' to design and map new formats, which could be a bottleneck if a wide variety of new formats need to be supported.","The paper provides a powerful demonstration that a unified meta-model can dramatically simplify the process of knowledge graph construction from heterogeneous sources. By abstracting away the complexities of individual data formats, the 'façade' approach empowers developers to focus on the semantic aspects of data integration, using familiar tools like SPARQL.",The paper identifies the need for further performance optimization and more extensive usability testing with the user community. It also opens up the challenge of extending the Facade-X meta-model to support an even wider range of data formats and more complex data structures.,"Future work includes further performance improvements, the development of more sophisticated query optimization techniques for the virtual SPARQL endpoint, and the extension of the Facade-X meta-model to cover more data formats. The authors also plan to engage further with the user community to improve the usability of the SPARQL Anything tool.","The paper offers a highly practical implementation insight for the HDM project: use SPARQL Anything as a core component of the data ingestion pipeline. This would allow the HDM to easily integrate data from a user's various personal sources (e.g., CSV exports from fitness apps, JSON from social media, etc.) into their personal knowledge graph without needing to write custom parsers for each format.",https://dl.acm.org/doi/10.1145/3555312,10.1145/3555312,"Knowledge Graph Construction, Heterogeneous Data, Data Integration, RDF, SPARQL, Meta-model, Facade-X, Semantic Web","data-integration, façade-pattern, heterogeneous-data, knowledge-graphs, schema-evolution, temporal-consistency, web-data",,,,,,,,,,,,,,,,,,,
azevedo_2023,A Polystore Architecture Using Knowledge Graphs to Support Queries on Heterogeneous Data Stores,"Leonardo Guerreiro Azevedo, Renan Francisco Santos Souza, Elton F. de S. Soares, Raphael M. Thiago, Julio Cesar Cardoso Tesolin, Anna C. Oliveira, Marcio Ferreira Moreno",2023,Yes,SUPER,"This paper is of super relevancy as it proposes a complete polystore architecture, HKPoly, designed to query heterogeneous data stores through a unified Knowledge Graph-based global schema. This directly addresses the HDM project's core challenge of integrating disparate personal data sources. The architecture's use of provenance to create explicit links between data fragments and its focus on reducing query complexity for the end-user provide a strong theoretical and practical foundation for the HDM system design, particularly for the upstream data processing and integration layer.","The key insight is the use of a Knowledge Graph not just as a data model, but as a comprehensive meta-layer that stores the global schema, local schemas, mappings, and provenance data. This allows the system to dynamically generate queries to underlying heterogeneous sources (via something like PostgreSQL FDWs) while presenting a simple, unified view to the user, effectively abstracting away the complexity of data location, format, and linkage.","The paper presents HKPoly, a polystore architecture that uses a Knowledge Graph to create a unified query layer over different types of databases (SQL, NoSQL, etc.). It uses provenance data to automatically link related information across these databases, making it much simpler for users to query complex, fragmented data.","This paper tackles the challenge of querying heterogeneous data residing in different, unlinked data stores. The authors propose a federated database architecture, HKPoly, which provides a single global conceptual schema to users. This schema, represented as a Knowledge Graph, encapsulates data heterogeneity, location, and linkage. The system uses meta-models for the global and local schemas, mappings between them, and captures provenance data from workflows to create explicit links between data. The architecture was implemented as a polystore service and evaluated in an Oil & Gas industry scenario, showing it could reduce query complexity by half with a manageable performance overhead (under 30%).",How to query data that are not explicitly connected residing on heterogeneous data stores?,"The authors propose a polystore architecture (HKPoly) based on the Mediator/Wrapper MDBS pattern. They use a Knowledge Graph (implemented with Hyperknowledge) to store a global conceptual schema, local schemas for each data source, and mappings between them. Data linkage is achieved by capturing workflow provenance using ProvLake. The architecture is implemented as a RESTful service and evaluated by comparing its query complexity (for the user) and query performance (for the database) against a standard PostgreSQL Foreign Data Wrapper (FDW) setup in a simulated Oil & Gas use case.","The proposed architecture allows for writing queries that are more than two times less complex for the user compared to a standard relational multidatabase system (PostgreSQL FDW). The trade-off is a performance overhead in query processing time that does not exceed 30%, which the authors deem acceptable.","The primary outcome is the HKPoly architecture itself, a viable polystore system that successfully uses a Knowledge Graph and provenance to provide a unified, simplified query interface over heterogeneous data stores.","The query processing time, while deemed acceptable, still has an overhead of up to 30% compared to a direct FDW implementation, indicating a need for further optimization. The complexity of setting up the GCS, LCS, and mappings relies on a Knowledge Engineer, which could be a bottleneck.","The paper concludes that the proposed polystore architecture, HKPoly, is a valid and useful approach for querying heterogeneous data stores. By using a Knowledge Graph for schema and provenance management, it significantly reduces the cognitive load on users writing queries, making integrated data access more feasible, with an acceptable performance trade-off.",The paper highlights the need for further research into query optimization for such polystore systems to reduce the performance overhead. Automating the creation of schemas and mappings is another area for future work.,"Future work includes improving query processing performance, further investigation into query optimization techniques, and potentially automating parts of the schema and mapping creation process.","A key insight is the practical use of PostgreSQL Foreign Data Wrappers (FDW) as the ""last mile"" connector to the underlying data stores. This is a pragmatic approach that leverages existing, robust technology. The use of a Knowledge Graph to store all the metadata (schemas, mappings, provenance) in a queryable format is the central implementation pattern that enables the entire system. The idea of using HK's `Context` node to modularize the knowledge is also a useful organizational pattern.",https://doi.org/10.1007/s00778-017-0474-5,10.1007/s00778-017-0474-5,"data-integration, federated-query, heterogeneous-data, knowledge-graph, mediator-wrapper, polystore, provenance, schema-mapping",A PolyStore Architecture Using Knowledge Graphs to Support Queries on Heterogeneous Data Stores,"Souza Renan Francisco Santos, Azevedo Leonardo Guerreiro, Tesolin Julio Cesar Cardoso, Oliveira Anna C., Soares Elton F. de S., Thiago Raphael M., Moreno Marcio Ferreira",2024,reference-manager,,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
bai_2023,Membership Inference Attacks and Defenses in Federated Learning: A Survey,"Li Bai, Haibo Hu, Qingqing Ye, Haoyang Li, Leixia Wang, Jianliang Xu",2023,Yes,MEDIUM,"This paper is of medium relevancy. While not directly focused on heterogeneous data integration or temporal architecture, it provides a comprehensive survey of privacy risks (Membership Inference Attacks) in Federated Learning. As the HDM project will handle sensitive personal data in a distributed manner, understanding these attack vectors and their defenses (like secure aggregation and differential privacy) is crucial for designing a secure and privacy-preserving system architecture.","The key insight is that Federated Learning, despite its privacy-preserving design, is highly vulnerable to Membership Inference Attacks (MIAs). The paper systematically categorizes these attacks (update-based vs. trend-based) and defenses, highlighting that the decentralized nature of FL creates unique attack surfaces (e.g., malicious clients, access to historical models) that differ significantly from centralized learning environments.",This paper provides a comprehensive survey of Membership Inference Attacks (MIAs) and their corresponding defenses within the context of Federated Learning (FL).,"This paper provides a comprehensive survey of Membership Inference Attacks (MIAs) and their corresponding defenses within the context of Federated Learning (FL). It introduces a taxonomy for both attacks and defenses, systematically reviewing existing literature. The authors highlight the unique privacy vulnerabilities in FL, where adversaries can be insiders (server or clients) and can exploit model updates and convergence trends to determine if a specific data record was used in training.","What are the unique membership inference attack surfaces in Federated Learning, and what are the state-of-the-art defense mechanisms to mitigate them?","The authors conduct a systematic literature review, categorizing existing research on MIAs in Federated Learning. They create a taxonomy for attacks (update-based and trend-based) and defenses (partial sharing, secure aggregation, noise perturbation, anomaly detection). The paper analyzes the strengths and weaknesses of each approach and compares them to attacks and defenses in centralized learning settings.","The survey reveals that FL is vulnerable to powerful MIAs from insiders (server or other clients) who can exploit access to model gradients, parameters, and historical versions. It identifies two main attack vectors: update-based attacks that analyze model parameters/gradients at specific points in time, and trend-based attacks that analyze the trajectory of indicators (like loss or prediction confidence) over time. The paper also systematically reviews defenses, noting their respective trade-offs between privacy, utility, and computational cost.",The primary outcome is a comprehensive and structured overview of the state-of-the-art in Membership Inference Attacks and defenses specifically for Federated Learning environments. This provides a clear roadmap for researchers and practitioners to understand the privacy risks and available countermeasures.,"As a survey, the paper synthesizes existing work and does not propose new attack or defense methods. The rapid evolution of the field means new techniques may have emerged since its publication.","Federated Learning is not inherently private. A deep understanding of the specific attack vectors, such as those exploiting model updates and convergence trends, is essential for designing robust, privacy-preserving distributed machine learning systems. Defenses must be carefully chosen based on the specific threat model and the acceptable trade-offs between privacy and model utility.","The paper identifies the need for more research into robust and efficient defense mechanisms that can withstand sophisticated, active attacks from malicious insiders. It also points to the need for better theoretical understanding of the privacy-utility trade-offs for different defense strategies in the FL context.","Future research should focus on developing more advanced and computationally efficient defense mechanisms, particularly against active and colluding adversaries. There is also a need for more comprehensive benchmarks to evaluate the effectiveness of different defense strategies under various FL scenarios.","The paper provides crucial implementation insights for the HDM project by detailing specific defense mechanisms. For example, it discusses the use of Secure Multi-party Computation (SMC) and Homomorphic Encryption (HE) for secure aggregation, and the application of Differential Privacy to add noise to model updates. These are all practical techniques that can be considered when designing the HDM's privacy architecture.",https://doi.org/10.1109/nana53684.2021.00062,10.1109/NaNA53684.2021.00062,"differential-privacy, federated-learning, membership-inference-attack, privacy, secure-aggregation, security, survey",Membership Inference Attacks and Defenses in Federated Learning: A Survey,"Bai Li, Hu Haibo, Ye Qingqing, Li Haoyang, Wang Leixia, Xu Jianliang",2024,reference-manager,10.1145/3704633,,,,,,Unified evaluation benchmark: Proposes a standardized framework to assess the effectiveness of defense mechanisms against membership inference attacks (MIAs).,,,"How can membership inference attacks (MIAs) and their defenses be systematically evaluated and improved within federated learning (FL) to enhance privacy, utility, and robustness against evolving threats?","The paper surveys Membership Inference Attacks (MIAs) and defenses in Federated Learning (FL). It categorizes MIAs as update-based or trend-based, reviews defense mechanisms like partial sharing and noise perturbation, and highlights the need for unified benchmarks. The study concludes with future research directions to enhance FL privacy and security.",The research goal is to survey membership inference attacks (MIAs) and defenses in federated learning (FL); the approach categorizes MIAs into update-based and trend-based types and reviews defense strategies; the principal finding is a comprehensive taxonomy and identification of research gaps for enhancing FL privacy and security.,,1.000,exact_title
balog_2019,Personal Knowledge Graphs: A Research Agenda,"Krisztian Balog, Tom Kenter",2019,Yes,SUPER,"This is a foundational paper that defines the concept of Personal Knowledge Graphs (PKGs) and outlines a research agenda. It's highly relevant to the HDM project as it directly addresses the core concepts of personal data management, the unique characteristics of PKGs (user-centric, sparse, temporal), and the challenges in their construction and use. This paper provides the ""why"" and ""what"" for the HDM project's ""how"".","The key insight is the distinction between *personal* KGs and *personalized* KGs. A personalized KG is a filtered/customized view of a general KG, whereas a personal KG contains entities that may not exist in any public KG (e.g., ""my mom's dentist""). This highlights the need for a fundamentally different approach to KG construction and maintenance, one that is user-centric and can handle sparse, ephemeral, and private data.","This position paper defines Personal Knowledge Graphs (PKGs) as user-centric knowledge bases containing entities of personal importance, outlines the key challenges in their construction (representation, entity linking, population) and use, and proposes a research agenda for the field.","The authors introduce the concept of a Personal Knowledge Graph (PKG) as a resource of structured information about entities personally related to a user. They differentiate PKGs from general-purpose KGs by three key aspects: (1) they include entities of personal interest, (2) they have a ""spiderweb"" layout with the user at the center, and (3) they are inherently integrated with external data sources. The paper identifies and discusses four main problem areas: Knowledge Representation, Semantic Annotation of Text, Population and Maintenance, and Integration with External Sources, formulating specific research questions for each.","What are the fundamental challenges and research directions for creating, maintaining, and utilizing Personal Knowledge Graphs?","This is a position paper and a research agenda, so the methodology is a conceptual analysis and a synthesis of existing work to define a new research area. It identifies key problems and formulates research questions.","The paper's key ""finding"" is the articulation of the unique properties and challenges of PKGs. It establishes that PKGs require different approaches for knowledge representation (handling sparse and short-lived relations), entity linking (dealing with entities with no digital footprint), population (requiring automatic, user-in-the-loop methods), and integration (continuous, two-way synchronization).","The primary outcome is the definition of a research agenda for Personal Knowledge Graphs, providing a foundational framework for future work in this area. It clearly separates PKGs as a distinct research subfield.","As a position paper, it does not offer concrete solutions or implementations. It raises questions rather than answering them. The authors acknowledge that creating large-scale, open datasets for PKG research is a significant challenge due to privacy concerns.","The paper concludes by emphasizing the need for a coordinated research effort to address the challenges of PKGs, which are seen as a foundational component for truly personal intelligent assistants and other personalized services.","The paper itself is a map of research gaps. Key gaps identified include: how to represent sparse and temporal personal knowledge, how to perform entity linking for ""long-tail"" personal entities, how to automatically populate and maintain PKGs with user-in-the-loop verification, and how to manage continuous, two-way integration with external sources.","The entire paper is a call for future work, structured around the research questions posed for each of the four problem areas.","The paper provides high-level implementation insights. The ""spiderweb"" architecture with the user at the center is a core design principle. The need for handling sparse data and short-lived relations suggests that the underlying data model must be flexible. The requirement for user-in-the-loop verification points to the need for interactive and explainable KG management tools.",https://doi.org/10.1145/3341981.3344241,10.1145/3341981.3344241,"data-integration, entity-linking, knowledge-representation, personal-information-management, personal-knowledge-graph, research-agenda, semantic-web",Personal Health Knowledge Graphs for Patients,"Rastogi Nidhi, Zaki Mohammed J.",2020,reference-manager,,,"Implementation Insights highlight that most approaches use brute force or static methods to create Personal Health Knowledge Graphs (PHKG), often limited by device resources and lack of dynamic updating. New insights reveal the need for hybrid, collaborative, and scalable PHKG construction, addressing privacy, data integration, and validation challenges.",,,,Literature review and critique of Knowledge Graph (KG) approaches for extracting personal context from patient data.,,,"How can Personal Health Knowledge Graphs (PHKGs) be effectively generated, represented, and integrated with existing knowledge bases to provide personalized health recommendations for patients, while addressing challenges related to data heterogeneity, scalability, validation, and patient privacy?","The paper reviews and critiques approaches for extracting personal context from patient data using small-sized Personal Health Knowledge Graphs (PHKGs). It discusses methods for generating PHKGs, highlights challenges like scalability and integration, and concludes that further research is needed to address validation, representation, and technical limitations for effective personalized health recommendations.","The paper's main objective is to review and critique methods for extracting personal context from patient data using small-sized Personalized Health Knowledge Graphs (PHKGs); it highlights brute-force and dynamic graph generation approaches, concluding that challenges remain in scalability, validation, and effective personal health recommendations.",,0.707,fuzzy_title
banking_2022,Incremental Analysis of Legacy Applica4ons Using Knowledge Graphs for Applica4on Moderniza4on,"Saravanan Krishnan, Alex Mathai, Amith Singhee, Atul Kumar, Shivali Agarwal, Keerthi Narayan Raghunath, David Wenk",2022,Yes,LOW,"The paper focuses on using knowledge graphs for legacy software modernization, which is not the core focus of the HDM project. However, the approach of using a KG to model and analyze complex systems is tangentially relevant.","The key insight is that a knowledge graph can serve as a powerful abstraction layer for understanding and analyzing large, complex legacy codebases. By representing code artifacts (programs, transactions, tables) and their dependencies as a KG, it becomes possible to perform incremental analysis, identify logical boundaries, and plan modernization efforts without getting lost in the low-level code details.","The paper presents a tool that uses a knowledge graph to analyze large legacy software systems, allowing experts to incrementally define and analyze parts of the system for modernization.","This paper presents a so6ware system analysis tool that allows a subject ma=er expert (SME) or system architect to analyze a large so6ware system incrementally. We analyze the source code and other arGfacts (such as data schema) to create a knowledge graph using a customizable ontology/schema. EnGGes and relaGons in our ontology can be defined for any combinaGon of programming languages and plaVorms. Using this knowledge graph, the analyst can then define logical boundaries around dependent EnGGes (e.g. Programs, TransacGons, Database Tables etc.). Our tool then presents different views showcasing the dependencies from the newly defined boundary to/from the other logical groups of the system. This exercise is repeated interacGvely to 1) IdenGfy the EnGGes and groupings of interest for a modernizaGon task and 2) Understand how a change in one part of the system may affect the other parts. To validate the efficacy of our tool, we provide an iniGal study of our system on two client applicaGons.",How can a large legacy software system be analyzed incrementally to support its modernization?,"The authors developed a software analysis tool that: 1) Uses a staGc analyzer (ADDI) to parse legacy source code. 2) Creates a knowledge graph in a Neo4j database using a custom, language-agnosGc ontology to represent code arGfacts and their relaGonships. 3) Allows a user (SME/architect) to interacGvely define ""increments"" (logical groups of arGfacts) and analyzes the dependencies (inside-out and outside-in edges) between the increment and the rest of the system.","The knowledge graph approach allows for an effective incremental analysis of complex legacy systems. It successfully abstracts away the complexity of the underlying code, enabling SMEs to identify logical boundaries and dependencies for modernization. The tool was validated on two client applications, showing a 20% increase in productivity.","The primary outcome is the tool itself, which provides a practical solution for the incremental analysis of legacy applications using knowledge graphs.",The current tool relies on staGc analysis. The quality of the analysis depends on the completeness of the staGc analyzer and the richness of the ontology defined by SMEs.,The paper concludes that using a knowledge graph for incremental analysis is a beneficial approach for modernizing legacy applications. It provides a structured way to understand complex dependencies and plan modernization efforts effectively.,"The paper suggests that future work should go beyond staGc analysis to include insights from data within the applicaGon (e.g., tables) and from operaGonal logs.","Future work includes understanding the data of the applicaGon (e.g., tables) and extracGng insights from operaGonal logs to enrich the knowledge graph.","A key implementation insight is the use of a language-agnosGc ontology, which makes the approach extensible to different legacy systems. Using a graph database like Neo4j allows for efficient traversal and analysis of the complex dependencies within the software system. The concept of ""increments"" with ""inside-out"" and ""outside-in"" dependency analysis is a practical pa=ern for managing the complexity of modernizaGon projects.",https://doi.org/10.1145/3493700.3493735,10.1145/3493700.3493735,"knowledge-graph, legacy-modernization, ontology, software-engineering, static-analysis",Incremental Analysis of Legacy Applications Using Knowledge Graphs for Application Modernization,"Krishnan Saravanan, Mathai Alex, Singhee Amith, Kumar Atul, Agarwal Shivali, Raghunath Keerthi Narayan, Wenk David",2022,reference-manager,10.1145/3493700.3493735,,,,,,"Static analysis of legacy source code to extract information, stored in an MS-SQL database.",,,"How can incremental analysis using knowledge graphs assist subject matter experts and architects in systematically identifying, isolating, and modernizing relevant portions of large legacy application codebases?","The paper presents a tool for incremental analysis of legacy software using knowledge graphs. The main objective is to help experts modernize large codebases by defining logical boundaries and dependencies. The methodology combines static analysis, knowledge graph construction, and iterative increment creation. Results show improved focus and efficiency in modernization tasks.","The research goal is to aid legacy application modernization by enabling subject matter experts to incrementally analyze large software systems; the approach uses static analysis and a customizable, language-agnostic knowledge graph; results show effective identification and isolation of relevant code portions for modernization tasks.",,0.945,fuzzy_title
bellomarini_2024a,Privacy-Preserving Synthetically Augmented Knowledge Graphs with Semantic Utility,"Luigi Bellomarini, Costanza Catalano, Andrea Coletta, Michela Iezzi, Pierangela Samarati",2024,Yes,HIGH,"This paper is highly relevant because it directly tackles the privacy concerns inherent in managing and sharing personal knowledge graphs. The HDM project needs robust privacy-preserving mechanisms, and this paper's focus on structural anonymization, protecting against re-identification attacks that exploit derived knowledge (reasoning), and maintaining semantic utility is directly applicable.","The key insight is that traditional graph anonymization techniques are insufficient for Knowledge Graphs because they don't account for new knowledge that can be derived through reasoning. An attacker can use these derived facts to break the anonymity. The paper introduces a privacy model ((k, x)-isomorphism anonymization) that explicitly considers this derived knowledge, ensuring a much stronger privacy guarantee.","This paper proposes a novel framework for sharing Knowledge Graphs while preserving privacy. It introduces a structural anonymization technique that synthetically augments the KG to prevent re-identification attacks, even when an attacker can use reasoning to derive new facts. The framework includes a new privacy measure that accounts for this derived knowledge and a utility metric to ensure the anonymized graph remains useful for downstream tasks.","How can knowledge graphs be shared while protecting sensitive information and maintaining semantic utility, especially when new knowledge can be derived through reasoning?","The authors propose a novel structural anonymization methodology based on (k, x)-isomorphism, which ensures that for any subgraph of size x, there are at least k-1 other structurally indistinguishable subgraphs, even after accounting for derived edges. They introduce two algorithms, KLONE and KGUARD, to achieve this. The approach is evaluated on synthetic and real-world datasets, measuring both privacy (δ-anonymity) and utility (Jaccard similarity of query results).","The proposed methods, KLONE and KGUARD, achieve perfect δ-anonymity (100% of subgraphs are not uniquely identifiable), significantly outperforming existing graph anonymization techniques that don't consider derived knowledge (which can leave up to 40% of subgraphs vulnerable). KGUARD is shown to be more efficient, adding fewer synthetic nodes and edges while preserving higher utility.","The primary outcome is a novel, robust framework for privacy-preserving KG sharing that considers the unique threat posed by logical reasoning. This includes the (k, x)-isomorphism privacy definition and two practical algorithms (KLONE and KGUARD) to implement it.","The proposed algorithms can have exponential worst-case complexity, although they perform well empirically. The paper focuses on structural anonymization and does not deeply explore the trade-offs with other privacy techniques like differential privacy. The utility metric is based on a predefined set of queries, which might not capture all possible uses of the KG.","Existing graph anonymization techniques are not sufficient for Knowledge Graphs. To ensure privacy, one must account for the new facts that can be inferred through reasoning. Structural anonymization through synthetic graph augmentation is a viable approach to achieve strong privacy guarantees while maintaining the utility of the KG for specific business tasks.","The paper identifies the need for more efficient anonymization algorithms, especially for very large graphs. It also suggests that future work could explore more complex diversity requirements beyond just node degrees and labels.","Future work includes investigating the split & merge procedure to speed up computation, and extending the diversity requirements beyond vertex labels and relationships.","The paper provides two concrete algorithms, KLONE and KGUARD, for implementing privacy-preserving KG augmentation. The concept of using a utility metric based on the Jaccard similarity of query results is a practical way to measure the usefulness of the anonymized graph. The idea of bucketing isomorphic subgraphs (in KGUARD) is a key technique for reducing the number of required modifications.",https://arxiv.org/abs/2410.12418,10.48550/arXiv.2410.12418,"Privacy-Preserving, Knowledge Graphs, Synthetic Data, Anonymization, Semantic Utility, Reasoning","data-integration, knowledge-graph",Privacy-Preserving Synthetically Augmented Knowledge Graphs with Semantic Utility,"Bellomarini Luigi, Catalano Costanza, Coletta Andrea, Iezzi Michela, Samarati Pierangela",2024,reference-manager,,,,,,,"(k,x)-isomorphism anonymization: A structural anonymization method ensuring each subgraph of x vertices has k−1 structurally indistinguishable counterparts with diverse sensitive attributes.",,,"How can knowledge graphs be anonymized to prevent re-identification attacks that exploit derived knowledge, while preserving business semantics, data utility, and sensitive attribute diversity?","This paper introduces a new structural anonymization method for knowledge graphs (KGs) called (k,x)-isomorphism anonymization, aiming to prevent re-identification while preserving data utility. Two algorithms, KLONE and KGUARD, are proposed and evaluated, showing improved privacy protection with controlled utility loss on real-world datasets.","The research goal is to prevent re-identification in knowledge graphs (KGs) while preserving utility; the approach introduces (k,x)-isomorphism anonymization and two algorithms (KLONE, KGUARD) to generate synthetic KGs; results show improved privacy and utility compared to existing methods.",,1.000,exact_title
beltran_2023,"ArticleCo-Design, Development, and Evaluation of a Health Monitoring Tool Using Smartwatch Data: A Proof-of-Concept Study","Ruhi Kiran Bajaj, Rebecca Mary Meiring, Fernando Beltran",2023,Yes,LOW,"This paper is tangentially related. It focuses on the front-end application and usability aspects of using personal health data (from smartwatches) for clinical monitoring, rather than the back-end challenges of heterogeneous data integration, which is the core focus of the HDM project. However, it provides valuable insights into the user (HCP) requirements for such systems.","The key insight is the critical importance of the co-design process with healthcare professionals (HCPs) to ensure the clinical utility and adoption of health monitoring tools. Simply providing raw data is not enough; tools must be designed to fit into clinical workflows and reduce, not increase, the workload of HCPs.","This study details the co-design, development, and evaluation of a web-based health monitoring tool that uses machine learning to detect anomalies in smartwatch data. The prototype was designed with input from healthcare professionals (HCPs) and evaluated for its usability. The results show that while HCPs see the potential, successful clinical integration requires careful design to meet their specific needs and workflow constraints.",How can a health monitoring tool using smartwatch data be effectively designed and developed to support healthcare professionals in clinical decision-making?,The study employed a three-phase Design Science Research (DSR) methodology: (1) A co-design phase where requirements were gathered from eight HCPs via an online survey. (2) A development phase where a web-based prototype was built using a public smartwatch dataset (PMData) and a clustering-based machine learning algorithm (from the PyCaret library) for anomaly detection. (3) An evaluation phase where the HCPs assessed the prototype's usability using the mHealth App Usability Questionnaire (MAUQ).,"The co-design process successfully identified key HCP requirements, such as the importance of heart rate data and the preference for graphical summaries. The resulting prototype received positive usability scores from over 60% of the HCPs, particularly for its ease of use and interface design. The study also found that HCPs would prefer a workflow where healthcare administrators first review the data to reduce the clinicians' workload.",The primary outcome is a proof-of-concept web application that demonstrates the feasibility of using smartwatch data and machine learning to create a health monitoring tool for HCPs. The study also provides a set of design guidelines and user requirements for future development in this area.,"The study has a small sample size of HCPs, which may not be representative. The machine learning algorithm used was a basic example and was not clinically validated. The study also did not include the perspectives of patients.","The study concludes that integrating smartwatch data into clinical care is feasible and potentially beneficial, but its success is highly dependent on a user-centered, co-design approach that involves HCPs from the beginning. The tool must be designed to be intuitive and to streamline, rather than complicate, the clinical workflow.",The paper highlights the need for larger-scale studies with more diverse participants (both HCPs and patients). There is also a significant gap in the clinical validation of anomaly detection algorithms for smartwatch data and in the development of standardized methods for integrating this data into EMRs.,"Future work includes expanding the prototype to incorporate more health data types (e.g., blood pressure, ECG), testing it with data from various smartwatch models, and conducting a real-world deployment study. Further research is also needed on reimbursement models for using smartwatch data in clinical practice.","A key implementation insight is the value of using a co-design approach to gather user requirements before development. The use of an open-source, low-code machine learning library like PyCaret can accelerate the development of the data analysis component. The suggestion of a tiered review process (with administrators doing initial screening) is a practical workflow consideration for managing HCP workload.",https://doi.org/10.3390/fi15030111,10.3390/fi15030111,"Health Monitoring, Smartwatch, Machine Learning, Anomaly Detection, Co-design, Design Science, Usability Study, Healthcare","data-integration, healthcare, knowledge-graph",,,,,,,,,,,,,,,,,,,
bendiken_2024,KNOW–A Real-World Ontology for Knowledge Capture with Large Language Models,Arto Bendiken,2024,Yes,MEDIUM,"This paper is of medium relevancy. It proposes a new ontology (KNOW) specifically designed for capturing everyday knowledge to be used with LLMs, which aligns with the HDM project's goal of modeling a user's personal world. While the paper focuses on the ontology itself rather than the integration architecture, the principles behind KNOW (pragmatism, focus on human universals, developer experience) are valuable for designing the HDM's own schema. The provision of SDKs for multiple languages is also a good practice to consider.","The key insight is the argument that for neuro-symbolic AI to become practical, a new kind of ontology is needed—one that is less concerned with perfect taxonomic correctness (like Cyc) and more focused on pragmatic, real-world utility and developer experience. The paper posits that LLMs can handle much of the ""commonsense"" knowledge, so the ontology should focus on structuring the most important, universal concepts of human life (spacetime and social relationships) in a way that is easy for both LLMs and software developers to use.","This paper introduces KNOW (Knowledge Navigator Ontology for the World), a new ontology designed to capture everyday knowledge for use in generative AI applications like personal assistants. The ontology focuses on human universals (spacetime and social concepts) and prioritizes pragmatic utility and developer experience over strict taxonomic correctness. The author argues that such an ontology is a crucial component for building practical and interoperable neuro-symbolic AI systems, where LLMs are augmented with explicit knowledge from a KG.","How to design a practical, real-world ontology for capturing everyday knowledge to be used in conjunction with Large Language Models for applications like personal AI assistants?",The paper presents a conceptual design for the KNOW ontology. The methodology is based on identifying human universals as the core concepts to model. The author compares this approach to existing ontologies like Schema.org and Cyc to highlight its unique design principles. The paper also describes the generation of software libraries for 12 programming languages to promote the ontology's adoption.,"The primary outcome is the KNOW ontology itself, presented as a public domain resource with accompanying software libraries. The paper establishes the design principles for this ontology, emphasizing pragmatism, focus on human universals, and developer experience.","The paper presents a first iteration of the ontology, and its scope is currently limited to spacetime and social concepts. It does not provide a detailed evaluation of the ontology's effectiveness in a real-world application. The practical challenges of populating and maintaining a KG based on this ontology are not deeply explored.","The paper concludes that a pragmatic, developer-friendly ontology like KNOW is a necessary step to realize the potential of neuro-symbolic AI. It positions KNOW as a foundational layer for building interoperable AI systems where knowledge can be shared and reused.",The paper identifies the need to extend the ontology's scope beyond the initial set of human universals. It also implicitly points to the challenge of encouraging widespread adoption of a new ontology in a field where ad-hoc schemas are common.,Future work will involve extending the scope of the ontology to cover more aspects of human life.,"The paper provides several valuable implementation insights. First, the focus on ""human universals"" is a good starting point for designing a personal knowledge schema. Second, the emphasis on developer experience, including providing SDKs in multiple languages, is a crucial factor for adoption. Third, the pragmatic approach to taxonomy (a flat class hierarchy) can simplify the modeling process. Finally, the idea of mapping to existing ontologies like Schema.org where possible is a good practice for interoperability.",,,"Ontology, Knowledge Representation, Large Language Models, LLM, Knowledge Graph, Neuro-symbolic AI, Commonsense Knowledge, Semantic Web",,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
berkeley_2017,Quality and Relevance Metrics for Selection of Multimodal Pretraining Data,"Roshan Rao, Debadeepta Dey, Sudha Rao, Asli Celikyilmaz, Elnaz Nouri, Bill Dolan",2017,Yes,LOW,"This paper is tangentially related. It explores how the quality and relevance of pretraining data affect downstream task performance for visuolinguistic models. While the HDM project deals with heterogeneous data, this paper's focus is on optimizing pretraining for large models, not on the architectural challenges of data integration, schema building, or temporal modeling. The metrics for data quality and relevance could be loosely inspiring but are not directly applicable to the core problems of the HDM project.","The key insight is that data selection for pretraining matters significantly. It's not just about the quantity of data, but also its quality (similarity between image and text) and relevance to downstream tasks. The paper shows that by creating metrics for these aspects, one can intelligently subsample large datasets to improve model performance, which is more efficient than simply using more data.","The paper proposes metrics to measure the quality and relevance of visuolinguistic data and shows that pretraining on a smaller, curated dataset selected using these metrics can outperform pretraining on larger, unfiltered datasets.","This paper investigates the impact of data quality and relevance on the performance of self-supervised pretraining for visuolinguistic models. The authors define two metrics—one for quality (based on image-text similarity using GloVe vectors) and one for relevance (based on TF-IDF similarity to downstream tasks). They evaluate these metrics by pretraining a ViLBERT-style model on various datasets (including ConceptualCaptions and custom-collected ones) and testing on downstream tasks like VQA and VCR. The results show that the proposed metrics correlate well with performance and that a smaller, high-quality, and relevant ""amalgam"" dataset can outperform larger, less-curated ones.","Given a fixed model, task, and data size, how does data quality and data relevance affect performance on downstream tasks? Is it possible to select pretraining data so as to maximize perfomance of a model on downstream tasks?","The authors define two metrics: a TF-IDF-based ""relevance"" score to measure the similarity between pretraining text and downstream task text, and a GloVe-based ""quality"" score to measure the similarity between paired images and text. They use these metrics to score four base datasets. They then pretrain a ViLBERT model on these datasets (downsampled to 2 million examples each) as well as on ""amalgam"" datasets created by selecting the highest-scoring examples. Performance is evaluated on four downstream tasks: VQA, VCR, Grounded Referring Expressions, and Image Retrieval.","Both the quality and relevance metrics showed a strong positive correlation with downstream task performance (Spearman's ρ of 0.893 for quality and 0.577 for relevance). Pretraining on a smaller ""amalgam"" dataset curated for high quality and relevance outperformed pretraining on larger, uncurated datasets. The study also found that data quality (image-text grounding) was a more important factor than data relevance.","The primary outcomes are the two proposed metrics for data quality and relevance, and the empirical demonstration that data curation based on these metrics is an effective strategy for improving the efficiency and performance of pretraining for visuolinguistic models.","The analysis is computationally expensive, making it hard to test many different metrics. The downstream tasks are broad, making it difficult to fully disentangle the effects of quality and relevance. The proposed metrics don't capture all the variance in performance, as shown by the Ngram Image Search dataset which performed better than its scores would suggest.","The paper concludes that simple, inexpensive metrics for data quality and relevance can be used to effectively filter large pretraining datasets, leading to better performance on downstream tasks. This suggests that data curation is a crucial and often overlooked aspect of the pretraining pipeline.","The paper points to the need for faster methods to evaluate data selection strategies. It also suggests that analyzing more niche downstream tasks could help to better disentangle the effects of quality and relevance. Finally, it notes that the proposed metrics are not perfect and that there is room for developing more sophisticated metrics.","The authors plan to apply their metrics to other domains, such as filtering large-scale video and ASR data, where the amount of available data is too large to be used entirely for pretraining.","The use of TF-IDF for relevance and GloVe vector similarity for quality are practical, easy-to-implement techniques for data scoring. The idea of creating a smaller, high-quality ""amalgam"" dataset from multiple sources is a useful strategy for efficient pretraining.",,,"data-curation, data-quality, data-relevance, machine-learning, pretraining, self-supervised-learning, visuolinguistic-models",Quality and Relevance Metrics for Selection of Multimodal Pretraining Data,"Rao Roshan, Rao Sudha, Nouri Elnaz, Dey Debadeepta, Celikyilmaz Asli, Dolan Bill",2020,reference-manager,10.1109/cvprw50498.2020.00486,,,,,"Difficulty disentangling the effects of quality and relatedness metrics, as they are correlated in the datasets.",,,,How do the quality and relatedness of image-text pairs in pretraining datasets impact the performance of models on downstream visuolinguistic tasks?,"The paper investigates how pretraining dataset quality and relatedness affect performance on visuolinguistic tasks. Using normalized scoring and correlation analysis, the study finds that higher quality datasets improve downstream results more than relatedness. The conclusion suggests prioritizing quality when selecting data for pretraining models.","The research goal is to maximize pretraining utility for downstream tasks using simple, inexpensive metrics; the approach involves applying these metrics to filter data for quality and relatedness; results show that higher-quality data improves performance, and future work aims to extend these methods to large paired video and ASR datasets.",,1.000,exact_title
berlin_2014,Benchmarking Scalability and Elasticity of Distributed Database Systems,"Jorn Kuhlenkamp, Markus Klems, Oliver Ross",2014,Yes,MEDIUM,"This paper is of medium relevancy. It provides a detailed performance, scalability, and elasticity benchmark of distributed database systems (HBase and Cassandra). While not directly about knowledge graphs or heterogeneous data integration in the semantic sense, the HDM project will require a scalable and elastic persistence layer. This paper's methodology for benchmarking these non-functional requirements is highly relevant for evaluating potential database technologies for the HDM system.","The key insight is the clear trade-off between scaling speed and performance stability in distributed databases. The paper demonstrates that while systems can be scaled quickly (e.g., by adding nodes without waiting for data re-distribution), this often comes at the cost of increased performance variability and potential data inconsistency. This highlights the need for careful consideration of scaling strategies based on the specific workload and availability requirements.","This paper reproduces and extends previous performance and scalability benchmarks for the distributed database systems HBase and Cassandra. It verifies that both systems scale nearly linearly but with different performance characteristics (Cassandra being better for reads, HBase for writes). The authors extend the original work by evaluating elasticity, measuring the trade-off between scaling speed and the performance impact on concurrent workloads.",The paper aims to reproduce previous performance and scalability benchmarks of HBase and Cassandra and extend them with an evaluation of elasticity.,"The authors reproduce experiments from prior research [14] using the YCSB benchmark on Amazon EC2 infrastructure. They compare the performance of HBase and Cassandra on various workloads (read-heavy, write-heavy, scan-heavy) and cluster sizes. They then extend these experiments to measure elasticity by observing the performance impact of adding or removing nodes during a running workload, testing different scaling strategies (e.g., varying data streaming throughput).","The reproduced experiments confirm that both Cassandra and HBase scale nearly linearly, and that Cassandra generally has better read performance while HBase has better write performance. The new elasticity experiments quantify the trade-off between scaling speed and performance stability, showing that faster scaling often leads to higher performance variability during the scaling operation.",The primary outcome is a verified and extended set of benchmarks for HBase and Cassandra that not only cover performance and scalability but also elasticity. This provides a more complete picture for decision-makers choosing a distributed database.,"The experiments were conducted on a specific version of the software and on a specific cloud infrastructure (Amazon EC2), which may not perfectly generalize to other environments. The workloads are synthetic (YCSB) and may not fully represent all real-world application behaviors.","The paper concludes that while general performance characteristics of distributed databases can be verified across different environments, absolute performance numbers are highly dependent on the underlying infrastructure. It also highlights that elasticity is a critical but often overlooked aspect of distributed systems, and that there is a clear trade-off between how fast a system can scale and how stable its performance remains during the scaling process.",The paper implicitly points to the need for more standardized and comprehensive benchmarking methodologies that include elasticity as a first-class citizen. It also highlights the challenge of reproducing benchmark results across different infrastructure environments.,Future work could involve developing more sophisticated elasticity benchmarks that cover a wider range of scaling scenarios and failure conditions.,"The paper provides a practical methodology for benchmarking the scalability and elasticity of distributed databases, which is a valuable process for the HDM project to adopt when selecting its own database technology. The detailed analysis of different EC2 instance types and storage configurations provides a good example of the factors to consider when deploying a database in the cloud. The distinction between horizontal and vertical scaling, and the analysis of their respective performance impacts, is also a key implementation consideration.",,,"Benchmarking, Scalability, Elasticity, Distributed Databases, NoSQL, Cassandra, HBase, Performance Evaluation","data-integration, knowledge-graph",Benchmarking Scalability and Elasticity of Distributed Database Systems,"Kuhlenkamp Jörn, Klems Markus, Röss Oliver",2014,reference-manager,,,,,,,Scalability benchmarking: Measures performance before and after scaling actions by changing load or system capacity between workload runs.,,,"How reproducible and reliable are performance, scalability, and elasticity benchmarking results for distributed database systems like HBase and Cassandra, and what factors influence discrepancies in experimental outcomes when using tools such as YCSB under different infrastructure configurations?","The paper aims to reproduce and verify performance and scalability benchmarks for Cassandra and HBase, focusing on Enterprise Application Performance Management. Using the YCSB benchmarking tool, the study finds Cassandra has lower read latency, while HBase has better write latency. Some original results could not be reproduced, highlighting variability in benchmarking outcomes.","The research goal is to benchmark and reproduce performance and scalability results for Cassandra and HBase using updated setups; the approach involves repeating prior experiments with newer software and hardware configurations; the principal finding is that some results were reproducible, but significant differences in absolute throughput and latency were observed.",,1.000,exact_title
bernard_2024,PKG API: A Tool for Personal Knowledge Graph Management,"Nolwenn Bernard, Krisztian Balog, Ivica Kostric, Petra Galuščáková, Martin G. Skjæveland, Weronika Łajewska, Vinay Setty",2024,Yes,SUPER,"This paper is highly relevant as it presents a concrete implementation of a PKG management system, including a user-friendly API and client. It directly addresses the practical challenges of building and interacting with PKGs, which is a core component of the HDM project. The focus on natural language interaction and a clear vocabulary provides a strong model for the HDM's own user interface and data model.","The key insight is that abstracting the complexity of PKG management behind a user-friendly, natural-language-driven interface is crucial for user adoption. While technologies like Solid provide the decentralized infrastructure, they often lack usability. This paper shows that a combination of a well-defined vocabulary, a service-oriented API, and an LLM-powered natural language layer can bridge this gap.","This paper proposes a complete solution for managing Personal Knowledge Graphs (PKGs), consisting of a user-facing PKG Client and a service-oriented PKG API. It introduces an RDF-based vocabulary to represent user statements, preferences, access rights, and provenance. A key feature is the NL2PKG component, which uses LLMs to translate natural language statements from users into structured data and API calls, making PKG management more accessible to non-expert users.",How to create a user-friendly and practical solution for managing Personal Knowledge Graphs that enables individuals to easily consolidate and control their fragmented personal data?,"The authors developed a complete software solution consisting of: (1) A PKG vocabulary based on RDF reification and existing vocabularies (SKOS, PAV). (2) A PKG API built with Flask, which includes an ""NL2PKG"" module that uses LLMs (Mistral-7b via Ollama) for intent classification and SPO extraction, and an entity linker (REL) to resolve entities. (3) A web-based PKG Client built with React for user interaction.","The work demonstrates the feasibility of creating a user-friendly PKG management system. The use of LLMs for natural language understanding significantly lowers the barrier to entry for end-users. The proposed RDF-based vocabulary is shown to be effective for representing complex user statements, including preferences and provenance.","The primary outcome is the open-source PKG API and Client, a complete, practical tool for personal knowledge graph management. This includes the PKG vocabulary, the NL2PKG component, and the user interface.",The paper acknowledges that the NL2PKG component's performance depends on the underlying LLM and entity linker. The current implementation is a demonstration and has not been evaluated in a large-scale user study. The resolution of entities in the user's private circle is mentioned as a challenge that requires a PKG-specific entity linker.,"The paper concludes that user-centric management tools are essential for the adoption of PKGs. By combining a robust data representation (the PKG vocabulary) with a user-friendly natural language interface, their work represents a major step forward in the practical realization of PKGs.","The paper highlights the general lack of practical, user-friendly PKG implementations. It also points to the need for better entity linking solutions specifically for personal entities that don't exist in public KGs.","Future work could involve improving the NL2PKG component, conducting user studies to evaluate the system's usability and effectiveness, and extending the PKG vocabulary to support more complex types of statements and reasoning.","The architecture of a separate API and Client is a standard and robust design. The use of LLMs via a local framework like Ollama is a good choice for privacy. The modular design of the NL2PKG component, allowing for different LLMs and entity linkers, is a good practice. The use of RDF reification to model statements is a standard Semantic Web pattern that provides flexibility.",https://arxiv.org/abs/2402.07540,10.48550/arXiv.2402.07540,"Personal Knowledge Graph, PKG, API, Knowledge Representation, Natural Language Interface, Semantic Web, User-Friendly, Data Management","data-integration, knowledge-graph, personal-knowledge",PKG API: A Tool for Personal Knowledge Graph Management,"Bernard Nolwenn, Kostric Ivica, Łajewska Weronika, Balog Krisztian, Galusčáková Petra, Setty Vinay, Skjæveland Martin G.",2024,reference-manager,10.1145/3589335.3651247,,,,,,"Deployment of a RESTful API (PKG API) using Flask, with a React-based user interface (PKG Client).",,,"How can a user-friendly, natural language-enabled personal knowledge graph (PKG) system be designed and implemented to allow individuals to intuitively manage and control their personal data?","The paper aims to create a user-friendly personal knowledge graph (PKG) system, enabling users to manage their data using natural language. Using a modular API (Flask backend) and a React-based client, the system translates user statements into structured data. Results show effective preference representation, supporting intuitive, user-centric PKG management.","The research goal is to enable user-friendly management of personal knowledge graphs (PKGs) via natural language; the approach combines a modular PKG API with NL2PKG translation and a web client, and the principal finding is that users can intuitively interact with PKGs using natural language statements.",,1.000,exact_title
bianchini_2022,A semantics-enabled approach for personalised Data Lake exploration,"Devis Bianchini, Valeria De Antonellis, Massimiliano Garda",2022,Yes,MEDIUM,"This paper is of medium relevancy. It addresses the exploration of heterogeneous data in Data Lakes, which is a related problem to the HDM project's data integration challenge. The PERSEUS approach, with its focus on semantic metadata, multi-dimensional modeling, and personalization, offers valuable patterns. While the context is enterprise BI rather than personal knowledge graphs, the phased approach to building a semantic layer on top of raw data is applicable to the HDM system's design.","The key insight is that a multi-layered, semantics-enabled approach is necessary to make large, heterogeneous Data Lakes usable for a wide range of users. The paper proposes a structured, three-phase process (Semantic Data Lake construction, Exploration Graph definition, and personalized Exploration Context identification) that progressively adds semantic richness and personalization to the raw data, transforming a ""data swamp"" into a navigable and useful information resource.","The paper proposes PERSEUS, a computer-aided approach for personalized data exploration in Data Lakes. It involves three phases: (1) building a semantic metadata catalog on top of the Data Lake, (2) modeling indicators and analysis dimensions into an Exploration Graph using a Multi-Dimensional Ontology, and (3) creating personalized Exploration Contexts based on user profiles and preferences.",How to enable a large number of users with different roles and competencies to extract value and knowledge from heterogeneous data sources stored in a Data Lake?,"The paper proposes the PERSEUS approach, which consists of three phases. First, a semantic metadata catalog is built using a semi-automatic annotation process supported by a tool called DL-DIVER. Second, data analysts use a Multi-Dimensional Ontology (MDO) and the Protégé tool to model indicators and analysis dimensions, creating an Exploration Graph. Third, personalized Exploration Contexts are identified based on user profiles, which are then used to filter and rank indicators for exploration. The approach was validated in a Smart City domain.","The experimental evaluation demonstrates the feasibility of the PERSEUS approach. The DL-DIVER tool effectively supports the semantic annotation process, significantly improving the quality of the metadata catalog compared to using raw attribute names. The preference-based system is shown to be effective in reducing the search space for indicators, and the personalization features improve the retrieval of relevant indicators for different user profiles.","The primary outcome is the PERSEUS methodology, a comprehensive, three-phase approach for personalized data exploration in Data Lakes. This includes the conceptual models (Semantic Data Lake, Exploration Graph, MDO), the supporting tools (DL-DIVER), and a demonstration of its feasibility in a real-world Smart City project.","The approach relies on significant manual effort from domain experts and data analysts, particularly in the initial setup of the semantic metadata catalog and the Exploration Graph. The query performance depends on the underlying Data Lake infrastructure (Hadoop/Spark in this case) and may not be suitable for real-time interactive exploration in all scenarios.","The paper concludes that a semantics-enabled, personalized approach is crucial for unlocking the value of Data Lakes. By progressively enriching the data with semantic metadata and user-specific context, the PERSEUS approach can make complex, heterogeneous data accessible and explorable for a wide range of users.","The paper suggests that future work could focus on improving the automation of the semantic annotation process, developing more sophisticated mapping techniques between the Exploration Graph and the Data Lake sources, and exploring the propagation of preferences across different exploration contexts.","Future research will focus on improving the DL-DIVER tool, enhancing the mapping definition process, and investigating the propagation of preferences across exploration contexts.","The three-phase architecture (semantic catalog, exploration graph, personalized contexts) is a useful pattern for building a semantic layer over raw data. The use of a Multi-Dimensional Ontology (MDO) to guide the modeling of indicators and dimensions is a good practice for ensuring consistency. The concept of using user profiles and preferences to create personalized ""Exploration Contexts"" is a valuable technique for tailoring the user experience.",https://doi.org/10.2785/56118,10.2785/56118,"Semantic Data Lake, Personalised Data Exploration, OLAP, Big Data, Ontology, Heterogeneous Data, Data Integration","data-integration, knowledge-graph, personal-knowledge",A semantics-enabled approach for personalised Data Lake exploration,"Bianchini Devis, De Antonellis Valeria, Garda Massimiliano",2023,reference-manager,10.1007/s10115-023-02014-1,,,,,,Top-n precision and Top-n recall metrics: Used to assess the effectiveness of personalized indicator suggestions by measuring the relevance of retrieved results.,,,"How can the PERSEUS approach enable personalized, context-aware exploration of multi-dimensional aggregated data in Semantic Data Lakes by leveraging user profiles, preferences, and semantic metadata to support decision making and data visualization across diverse application domains?","The paper proposes PERSEUS, a computer-aided approach for personalized exploration of multi-dimensional data in Data Lakes. Using semantic metadata catalogs, Multi-Dimensional Ontology, and user profiles, PERSEUS enables interactive data exploration. Validated in the Brescia Smart Living project, results show improved semantic annotation and relevant indicator suggestions.","The paper's main objective is to enable personalized exploration of Data Lakes using the PERSEUS approach, which formalizes semantic metadata catalog construction, models indicators with a Multi-Dimensional Ontology, and incorporates user preferences; results show effective support for domain experts, efficient query response, and improved personalized indicator suggestions.",,1.000,exact_title
bikakis_2021,Pattern-based design applied to cultural heritage knowledge graphs,"Valentina Anita Carriero, Aldo Gangemi, Maria Letizia Mancinelli, Andrea Giovanni Nuzzolese, Valentina Presutti, Chiara Veninata",2021,Yes,HIGH,"This paper is highly relevant because it provides a detailed, practical case study of building a large, complex knowledge graph (ArCo) using a pattern-based design methodology (eXtreme Design). The HDM project faces similar challenges in modeling a complex domain (personal data) and can directly benefit from the lessons learned in the ArCo project. The focus on Ontology Design Patterns (ODPs), test-driven development, and a modular architectural pattern (root-thematic-foundations) are all best practices that can be adopted for the HDM system's ontology design.","The key insight is that a rigorous, pattern-based, and test-driven methodology is essential for developing high-quality, maintainable, and extensible knowledge graphs, especially in complex domains like Cultural Heritage. The paper demonstrates that the eXtreme Design (XD) methodology, adapted for the specific needs of the domain, provides a structured and effective way to manage the development process, from requirement gathering to validation.","This paper presents ArCo, the knowledge graph of Italian Cultural Heritage, and details the methodology used for its development. It describes how the eXtreme Design (XD) methodology, which is based on Ontology Design Patterns (ODPs) and test-driven development, was adapted and applied to the cultural heritage domain. The paper also introduces a novel architectural pattern for large ontology networks and a new tool for unit-testing KGs.","How to apply a pattern-based and test-driven methodology to the development and validation of a large-scale, domain-specific knowledge graph like the Italian Cultural Heritage KG (ArCo)?","The authors applied the eXtreme Design (XD) methodology, which involves: (1) collecting requirements as user stories and translating them into competency questions (CQs), (2) matching CQs to existing Ontology Design Patterns (ODPs), (3) implementing the ODPs in ontology modules, and (4) performing unit and integration testing based on the CQs. They extended this methodology to handle requirements from a diverse community and developed a new architectural pattern (root-thematic-foundations) for the ontology network.","The successful development of ArCo, a large-scale knowledge graph with ~172.5M triples, demonstrates the effectiveness of the adapted XD methodology. The paper provides a detailed account of the design process, including the selection and specialization of ODPs. It also introduces TESTaLOD, a new tool for supporting unit testing of KGs, and presents a rigorous evaluation of the ArCo ontologies.","The primary outcome is a detailed case study and a set of methodological guidelines for building large, high-quality knowledge graphs. This includes the ArCo KG itself, the adapted XD methodology, the root-thematic-foundations architectural pattern, and the TESTaLOD tool.","The process described still relies heavily on manual effort from domain experts and ontology engineers, particularly for requirement engineering and matching CQs to ODPs. The paper focuses on the cultural heritage domain, and while the methodology is general, some of the specific patterns and challenges may not directly translate to other domains.","The paper concludes that a pattern-based, test-driven methodology like XD is crucial for the successful engineering of complex knowledge graphs. The experience with ArCo shows that such a methodology can be adapted to handle the specific challenges of a domain, leading to a high-quality and maintainable resource.","The paper highlights the need for better tool support for pattern-based ontology design, particularly for matching requirements to ODPs. It also points to the challenge of gathering and managing requirements from a large and diverse community of stakeholders.","Future work includes further refinement of the XD methodology, development of more advanced tools for pattern-based design and testing, and extending the ArCo KG to cover more aspects of cultural heritage.",The paper provides a wealth of practical implementation insights. The root-thematic-foundations architectural pattern is a very useful model for structuring a large ontology network. The process of translating user stories into competency questions and then matching them to ODPs is a clear and effective design workflow. The emphasis on test-driven development and the creation of a dedicated testing tool (TESTaLOD) is a crucial lesson in ensuring the quality and robustness of the KG.,https://doi.org/10.3233/SW-200422,10.3233/SW-200422,"Knowledge Graph, Ontology Design Patterns, ODP, Cultural Heritage, eXtreme Design, Ontology Engineering, Test-Driven Development, Semantic Web","data-integration, knowledge-graph",Pattern-based design applied to cultural heritage knowledge graphs,"Carriero Valentina Anita, Gangemi Aldo, Mancinelli Maria Letizia, Nuzzolese Andrea Giovanni, Presutti Valentina, Veninata Chiara",2021,reference-manager,10.3233/sw-200422,,,,,,"Iterative Design Methodology: The study reports results for three versions of ArCo (v0.1, v0.5, v1.0), each resulting from separate iterations of the design methodology.",,,"How can a modular, pattern-based ontology network be designed to effectively capture, generalize, and address competency questions and requirements for representing cultural heritage knowledge in the ArCo project?","The paper aims to improve mapping between input data and ontology models for Italian Cultural Heritage. Using the ArCo approach, it emphasizes institutional control over data and ontological commitment. The methodology includes inference, error, and competency tests, showing ArCo's soundness and terminological coverage. The study concludes ArCo effectively supports rich, interoperable cultural data.","The research goal is to enhance cultural heritage knowledge graphs; the approach extends the eXtreme Design methodology with a root-thematic-foundations ontology pattern and formal evaluation; results show homogeneous, cohesive modules and improved data quality through iterative refinement and data cleansing.",,1.000,exact_title
bloor_2018,Towards a Personal Health Knowledge Graph Framework for Patient Monitoring,"Daniel Bloor, Nnamdi Ugwuoke, David Taylor, Keir Lewis, Luis Mur, Chuan Lu",2018,Yes,HIGH,"This paper is highly relevant as it proposes a concrete framework for constructing Personal Health Knowledge Graphs (PHKGs) for patient monitoring. This directly aligns with the HDM project's goals, particularly in the healthcare domain. The framework's emphasis on integrating heterogeneous data sources (EHRs, sensors, omics), using ontologies for semantic mapping, and employing a reasoning engine for generating alerts and insights provides a strong architectural blueprint for the HDM system.","The key insight is the practical, modular approach to building a PHKG. The framework separates concerns into distinct components: ontology management, data harmonization (for time-series, free text, and multimodal data), KG construction, reasoning, and personalization. This modularity makes the complex problem of building a PHKG more manageable and adaptable to different chronic diseases and data sources.","This paper proposes a framework for constructing Personal Health Knowledge Graphs (PHKGs) to monitor patients with chronic diseases. The framework integrates heterogeneous data from clinical databases, ontologies, and healthcare guidelines to support alerts, interpretation, and querying of patient data. A use case for Chronic Obstructive Pulmonary Disease (COPD) demonstrates the framework's feasibility.",How can a Personal Health Knowledge Graph be constructed from heterogeneous data sources to effectively monitor patients with chronic diseases?,"The paper proposes a 7-component framework: (1) Ontology selection and merging, (2) Data processing and harmonization (including time-series summarization and NLP for free text), (3) General KG construction from ontologies and guidelines, (4) PHKG creation by mapping transformed data to the KG, (5) Reasoning and inference using rule-based and model-based approaches, (6) Personalization and subgraph extraction, and (7) an API for downstream tasks. The authors implemented a prototype for COPD monitoring using the MIMIC-III dataset, MongoDB for data storage, and Neo4j for the graph database.","The authors successfully constructed a PHKG for COPD with 3.5 million nodes and 4 million relationships. The system was able to generate risk-based alerts using personalized thresholds and demonstrate enhanced querying capabilities through ontological inference (e.g., querying for a disease and getting back patients with its subtypes).","The primary outcome is a comprehensive and practical framework for building PHKGs for patient monitoring. The paper also presents a proof-of-concept implementation for COPD, demonstrating the framework's viability.",The paper is a proposal and a preliminary implementation. The system has not been clinically validated or tested with real-time patient data. The machine learning components are mentioned as future work and are not deeply integrated into the current prototype.,"The paper concludes that the proposed framework provides a viable approach for constructing PHKGs for chronic disease monitoring. By integrating diverse data sources and leveraging semantic technologies, the system can provide valuable support for clinicians and patients.","The paper identifies the need for more advanced machine learning and multimodal analysis capabilities, such as using graph neural networks for more effective and accurate inferences.","Future work will focus on improving the machine learning and multimodal analysis capabilities of the system, leveraging advanced algorithms such as graph neural networks.","The paper offers several practical implementation insights. The use of a dual-database approach (MongoDB for raw/metadata, Neo4j for the graph) is a good pattern for managing different types of data. The data harmonization steps, including time-series summarization and using NLP tools like MedCAT for clinical text, are concrete techniques that can be adopted. The use of Cypher query triggers in Neo4j for real-time rule-based inference is another practical tip.",,,"Personal Health Knowledge Graph, PHKG, Patient Monitoring, COPD, Healthcare, Data Integration, Ontology, Knowledge Graph, Neo4j","data-integration, healthcare, knowledge-graph, personal-knowledge",Towards a Personal Health Knowledge Graph Framework for Patient Monitoring,"Bloor Daniel, Ugwuoke Nnamdi, Taylor David, Lewis Keir, Mur Luis, Lu Chuan",2023,reference-manager,,,,,,,"Use of the MIMIC-III dataset for testing and validating the prototype system, including both structured (vital signs) and unstructured (clinical notes) data.",,,"How can a modular framework integrating ontologies, semantic technologies, and multimodal data be developed and implemented to construct and personalize personal health knowledge graphs (PHKGs) for chronic disease monitoring, specifically for patients with chronic obstructive pulmonary disease (COPD)?","The paper proposes a modular framework for constructing temporal knowledge graphs (KGs) to monitor COPD patients. Using ontologies, data harmonization, and NLP tools like MedCAT, the system summarizes and annotates time series and free text data. Key findings include efficient data storage, personalized risk scoring, and improved reasoning for patient care.","The paper's main objective is to construct personal health knowledge graphs (PHKGs) for chronic disease monitoring using a modular framework that integrates expert knowledge and multimodal health data; the key method combines semantic technologies, ontologies, and machine learning; the principal finding is a prototype system for COPD patient monitoring using Neo4j and MongoDB.",,1.000,exact_title
sharma_2025,Temporal Reasoning in AI Systems,Abhishek Sharma,2025,Yes,LOW,Tangentially related to knowledge management or data systems,"Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on temporal reasoning in ai systems providing insights for knowledge graph development and data integration.,"This 2025 paper by Abhishek Sharma explores temporal reasoning in ai systems. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"ai, healthcare, knowledge-graph, machine-learning, ontology, semantic, temporal",,,,,,,,,,,,,,,,,,,
bogachov_2018,A Lightweight Multi-Expert Generative Language Model System for Engineering Information and Knowledge Extraction,"Bogdan Bogachov, Yaoyao Fiona Zhao",2018,Yes,MEDIUM,"This paper is of medium relevancy. It proposes a ""Small Language Graph"" (SLG) architecture, which is a system of small, specialized language models (experts) connected in a graph. This is relevant to the HDM project's goal of building a modular and efficient system. While not a knowledge graph in the traditional semantic web sense, the SLG's graph-based, multi-expert approach to handling domain-specific knowledge offers an interesting architectural pattern that could be adapted for managing different facets of a user's personal data.","The key insight is that a system of small, specialized expert models can outperform a single, larger model in domain-specific tasks, both in terms of accuracy (by reducing ""knowledge overshadowing"" and hallucinations) and computational efficiency. By isolating knowledge into distinct, fine-tuned experts, the system can provide more precise and reliable information for specialized domains like engineering.","This paper introduces the Small Language Graph (SLG), a lightweight system of multiple small language models (experts) fine-tuned on specific, concise texts. This graph-based architecture is designed to address the challenges of high computational costs and hallucinations in large language models, particularly in engineering contexts. The system demonstrates superior performance and faster fine-tuning compared to conventional methods.",How to create a lightweight and accurate generative AI system for specific engineering domains that mitigates hallucinations and reduces computational costs?,"The authors propose the Small Language Graph (SLG) system. The methodology involves: (1) Splitting a domain-specific dataset (a Structural Repair Manual) into isolated chunks to avoid data overlap. (2) Fine-tuning small language models (Llama-3.2-1B-Instruct) on each chunk to create ""expert"" nodes. (3) Using another fine-tuned small LLM as an ""orchestrator"" to route user queries to the appropriate expert. (4) Connecting the experts in a graph architecture using LangGraph. The performance is evaluated against fine-tuned standalone LLMs using ROUGE-L, Exact Match, and METEOR metrics.","The SLG system, built on smaller models, outperformed a larger standalone model (Llama-3.1-8B-Instruct) on the Exact Match metric by a factor of three, indicating a significant reduction in hallucinations. The fine-tuning process for the entire SLG system was 1.7 times faster than for the larger model. The system can be run on a single consumer-grade GPU.","The primary outcome is the Small Language Graph (SLG) system, a proof-of-concept demonstrating a novel, lightweight, multi-expert architecture for domain-specific generative AI.","The study is limited to a single engineering domain and dataset. The evaluation of hallucination is based primarily on the Exact Match metric, without extensive human evaluation. The current implementation is not a full chatbot and lacks memory and conversational context. The orchestrator's accuracy in routing queries is around 70% and needs improvement.","The paper concludes that a multi-expert system of small, specialized language models can be more accurate and computationally efficient than a single large model for domain-specific tasks. This approach has the potential to make generative AI more accessible to smaller companies and could pave the way for decentralized AI systems.","The paper identifies the need for more extensive comparisons with other models (like larger Llama models and RAG systems) and more rigorous hallucination checking. Future work should also focus on improving the orchestrator, adding conversational capabilities, and incorporating multimodal data.","Future work includes comparing the SLG with larger models and RAG systems, performing more thorough hallucination checks, improving the orchestrator, and adding features like conversational memory and multimodal data support.","The graph-based architecture of specialized ""expert"" nodes is a valuable pattern for modularizing knowledge and processing. The idea of isolating training data to prevent ""knowledge overshadowing"" is an important consideration for fine-tuning models on diverse personal data. The use of a lightweight orchestrator to route queries is a practical approach for building a multi-component system.",https://doi.org/10.48550/arxiv.2302.04023.,10.48550/arXiv.2302.04023.,"Small Language Model, Small Language Graph, Multi-expert System, Fine-tuning, Generative AI, Engineering, Hallucination","data-integration, knowledge-graph",A Lightweight Multi-Expert Generative Language Model System for Engineering Information and Knowledge Extraction,"Bogachov Bogdan, Zhao Yaoyao Fiona",2025,reference-manager,,,,,,,Prompt engineering: Designing and refining prompts to interact with LLMs for efficient and accurate information generation.,,,"How can a computationally efficient and accurate method be developed to adapt large language models for domain-specific engineering tasks, addressing the limitations of existing approaches such as prompt engineering, fine-tuning, and Retrieval-Augmented Generation?","The paper aims to develop a lightweight LLM adaptation method for engineering domains, focusing on maximizing accuracy and reducing hallucinations. Using a Cessna aircraft Structural Repair Manual, the methodology involves dataset preparation and SLG system construction. Significant findings highlight improved accuracy and applicability across engineering domains, though image data is excluded.","The research goal is to create a lightweight adaptation method for large language models in engineering; the approach, called Small Language Graph (SLG), uses a graph of small expert models; results show SLG outperforms conventional fine-tuning by 3x on Exact Match and is 1.7x faster.",,1.000,exact_title
bontempelli_2017,Lifelong Personal Context Recognition,"Andrea Bontempelli, Marcelo Rodas Britez, Xiaoyue Li, Haonan Zhao, Luca Erculiani, Stefano Teso, Andrea Passerini, Fausto Giunchiglia",2017,Yes,HIGH,"This paper is highly relevant as it directly addresses the core conceptual challenges of building a lifelong personal AI assistant, which is the ultimate vision for the HDM project. It outlines the three key pillars: (1) representing the user's personal situational context, (2) performing lifelong context recognition robust to change, and (3) maintaining human-AI alignment. This provides a strong theoretical and conceptual framework for the HDM system's architecture and long-term research goals.","The key insight is that a truly symbiotic Human-AI system cannot be achieved with KR or ML alone; it requires a synthesis of both. The paper argues that to overcome the ""problem of generality"" and brittleness, an AI must continually align its understanding of the world with its user's subjective perspective. This requires a KR framework to model the user's context and an ML framework that can learn and adapt to this context over a lifetime, all orchestrated through a bidirectional interaction loop.","This paper outlines the key challenges in developing AIs that live in lifelong symbiosis with a human. The authors argue that the central task is for the AI to understand the user's personal situational context at all times. They propose a three-pronged approach: (1) a knowledge representation scheme for personal context, (2) machine learning techniques for lifelong context recognition that are robust to change (e.g., concept drift and knowledge drift), and (3) a machine-human alignment loop to maintain a shared understanding through continual interaction.","How to build an AI that can live in lifelong symbiosis with a human, continuously understanding and adapting to their personal situational context?","The paper presents a conceptual framework and summarizes the authors' research efforts in three areas: (1) Knowledge Representation: They propose modeling the personal situational context as a Knowledge Graph, composed of a ""Life Sequence"" of contexts (defined by location, event, people, objects, etc.). (2) Machine Learning: They discuss the challenges of lifelong Personal Context Recognition (PCR), including handling changes in the user's descriptions (skeptical learning) and changes in the world itself (knowledge drift). (3) Human-AI Alignment: They posit the need for a continual, bidirectional interaction loop to maintain alignment, though this is presented as a major area for future research.",The paper establishes a clear conceptual framework for building a lifelong personal AI. It identifies the key research challenges and provides a roadmap for tackling them. The authors' work on skeptical learning and knowledge drift provides initial solutions for the ML component of the framework.,"The primary outcome is a research agenda and a conceptual framework for Human-AI Symbiosis, centered around the problem of Lifelong Personal Context Recognition.","The paper is a short position paper and does not provide a complete, implemented system. Many of the ideas, particularly around the machine-human alignment loop, are presented as open research questions rather than solved problems.","The paper concludes that building a symbiotic AI requires a deep integration of Knowledge Representation and Machine Learning. Neither field can solve the problem of generality and brittleness in isolation. A lifelong, bidirectional interaction between the human and the AI is essential for maintaining alignment and enabling the AI to adapt to a constantly changing world.","The paper highlights the need for more research on the machine-human alignment loop, including how to structure the interaction to be effective without being burdensome for the user. It also points to the challenge of translating between the outputs of ML models and the symbolic representations in the KR component.","Future research will focus on designing the machine-human alignment loop, including how to manage the cognitive load on the user and how to translate between ML outputs and the KR layer. The authors also emphasize the need for more real-world experiments and interdisciplinary collaboration.","The paper provides a strong conceptual model for the HDM's knowledge representation, based on a ""Life Sequence"" of personal situational contexts represented as KGs. The identification of specific ML challenges like ""knowledge drift"" is a crucial insight for designing the learning components of the HDM. The emphasis on bidirectional interaction highlights the need for an explainable and interactive user interface.",,,"Personal Context, Lifelong Learning, Human-AI Symbiosis, Knowledge Representation, Machine Learning, Explainable AI, Knowledge Drift","data-integration, knowledge-graph, personal-knowledge",Lifelong Personal Context Recognition,"Bontempelli Andrea, Britez Marcelo Rodas, Li Xiaoyue, Zhao Haonan, Erculiani Luca, Teso Stefano, Passerini Andrea, Giunchiglia Fausto",2022,reference-manager,,,"Implementation Insights highlight three main challenges: (1) Representing context to capture any real-world situation and preserve identity across contexts, even with conflicting properties; (2) Embedding machine learning in time and enabling two-way human-AI interaction; (3) Maintaining lifelong alignment through Computer Vision and Natural Language Processing. New insights include the need for structure-aware predictors and robust, incremental learning to handle unpredictable changes.",,,,General Knowledge Representation (KR) mechanism: Defines personal context to let the machine view the world from the user's perspective.,,,"How can AI systems achieve lifelong, flexible alignment with humans through general knowledge representation, adaptive machine learning, and continual, bi-directional interaction, enabling effective personal context recognition and mutual understanding in real-world, evolving environments?","The paper aims to develop AI systems capable of lifelong, holistic symbiosis with humans via smart wearables. Using knowledge representation, machine learning, and a machine-human alignment loop, experiments (notably with 158 students over four weeks) show the need for context-aware, adaptable, and ethically grounded AI for real-world human interaction.","The research goal is to develop lifelong human-AI symbiosis via smart wearables using a general Knowledge Representation (KR) mechanism, adaptive Machine Learning (ML), and a machine-human alignment loop; the approach combines context modeling, real-world experiments, and bi-directional interaction, with results based on the SmartUnitn2 dataset.",,1.000,exact_title
boyd_2025,AMEND 2.0: module identifcation and multi-omic data integration with multiplex-heterogeneous graphs,"Samuel S. Boyd, Chad Slawson, Jefrey A. Thompson",2025,Yes,MEDIUM,"This paper is of medium relevancy. It presents a sophisticated method (AMEND 2.0) for integrating multi-omic data using complex biological networks (multiplex-heterogeneous graphs). While the domain is very specific (bioinformatics), the underlying challenge of integrating heterogeneous data types and the use of advanced graph-based techniques (Random Walk with Restart for Multiplex-Heterogeneous Graphs) are relevant to the HDM project. The architectural patterns for handling multiplex and heterogeneous graphs could inform the design of the HDM's own knowledge graph, especially if it needs to model different types of relationships or entities.","The key insight is that for effective multi-omic data integration, the integration should happen *during* the network diffusion process, not before or after. The proposed RWR-MH (Random Walk with Restart for Multiplex-Heterogeneous) method allows for this by providing fine-grained control over how information flows between different layers (e.g., different interaction types) and components (e.g., different molecule types) of a complex biological network. This enables a more nuanced and powerful analysis than methods that treat the integrated network as a simple, flat graph.","This paper presents AMEND 2.0, an updated method for active module identification that can analyze multiplex and heterogeneous networks integrated with multi-omic data. The method is powered by a novel Random Walk with Restart for Multiplex-Heterogeneous networks (RWR-MH) and includes features for degree bias adjustment and multi-objective module identification. The authors demonstrate its effectiveness on two real-world multi-omic datasets.","How to effectively integrate and analyze multi-omic data using biological networks, accommodating multiple data types and complex network structures in a generalizable framework?","The authors present AMEND 2.0, an iterative active module identification method. Its core is RWR-MH, a network diffusion algorithm for multiplex-heterogeneous graphs. The paper details the mathematical formulation of RWR-MH, including a re-parameterization for more predictable behavior. The method is evaluated on two real-world multi-omic datasets (TCGA-KIRC and an OGT knockout study) and on several node ranking and degree bias adjustment tasks.",AMEND 2.0 is shown to be a versatile and effective tool for multi-omic data integration. The RWR-MH component allows for a more nuanced analysis of complex networks compared to previous methods. The application to real-world datasets successfully identified biologically relevant modules and molecular features involved in kidney cancer and lipid metabolism.,"The primary outcome is the AMEND 2.0 R package, a flexible and powerful tool for active module identification and multi-omic data integration on complex networks. The paper also introduces the RWR-MH algorithm and novel degree bias adjustment methods (IN and BS).","The method is highly specialized for bioinformatics and requires deep domain knowledge to construct the input networks and interpret the results. The complexity of the RWR-MH parameters (seed weights, cross-talk parameters) might be challenging to tune for users without expertise in network analysis.","The paper concludes that as multi-omic datasets become more common, new methods are needed to fully exploit their complexity. AMEND 2.0 provides a versatile and generalizable solution for analyzing multi-omic data in a network context, combining several advanced network analysis techniques into a single framework.","The paper implicitly points to the need for more user-friendly tools for building and analyzing multiplex-heterogeneous networks. It also suggests that the optimal level of ""cross-talk"" between different network layers and components is context-dependent and requires further investigation.","Future work could involve applying AMEND 2.0 to a wider range of multi-omic datasets and disease contexts, as well as developing more automated methods for tuning the RWR-MH parameters.","The paper provides a detailed description of how to model and analyze multiplex-heterogeneous graphs, which is a valuable architectural pattern. The RWR-MH algorithm, with its separate normalization of intra- and inter-layer/component matrices and its explicit cross-talk parameters, is a sophisticated technique for managing information flow in a complex graph. The discussion of degree bias adjustment is also a relevant consideration for any graph-based analysis.",https://doi.org/10.1186/s12859-025-06063-x.,10.1186/s12859-025-06063-x,"Multi-omic, Data Integration, Biological Networks, Active Module Identification, Knowledge Graph, Heterogeneous Graph, Multiplex Graph, Network Diffusion","data-integration, heterogeneous-data, knowledge-graph",AMEND 2.0: module identification and multi-omic data integration with multiplex-heterogeneous graphs,"Boyd Samuel S., Slawson Chad, Thompson Jeffrey A.",2025,reference-manager,10.1186/s12859-025-06063-x,,,,,,Random Walk with Restart for multiplex-heterogeneous networks (RWR-MH): A network diffusion method for analyzing multi-omic data across multiple network layers and components.,,,"How does the updated AMEND algorithm enable effective multi-omic data integration and active module identification on multiplex-heterogeneous networks, while addressing challenges such as degree bias and multi-objective node selection?","AMEND 2.0 is introduced as a flexible method for active module identification and multi-omic data integration using multiplex-heterogeneous network diffusion. The study applies AMEND to TCGA-KIRC and OGT knockout datasets, demonstrating effective module identification and degree bias mitigation. AMEND is broadly applicable but network-dependent.","The research goal was to identify key molecular modules in complex multi-omic data; the approach used AMEND 2.0, which integrates multi-omic data via multiplex-heterogeneous network diffusion with degree bias mitigation; results show AMEND effectively identifies biologically relevant modules in diverse datasets.",,0.994,fuzzy_title
brennan_2016,Towards a knowledge driven framework for bridging the gap between software and data engineering,"Monika Solanki, Bojan Božic´, Christian Dirschl, Rob Brennan",2016,Yes,HIGH,"This paper is highly relevant. The HDM project is a data-intensive software system, and this paper's proposal of a suite of ontologies (the ALIGNED suite) to bridge the gap between software and data engineering provides a powerful architectural pattern. The concepts of a Design Intent Ontology (DIO), Software Lifecycle Ontology (SLO), and Data Lifecycle Ontology (DLO) offer a robust, high-level framework for managing the development and maintenance of a system that handles heterogeneous personal data. The emphasis on provenance (using W3C PROV) is also a critical requirement for the HDM.","The key insight is that software engineering and data engineering, while often treated as separate disciplines, can and should be integrated using a common semantic layer. An ontology-based framework can provide this layer, enabling better tool-chain integration, unified governance, and clearer communication across teams and processes.","This paper presents the ALIGNED suite of ontologies, a framework designed to bridge the gap between software and data engineering for large-scale, data-intensive systems. The suite provides semantic models for design intents, software and data lifecycles, and data quality. The authors demonstrate its application in two complex use cases (a legal information system and a historical databank), showing how the ontologies can facilitate tool integration and unified governance.","How can a knowledge-driven framework, based on a suite of ontologies, be used to bridge the gap between software engineering and data engineering processes for data-intensive systems?","The authors developed the ALIGNED suite of ontologies based on a thorough requirements analysis from real-world use cases. The methodology involved: (1) identifying generic and use-case-specific requirements, (2) designing a modular suite of ontologies (reusing existing standards like PROV-O where possible), (3) deploying and validating the ontologies in two large-scale projects (JURION and Seshat), and (4) evaluating the ontologies against established design principles (e.g., Gruber's principles).","The ALIGNED ontology suite provides an effective framework for integrating software and data engineering processes. The use of these ontologies enables better tool-chain integration, unified governance, and the creation of a common semantic understanding across different parts of a data-intensive system. The user-driven evaluation showed a 50% increase in efficiency for certain tasks.","The primary outcome is the ALIGNED suite of ontologies itself, a publicly available and well-documented resource for building data-intensive systems. The paper also provides a set of requirements and design patterns for this domain.","The paper acknowledges that the development of such ontologies still requires significant manual effort from domain experts. The evaluation, while positive, is based on specific use cases and tools within the ALIGNED project.","The paper concludes that a knowledge-driven framework based on ontologies is a powerful approach for aligning software and data engineering. This alignment is crucial for increasing the productivity, agility, and quality of data-intensive systems.",The paper implicitly points to the need for more automated tools for ontology engineering and for mapping between different domain-specific models.,Future work includes the empirical evaluation of the ontologies in a wider range of use cases and the development of more advanced tools that leverage the ALIGNED framework.,"The modular architecture of the ALIGNED suite (provenance, generic, domain-specific layers) is a key implementation pattern. The use of W3C PROV as a foundational layer for all models is a best practice for ensuring data lineage. The paper also provides concrete examples of how to use the ontologies to create audit trails and integrate different tools (like JIRA and Confluence).",https://doi.org/10.1016/j.jss.2018.12.017,10.1016/j.jss.2018.12.017,"Ontology, Software Engineering, Data Engineering, Data Integration, Knowledge-Driven Framework, Semantic Web, Provenance, Data Lifecycle, Software Lifecycle","data-integration, knowledge-graph",Towards a knowledge driven framework for bridging the gap between software and data engineering,"Solanki Monika, Božić Bojan, Dirschl Christian, Brennan Rob",2019,reference-manager,10.1016/j.jss.2018.12.017,,"Implementation Insights highlight that integrating DIO conceptualizations into PoolParty Thesaurus (PPT) improved search efficiency by 50%. The ALIGNED ontology suite supports unified governance, interoperability, and complex requirements integration across diverse, large-scale, data-intensive systems, with ongoing empirical evaluation in real-world use cases.",,,,"Data Lifecycle Management: Includes extraction, storage, authoring, interlinking, enrichment, quality analysis, repair, and publication of data.",,,"How can a unified suite of ontologies be developed and applied to effectively integrate and align software and data engineering tasks, processes, and datasets across large-scale, data-intensive systems in diverse domains such as legal information platforms and global history databanks?","The paper presents version 3 of the ALIGNED ontology suite, aiming to semantically integrate software and data engineering tasks. Using requirements analysis and deployment in real-world cases (JURION, Seshat), it demonstrates improved governance and efficiency. The suite enables unified data management, with formal evaluation confirming its practical benefits.","The paper's main objective is to provide a comprehensive overview of the ALIGNED ontology suite for unified governance in software and data engineering, using a requirements-driven approach, with results showing improved efficiency (e.g., 50% faster semantic search) and practical deployment in large-scale, real-world systems.",,1.000,exact_title
briggs_2021,A Review of Privacy-preserving Federated Learning for the Internet-of-Things,"Christopher Briggs, Zhong Fan, Peter Andras",2021,Yes,HIGH,"This paper is highly relevant as it provides a comprehensive survey of privacy-preserving federated learning, a key architectural consideration for the HDM project. Given that the HDM will manage sensitive personal data in a distributed manner, understanding the privacy risks, attack vectors, and defense mechanisms (like differential privacy and secure aggregation) discussed in this paper is crucial for designing a robust and trustworthy system.","The key insight is that federated learning is not inherently private. While it prevents direct data sharing, the model updates themselves can leak sensitive information. Therefore, additional privacy-enhancing technologies are essential. The paper provides a clear overview of the trade-offs between privacy, model utility, and communication efficiency, which is a critical consideration for any practical implementation.","This paper provides a comprehensive review of federated learning as a privacy-preserving machine learning approach for distributed data, with a particular focus on its application in the Internet-of-Things (IoT). It surveys a wide range of methods for improving communication efficiency, handling client heterogeneity, and preserving privacy, identifying the strengths and weaknesses of each.","What are the state-of-the-art privacy-preserving methods for federated learning, and what are the key challenges and future directions for their application in the IoT?","The authors conduct a systematic literature review, surveying a wide variety of papers on federated learning. They categorize the research into three main areas: communication efficiency, client heterogeneity, and privacy-preserving methods. The paper provides a historical context by discussing distributed machine learning and then delves into the specifics of federated learning and its associated privacy challenges.","The paper finds that while federated learning offers a good starting point for privacy, it is vulnerable to various attacks. It identifies a range of privacy-preserving techniques, including anonymization, encryption (homomorphic and SMC), and differential privacy, and discusses their applicability to federated learning. It also highlights the importance of communication-efficient methods (like model compression) for the resource-constrained IoT environment.","The primary outcome is a comprehensive survey that serves as a valuable guide to the field of privacy-preserving federated learning. It provides a clear taxonomy of the challenges and solutions, and outlines a roadmap for future research.","As a survey, the paper synthesizes existing work and does not propose new methods. The field of federated learning is evolving rapidly, so some of the discussed techniques may have been superseded by newer approaches.","The paper concludes that federated learning, when combined with robust privacy-preserving mechanisms, is a powerful paradigm for machine learning on distributed, sensitive data. However, there is no one-size-fits-all solution, and the choice of methods depends on the specific application's requirements regarding privacy, utility, and efficiency.","The paper identifies several research gaps, including the need for better methods for hyperparameter tuning in a federated setting, more research into continual learning on distributed data, and the development of more efficient and robust privacy-preserving techniques.","Future work should focus on developing more advanced and computationally efficient privacy-preserving methods, exploring the combination of federated learning with fog computing, and designing federated learning algorithms specifically for low-power IoT devices.",The paper provides a good overview of practical privacy-preserving techniques that can be implemented in a federated system. This includes the use of Secure Multi-party Computation (SMC) for secure aggregation of model updates and the application of differential privacy (both global and local) to add noise to the updates and protect individual contributions. The discussion of communication-efficient techniques like model quantization and sparsification is also highly relevant for practical deployment.,,,"Federated Learning, Privacy, IoT, Survey, Differential Privacy, Secure Aggregation, Machine Learning","data-integration, educational-technology, knowledge-graph",A Review of Privacy-preserving Federated Learning for the Internet-of-Things,"Briggs Christopher, Fan Zhong, Andras Peter",2020,reference-manager,,,"Implementation Insights highlight that local differential privacy adds noise to individual data, protecting user privacy but requiring large user numbers for accurate statistics. Apple and Google use this in practice. Federated learning benefits from privacy mechanisms like differential privacy, homomorphic encryption, and secure multi-party computation, but faces challenges in model optimization and continual learning.",,,,"Suppressive methods: Remove or generalize data attributes, restrict queries, or return sampled data to protect privacy.",,,"How can privacy-preserving federated learning be effectively implemented to balance data privacy, utility, computational efficiency, and scalability in distributed machine learning, particularly in edge and fog computing environments?","The paper reviews methods for protecting individual privacy in data releases, especially in machine learning. It examines suppressive and perturbative privacy mechanisms, anonymization, homomorphic encryption, and secure multi-party computation. The study highlights the privacy-utility tradeoff and challenges like linkage attacks, concluding that maintaining privacy remains difficult despite existing methods and regulations.","The research goal is to review privacy-preserving methods for data releases in machine learning, the key approach is categorizing methods as suppressive or perturbative (including anonymization and k-anonymity), and the principal finding is that balancing privacy and data utility remains challenging due to risks like linkage attacks.",,1.000,exact_title
budhdeo_2021,Scoping review of knowledge graph applications in biomedical and healthcare sciences,"Sanjay Budhdeo, Joe Zhang, Yusuf Abdulle, Paul M Agapow, Douglas GJ McKechnie, Matt Archer, Viraj Shah, Eugenia Forte, Ayush Noori, Marinka Zitnik, Hutan Ashrafian, Nikhil Sharma",2021,Yes,HIGH,"This paper is highly relevant as it provides a comprehensive scoping review of KG applications in biomedicine and healthcare. This is directly applicable to the HDM project, especially its healthcare-related aspects. The focus on data heterogeneity, integration challenges, and the need for validation aligns perfectly with the HDM's research focus.","The key insight is the systematic identification of a gap between the potential of KGs in healthcare and their actual clinical translation. The paper highlights that while there's a lot of research, there's a lack of real-world validation and standardized practices. The delineation of KGs into ""biomedical"" and ""clinical"" clusters is also a significant insight.","This paper conducts a scoping review of 255 articles to characterize the use of knowledge graphs in biomedical and healthcare sciences. It finds that while medical science insights and drug repurposing are common applications, there is a wide variety of use cases. The review highlights the heterogeneity of KGs in terms of size and data sources, with DrugBank being the most common. It also notes that while advanced machine learning techniques are used, simple querying remains a prevalent analysis method. A key finding is the lack of real-world validation for insights derived from these KGs, posing a major challenge for their clinical translation.","What are the use cases, data characteristics, and research attributes of knowledge graphs in the biomedical and healthcare sciences, and to what extent are the findings from these KGs validated in the real world?","The authors conducted a scoping review following the PRISMA-ScR checklist. They performed keyword-based searches on multiple databases (MEDLINE, EMBASE, medRxiv, arXiv, bioRxiv) and screened 255 articles for inclusion. Data was extracted on demographics, graph characteristics, data sources, analysis techniques, and validation methods.","The most common use cases for KGs are medical science insights and drug repurposing. KGs are heterogeneous in size and data sources. DrugBank is the most used data source. A meta-analysis of node classes suggests a split between ""biomedical"" and ""clinical"" graphs. While advanced ML is used, simple querying is the most common analysis technique. A major finding is that most studies rely on ""inside graph"" validation, with very few performing ""outside graph"" validation (e.g., clinical trials).","A comprehensive scoping review that systematically describes the landscape of KG applications in biomedicine and healthcare. It provides a categorization of use cases, an analysis of graph characteristics, and a critical assessment of validation practices in the field.",The review has a cut-off date of November 2021. The search strategy might have missed some relevant papers. The review is limited to academic literature and does not include commercial or patent data. The categorization of use cases was developed by the authors and is exploratory.,"KGs have many possible uses in biomedicine and healthcare, but their full potential is yet to be realised. The two most popular use cases to date are generation of medical science insights and drug repurposing. There is an opportunity to expand work areas across other use cases and across diseases. Heterogeneity in graph size and context specificity suggests further work is needed to understand optimum graph construction. There are many different techniques used in graph analysis - deploying more sophisticated graph machine learning techniques may improve insights gained from KGs. Validation of findings from graphs through external testing will increase the robustness of conclusions drawn from graphs.","The paper identifies several gaps: the need for best practices in KG construction (especially regarding size and connectivity), better integration of -omics and patient data, understanding how to integrate KGs with LLMs, and the need for more open-sourcing of graphs and data. The most significant gap is the lack of ""outside graph"" validation.","Future research should focus on establishing best practices for KG construction and analysis, improving the integration of diverse data types, exploring the synergy between KGs and LLMs, and, most importantly, conducting more real-world validation of KG-derived insights.","The paper highlights the challenges of integrating clinical data (EHRs) due to lack of standardization, noise, and privacy concerns. This is a crucial consideration for the HDM project. The clear distinction between ""biomedical"" and ""clinical"" KGs is a useful conceptual model. The finding that simple querying is a common analysis method suggests that even basic KG functionality can be valuable.",https://doi.org/10.3389/fgene.2020.610798,10.3389/fgene.2020.610798,"Knowledge Graph, Survey, Scoping Review, Healthcare, Biomedicine, Data Integration, Validation, Machine Learning, Ontology","data-integration, healthcare, knowledge-graph",Scoping review of knowledge graph applications in biomedical and healthcare sciences,"Budhdeo Sanjay, Zhang Joe, Abdulle Yusuf, Agapow Paul M, McKechnie Douglas GJ, Archer Matt, Shah Viraj, Forte Eugenia, Noori Ayush, Zitnik Marinka, Ashrafian Hutan, Sharma Nikhil",2023,reference-manager,,,,,,"Manuscript inclusion cut-off date was November 2021, possibly missing recent developments.",,,,,,"The research goal was to conduct a scoping review of knowledge graph use in health, using systematic data extraction and categorization; the principal finding is that most future work focuses on improving data (99 counts) and algorithms (59 counts), with less emphasis on clinical validation or application.",No information available,1.000,exact_title
cai_2022,Temporal Knowledge Graph Completion: A Survey,"Borui Cai, Yong Xiang, Longxiang Gao, He Zhang, Yunfeng Li, Jianxin Li",2022,Yes,HIGH,"This paper is highly relevant as it provides a comprehensive survey of temporal knowledge graph completion (TKGC), a core area of interest for the HDM project's temporal-first architecture. Understanding the state-of-the-art, challenges, and future directions in TKGC is crucial for designing the HDM's knowledge representation and reasoning capabilities.","The key insight is the systematic categorization of TKGC methods, which provides a clear map of the research landscape. It highlights that the central challenge in TKGC is how to effectively integrate temporal validity into models to capture the dynamics of entities and relations.","A comprehensive survey of methods for predicting missing links in knowledge graphs that change over time, categorizing approaches and outlining future challenges.","This paper provides a comprehensive survey of recent advances in Temporal Knowledge Graph Completion (TKGC). It details the background, benchmark datasets, and evaluation metrics for TKGC. The paper categorizes existing TKGC methods based on how they incorporate temporal information, including time-included tensor decomposition, time-based transformation, dynamic embedding, learning from KG snapshots, reasoning with historical context, and temporal logical rules. It concludes by discussing open challenges and future research directions.","What are the recent advances in Temporal Knowledge Graph Completion (TKGC), how can existing methods be categorized, and what are the open challenges and future directions for the field?","The authors conducted a comprehensive literature survey. They detail the background of TKGC, including preliminaries, benchmark datasets (ICEWS, GDELT, YAGO15k, WIKIDATA), and evaluation metrics (Hits@k, MR, MRR). They then propose a taxonomy to categorize existing TKGC methods.","The paper finds that TKGC methods significantly improve link prediction by incorporating temporal information. It identifies six main categories of approaches for integrating time: time-included tensor decomposition, time-based transformation, dynamic embedding, learning from KG snapshots, reasoning with historical context, and temporal logical rules.","The primary outcome is a comprehensive survey that, for the first time, systematically summarizes and categorizes the research in Temporal Knowledge Graph Completion.","As a survey, it does not present new methods or experimental results. The authors explicitly state they do not compare the published performance of existing methods due to implementation differences. The field is rapidly evolving, so new methods may have emerged since its publication.","TKGC is a crucial and rapidly growing research area. While significant progress has been made, there are still open challenges, particularly in incorporating external knowledge, developing better negative sampling techniques, scaling to larger graphs, and handling evolving knowledge graphs in a continual learning setting.","The paper identifies several gaps: the need to incorporate external knowledge (like entity types and semantics from LLMs), the need for more sophisticated time-aware negative sampling techniques, the challenge of scaling TKGC methods to real-life, billion-fact KGs, and the need for incremental/continual learning approaches for evolving KGs.","Future research should focus on addressing the identified gaps, including developing methods for incorporating external knowledge, creating better negative sampling strategies, designing distributed and compositional models for scalability, and investigating continual learning techniques for dynamic KGs.","The paper provides a valuable overview of different architectural patterns for TKGC. The categorization itself is an implementation insight, guiding the choice of approach based on the problem. For example, tensor decomposition methods are lightweight, while snapshot-based methods using GCNs can capture complex structural dependencies. The discussion of different loss functions (margin ranking, cross-entropy) is also a practical consideration.",,,"data-integration, knowledge-graph, temporal-data",Temporal Knowledge Graph Completion: A Survey,"Cai Borui, Xiang Yong, Gao Longxiang, Zhang He, Li Yunfeng, Li Jianxin",2023,reference-manager,10.24963/ijcai.2023/734,,,,,,Time-included tensor decomposition: Represents the knowledge graph as a 4-way tensor to learn hidden patterns using tensor decomposition techniques.,,,"How can temporal knowledge graph completion (TKGC) methods effectively incorporate time validity, historical context, attention mechanisms, heuristic-based relevance, and temporal logical rules to improve link prediction accuracy and interpretability in dynamic knowledge graphs?","This paper surveys recent advances in temporal knowledge graph completion (TKGC), focusing on methods that incorporate time validity for link prediction. It categorizes TKGC approaches, highlights improved prediction with temporal information, discusses open challenges, and suggests future research directions like using external knowledge and time-aware negative sampling.","The research goal is to survey recent advances in temporal knowledge graph completion (TKGC); the approach organizes TKGC methods by how they incorporate temporal validity for link prediction; the principal finding is that while progress is significant, challenges remain, especially in prediction accuracy and dataset limitations.",,1.000,exact_title
cai_2023,Temporal Knowledge Graph Completion with Time-sensitive Relations in Hypercomplex Space,"Li Cai, Xin Mao, Zhihong Wang, Shangqing Zhao, Yuhao Zhou, Changxu Wu, Man Lan",2023,Yes,HIGH,This paper is highly relevant as it proposes a novel and more expressive method for temporal knowledge graph completion (TKGC) using quaternion representations in hypercomplex space. This directly addresses the HDM project's need for advanced temporal modeling capabilities. The focus on capturing time-sensitive relations through rotation and periodic translation offers a sophisticated technique for handling the complex temporal dynamics of personal data.,"The key insight is that modeling time-sensitive relations, rather than just time-aware entities, provides a more powerful way to capture temporal dynamics in a TKG. The use of quaternions for time-aware rotation and periodic time translation allows the model to capture complex temporal variability more effectively than methods operating in real or complex spaces.","This paper introduces a novel method for temporal knowledge graph completion (TKGC) that uses quaternion representations in hypercomplex space to model time-sensitive relations. The proposed approach, TQuatE, employs time-aware rotation and periodic time translation to capture complex temporal patterns and is theoretically shown to model a wide range of relational patterns.",How can we improve the performance of temporal knowledge graph completion by better capturing the complex temporal variability of facts?,"The authors propose TQuatE, a TKGC model that uses quaternion embeddings for entities, relations, and time. It models time-sensitive relations through a combination of time-aware rotation (using the Hamilton product) and periodic time translation (using a sine function on a periodic time embedding). The model is evaluated on three public datasets (ICEWS14, ICEWS05-15, GDELT) and compared against a range of static and temporal baseline methods.","The proposed TQuatE model achieves state-of-the-art performance on all three benchmark datasets, significantly outperforming existing methods, especially on the GDELT dataset which is known for its complex temporal variability. For example, it improves MRR over the previous state-of-the-art by up to 8.38% on GDELT.","The primary outcome is the TQuatE model, a novel and high-performing approach for TKGC. The paper also provides theoretical proofs that the model can capture symmetric, asymmetric, inverse, compositional, and evolutionary relation patterns.","The paper notes that the quaternion multiplication is more computationally expensive than complex multiplication, leading to longer training times compared to some baselines, even though the performance improvement on some datasets is marginal.","The paper concludes that leveraging the expressive power of hypercomplex space, specifically quaternions, to model time-sensitive relations is an effective strategy for improving the performance of temporal knowledge graph completion.","The paper highlights the need for more efficient methods for TKGC, as the complexity of quaternion operations can be a bottleneck. It also implicitly points to the ongoing challenge of balancing model expressiveness with computational cost.",Future work could focus on optimizing the computational efficiency of quaternion-based models for TKGC.,"The paper provides a concrete implementation of a quaternion-based TKGC model, TQuatE. The use of time-aware rotation and periodic time translation are specific techniques that can be adopted. The detailed hyperparameter analysis and complexity comparison also offer valuable insights for implementation.",https://doi.org/10.1007/3-540-44503-x_27,10.1007/3-540-44503-X_27,"Temporal Knowledge Graph, Knowledge Graph Completion, TKGC, Hypercomplex Space, Quaternion, Time-sensitive Relations, Temporal Modeling, Deep Learning","data-integration, knowledge-graph, temporal-data",,,,,,,,,,,,,,,,,,,
caia_2024,A Survey on Temporal Knowledge Graph: Representation Learning and Applications,"Li Caia, Xin Mao, Yuhao Zhou, Zhaoguang Long, Changxu Wu, Man Lana, North Zhongshan Road, Industrial Engineering",2024,Yes,HIGH,Contains relevant concepts applicable to HDM systems,"""Most current studies mainly focus on static knowledge graphs, whose facts do not change with time, and disregard their dynamic evolution over time."" Proposes incorporating ""time information into the standard knowledge graph framework"".",Comprehensive survey addressing critical temporal modeling limitations in current,"This survey addresses the limitation that most knowledge graphs are static and don't capture temporal dynamics, proposing to incorporate time information into knowledge graph frameworks to model entity and relation dynamics over time.",How can temporal information be effectively incorporated into knowledge graphs to model dynamics of entities and relations over time?,"Survey methodology covering definitions, datasets, evaluation metrics, and taxonomy of temporal knowledge graph representation learning technologies.",Comprehensive analysis of temporal knowledge graph representation learning; identification of core technologies; application exploration for temporal reasoning.,Framework for incorporating temporal dynamics into knowledge graph systems.,Survey nature limits specific algorithmic contributions; focus on existing work analysis rather than novel methods.,Establishes comprehensive understanding of temporal knowledge graph representation learning and applications.,Need for more sophisticated temporal representation techniques; better temporal reasoning capabilities.,Focus on sophisticated temporal representation and reasoning techniques for dynamic knowledge systems.,Provides comprehensive guidance for implementing temporal knowledge graph systems with dynamic entity and relation modeling.,https://arxiv.org/abs/2403.04782,arXiv:2403.04782,"ai, heterogeneous, integration, knowledge-graph, llm, machine-learning, memory, personal, semantic, survey, temporal",Enhancing Temporal Knowledge Graph Representation with Curriculum Learning,"Liu Yihe, Shen Yi, Dai Yuanfei",2024,reference-manager,10.3390/electronics13173397,,,,,,"Curriculum learning: The framework uses curriculum learning, gradually training the model on data of increasing complexity to improve performance and efficiency.",,,"How can a curriculum learning framework that progressively increases data difficulty and complexity during training enhance the performance, generalization, and robustness of temporal knowledge graph representation models?","The paper proposes a curriculum learning-guided framework for temporal knowledge graph representation. Using a difficulty assessor and curriculum temperature scaling, the method adapts training to data complexity. Experiments on ICEWS datasets show 1–2% MRR improvement and faster training, demonstrating enhanced performance, efficiency, and broad applicability.","The research goal is to improve temporal knowledge graph representation using a curriculum learning approach; the method segments training data by difficulty and adapts training progression, resulting in 1–2% higher MRR and faster training compared to baselines, demonstrating enhanced performance, efficiency, and generalization.",,0.730,fuzzy_title
callahan_2024,An open source knowledge graph ecosystem for the life sciences,"Tifany J. Callahan, Ignacio J. Tripodi, Adrianne L. Stefanski, Luca Cappelletti, Sanya B. Taneja, Jordan M. Wyrwa, Elena Casiraghi, Nicolas A. Matentzoglu, Justin Reese, Jonathan C. Silverstein, Charles Tapley Hoyt, Richard D. Boyce, Scott A. Malec, Deepak R. Unni, Marcin P. Joachimiak, Peter N. Robinson, Christopher J. Mungall, Emanuele Cavalleri, Tommaso Fontana, Giorgio Valentini, Marco Mesiti, Lucas A. Gillenwater, Brook Santangelo, Nicole A. Vasilevsky, Robert Hoehndorf, Tellen D. Bennett, Patrick B. Ryan, George Hripcsak, Michael G. Kahn, Michael Bada, William A. Baumgartner Jr✉& Lawrence E. Hunter",2024,Yes,LOW,Tangentially related to knowledge management or data systems,Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on an open source knowledge graph ecosystem for the life sciences providing insights for knowledge graph development and data integration.,"This 2024 paper by Tifany J. Callahan, Ignacio J. Tripodi, Adrianne L. Stefanski, Luca Cappelletti, Sanya B. Taneja, Jordan M. Wyrwa, Elena Casiraghi, Nicolas A. Matentzoglu, Justin Reese, Jonathan C. Silverstein, Charles Tapley Hoyt, Richard D. Boyce, Scott A. Malec, Deepak R. Unni, Marcin P. Joachimiak, Peter N. Robinson, Christopher J. Mungall, Emanuele Cavalleri, Tommaso Fontana, Giorgio Valentini, Marco Mesiti, Lucas A. Gillenwater, Brook Santangelo, Nicole A. Vasilevsky, Robert Hoehndorf, Tellen D. Bennett, Patrick B. Ryan, George Hripcsak, Michael G. Kahn, Michael Bada, William A. Baumgartner Jr✉& Lawrence E. Hunter explores an open source knowledge graph ecosystem for the life sciences. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,https://doi.org/10.1101/2023.02.11.528088,10.1101/2023.02.11.528088,"ai, children, healthcare, heterogeneous, integration, knowledge-graph, machine-learning, memory, ontology, pediatric, personal, semantic, survey",An open source knowledge graph ecosystem for the life sciences,"Callahan Tiffany J., Tripodi Ignacio J., Stefanski Adrianne L., Cappelletti Luca, Taneja Sanya B., Wyrwa Jordan M., Casiraghi Elena, Matentzoglu Nicolas A., Reese Justin, Silverstein Jonathan C., Hoyt Charles Tapley, Boyce Richard D., Malec Scott A., Unni Deepak R., Joachimiak Marcin P., Robinson Peter N., Mungall Christopher J., Cavalleri Emanuele, Fontana Tommaso, Valentini Giorgio, Mesiti Marco, Gillenwater Lucas A., Santangelo Brook, Vasilevsky Nicole A., Hoehndorf Robert, Bennett Tellen D., Ryan Patrick B., Hripcsak George, Kahn Michael G., Bada Michael, Baumgartner William A., Hunter Lawrence E.",2024,reference-manager,10.1038/s41597-024-03171-w,,,,,,"Systematic comparison: Methods were systematically compared using a survey based on five criteria—KG construction functionality, maturity, availability, usability, and reproducibility.",,,"How does PheKnowLator enable the automated, FAIR construction and analysis of ontologically grounded biomedical knowledge graphs, and how does it compare to existing open-source KG construction methods in terms of functionality, usability, maturity, availability, and reproducibility?","The paper presents PheKnowLator, a semantic ecosystem for automating the FAIR construction of ontologically grounded knowledge graphs (KGs). Using a systematic survey of 16 open-source KG construction methods, the study found PheKnowLator comparable or superior in functionality, usability, maturity, and reproducibility, highlighting its flexibility and advanced features.","The paper's main objective was to systematically compare open-source biomedical knowledge graph (KG) construction methods; using a survey-based approach, it evaluated 15 tools across five criteria, and found that PheKnowLator offers unique features for quality assessment, flexible KG construction, and advanced analysis compared to other methods.",,1.000,exact_title
cao_2020,Building and Using Personal Knowledge Graph to Improve Suicidal Ideation Detection on Social Media,"Lei Cao, Huijun Zhang, Ling Feng",2020,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Addresses data implicitness and sparsity challenges in social media analysis; enables deeper understanding of individual's social media signals; integrates multiple personal factor dimensions.,Novel application of PKGs for suicidal ideation detection achieving over 93% accuracy through integration of personal factors and deep neural networks.,"This paper constructs a suicide-oriented knowledge graph combined with deep neural networks for suicidal ideation detection on social media, using a two-layered attention mechanism to reason about key risk factors and achieving over 93% accuracy on microblog and Reddit data.",How can personal knowledge graphs improve suicidal ideation detection on social media platforms?,"Constructed suicide-oriented knowledge graph, integrated deep neural networks, implemented two-layered attention mechanism, analyzed personal factors across social media platforms.","Achieved over 93% accuracy in suicidal ideation detection; identified top 3 key personal factor indicators: post content, personality, and personal experience.",,Platform-specific detection approach; relies on social media data comprehensiveness.,Demonstrates practical application of PKGs for mental health monitoring with high accuracy in risk detection.,,"Expand PKG across more platforms, refine attention mechanism, develop more nuanced risk factor identification.",Provides practical implementation of PKG for healthcare applications with focus on multi-dimensional personal factor analysis and attention mechanisms.,https://arxiv.org/abs/2012.09123,10.48550/arXiv.2012.09123,"deep-learning, mental-health-tech, personal-knowledge-graph, social-media-analysis, suicidal-ideation",Building and Using Personal Knowledge Graph to Improve Suicidal Ideation Detection on Social Media,"Cao Lei, Zhang Huijun, Feng Ling",2020,reference-manager,,,"Implementation Insights highlight that lower data noise leads to higher detection performance. The knowledge graph (KG)-based method consistently outperforms others, achieving up to 94.53% accuracy. Key properties in information gain are crucial for risk analysis. Limitations include insufficient personal data and challenges with noisy, sparse social media data.",,,,Ablation study: Compared model performance with and without the user knowledge graph to assess its impact.,,,"How can a structured personal suicide-oriented knowledge graph, unified with deep neural networks and attention mechanisms, improve the accuracy of suicidal ideation detection on social media by identifying and weighting key personal risk factors?","The study aims to detect suicidal ideation using social media data, achieving over 93% accuracy and F1-measure. It identifies posts, personality, and experience as key indicators, with posted texts and stress levels most significant. Limitations include insufficient data and noise. The research suggests further exploration beyond social media.","The research goal is to improve suicidal ideation detection by integrating a personal suicide-oriented knowledge graph; the approach uses a KG-based method combining multiple data modalities; results show the KG-based method significantly outperforms others, with up to 7.58% higher accuracy and F1-measure compared to methods without the knowledge graph.",,1.000,exact_title
carbonaro_2023,CONNECTED: leveraging digital twins and personal knowledge graphs in healthcare digitalization,"Antonella Carbonaro, Alberto Marfoglia, Filippo Nardini, Sabato Mellone",2023,Yes,HIGH,Directly addresses HDM/PKG concepts with focus on personal data management,"Proposes CONNECTED framework with four-layer architecture (Source, Standard, Digital Twin, Application layers) using technologies like Eclipse Hono, Apache Kafka, and Stardog for creating general-purpose patient digital twins accessible through APIs with semantic reasoning capabilities.",Multi-layer framework for healthcare digitalization that integrates digital twins and personal knowledge graphs to overcome technical and organizational barriers while ensuring interoperability and data standardization.,"This paper addresses challenges in healthcare digitalization by proposing the CONNECTED (COmpreheNsive and staNdardized hEalth-Care plaTforms to collEct and harmonize clinical Data) framework, a conceptual multi-level architecture aimed at integrating heterogeneous data sources using modern healthcare standards. The framework creates general-purpose patient digital twins using Personal Knowledge Graphs that support API-accessible applications for specific tasks, services, and simulations while ensuring data integrity, privacy control, and standards compliance.",How can digital twins and personal knowledge graphs be effectively integrated in healthcare digitalization to overcome technical and organizational barriers while ensuring interoperability and data standardization?,"Developed CONNECTED framework with four-layer architecture: Source Layer for data collection, Standard Layer for harmonization using FHIR, Digital Twin Layer for patient digital twins using PKGs, Application Layer for custom applications, implemented using Eclipse Hono, Apache Kafka, Stardog technologies.","Demonstrated framework capability through fall prediction use case in elderly patients with osteoporosis, showed effective integration of diverse data sources, provided semantic reasoning capabilities for deriving insights from patient data, established foundation for open-source prototype development.",Multi-layer healthcare digitalization framework with comprehensive patient digital twin capabilities and standards-based interoperability for diverse healthcare applications.,"Challenges in ensuring data integrity and reliability, complexity in managing privacy and access control, need for addressing legal and ethical considerations in healthcare data processing, requirements for extensive validation across diverse healthcare scenarios.","Provides novel approach to healthcare digitalization creating flexible, standards-based framework for patient digital twins that enables comprehensive patient modeling while maintaining interoperability and compliance with healthcare standards.","Need for concrete implementation and extensive validation, investigation of computational model integration for enhanced capabilities, development of simulation capabilities in digital twins, broader assessment across diverse healthcare institutions.","Develop concrete implementation with comprehensive validation studies, investigate computational model integration for enhanced digital twin capabilities, enable advanced simulation capabilities, assess scalability across diverse healthcare institutions.","Offers architectural guidance for implementing digital twin and PKG integration in healthcare with focus on standards compliance, semantic reasoning, and interoperability essential for HDM healthcare digitalization applications.",https://doi.org/10.3389/fdgth.2023.1322428,10.3389/fdgth.2023.1322428,"ai, digital-twin, healthcare, heterogeneous, integration, knowledge-graph, machine-learning, personal, privacy, semantic, survey",CONNECTED: leveraging digital twins and personal knowledge graphs in healthcare digitalization,"Carbonaro Antonella, Marfoglia Alberto, Nardini Filippo, Mellone Sabato",2023,reference-manager,10.3389/fdgth.2023.1322428,,,,,,"Use of Eclipse Hono for integrating and communicating with various IoT devices, supporting multiple protocols and custom data transformation.",,,"How can a modular, standardized architectural framework like CONNECTED, integrating Personal Knowledge Graphs and Digital Twins, address challenges of data fragmentation, interoperability, and secure data management to improve healthcare applications and patient-centric services?","The paper proposes CONNECTED, a modular framework to integrate diverse healthcare data using modern standards, enabling general-purpose Digital Twins (DTs) supported by Personal Knowledge Graphs (PKGs). The methodology involves adopting technologies like Eclipse Hono, Apache Kafka, and Stardog. Results highlight PKGs’ effectiveness for semantic data modeling. The framework’s implications include improved patient-centric applications and data interoperability.","The research goal is to address healthcare data fragmentation by proposing CONNECTED, a multi-level architectural framework using Digital Twins and Personal Knowledge Graphs for data integration; the approach leverages technologies like Eclipse Hono, Apache Kafka, and Stardog, with results focused on enabling interoperable, patient-centric digital health ecosystems.",,1.000,exact_title
castilloescamilla_2024,The Role of Physical Activity on Spatial and Temporal Cognitive Processing in Young Women,"Joaquín Castillo-Escamilla, María del Mar Salvador-Viñas, José Manuel Cimadevilla",2024,Yes,LOW,Tangentially related to knowledge management or data systems,"Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on the role of physical activity on spatial and temporal cognitive processing in young women providing insights for knowledge graph development and data integration.,"This 2024 paper by Joaquín Castillo-Escamilla, María del Mar Salvador-Viñas, José Manuel Cimadevilla explores the role of physical activity on spatial and temporal cognitive processing in young women. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3390/brainsci15050431,"knowledge-graph, machine-learning, mental-health, temporal",The Role of Physical Activity on Spatial and Temporal Cognitive Processing in Young Women,"Castillo-Escamilla Joaquín, Salvador-Viñas María del Mar, Cimadevilla José Manuel",2025,reference-manager,10.3390/brainsci15050431,,,,,,"Repeated measures ANOVA was used to analyze group (athlete/sedentary), type (faster/slower), and time (above/below 1000 ms) effects on accuracy and response times in the Time Comparison Task.",,,"How does physical activity influence time processing in young female adults, and is this influence similar to its effects on spatial processing?","The study aimed to compare spatial and temporal cognitive performance between physically active and sedentary female students. Using repeated measures ANOVA on Time Comparison and Boxes Room tasks, it analyzed accuracy, response times, errors, and latencies. The methodology included group comparisons and correlation analyses to assess relationships between variables.","The research goal was to examine the benefits of physical activity on time processing in young female adults using the Time Comparison Task and spatial memory measures; the approach involved comparing physically active and sedentary groups, and the principal finding was that physical activity improved time processing, paralleling spatial memory results.",,1.000,exact_title
castro_2019,Research Knowledge Graphs: the Shifting Paradigm of Scholarly Information Representation,"Leyla Jael Castro, Benjamin Zapilko, Saurav Karmakar, Brigitte Mathiak, Markus Stocker, Wolfgang Otto",2019,Yes,MEDIUM,Contains relevant concepts applicable to HDM systems,Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on research knowledge graphs: the shifting paradigm of scholarly information representation providing insights for knowledge graph development and data integration.,"This 2019 paper by Leyla Jael Castro, Benjamin Zapilko, Saurav Karmakar, Brigitte Mathiak, Markus Stocker, Wolfgang Otto explores research knowledge graphs: the shifting paradigm of scholarly information representation. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,https://doi.org/10.15488/13072,10.15488/13072,"ai, healthcare, heterogeneous, integration, knowledge-graph, llm, machine-learning, ontology, personal, semantic, survey",Research Knowledge Graphs: The Shifting Paradigm of Scholarly Information Representation,"Zloch Matthäus, Dessì Danilo, D’Souza Jennifer, Castro Leyla Jael, Zapilko Benjamin, Karmakar Saurav, Mathiak Brigitte, Stocker Markus, Otto Wolfgang, Auer Sören, Dietze Stefan",2025,reference-manager,10.1007/978-3-031-94578-6\_8,,,,,,Use of quality-controlled ground truth datasets for scholarly information extraction tasks.,,,"How do Research Knowledge Graphs (RKGs) transform the representation, integration, and citability of scholarly research artifacts and entities, and what are their applications, challenges, and future roles in advancing the scholarly domain?","The paper investigates Research Knowledge Graphs (RKGs), focusing on their role in representing, interlinking, and crediting diverse research artifacts. Using Semantic Web practices, the study reviews RKG applications, construction methodologies, and challenges, concluding that RKGs enhance transparency, reproducibility, and knowledge discovery in scholarly research.","The paper's research goal is to investigate, describe, and categorize Research Knowledge Graphs (RKGs) for scholarly information; its approach involves analyzing RKG examples, construction methods, and challenges; its principal finding is that RKGs enhance research transparency, interoperability, and traceability by interlinking diverse scholarly artifacts using standardized semantic technologies.",,1.000,exact_title
chakraborty_2022,Personal Research Knowledge Graphs,"Prantika Chakraborty, Sudakshina Dutta, Debarshi Kumar Sanyal",2022,Yes,HIGH,Directly addresses HDM/PKG concepts with focus on personal data management,Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on personal research knowledge graphs providing insights for knowledge graph development and data integration.,"This 2022 paper by Prantika Chakraborty, Sudakshina Dutta, Debarshi Kumar Sanyal explores personal research knowledge graphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"ai, knowledge-graph, machine-learning, personal, privacy, semantic, survey, temporal",Personal Health Knowledge Graphs for Patients,"Rastogi Nidhi, Zaki Mohammed J.",2020,reference-manager,,,"Implementation Insights highlight that most approaches use brute force to generate Personal Health Knowledge Graphs (PHKGs), often inferring patient preferences from general Knowledge Graphs (KGs). Challenges include static summaries, limited entity updates, device constraints, and lack of scalable, dynamic PHKG creation. New insight: hybrid patient-clinician collaboration is suggested.",,,,Literature review of Knowledge Graph (KG) approaches for extracting personal context from patient data.,,,"How can Personal Health Knowledge Graphs (PHKGs) be effectively generated, represented, and integrated with existing knowledge bases to provide personalized health recommendations, while addressing challenges related to data heterogeneity, scalability, validation, and patient-specific requirements?","The paper reviews and critiques methods for extracting personal context from patient data using small-sized Personal Health Knowledge Graphs (PHKGs). It discusses methodologies like summarizing patient data, dynamic PHKG creation, and integrating heterogeneous sources. Key findings highlight challenges in scalability, representation, and validation. The study concludes that further research is needed to address these issues.","The paper's main objective is to review and critique methods for extracting personal context from patient data using small-sized Personalized Health Knowledge Graphs (PHKGs); it evaluates existing approaches and highlights challenges, concluding that further research is needed to improve dynamic, scalable, and accurate PHKG construction for health recommendations.",,0.773,fuzzy_title
chakraborty_2023,A Comprehensive Survey of Personal Knowledge Graphs,"Prantika Chakraborty, Debarshi Kumar Sanyal",2023,Yes,HIGH,Directly addresses HDM/PKG concepts with focus on personal data management,Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on a comprehensive survey of personal knowledge graphs providing insights for knowledge graph development and data integration.,"This paper provides a comprehensive overview of the state-of-the-art in personal knowledge graphs (PKGs), covering their definition, lifecycle, and applications. It discusses the challenges and opportunities in this emerging field.",What is the state-of-the-art in personal knowledge graphs?,Systematic literature review,"The paper identifies key research themes and challenges in PKG research, including data integration, privacy, and user interaction.",The paper provides a roadmap for future research in PKGs.,The paper does not propose a specific solution but rather provides a comprehensive overview of the field.,The paper provides a comprehensive overview of the state-of-the-art in PKGs and identifies key research challenges.,The paper highlights the need for more research on data integration and privacy in PKGs.,The paper suggests that future work should focus on developing more user-friendly and privacy-preserving PKG solutions.,The paper provides a good overview of the design considerations for PKGs.,https://doi.org/10.1002/widm.1513,10.1002/widm.1513,"ai, children, knowledge-graph, llm, machine-learning, memory, ontology, pediatric, personal, privacy, semantic, survey, temporal",A comprehensive survey of personal knowledge graphs,"Chakraborty Prantika, Sanyal Debarshi Kumar",2023,reference-manager,10.1002/widm.1513,,,,,"Bias in conversations: algorithmic bias, people-centric bias, and their combination.",,,"No source code is provided. Data sharing is not applicable as no new data were created or analyzed. Therefore, the reproducibility of the research is limited.",,,"The paper's main objective is to survey literature on Personal Knowledge Graphs (PKGs), categorizing their applications, discussing construction methods from user data, and highlighting limitations, with the key finding that PKGs serve as personalized information databases with diverse applications and future improvement opportunities.",,1.000,exact_title
challenges_2005,MARK: Memory Augmented Refinement of Knowledge,To overcome these challenges,2005,Yes,MEDIUM,Contains relevant concepts applicable to HDM systems,Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on mark: memory augmented refinement of knowledge providing insights for knowledge graph development and data integration.,"This 2005 paper by To overcome these challenges explores mark: memory augmented refinement of knowledge. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"ai, healthcare, integration, knowledge-graph, llm, machine-learning, memory, personal, semantic, survey, temporal",MARK: Memory Augmented Refinement of Knowledge,"Ganguli Anish, Deb Prabal, Banerjee Debleena",2023,reference-manager,,,,,,,,,,,,{{,,1.000,exact_title
challenges_2021,"XIN PENG, Fudan University, China CHONG WANG, Fudan University, China MINGWEI LIU, Sun Yat-sen University, China YILING LOU, Fudan University, China YIJIAN WU, Fudan University, China","To address these challenges, we propose the concept, framework of Code Digital Twin, a conceptual representation of tacit knowledge that encapsulates the concepts, functionalities, design rationales behind code elements, co-evolving with the software. The framework structures tacit knowledge into two key categories: the artifact-oriented backbone, which establishes a foundational structure by linking concepts, functionalities to software artifacts, the rationale-centric explanations, which enrich this foundation by capturing the decisions that have shaped the system's design, evolution. The methodology for realizing a code digital twin combines structured, unstructured knowledge representations, integrating knowledge graphs, frames, textual descriptions to capture domain concepts",2021,Yes,MEDIUM,Contains relevant concepts applicable to HDM systems,Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on xin peng, fudan university, china chong wang, fudan university, china mingwei liu, sun yat-sen university, china yiling lou, fudan university, china yijian wu, fudan university, china providing insights for knowledge graph development and data integration.","This 2021 paper by To address these challenges, we propose the concept, framework of Code Digital Twin, a conceptual representation of tacit knowledge that encapsulates the concepts, functionalities, design rationales behind code elements, co-evolving with the software. The framework structures tacit knowledge into two key categories: the artifact-oriented backbone, which establishes a foundational structure by linking concepts, functionalities to software artifacts, the rationale-centric explanations, which enrich this foundation by capturing the decisions that have shaped the system's design, evolution. The methodology for realizing a code digital twin combines structured, unstructured knowledge representations, integrating knowledge graphs, frames, textual descriptions to capture domain concepts explores xin peng, fudan university, china chong wang, fudan university, china mingwei liu, sun yat-sen university, china yiling lou, fudan university, china yijian wu, fudan university, china. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,https://doi.org/10.1145/3611643.3616317,10.1145/3611643.3616317,"ai, digital-twin, integration, knowledge-graph, llm, machine-learning, semantic, survey",,,,,,,,,,,,,,,,,,,
chami_2003,A SysML-based Integration Framework for the Engineering of Mechatronic Systems,Mohammad Chami,2003,Yes,LOW,"This paper is only tangentially relevant as it discusses a SysML-based integration framework for mechatronic systems, with limited direct application to knowledge management or data-centric HDM systems.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on a sysml-based integration framework for the engineering of mechatronic systems providing insights for knowledge graph development and data integration.,"This 2003 paper by Mohammad Chami explores a sysml-based integration framework for the engineering of mechatronic systems. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"ai, integration, machine-learning",A SysML-based Integration Framework for the Engineering of Mechatronic Systems,"Chami Mohammad, Seemüller Holger, Voos Holger",2023,reference-manager,,,,,,,"V-model: A process model divided into four phases—requirements, system design, domain-specific design, and integration—used to structure interdisciplinary engineering and validation.",,,"How can an integrated framework based on SysML and the V-model improve interdisciplinary collaboration, data integration, and knowledge-sharing in the engineering process of mechatronic systems?","The paper aims to address the complexity and interdisciplinary challenges in mechatronic system engineering by proposing a SysML-based integration framework. Using the V-model process and SysML for system design, the approach improves collaboration, manages complexity, and supports model-based engineering. The framework enhances communication and understanding among engineers.","The paper's main objective is to improve collaboration in mechatronic engineering by integrating domain-specific models using a SysML-based framework, with the key method being the unification of models under a distributed SysML system model, and the principal finding is enhanced knowledge-sharing, traceability, and interdisciplinary communication.",,1.000,exact_title
chan_2024,Multi-task Heterogeneous Graph Learning on Electronic Health Records,"Tsai Hor Chan, Guosheng Yin, Kyongtae Bae, Lequan Yua, Hong Kong, Pokfulam Road, Diagnostic Radiology",2024,Yes,HIGH,Contains relevant concepts applicable to HDM systems,"Proposes MulT-EHR framework using heterogeneous graphs to model complex EHR interactions with causal inference-based denoising and multi-task learning, consistently outperforming state-of-the-art across four healthcare prediction tasks.",Multi-task learning framework for heterogeneous electronic health record analysis,"This paper addresses challenges in electronic health record (EHR) analysis including data heterogeneity, sparsity, and complexity by proposing MulT-EHR, a multi-task learning framework that leverages heterogeneous graphs to model complex EHR interactions. The approach incorporates a causal inference-based denoising module to reduce confounding effects and implements inter-task knowledge regularization to improve prediction performance across multiple healthcare tasks simultaneously.","How can heterogeneous graph neural networks effectively handle complex, noisy EHR data for multi-task healthcare prediction while addressing data sparsity and confounding effects?","Developed MulT-EHR framework with heterogeneous graph modeling, implemented causal inference-based denoising module, applied inter-task knowledge regularization, evaluated on MIMIC-III and MIMIC-IV datasets across four prediction tasks.","Consistently outperforms state-of-the-art methods across drug recommendation, length of stay prediction, mortality prediction, and readmission prediction tasks; demonstrates robustness to component variations and hyperparameter changes.",Multi-task heterogeneous graph learning framework for EHR analysis with superior performance across multiple healthcare prediction tasks and improved robustness to data noise.,Evaluation limited to specific MIMIC datasets; potential challenges in generalizing to other healthcare systems; computational complexity considerations for large-scale deployment not fully addressed.,Successfully demonstrates that heterogeneous graph neural networks with causal denoising can significantly improve multi-task healthcare prediction while handling complex EHR data characteristics.,Need for broader evaluation across diverse healthcare systems; investigation of computational efficiency for real-world deployment; exploration of additional healthcare prediction tasks.,Extend framework to additional healthcare datasets and prediction tasks; optimize computational efficiency for large-scale deployment; investigate integration with existing clinical decision support systems.,"Provides technical framework for heterogeneous health data integration using graph neural networks, demonstrating multi-task learning capabilities essential for comprehensive personal health knowledge systems.",https://arxiv.org/abs/2408.07569,arXiv:2408.07569,"ai, healthcare, heterogeneous, knowledge-graph, machine-learning, memory, personal, semantic, survey, temporal",Multi-task heterogeneous graph learning on electronic health records,"Chan Tsai Hor, Yin Guosheng, Bae Kyongtae, Yu Lequan",2024,reference-manager,10.1016/j.neunet.2024.106644,,,,,"EHR data presents challenges of heterogeneity, sparsity, and complexity, making feature representation learning difficult.",,,,,,"The research goal is to improve predictive performance on EHR tasks using a unified multi-task graph learning approach (MulT-EHR); the method employs shared-weight multi-task learning with robust hyperparameter tuning, and results show MulT-EHR outperforms all compared single- and multi-task baselines across multiple benchmarks.",,1.000,exact_title
chang_2021,Sequential Recommendation with Graph Neural Networks,"Jianxin Chang, Chen Gao, Yu Zheng, Yiqun Hui, Yanan Niu, Yang Song, Depeng Jin, Yong Li",2021,Yes,HIGH,Tangentially related to knowledge management or data systems,SURGE creates tight item-item interest graphs from loose sequences using metric learning; implements cluster-aware and query-aware graph propagation; successfully handles noisy preference signals and rapid preference changes; demonstrates significant performance gains,Graph neural network approach for sequential recommendation that clusters user,"This paper presents SURGE (Sequential Recommendation with Graph Neural Networks) to address two key challenges in sequential recommendation: implicit and noisy preference signals in user behavior, and rapidly changing user preferences. SURGE reconstructs loose item sequences into tight item-item interest graphs using metric learning, creating dense interest clusters to distinguish core user interests. The method applies cluster-aware and query-aware graph convolutional propagation to dynamically extract users' current activated interests from noisy behavioral sequences. Experimental validation on public and industrial datasets demonstrates significant performance gains compared to state-of-the-art methods.",How to extract meaningful user interests from noisy behavioral sequences while handling rapidly changing user preferences in sequential recommendation?,Metric learning for interest graph construction; cluster-aware and query-aware graph convolutional propagation; dense interest clustering; dynamic interest extraction from noisy sequences,Significant performance gains compared to state-of-the-art methods; effective handling of noisy preference signals; successful modeling of rapidly changing user preferences; validated on both public and industrial datasets,SURGE framework for graph-based sequential recommendation; interest clustering approach; noise-robust preference extraction; dynamic user interest modeling,Framework complexity requires careful implementation; evaluation methodology details not fully specified; computational overhead of interest clustering not characterized,Graph-based interest clustering effectively addresses fundamental challenges in sequential recommendation by extracting meaningful patterns from noisy user behavior and adapting to preference changes,Challenges in handling noisy preference signals in user behavior; rapidly changing user preferences difficult to capture; need for robust sequential recommendation frameworks,Investigate real-time recommendation deployment; optimize interest clustering efficiency; explore domain-specific interest modeling approaches,Reconstructs item sequences into interest graphs using metric learning; provides noise-robust approach to preference extraction; enables dynamic adaptation to changing user interests,https://arxiv.org/abs/2106.14226,10.48550/arXiv.2106.14226,"ai, heterogeneous, integration, knowledge-graph, memory, personal, semantic, survey, temporal",Sequential Recommendation with Graph Neural Networks,"Chang Jianxin, Gao Chen, Zheng Yu, Hui Yiqun, Niu Yanan, Song Yang, Jin Depeng, Li Yong",2021,reference-manager,10.1145/3404835.3462968,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
chavesfraga_2024,Are Knowledge Graphs Ready for the Real World? Challenges and Perspectives,"David Chaves-Fraga, Oscar Corcho, Anastasia Dimou, Maria-Esther Vidal, Ana Iglesias-Molina, Dylan Van Assche",2024,Yes,HIGH,Directly addresses HDM/PKG concepts with focus on personal data management,Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on are knowledge graphs ready for the real world? challenges and perspectives providing insights for knowledge graph development and data integration.,"This 2024 paper by David Chaves-Fraga, Oscar Corcho, Anastasia Dimou, Maria-Esther Vidal, Ana Iglesias-Molina, Dylan Van Assche explores are knowledge graphs ready for the real world? challenges and perspectives. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.4230/DagRep.14.2.1,"blockchain, data-integration, federated-learning, knowledge-graph, machine-learning, personal-health, privacy, semantic-web",Are Knowledge Graphs Ready for the Real World? Challenges and Perspective,"Chaves-Fraga David, Corcho Oscar, Dimou Anastasia, Vidal Maria-Esther, Iglesias-Molina Ana, Van Assche Dylan",2024,reference-manager,,,,,,Lack of standard access control mechanisms in KG systems.,,,,"Are knowledge graphs ready for real-world applications, and what are the main social and technical challenges—including privacy, quality, governance, and stakeholder engagement—that must be addressed to enable their effective construction, maintenance, and use across diverse contexts?",,"The paper's main objective is to enable semantic orchestration of digital twins using the SMOL language; its key method is semantic lifting of program states to RDF for semantic reflection; the principal finding is that this approach maintains a coherent semantic view and type safety, demonstrated in geological process simulation.","Keywords and phrases: access control and privacy, federated query processing, intelligent knowledge graph management, programming paradigms for knowledge graphs, semantic data integration.",0.900,fuzzy_title
chen_2020,A Survey on Collaborative Mechanisms Between Large and Small Language Models,"Yi Chen, JiaHao Zhao, HaoHao Han, Computer Applications",2020,Yes,HIGH,Directly addresses HDM/PKG concepts with focus on personal data management,Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a survey on collaborative mechanisms between large and small language models providing insights for knowledge graph development and data integration.,"This 2020 paper by Yi Chen, JiaHao Zhao, HaoHao Han, Computer Applications explores a survey on collaborative mechanisms between large and small language models. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"ai, federated, healthcare, heterogeneous, integration, knowledge-graph, llm, machine-learning, memory, personal, privacy, semantic, survey",A Survey on Collaborative Mechanisms Between Large and Small Language Models,"Chen Yi, Zhao JiaHao, Han HaoHao",2025,reference-manager,,,,,,,"Model Fusion and Result Integration: Techniques like weight averaging, ensemble learning, and majority voting are used to merge model parameters or outputs, creating unified systems that leverage the strengths of both LLMs and SLMs.",,,"How can collaborative mechanisms between large and small language models be designed and optimized to leverage their complementary strengths, address key challenges such as efficiency, consistency, and privacy, and enable broader, more effective applications across diverse real-world scenarios?","The paper explores collaborative mechanisms between large and small language models, aiming to create smarter, more integrated systems. It reviews methods like dynamic task allocation, structured communication, model fusion, and state synchronization. Key findings highlight improved efficiency and flexibility but note challenges in consistency, evaluation, and security. Future research directions are outlined.","The paper's research goal is to systematically review large-small language model collaboration; it uses a survey approach to analyze collaboration modes and key technologies, and concludes that such collaboration can enhance efficiency and applicability but faces challenges in efficiency, consistency, evaluation, and security.",,1.000,exact_title
chen_2022,Integrating Manifold Knowledge for Global Entity Linking with Heterogeneous Graphs,"Zhibin Chen, Yuting Wu, Yansong Feng",2022,Yes,MEDIUM,Contains relevant concepts applicable to HDM systems,"Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on integrating manifold knowledge for global entity linking with heterogeneous graphs providing insights for knowledge graph development and data integration.,"This 2022 paper by Zhibin Chen, Yuting Wu, Yansong Feng explores integrating manifold knowledge for global entity linking with heterogeneous graphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,https://doi.org/10.1162/dint_a_00116,10.1162/dint_a_00116,"ai, heterogeneous, integration, knowledge-graph, machine-learning, semantic, survey","Heterogeneous Graphs""","Chen Zhibin, Wu Yuting, Feng Yansong, Zhao Dongyan",2022,reference-manager,10.1162/dint\_a\_00116,,,,,Residual connection with K = 2 drops both in-domain and cross-domain performance.,,,,How can heterogeneous graph neural networks be leveraged to improve global entity linking by modeling and integrating diverse types of information within documents?,,"The research goal is to improve global entity linking; the approach uses HEGEL, a heterogeneous graph neural network that models interactions among diverse information sources; results show HEGEL achieves state-of-the-art performance in entity linking tasks.",Keywords: Entity linking; Heterogeneous graph; Graph neural network; Entity disambiguation; Knowledge base,0.900,fuzzy_title
chen_2023a,"Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities","Jiaoyan Chen, Hang Dong, Janna Hastings, Ernesto Jiménez-Ruiz, Vanessa López, Pierre Monnin, Catia Pesquita, Petr Škoda, Valentina Tamma",2023,Yes,HIGH,"This survey provides a comprehensive overview of the state-of-the-art in knowledge graphs for the life sciences, covering construction, management, knowledge discovery, and explainable AI. Its focus on integrating heterogeneous data and addressing challenges like scalability and data quality is directly aligned with the core research themes of the HDM project.","The paper highlights the critical role of KGs in managing and interpreting vast amounts of complex, relational data in the life sciences. It underscores the need for advanced knowledge-driven technologies to facilitate scientific discovery. The discussion on challenges like data heterogeneity, scalability, and explainability provides a clear roadmap for future research in the field.","A comprehensive survey on the use of knowledge graphs in life sciences, covering their construction, application in knowledge discovery, and role in explainable AI, while outlining key challenges and future directions.","This survey and position paper provides a detailed overview of the recent developments, challenges, and opportunities for using knowledge graphs (KGs) in the life sciences. The authors focus on three main areas: the construction and management of KGs, the use of KGs for knowledge discovery, and the application of KGs in explainable AI. The paper discusses various use cases, highlights key challenges such as data heterogeneity, scalability, and the need for human-in-the-loop systems, and sets out a vision for the future impact of these technologies on scientific discovery.","What are the recent developments, challenges, and opportunities in the use of knowledge graphs for the life sciences, particularly in the areas of KG construction, knowledge discovery, and explainable AI?","The paper is a survey and position paper. The authors conducted a comprehensive literature review, analyzed existing research, and synthesized the findings to provide an overview of the field. They use exemplary use cases to illustrate key concepts and challenges.","The paper identifies several key findings, including: the increasing importance of KGs for integrating heterogeneous data in life sciences; the need for scalable and automated methods for KG construction and maintenance; the potential of KGs to accelerate scientific discovery through advanced data analytics and machine learning; and the crucial role of KGs in developing explainable AI systems for healthcare and other life science applications.","The primary outcome is a comprehensive survey and position paper that provides a clear overview of the state-of-the-art in KGs for the life sciences. It serves as a valuable resource for researchers and practitioners by identifying key challenges, open research questions, and future directions.","As a survey paper, it does not present novel experimental results. The scope is broad, which means that some topics are not covered in great depth. The rapid pace of research in this field means that some of the discussed approaches may have been superseded by newer methods.","Knowledge graphs are a powerful and effective method for representing and reasoning with heterogeneous data in the life sciences. In combination with modern machine learning and NLP techniques, KGs will become a foundational technology for AI in the life sciences, enabling more reliable scientific discovery and more explainable AI systems.","The paper identifies several research gaps, including the need for better methods for handling data heterogeneity and evolution, ensuring the quality and reliability of KGs, developing more scalable and efficient KG management systems, and creating more effective methods for integrating KGs with machine learning models to support explainable AI.","Future work should focus on addressing the identified challenges, such as developing more robust and scalable methods for KG construction and maintenance, exploring new techniques for knowledge discovery, and creating more advanced methods for explainable AI. There is also a need to investigate the use of KGs in personalized medicine and other emerging areas of the life sciences.","The paper provides several implementation insights, such as the importance of using standardized ontologies and vocabularies, the need for automated tools for KG construction and maintenance, and the value of integrating KGs with machine learning pipelines. It also highlights the importance of human-in-the-loop approaches to ensure the quality and reliability of KGs.",https://doi.org/10.4230/TGDK.1.1.5,10.4230/TGDK.1.1.5,"data-integration, explainable-ai, knowledge-discovery, knowledge-graph, life-sciences, ontology, semantic-web, survey",,,,,,,,,,,,,,,,,,,
chen_2023b,Local-Global History-aware Contrastive Learning for Temporal Knowledge Graph Reasoning,"Wei Chen, Huaiyu Wan, Yuting Wu ∗, Shuyuan Zhao, Jiayaqi Cheng, Yuxin Li, Youfang Lin",2023,Yes,HIGH,"Directly addresses temporal modeling in knowledge graphs with focus on historical information encoding and noise resistance, critical for HDM temporal context challenges",Entity-aware attention mechanisms improve temporal reasoning; Contrastive learning enhances noise resistance in TKG; Historical information fusion is crucial for accurate future predictions,Improves temporal knowledge graph reasoning through local-global history-aware,"Temporal knowledge graphs (TKGs) represent fact dynamics over time, with significant potential for predicting future events. Current methods struggle with effectively encoding historical information and handling noisy inputs. The researchers propose LogCL, a novel contrastive learning approach that improves historical information processing and model robustness. The LogCL model introduces an entity-aware attention mechanism and four historical query contrast patterns to address existing limitations. By better capturing key historical context and resisting interference, the approach demonstrates superior performance across benchmark datasets.",How to improve temporal knowledge graph (TKG) reasoning by addressing challenges in historical information encoding and noise resistance,Proposed LogCL (Local-Global History-aware Contrastive Learning) model; Used entity-aware attention mechanism; Implemented four historical query contrast patterns,Demonstrated better and more robust performance than state-of-the-art baselines; Improved extrapolation of unknowable future facts in temporal knowledge graphs,LogCL model; Enhanced historical information encoding technique; Improved noise resistance in TKG reasoning,Not explicitly detailed in the abstract,LogCL effectively guides fusion of local and global historical information and enhances interference resistance,Neglecting historical information in knowledge graph snapshots; Weak anti-noise capabilities in existing methods,Not specifically mentioned,Applicable across diverse fields for predicting future unknown facts; Focuses on modeling historical fact patterns,https://arxiv.org/abs/2312.01601,10.48550/arXiv.2312.01601,"contrastive-learning, historical-encoding, noise-resistance, temporal-knowledge-graph, tkg-reasoning",Local-Global History-aware Contrastive Learning for Temporal Knowledge Graph Reasoning,"Chen Wei, Wan Huaiyu, Wu Yuting, Zhao Shuyuan, Cheng Jiayaqi, Li Yuxin, Lin Youfang",2023,reference-manager,,,,,,,"Global Entity-Aware Attention Encoder: Models global historical facts related to queries, capturing important historical patterns beyond recent events.",,,How can both global and local historical information be effectively captured and filtered to improve the accuracy and robustness of temporal knowledge graph extrapolation for predicting future unknown facts?,"The paper aims to improve future fact prediction in temporal knowledge graphs (TKG) by integrating both global and local historical information. It proposes LogCL, which uses entity-aware attention encoders and a local-global contrast module. Experiments show LogCL achieves higher prediction accuracy, highlighting the importance of combining global and local patterns.",The research goal is to improve temporal knowledge graph (TKG) extrapolation by better integrating local and global historical information; the approach uses a Local-global history-aware Contrastive Learning model (LogCL) with entity-aware attention and a contrast module; results show LogCL achieves more robust and accurate predictions than state-of-the-art methods.,"Tags: Temporal Knowledge Graph (TKG), TKG extrapolation, global historical information, local historical information, entity-aware attention, embedding, attention encoder, recurrent encoder, prediction, historical fact patterns, mean pooling, time semantic component, subgraph sample.",1.000,exact_title
chen_2024a,1 Temporal Knowledge Graph Reasoning Based on Dynamic Fusion Representation Learning,Hongwei Chen,2024,Yes,MEDIUM,"This paper is relevant as it explores dynamic fusion representation learning for temporal knowledge graph reasoning, contributing to improved temporal inference and knowledge integration—key challenges for HDM systems requiring robust temporal reasoning.","TD-RKG introduces a dynamic fusion approach for temporal knowledge graph reasoning, integrating local recurrent encoding, implicit encoding, and attention to improve entity/relation prediction.","A novel dynamic fusion model (TD-RKG) for temporal knowledge graph reasoning, outperforming baselines on standard datasets.","TD-RKG: dynamic fusion of local recurrent, implicit, and attention layers for temporal KG reasoning; achieves SOTA on ICEWS14, ICEWS05-15, YAGO.",How can implicit correlations and time sensitivity in temporal knowledge graphs be effectively modeled for improved reasoning and prediction?,"Proposes TD-RKG: combines relation-aware GCN, GRU, implicit correlation encoder, attention, and Conv-TransE decoder; evaluated on three TKG datasets.",TD-RKG outperforms static and dynamic baselines on MRR and Hits@N; ablation shows all modules contribute; strong generalization and fast convergence.,TD-RKG achieves SOTA on multiple metrics across datasets; dynamic implicit encoding and attention layers are key contributors.,"Hits@3 on YAGO not SOTA due to new entity initialization; future work: meta-learning for new entities, multimodal data integration.","TD-RKG is effective for implicit correlation and time sensitivity, but struggles with new entities and multimodal data.",Meta-learning for new entities; multimodal learning for text/images in TKGs.,"TD-RKG's modular design (GCN, GRU, attention, MLP, Conv-TransE) can be adapted for other temporal reasoning tasks; PyTorch implementation; uses ICEWS14, ICEWS05-15, YAGO datasets.",https://onlinelibrary.wiley.com/doi/10.1111/exsy.13758,10.1111/exsy.13758,Knowledge Graph; Machine Learning; Recommendation System; Semantic Web; Temporal,"data-integration, educational-technology, knowledge-graph, temporal-data",Temporal Knowledge Graph Reasoning Based on Dynamic Fusion Representation Learning,"Chen Hongwei, Zhang Man, Chen Zexi",2024,reference-manager,10.1111/exsy.13758,,,,,,Dynamic local recurrent encoding layer (LRE): Captures neighboring historical facts to improve prediction accuracy.,,,How can the proposed TD-RKG method effectively address the challenges of implicit correlation and time sensitivity in temporal knowledge graph reasoning by holistically modeling global dynamic information and encoding historical facts into entity and relationship representations?,"The paper investigates TD-RKG, a model for temporal knowledge graph reasoning. Using ablation studies on three datasets, it shows that dynamic local recurrent encoding and implicit encoding layers significantly improve performance. TD-RKG outperforms baselines in most metrics, effectively addressing implicit correlation and time sensitivity, though struggles with new entities.","The research goal is to improve temporal knowledge graph (TKG) completion; the TD-RKG approach uses dynamic local recurrent, implicit encoding, and attention layers; results show TD-RKG outperforms baselines in most metrics, especially in capturing implicit correlations and time sensitivity, though it underperforms on Hits@3 for YAGO.",,0.900,fuzzy_title
chen_2024b,Medical Hallucination in Foundation Models and Their Impact on Healthcare,"Shan Chen, Shuyue Stella Li, Kumail Alhamoud, Jimin Mun, Cristina Grau, Minseok Jung, Rodrigo Gameiro, Lizhou Fan, Eugene Park, Tristan Lin, Wonjin Yoon, Maarten Sap, Yulia Tsvetkov, Paul Liang, Xuhai Xu, Xin Liu, Hyeonhoon Lee, Hae Won Park, Cynthia Breazeal",2024,Yes,HIGH,"This paper is highly relevant as it systematically analyzes the phenomenon of medical hallucination in foundation models, providing a taxonomy, benchmarks, and mitigation strategies. Its focus on clinical safety, regulatory implications, and the integration of detection and reduction techniques directly supports HDM's goals for trustworthy, explainable, and safe AI in healthcare applications.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on medical hallucination in foundation models and their impact on healthcare providing insights for knowledge graph development and data integration.,"This 2024 paper by Shan Chen, Shuyue Stella Li, Kumail Alhamoud, Jimin Mun, Cristina Grau, Minseok Jung, Rodrigo Gameiro, Lizhou Fan, Eugene Park, Tristan Lin, Wonjin Yoon, Maarten Sap, Yulia Tsvetkov, Paul Liang, Xuhai Xu, Xin Liu, Hyeonhoon Lee, Hae Won Park, Cynthia Breazeal explores medical hallucination in foundation models and their impact on healthcare. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1056/NEJMcpc1802826.,"data-integration, healthcare, knowledge-graph",,,,,,,,,,,,,,,,,,,
christino_2022,A Theoretical Approach for Structuring and Analysing Knowledge Provenance for Visual Analytics,"L. Christino, S. Rezaeipour, E. Milios, F. Paulovich",2022,Yes,HIGH,"This paper is highly relevant as it introduces the Visual Analytics Knowledge Graph (VAKG), a conceptual framework for structuring and analyzing knowledge provenance in visual analytics workflows. Its formalization of temporal and atemporal aspects of user and machine interactions enables standardized, extensible knowledge graphs for behavior and knowledge provenance—directly supporting HDM's goals for transparent, analyzable, and interoperable knowledge systems.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a theoretical approach for structuring and analysing knowledge provenance for visual analytics providing insights for knowledge graph development and data integration.,"This 2022 paper by L. Christino, S. Rezaeipour, E. Milios, F. Paulovich explores a theoretical approach for structuring and analysing knowledge provenance for visual analytics. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1111/cgf.13324,"data-integration, knowledge-graph",A Theoretical Approach for Structuring and Analysing Knowledge Provenance for Visual Analytics,"Christino L., Rezaeipour S., Milios E., Paulovich F.",2023,reference-manager,,,"The implementation of VAKG enables automatic, scalable collection and structuring of user workflows and feedback, allowing researchers to analyze tool usage and user knowledge gain. VAKG does not expand analytical techniques but optimizes their use. Insights include identifying tool limitations and suggesting interface improvements based on user interaction data.",,,,Modeling the VA tool and designing a knowledge graph structure based on a formal VA model and ontology.,,,"How can the Visual Analytics Knowledge Graph (VAKG) framework formalize and standardize the acquisition, structuring, and analysis of user behavior and knowledge provenance in visual analytics tools to enable comprehensive understanding and comparison of knowledge generation during data analysis?","The paper introduces the Visual Analytics Knowledge Graph (VAKG) framework, aiming to formalize and analyze user knowledge acquisition in Visual Analytics (VA) tools. Using case studies and surveys, it demonstrates VAKG’s ability to model workflows, track user behavior, and compare knowledge gained, highlighting its structured, theoretically grounded approach.","The paper’s main objective is to formalize the Visual Analytics Knowledge Graph (VAKG) method for modeling and analyzing user knowledge in VA tools; the key approach is an automated, ontology-based knowledge graph pipeline; principal findings show VAKG enables scalable, insightful analysis of user behavior and tool limitations.",,1.000,exact_title
chu_2021,TIMEBENCH: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models,"Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Haotian Wang, Ming Liu, Bing Qin",2021,Yes,HIGH,"This paper is highly relevant as it introduces TIMEBENCH, a comprehensive benchmark for evaluating temporal reasoning in large language models. Its focus on systematically assessing and analyzing the temporal reasoning capabilities and limitations of state-of-the-art models directly supports the HDM project's need for robust temporal understanding in AI systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on timebench: a comprehensive evaluation of temporal reasoning abilities in large language models providing insights for knowledge graph development and data integration.,"This 2021 paper by Zheng Chu, Jingchang Chen, Qianglong Chen, Weijiang Yu, Haotian Wang, Ming Liu, Bing Qin explores timebench: a comprehensive evaluation of temporal reasoning abilities in large language models. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.18653/V1/2023.EMNLP-MAIN.298,"data-integration, knowledge-graph, temporal-data",TIMEBENCH: A Comprehensive Evaluation of Temporal Reasoning Abilities in Large Language Models,"Chu Zheng, Chen Jingchang, Chen Qianglong, Yu Weijiang, Wang Haotian, Liu Ming, Qin Bing",2024,reference-manager,,,,,,,"Multi-Select Task Format: Models select all possible correct answers from provided options, addressing limitations of traditional multiple-choice formats.",,,"How can a comprehensive and hierarchical benchmark be designed to evaluate and quantify the temporal reasoning abilities of large language models across symbolic, commonsense, and event-based scenarios using diverse datasets and task formats?","TIMEBENCH introduces a comprehensive, hierarchical benchmark to evaluate large language models’ temporal reasoning in complex scenarios. It categorizes tasks into symbolic, commonsense, and event temporal reasoning, using diverse formats and 10 datasets. Results highlight challenges in time expression understanding. The benchmark enables systematic, human-aligned model assessment.","The research goal is to comprehensively evaluate large language models' temporal reasoning using the hierarchical TIMEBENCH benchmark; the approach categorizes tasks into symbolic, commonsense, and event temporal reasoning across diverse formats; results provide a normalized, multispectral assessment of model performance relative to humans.",No information available,1.000,exact_title
cinti_2024,The Roadmap toward Personalized Medicine: Challenges and Opportunities,"Caterina Cinti, Maria Giovanna Trivella, Michael Joulie, Hussein Ayoub, Monika Frenzel, on behalf of the International Consortium for Personalised Medicine and Working Group 'Personalised Medicine in Healthcare' (WG2",2024,Yes,MEDIUM,"Moderately relevant to HDM systems as it addresses healthcare data integration challenges, digital health infrastructure needs, and data sharing frameworks essential for personal health knowledge graphs. The paper's emphasis on secure data storage systems, interoperability requirements, and ethical considerations for health data management provides valuable insights for HDM implementation in healthcare contexts, though it focuses more on policy and organizational aspects rather than technical PKG architectures.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on the roadmap toward personalized medicine: challenges and opportunities providing insights for knowledge graph development and data integration.,"This 2024 paper by Caterina Cinti, Maria Giovanna Trivella, Michael Joulie, Hussein Ayoub, Monika Frenzel, on behalf of the International Consortium for Personalised Medicine and Working Group 'Personalised Medicine in Healthcare' (WG2 explores the roadmap toward personalized medicine: challenges and opportunities. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",The Roadmap toward Personalized Medicine: Challenges and Opportunities,"Cinti Caterina, Trivella Maria Giovanna, Joulie Michael, Ayoub Hussein, Frenzel Monika",2024,reference-manager,10.3390/jpm14060546,,,,,Limited or short-term financial resources impede infrastructure and data integration.,,,,,,"The paper’s main objective is to identify key tasks and facilitators for implementing personalized medicine (PM) through expert interviews and PM examples, using a semi-structured data collection approach; principal findings highlight eight major facilitators and stress the importance of stakeholder collaboration, education, resources, and ethical considerations.",,1.000,exact_title
clark_2001,Knowledge Patterns,"Peter Clark, John Thompson, Bruce Porter, Knowledge Systems, Texas Austin",2001,Yes,HIGH,"This paper is highly relevant to the HDM project because it addresses the fundamental challenge of knowledge representation and reuse in complex systems. The concept of ""knowledge patterns"" provides a powerful framework for modularizing and structuring the knowledge base of an HDM system, which needs to integrate heterogeneous data from diverse personal and external sources. The paper's emphasis on making modeling decisions explicit is crucial for building a transparent and maintainable HDM. The techniques described can be directly applied to develop a library of reusable knowledge patterns for common personal data types (e.g., calendars, contacts, health data), facilitating the construction of a robust and scalable PKG.","The paper introduces ""knowledge patterns,"" a technique for constructing axiom-rich formal ontologies by explicitly representing recurring patterns of knowledge and mapping them to domain-specific concepts. This approach modularizes ontologies, making modeling decisions clear and facilitating knowledge reuse.","This paper presents ""knowledge patterns,"" a novel technique for building formal ontologies. Instead of writing axioms from scratch, this method identifies and reuses recurring patterns of knowledge. By separating abstract theories from their specific applications, it provides a more modular, flexible, and explicit way to construct complex knowledge bases, overcoming the limitations of traditional inheritance-based approaches.","How can we better structure and modularize formal, axiom-rich ontologies to make modeling decisions explicit and facilitate the reuse of recurring knowledge patterns?","The paper proposes the ""knowledge patterns"" technique, which involves: 1. Identifying and representing recurring theory schemata as explicit, self-contained patterns. 2. Defining morphisms (mappings) for each application of a pattern to a target knowledge base. 3. Importing morphed copies of the pattern into the knowledge base. The authors illustrate this with examples from a knowledge-based system for astronaut training (KB-PHaSE).","Knowledge patterns provide a more flexible and explicit way to reuse knowledge compared to traditional inheritance. They allow for the application of abstract theories in multiple, distinct ways to the same domain concept and support partial application of a theory. This leads to better modularization and clearer representation of modeling decisions in formal ontologies.","The primary outcome is the ""knowledge patterns"" technique itself, a new method for ontological engineering. The paper also presents the KB-PHaSE system as a practical application and proof-of-concept for this technique.","The authors acknowledge several limitations: the approach does not support run-time modeling decisions, it doesn't address how to find relevant patterns or their boundaries, and it leaves the task of finding appropriate mappings to the knowledge engineer.","Knowledge patterns are a significant technique for modularizing axioms in formal ontologies, isolating general theories for reuse, and making modeling decisions explicit. This approach can foster the development of reusable theory libraries, which are essential for building large-scale formal ontologies and knowledge-based systems.","The paper points to the need for methods to automatically discover relevant knowledge patterns and their mappings, which is a focus of research in analogical reasoning. It also suggests that further work is needed to explore run-time application of these patterns.","Future work could explore the automatic discovery of knowledge patterns and their mappings, potentially drawing from research in analogical reasoning. They also mention the possibility of developing a run-time version of the pattern application mechanism.","The paper provides insights into implementing knowledge patterns, including the use of morphisms for mapping and the handling of symbols that don't have counterparts in the target knowledge base. The KB-PHaSE system serves as a concrete example of how these patterns can be used to build a complex knowledge base from component theories.",,,"Knowledge Representation, Ontology, Knowledge Engineering, Knowledge Reuse, Formal Methods, AI, Semantic Web","data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
clau_2024,iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models,Pierre CLÉAU,2024,Yes,HIGH,"Addresses incremental knowledge graph construction using large language models with zero-shot capability, highly relevant to HDM systems requiring continuous knowledge graph updates and construction from diverse unstructured data sources.","Proposes iText2KG method comprising four modules (Documents Distiller, Incremental Entities Extractor, Incremental Relations Extractor, Graph Integrator) achieving superior performance across converting scientific papers, websites, and CVs to knowledge graphs through plug-and-play zero-shot approach.","Incremental, topic-independent knowledge graph construction method using large","This paper addresses the challenge that most available data is unstructured, making information access challenging, while traditional NLP methods for knowledge graph construction have limitations like predefined entity types and requiring supervised learning. iText2KG proposes an incremental, topic-independent KG construction method without post-processing that leverages large language models' capabilities through a plug-and-play, zero-shot approach applicable across a wide range of KG construction scenarios.",How can large language models be used to incrementally construct consistent knowledge graphs with resolved entities and relations from unstructured text without requiring supervised learning or extensive post-processing?,"Developed iText2KG framework with four modules: Documents Distiller, Incremental Entities Extractor, Incremental Relations Extractor, and Graph Integrator, implemented zero-shot learning approach, tested across three scenarios: converting scientific papers to graphs, websites to graphs, and CVs to graphs.","Demonstrated superior performance compared to baseline methods across all tested scenarios, achieved effective resolution of semantic entity and relation duplication challenges, provided flexible approach requiring no extensive post-processing or supervised training.",Incremental knowledge graph construction framework with zero-shot capability and superior performance across diverse document types and domains.,"Evaluation limited to three specific scenarios, computational efficiency considerations for large-scale incremental updates not fully characterized, potential challenges in handling domain-specific terminology requiring further investigation.","Represents significant advancement in automated, flexible knowledge graph construction using large language models with practical applicability across diverse unstructured data sources and domains.","Need for broader evaluation across additional document types and domains, optimization for computational efficiency in large-scale incremental scenarios, integration with existing knowledge management systems.","Expand evaluation to additional document types and specialized domains, optimize computational efficiency for large-scale incremental processing, develop integration capabilities with existing knowledge graph platforms.",Provides practical Python package for incremental knowledge graph construction with focus on entity resolution and relation extraction essential for HDM systems requiring continuous knowledge graph updates from diverse sources.,https://arxiv.org/abs/2409.03284,arXiv:2409.03284,"entity-resolution, incremental-knowledge-graph-construction, llm, unstructured-data-processing, zero-shot-learning",,,,,,,,,,,,,,,,,,,
cognitiveyunp_2023,ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs,"cognitive.yunp, zhmen, lia, hanzhen, Volker.Tres",2023,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Proposes ForecastTKGQA model that employs TKG forecasting module for future inference, addresses limitation that existing TKGQA methods perform poorly on forecasting questions and struggle with yes-no and fact reasoning questions",Novel benchmark dataset and forecasting-focused temporal knowledge graph question answering framework,"This paper addresses limitations in existing temporal knowledge graph question answering (TKGQA) methods by introducing ForecastTKGQuestions, a large-scale benchmark dataset for temporal question answering and forecasting. The research identifies that state-of-the-art TKGQA methods perform poorly on forecasting questions and are unable to answer yes-no questions and fact reasoning questions. The dataset includes three types of questions: entity prediction, yes-no, and fact reasoning questions, with the constraint that QA models can only access TKG information before the timestamp annotated in the question. The proposed ForecastTKGQA model employs a TKG forecasting module for future inference to answer all three question types.",How to develop temporal knowledge graph question answering systems that can effectively answer future-oriented questions using only historical knowledge graph information?,ForecastTKGQA model with TKG forecasting module for future inference; ForecastTKGQuestions benchmark dataset with three question types; experimental evaluation focusing on forecasting capabilities; comprehensive analysis of existing TKGQA method limitations,ForecastTKGQA outperforms recent TKGQA methods on entity prediction; demonstrates effectiveness across all three question types; identifies significant performance gaps in existing methods for forecasting questions,,Limited to specific temporal knowledge graph domains; evaluation focused primarily on structured temporal queries; computational complexity of forecasting module not fully characterized,Demonstrates importance of forecasting capabilities in temporal knowledge graph question answering and provides foundation for future research in temporal reasoning systems,,Expand benchmark to more diverse temporal domains; develop more sophisticated forecasting techniques; investigate real-world applications of temporal question answering,Addresses critical gap in temporal knowledge graph question answering; provides foundation for future research in temporal reasoning; demonstrates practical approach to future-oriented reasoning,https://arxiv.org/abs/2208.06501,10.48550/arXiv.2208.06501,"forecasting, iswc-2023, question-answering, temporal-knowledge-graph, temporal-reasoning",ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs,"Ding Zifeng, Li Zongyue, Qi Ruoxia, Wu Jingpei, He Bailan, Ma Yunpu, Meng Zhao, Chen Shuo, Liao Ruotong, Han Zhen, Tresp Volker",2023,reference-manager,,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
cudrmauroux_2020,Leveraging Knowledge Graphs for Big Data Integration: the XI Pipeline,Philippe Cudré-Mauroux,2020,Yes,HIGH,"This paper is highly relevant as it presents the XI Pipeline, a systematic 5-step approach for integrating heterogeneous data using Knowledge Graphs. The pipeline (NER → Entity Linking → Type Ranking → Co-Reference Resolution → Relation Extraction) directly addresses HDM's core challenge of heterogeneous data integration. The paper's emphasis on fine-grained entity types, the importance of customization over generic solutions, and lessons learned from real-world deployments (ScienceWise, ArmaTweet, Guider) provide valuable architectural insights for HDM system design. The focus on semi-structured and unstructured data integration aligns perfectly with HDM's upstream data orchestration goals.","The key insight is the systematic, modular approach to Knowledge Graph-based data integration through the XI Pipeline. The paper demonstrates that effective heterogeneous data integration requires: (1) a multi-step processing pipeline with specialized components, (2) fine-grained entity typing rather than coarse categories, (3) human-in-the-loop validation for quality assurance, and (4) domain-specific customization rather than generic platforms. This directly informs HDM's bespoke system design approach.","This paper introduces the XI Pipeline, a comprehensive 5-step framework for integrating semi-structured and unstructured data using Knowledge Graphs. The pipeline consists of Named Entity Recognition, Entity Linking, Type Ranking, Co-Reference Resolution, and Relation Extraction. The authors demonstrate the framework's effectiveness through three real-world use cases: ScienceWise (research articles), ArmaTweet (social media), and Guider (cloud infrastructure). The paper provides valuable lessons learned about the importance of fine-grained entity types, human validation, and domain-specific customization in Knowledge Graph-based data integration systems.",How can Knowledge Graphs be leveraged to systematically integrate heterogeneous semi-structured and unstructured data sources in enterprise environments?,"The paper presents the XI Pipeline methodology consisting of five sequential steps applied to input data: (1) Named Entity Recognition using IR techniques for closed domains or NLP/ML for open domains, (2) Entity Linking using probabilistic graphs and microtask crowdsourcing, (3) Type Ranking to identify relevant fine-grained entity types, (4) Co-Reference Resolution for noun phrases using type information and neural networks, and (5) Relation Extraction using distant supervision and neural architectures. Three use cases demonstrate practical applications across different domains.","The XI Pipeline successfully integrates heterogeneous data across multiple domains, with human involvement improving entity linking results by over 10%. The framework enables complex query capabilities (e.g., 'find all politicians dying in Switzerland') and practical applications including job auditing, SLO extraction, and global job ranking. Key findings emphasize the crucial role of fine-grained entity types and the necessity of domain-specific customization for effective data integration.","The primary outcome is the XI Pipeline framework itself, a systematic 5-step methodology for Knowledge Graph-based data integration. The paper also delivers three practical systems (ScienceWise, ArmaTweet, Guider) demonstrating real-world applicability, along with architectural insights about the importance of fine-grained typing, human validation, and domain specialization in heterogeneous data integration projects.","The approach requires significant manual effort and domain expertise for customization. Automated techniques alone cannot fully capture semantic complexity of arbitrary input data. The integration quality is constrained by the underlying Knowledge Graph quality, including errors, inconsistencies, and missing data. Generic platforms proved impractical, requiring specialized approaches for each use case and data modality.","Knowledge Graphs provide powerful and flexible abstractions for heterogeneous data integration, but success requires systematic approaches, human validation, fine-grained entity typing, and domain-specific customization. The XI Pipeline demonstrates that effective integration is achievable through modular, multi-step processing combined with careful attention to data quality and semantic precision.",The paper identifies the need for composable software libraries focused on specific integration subprocesses and data modalities. It highlights challenges in scaling automated semantic understanding and the ongoing requirement for human expertise in complex integration scenarios. The quality dependency on underlying Knowledge Graph completeness and accuracy remains a significant limitation.,"Future work should focus on developing libraries of composable software artifacts for different integration subprocesses and data modalities, improving automated semantic understanding capabilities, and addressing Knowledge Graph quality issues including error correction and completeness enhancement.","The paper provides concrete implementation insights including the use of probabilistic graphs for entity disambiguation, microtask crowdsourcing for quality improvement, fine-grained type hierarchies for downstream task optimization, distant supervision for relation extraction, and neural architectures (Aggregated Piecewise CNN) for semantic relationship identification. The modular pipeline design and domain-specific customization approach are key architectural patterns for HDM implementation.",10.3233/SW-190371,"Cloud Computing, Data Integration, Knowledge Graph, Machine Learning, Recommendation System, Semantic Web",,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
wang_2024,Question answering over temporal knowledge graphs based on hierarchical semantic extraction,"Jian Wang, Wenjuan Zhang, Qi He, Danfeng Zhao",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Proposes HSTQA model using hierarchical semantic extraction to improve temporal reasoning in complex question-answering scenarios; focuses on capturing semantic and implicit temporal information.,Novel model for temporal knowledge graph question answering using hierarchical semantic extraction and multi-granularity fusion techniques.,This paper addresses Temporal Knowledge Graph Question Answering (TKGQA) by proposing HSTQA model that uses hierarchical semantic extraction to improve temporal reasoning and handle multi-granularity temporal problems.,How can temporal knowledge graphs better support question answering for complex temporal scenarios?,"Employed graph convolutional networks, used multi-granularity fusion technique, focused on capturing semantic and implicit temporal information.",HSTQA improves Hits@1 by 10.8% compared to traditional methods in handling multi-granularity temporal problems.,,Abstract only - evaluation methodology and broader applicability details not available from abstract.,Demonstrates improved temporal reasoning capabilities for knowledge graph question answering systems.,,"Expand evaluation to more temporal reasoning tasks, integrate with larger-scale temporal KGs, explore real-world application scenarios.",Provides approach for temporal reasoning in KG systems that could be relevant for time-based queries in HDM applications.,https://ieeexplore.ieee.org/document/10924876/,10.1109/SWC62898.2024.00207,"multi-granularity, question-answering, temporal-knowledge-graph, temporal-reasoning",Question answering over temporal knowledge graphs based on hierarchical semantic extraction,"Wang Jian, Zhang Wenjuan, He Qi, Zhao Danfeng",2024,reference-manager,10.1109/swc62898.2024.00207,,"The paper introduces HSTQA, which uses a hierarchical semantic extraction method and multi-granularity fusion to better capture both global and local temporal features in questions. Structure-enhanced and relation fusion units further improve temporal reasoning. Ablation studies show each module significantly boosts performance, especially for complex temporal queries.",,,,Hierarchical Semantic Extraction Method: Extracts both global and local semantic information from questions to better capture implicit temporal details.,,,How can hierarchical semantic extraction and multi-granularity fusion improve complex temporal reasoning and question answering over temporal knowledge graphs?,"The paper proposes HSTQA, a hierarchical semantic extraction-based model for complex temporal reasoning in temporal knowledge graph question answering (TKGQA). Using modules for semantic extraction, multi-granularity fusion, and relation integration, HSTQA outperforms baselines on the MultiTQ dataset, especially for multi-granularity and single-constraint temporal questions.","The research goal is to enhance complex temporal question answering over temporal knowledge graphs; the approach uses a hierarchical semantic extraction method and multi-granularity fusion in the HSTQA model; results show HSTQA significantly outperforms previous models, especially in handling multi-granularity and implicit temporal reasoning tasks.",,1.000,exact_title
das_2025,Detection-Fusion for Knowledge Graph Extraction from Videos,"Taniya Das, Louis Mahon, Thomas Lukasiewicz",2025,Yes,HIGH,"Directly addresses knowledge graph extraction from multimodal video data, highly relevant to HDM systems requiring personal data integration from diverse multimedia sources",Two-stage detection-fusion approach overcomes language model limitations in video understanding; structured knowledge representations more computer-processable than natural language; background knowledge integration improves extraction accuracy,Novel deep learning approach for extracting semantic knowledge graphs from videos,"This paper addresses challenges in extracting semantic content from video inputs by proposing knowledge graph annotation as an alternative to natural language descriptions. Current systems relying on language models have major shortcomings: over-reliance on statistical regularities rather than visual content, difficult computer processing of natural language output, and evaluation challenges. The research proposes a deep learning model that first predicts pairs of individuals, then determines relations between them, incorporating background knowledge from Visual Genome dataset to improve accuracy.",How to extract semantic content from video inputs more effectively than current language model approaches while providing computer-processable structured representations?,"Deep learning model with two-stage process: 1) detection module identifies objects, actions, events; 2) fusion module combines visual information with language understanding; incorporation of background knowledge from Visual Genome dataset",Current language model approaches have significant limitations in video understanding; knowledge graphs provide more computationally processable video semantic representations; first work to include background knowledge in video KG extraction,Knowledge graph annotation method for videos; improved accuracy in identifying objects and relationships; enhanced computer-processable semantic representations; background knowledge integration,Computational complexity of two-stage approach; evaluation methodology details not fully specified; generalization across video domains not demonstrated,Knowledge graphs provide more computationally processable and evaluation-friendly video semantic representations compared to traditional natural language descriptions,"Overreliance on language models for video semantic interpretation; lack of structured, computer-processable video understanding; limited background knowledge integration",Extend to larger-scale video datasets; investigate domain-specific background knowledge; optimize computational efficiency for real-time processing,First approach to predict pairs of individuals then relations between them; incorporates background knowledge for improved accuracy; demonstrates practical structured video understanding,https://arxiv.org/abs/2501.00136,10.48550/arXiv.2501.00136,"computer-vision, deep-learning, knowledge-graph, multimodal-ai, video-understanding",,,,,,,,,,,,,,,,,,,
dengel_2023,Towards Self-organizing Personal Knowledge Assistants in Evolving Corporate Memories,"Andreas Dengel, Christian Jilek, Markus Schröder, Heiko Maus, Sven Schwarz",2023,Yes,SUPER,"Exceptionally relevant to HDM core objectives. Presents comprehensive framework for Personal Knowledge Assistants (PKAs) built on knowledge graph foundations, addressing heterogeneous data integration from 'messy enterprise data' through Corporate Memory systems. Introduces Managed Forgetting as automated information lifecycle management using Memory Buoyancy and Preservation Value for temporal-first architecture. Context Spaces (cSpaces) provide explicit user context representation addressing project fragmentation. Semantic Desktop ecosystem bridges personal devices with corporate knowledge. Decade of research on self-organizing systems, user-controlled personal knowledge management, and KG construction from distributed heterogeneous sources directly aligns with HDM's bespoke PKG development, upstream data orchestration, and temporal-first design principles.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on towards self-organizing personal knowledge assistants in evolving corporate memories providing insights for knowledge graph development and data integration.,"This 2023 paper by Andreas Dengel, Christian Jilek, Markus Schröder, Heiko Maus, Sven Schwarz explores towards self-organizing personal knowledge assistants in evolving corporate memories. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,1017026dans-x55-69zp,Towards Self-organizing Personal Knowledge Assistants in Evolving Corporate Memories,"Jilek Christian, Schröder Markus, Maus Heiko, Schwarz Sven, Dengel Andreas",2023,reference-manager,,,"The paper highlights evaluation challenges in PIM and knowledge work, such as subjectiveness, missing datasets, and privacy issues. To address these, a multi-lane evaluation strategy was used, including user studies, inquiries, and data-driven studies. Implementation insights include Managed Forgetting, condensation, and context-based note-taking for improved user support.",,,,"Short-term studies: Conducted in controlled laboratory settings with 20–50 participants for 30–90 minutes, sometimes using simulated scenarios.",,,"How can self-organizing personal knowledge assistants be developed and evaluated to effectively support personal information management and knowledge work, particularly through automation and Managed Forgetting, while addressing challenges such as subjectiveness, privacy, and evaluation methodology?","The paper addresses evaluation challenges in Personal Information Management (PIM) and knowledge work support by developing a multi-lane evaluation strategy. Using short-term lab studies, medium/long-term studies, inquiries, and data-driven approaches, the authors balance methodological rigor, privacy, and dataset limitations. The strategy enables flexible, context-appropriate evaluations.","The research goal was to address evaluation challenges in PIM and knowledge work support by developing a multi-lane evaluation strategy, using both short-term controlled studies and longer-term real-world studies, with results showing this approach effectively balances methodological rigor, participant numbers, and privacy concerns.",,1.000,exact_title
din_2019,Towards a Flexible System Architecture for Automated Knowledge Base Construction Frameworks,Osman Din,2019,Yes,HIGH,"Highly relevant to HDM's automated knowledge graph construction objectives. Presents comprehensive framework architecture for Automated Knowledge Base Construction (AKBC) addressing scalability, extensibility, and usability challenges. Supports multiple data types and formats essential for heterogeneous data integration. Domain-specific feature addition capabilities align with bespoke PKG system design. Human-in-the-Loop error analysis and flexible feature selection support upstream data quality orchestration. Architectural principles for processing diverse document types (text, tables, images) and automated fact extraction directly inform HDM's goal of seamless multi-source data fusion and knowledge graph construction from heterogeneous enterprise data sources.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on towards a flexible system architecture for automated knowledge base construction frameworks providing insights for knowledge graph development and data integration.,"This 2019 paper by Osman Din explores towards a flexible system architecture for automated knowledge base construction frameworks. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,101477827330042733069,,,,,,,,,,,,,,,,,,,
discovery_2024,Automated Monitoring Method for Enterprise Microservices Network Operation Status Based on Database Knowledge Graph,Service Discovery,2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Integrates NLP and LSTM networks with database knowledge graphs for proactive system failure prediction and resource optimization,Knowledge graph-based monitoring system for enterprise microservices using AI,This research integrates Natural Language Processing and Long Short-Term Memory networks with database knowledge graphs to process real-time and historical data for proactive system failure prediction and resource optimization,How can enterprise microservices networks be effectively monitored and managed using advanced data analysis techniques?,"Database knowledge graph approach, NLP integration, LSTM networks for prediction, real-time and historical data processing","Developed scalable and dynamic solution for diverse enterprise requirements, enables proactive failure prediction, optimizes resource allocation",,"Focus on enterprise systems, personal application adaptation needed",Demonstrates practical KG application for complex system monitoring and prediction,,"Implement for personal device monitoring, integrate with HDM system health tracking, develop alerts",Agent Epsilon: Enterprise KG architecture adaptable to HDM system monitoring and predictive maintenance,https://ieeexplore.ieee.org/document/10704355/,10.1109/ACCESS.2024.3471689,"enterprise-monitoring, knowledge-graph, lstm, microservices, nlp, predictive-maintenance",Automated Monitoring Method for Enterprise Microservices Network Operation Status Based on Database Knowledge Graph,"Hu Qidi, Long Yujiang, Zhong Ye, Zhang Guangyi, Wei Wei",2024,reference-manager,10.1109/ecnct63103.2024.10704355,,"Implementation Insights highlight that integrating knowledge graphs with NLP and LSTM enables high anomaly detection (15 times/month), accurate load prediction (92.38%), and effective resource optimization (30 recommendations/month). The system provides early warnings (72 hours), achieves 88.74% fault prediction accuracy, and prevented 5 major faults, demonstrating practical effectiveness and scalability.",,,,"Natural Language Processing (NLP) techniques, including Named Entity Recognition (NER), were used to extract entities and relationships from system logs and user activity data.",,,"How can knowledge graphs be constructed and applied within a microservices architecture to enhance automated operational management, including fault prediction, configuration optimization, and system reliability?","The paper investigates building knowledge graph systems using a microservices architecture. It employs modular, containerized services with automated deployment, monitoring, and scaling. Key findings show that this approach enables efficient knowledge extraction, integration, and reasoning, resulting in scalable, reliable, and high-quality knowledge bases for AI applications.","The research goal is to enhance microservice system reliability and efficiency through automated operational management; the approach integrates CI/CD, centralized configuration, monitoring, and Kubernetes-based scaling; results show improved service health, rapid scalability, and reduced manual intervention.",,1.000,exact_title
division_2021,Data Integration Challenges for Machine Learning in Precision Medicine,"Clinical Research Division, Mexico City, Computational Genomics Division",2021,Yes,HIGH,"Highly relevant to HDM healthcare applications and heterogeneous data integration objectives. Addresses precision medicine's core challenge of integrating vast heterogeneous databases (molecular, environmental, clinical, genomic) into unified analytical frameworks for personalized health outcomes. Emphasizes managing diverse data formats (structured/unstructured) with varying confidentiality levels within unified architecture. AI/ML approaches for handling individual genetic and environmental heterogeneity align with HDM's multi-modal data fusion goals. Data integration challenges in biomedical research directly inform HDM's upstream data orchestration and schema harmonization needs for healthcare PKG systems. Computational intelligence approaches to complex medical data analytics provide insights for bespoke healthcare knowledge graph architectures.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on data integration challenges for machine learning in precision medicine providing insights for knowledge graph development and data integration.,"This 2021 paper by Clinical Research Division, Mexico City, Computational Genomics Division explores data integration challenges for machine learning in precision medicine. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,103389fmed2021784455full,Data Integration Challenges for Machine Learning in Precision Medicine,"Martínez-García Mireya, Hernández-Lemus Enrique",2022,reference-manager,10.3389/fmed.2021.784455,,,,,,Algorithmic inventory: Creating and maintaining a record of computational methods used in the institution.,,,"How can diverse biomedical data sources—including molecular, clinical, social, and environmental information—be effectively integrated, modeled, and managed using AI/ML approaches to advance Precision Medicine while addressing ethical, legal, and privacy challenges?","The paper discusses the importance of a Data Management Plan (DMP) for projects handling large, sensitive datasets. The DMP sets guidelines for data handling, quality control, preservation, and compliance with legal and organizational requirements. The study highlights DMPs as essential for ensuring data integrity, security, and future usability.","The paper's main objective is to discuss challenges in applying large-scale data analytics for Precision Medicine, using a review approach, and concludes that comprehensive data management plans are needed to address technical, computational, ethical, and policy issues for effective AI/ML integration in clinical settings.",,1.000,exact_title
doerr_2017,A Workflow Model for Holistic Data Management and Semantic Interoperability in Quantitative Archival Research,Martin Doerr,2017,Yes,HIGH,"Highly relevant for HDM's heterogeneous data integration objectives. Presents comprehensive workflow model for holistic data management and semantic interoperability in archival research, featuring provenance-aware data curation, ontology-based integration, and knowledge graph construction. The workflow addresses multi-source data integration challenges, schema harmonization, and upstream data orchestration principles central to HDM's bespoke PKG system development. Provides detailed methodologies for source schema creation, data transformation, and semantic network generation that directly inform HDM's temporal-first architecture design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a workflow model for holistic data management and semantic interoperability in quantitative archival research providing insights for knowledge graph development and data integration.,"This 2017 paper by Martin Doerr explores a workflow model for holistic data management and semantic interoperability in quantitative archival research. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",A Workflow Model for Holistic Data Management and Semantic Interoperability in Quantitative Archival Research,"Fafalios Pavlos, Marketakis Yannis, Axaridou Anastasia, Tzitzikas Yannis, Doerr Martin",2023,reference-manager,,,"Implementation Insights highlight key data quality challenges: missing information affects analysis accuracy; data entry errors impact consistency and user experience; and non-consistent comparative values hinder comparisons. The workflow supports provenance tracking, recursive revisions, and user validation, enabling reproducible research and addressing real historians’ needs. No new insights beyond these lessons are presented.",,,,"Free text search and interactive interface: Users explore integrated data using keyword searches or user-friendly interfaces, resulting in ranked lists and visualizations.",,,"How can integrated semantic data and user-friendly exploration interfaces improve the effectiveness, usability, and trustworthiness of archival research, particularly in addressing complex information needs and ensuring data quality in historical studies?","The paper presents a holistic workflow model for data management in archival research, focusing on semantic data integration and provenance preservation. Researchers and data engineers collaborate through processes like transcription and curation. Key findings highlight improved usability, trustworthiness, and data quality dimensions (completeness, consistency, conciseness), supporting advanced research and analysis.","The research goal is to improve data quality and usability in maritime history research using semantic technologies; the approach involves a workflow model focusing on completeness, consistency, and conciseness of semantic data, with results showing enhanced data exploration and analysis through user-friendly interfaces and multi-perspective result visualizations.",,1.000,exact_title
dragoni_2023,Integrating Functional Status Information into Knowledge Graphs to Support Self-Health Management,"Mauro Dragoni, Tania Bailoni, Ivan Donadello, Jean-Claude Martin, Helena Lindgren",2023,Yes,HIGH,"Highly relevant for HDM's PKG architecture and healthcare data integration objectives. Presents FuS-KG (Functional Status Knowledge Graph) extending HeLiS ontology with three specialized modules (Enablers, Barriers, Arguments) for personal health management. Demonstrates practical implementation of heterogeneous healthcare data integration including electronic health records, sensor data, and behavioral information within user-centric PKG architecture. The ontology-based integration methodologies, temporal modeling of health states, and multi-source data fusion approaches directly inform HDM's bespoke PKG system development for healthcare applications.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on integrating functional status information into knowledge graphs to support self-health management providing insights for knowledge graph development and data integration.,"This 2023 paper by Mauro Dragoni, Tania Bailoni, Ivan Donadello, Jean-Claude Martin, Helena Lindgren explores integrating functional status information into knowledge graphs to support self-health management. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,101162dint-a-00203,Integrating Functional Status Information into Knowledge Graphs to Support Self-Health Management,"Dragoni Mauro, Bailoni Tania, Donadello Ivan, Martin Jean-Claude, Lindgren Helena",2023,reference-manager,10.1162/dint\_a\_00203,,,,,"Health assessments represent only a snapshot of a person’s status, not capturing long-term behavior change.",,,"The research emphasizes reproducibility by planning to publish the Barrier Ontology in open-source repositories like BioPortal and OBO Foundry for community review. However, there is no explicit mention of source code availability for the project. Evaluations confirm consistency and error-free ontology modules.",,,The research goal is to design an AI-enabled system for monitoring and preventing functional decline using motivational coaching; the approach involves building a knowledge graph integrating expert input and literature on behavior change; the principal finding is a refined ontology supporting personalized self-health management.,"Tags: behavior change techniques, theoretical mechanisms of action, ontology, knowledge graph, self-health management, barriers, Transtheoretical Model of change, argumentation, context, utility, technique, strategy, support, attack, physical activity, patient, health barrier, psychological barrier, social barrier.",1.000,exact_title
driskell_2021,A Lexical Approach to Assessing Stress: Development and Proof- of- Concept,"Tripp Driskell, Eduardo Salas, C. Shawn Burke, James E. Driskell",2021,Yes,MEDIUM,"Medium relevance for HDM personal health monitoring applications. Develops methodology for non-obtrusive stress detection through lexical analysis of spontaneous verbal communications, identifying five core stress dimensions (attentional focus, cognitive load, negative emotions, anxiety, social impairment) via linguistic indicators. While the natural language processing approach for behavioral data extraction and real-time psychological state assessment could complement HDM's temporal health monitoring capabilities within PKG systems, the research is primarily focused on operational environments rather than heterogeneous data integration or bespoke PKG architecture design that are central to HDM objectives.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a lexical approach to assessing stress: development and proof- of- concept providing insights for knowledge graph development and data integration.,"This 2021 paper by Tripp Driskell, Eduardo Salas, C. Shawn Burke, James E. Driskell explores a lexical approach to assessing stress: development and proof- of- concept. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",A Lexical Approach to Assessing Stress: Development and Proof-of-Concept,"Driskell Tripp, Salas Eduardo, Burke C. Shawn, Driskell James E.",2021,reference-manager,10.1177/00187208211045167,,,,,,"Word-count approach: Analyzes text by counting keywords linked to specific psychological constructs, ignoring word order and context.",,,"How effective are word-count approaches in analyzing psychological constructs within verbal content, considering their limitations in capturing sentence-level meaning and context?",,"The research goal is to unobtrusively assess stress effects in high-demand settings using a word-count analytic approach, and the principal finding is that the developed tool, STRESSnet, effectively evaluates cognitive and emotional states like stress, anxiety, and team orientation from ongoing communications.",,1.000,exact_title
du_2024,CTGNN: Crystal Transformer Graph Neural Network for Crystal Material Property Prediction,"Zijian Du, Luozhijie Jin, Le Shu, Yan Cen, Yuanfeng Xu, Yongfeng Mei",2024,Yes,LOW,"Low relevance for HDM heterogeneous data integration objectives. While CTGNN demonstrates advanced graph neural network architecture combining Transformer models with GNNs for crystal material property prediction, achieving superior performance on formation energy and bandgap prediction tasks, the research is domain-specific to computational materials science. The paper focuses on homogeneous crystal structure data from CIF files rather than heterogeneous data integration, lacks temporal-first architecture considerations central to HDM, and does not address schema harmonization, multi-source data fusion, or personal knowledge graph applications that are core to HDM objectives.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on ctgnn: crystal transformer graph neural network for crystal material property prediction providing insights for knowledge graph development and data integration.,"This 2024 paper by Zijian Du, Luozhijie Jin, Le Shu, Yan Cen, Yuanfeng Xu, Yongfeng Mei explores ctgnn: crystal transformer graph neural network for crystal material property prediction. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",CTGNN: Crystal Transformer Graph Neural Network for Crystal Material Property Prediction,"Du Zijian, Jin Luozhijie, Shu Le, Cen Yan, Xu Yuanfeng, Mei Yongfeng, Zhang Hao",2024,reference-manager,,,"The Implementation Insights highlight that CTGNN combines Transformer structures with traditional Graph Neural Networks (GNNs), using an angular encoder to capture angle features. Dual-Transformer modules model both local and broader atomic interactions. CTGNN outperforms models like CGCNN and MEGNET in predicting formation energy and bandgap, especially for perovskites.",,,,Transformer model: Uses multi-head self-attention to process sequential data and learn relationships between sequences.,,,"How can the proposed Crystal Transformer Graph Neural Network (CTGNN), which integrates Transformer architectures and traditional graph neural network inductive biases with angular encoding, improve the prediction of material properties compared to existing models?","The paper proposes the Crystal Transformer Graph Neural Network (CTGNN) to improve materials property prediction. CTGNN combines Transformer-based message passing and traditional graph neural network (GNN) inductive biases, using an angular encoder for angle features. Experiments show CTGNN outperforms other models on widely-used materials databases, highlighting its effectiveness.","The research goal is to improve materials property prediction by proposing the Crystal Transformer Graph Neural Network (CTGNN), which combines Transformer-based message capturing and GNN inductive bias; the approach uses dual-Transformer structures with angular encoding, and results show CTGNN outperforms other models on widely-used materials databases.",,1.000,exact_title
dunbar_2022,Driving Digital Engineering Integration and Interoperability Through Semantic Integration of Models with Ontologies,"Daniel Dunbar, Semantic Web, Digital Engineering",2022,Yes,HIGH,"High relevance for HDM heterogeneous data integration objectives. The DEFII framework directly addresses core HDM priorities through semantic web technologies for ontology-based data integration across heterogeneous engineering tools and domains. The paper demonstrates schema harmonization using controlled vocabulary and ontological mapping, implements upstream data orchestration through mapping interfaces, and uses graph-based triple stores similar to PKG architectures. The three notional interfaces (Direct, Mapping, Specified Model) provide tool-agnostic access patterns essential for bespoke system design. The framework successfully integrates diverse data sources across systems engineering, cyber security, and analysis domains, achieving the multi-domain data fusion capabilities central to HDM temporal-first architecture and upstream-focused schema design.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on driving digital engineering integration and interoperability through semantic integration of models with ontologies providing insights for knowledge graph development and data integration.,"This 2022 paper by Daniel Dunbar, Semantic Web, Digital Engineering explores driving digital engineering integration and interoperability through semantic integration of models with ontologies. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Driving Digital Engineering Integration and Interoperability Through Semantic Integration of Models with Ontologies,"Dunbar Daniel, Hagedorn Thomas, Blackburn Mark, Dzielski John, Hespelt Steven, Kruse Benjamin, Verma Dinesh, Yu Zhongyuan",2023,reference-manager,,,"The DEFII framework uses MISD and Specified Model Interface to enable tool interoperability and tool-agnostic data access. It standardizes data mapping, supports flexible analysis, and allows middleware for tool-specific needs. Limitations include manual connections and recursive patterns; future research should address complex analysis patterns and semantic mapping.",,,,"Mapping SysML system models to ontology-aligned, tool-agnostic representations stored in a triple store (GraphDB).",,,"How does the DEFII framework use ontology-aligned data and standardized interfaces to address integration and interoperability challenges in Digital Engineering, particularly in enabling tool interoperability and automated reasoning across heterogeneous engineering tools and data sources?","The paper aims to demonstrate how the Model Interface Specification Diagram (MISD) enables tool-agnostic, ontology-aligned data exchange for cyber vulnerability analysis. Using SysML and MATLAB, the study maps system models to ontologies, calculates CVSS scores, and shows improved tool interoperability. The DEFII framework supports flexible, reusable data integration.","The research goal is to address integration and interoperability in Digital Engineering by using ontology-aligned data; the approach employs the DEFII framework with the Model Interface Specification Diagram (MISD); results show tool-agnostic, flexible data access and successful CVSS analysis via MATLAB, confirming improved interoperability.",,1.000,exact_title
editor_2022,Research Article Privacy-Preserving Federated Graph Neural Network Learning on Non-IID Graph Data,Academic Editor,2022,Yes,MEDIUM,"Medium relevance for HDM heterogeneous data integration objectives. The PPFL-GNN framework addresses privacy-preserving federated learning on graph neural networks with non-IID data, which aligns with HDM's need for privacy-conscious multi-source data integration. The embedding alignment techniques using SVD-based Procrustes problem formulation provide valuable methods for harmonizing different data representations across distributed systems, directly applicable to schema harmonization challenges in heterogeneous PKG architectures. The federated approach with public/private node separation offers a framework for privacy-preserving integration of personal data from multiple sources. While not explicitly temporal-first or focused on upstream data orchestration, the graph neural network architectures and alignment methodologies are relevant for bespoke PKG system designs requiring distributed, privacy-preserving data fusion across heterogeneous sources.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on research article privacy-preserving federated graph neural network learning on non-iid graph data providing insights for knowledge graph development and data integration.,"This 2022 paper by Academic Editor explores research article privacy-preserving federated graph neural network learning on non-iid graph data. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph",Privacy-Preserving Federated Graph Neural Network Learning on Non-IID Graph Data,"Zhang Kainan, Cai Zhipeng, Seo Daehee",2023,reference-manager,10.1155/2023/8545101,,,,,Improvement from federated learning diminishes as subgraph density increases.,,,,,,"The research goal is to improve privacy-preserving graph learning using federated learning; the approach applies federated DeepWalk and federated GAT frameworks on Cora and CiteSeer datasets; results show federated methods outperform local training, with global improvements up to +18.8 in classification accuracy.",,0.900,fuzzy_title
eitan_2023,Synaptic proteins in neuron-derived extracellular vesicles as biomarkers for Alzheimer's disease: novel methodology and clinical proof of concept,"Erez Eitan, Tricia Thornton-Wells, Katya Elgart, Eren Erden, Eve Gershun, Amir Levine, Olga Volpert, Mitra Azadeh, Daniel G. Smith, Dimitrios Kapogiannis",2023,Yes,HIGH,"Highly relevant to HDM healthcare applications, demonstrates novel biomarker discovery methodology using extracellular vesicles that could inform personal health monitoring and early disease detection systems.",Developed minimally invasive method to isolate neuron-derived extracellular vesicles (NDEVs) from blood plasma; achieved 94.7% classification accuracy for AD patients using protein biomarker model.,Novel methodology for isolating neuron-derived extracellular vesicles as Alzheimer's disease biomarkers.,"This paper develops a minimally invasive method to isolate neuron-derived extracellular vesicles (NDEVs) from blood plasma to identify potential Alzheimer's disease biomarkers, achieving 94.7% classification accuracy.","Can neuron-derived extracellular vesicles provide novel, non-invasive biomarkers for early Alzheimer's disease detection?","Used antibodies against GAP43 and NLGN3 to capture NDEVs, analyzed plasma samples from early AD patients and controls, measured multiple proteins and RNA markers, validated using electron microscopy and proteomics.","p181-Tau, Aβ42, and NRGN elevated in AD; proBDNF, GluR2, PSD95, GAP43, and Syntaxin-1 reduced; developed model correctly classifying 94.7% of AD participants.","Novel NDEV isolation method offers promising, minimally invasive platform for developing AD biomarkers with high classification accuracy.","Small sample size; requires validation in larger, more diverse populations; long-term stability of biomarkers not assessed.",Demonstrates feasibility of using extracellular vesicles for non-invasive disease biomarker discovery applicable to personal health monitoring.,Expand to other neurodegenerative diseases; validate in larger populations; develop point-of-care testing methods.,Scale up validation studies; integrate with digital health platforms; develop automated analysis pipelines.,Agent Alpha: Excellent biomarker discovery methodology highly relevant to HDM healthcare monitoring. Non-invasive approach aligns with personal health data collection needs.,https://www.oaepublish.com/articles/evcna.2023.13,10.20517/evcna.2023.13,"alzheimers-disease, biomarkers, extracellular-vesicles, liquid-biopsy, neurodegenerative-disease",Synaptic proteins in neuron-derived extracellular vesicles as biomarkers for Alzheimer’s disease: novel methodology and clinical proof of concept,"Eitan Erez, Thornton-Wells Tricia, Elgart Katya, Erden Eren, Gershun Eve, Levine Amir, Volpert Olga, Azadeh Mitra, Smith Daniel G., Kapogiannis Dimitrios",2023,reference-manager,10.20517/evcna.2023.13,,,,,,"Retrospective analysis of de-identified samples from commercial and government biobanks, collected under strict regulatory and ethical standards.",,,"How can neuronal-derived extracellular vesicles (NDEVs) isolated from blood serve as specific, minimally invasive biomarkers for detecting and monitoring Alzheimer’s disease pathology in living patients?","The study aimed to determine if changes in synaptic proteins in cerebrospinal fluid occur before neurodegeneration markers in preclinical Alzheimer’s disease. Using de-identified samples and statistical analyses, the study found synaptic protein changes precede neurodegeneration markers, suggesting early biomarker potential for Alzheimer’s disease detection.","The research goal was to evaluate synaptic proteins in neuron-derived extracellular vesicles as Alzheimer’s disease biomarkers using a novel methodology; the approach involved clinical proof of concept and statistical analyses; results showed these biomarkers can distinguish early-stage Alzheimer’s disease from controls, supporting their diagnostic potential.",,1.000,exact_title
engineering_2020,Quality-focused design patterns for digital twin systems Preprint not peer reviewed,Mechatronic Engineering,2020,Yes,HIGH,"High relevance for HDM heterogeneous data integration objectives. The paper presents four quality-focused design patterns (Performance efficiency, Reliability, Reconfigurability, Interoperability) for digital twin systems that directly address core HDM challenges. The reference architecture with DT aggregation hierarchy, services network, and management services provides proven frameworks for multi-source data integration. The interoperability design pattern specifically targets 'heterogenous data handling' and recommends data homogenization and structuring approaches essential for schema harmonization in PKG systems. The pre-storage vs post-storage aggregation concepts align with upstream data orchestration priorities, while the modular, loosely-coupled architecture supports bespoke PKG system designs. Case studies across heliostat fields, water distribution systems, and smart cities demonstrate multi-domain applicability crucial for HDM's cross-sector data integration goals. The systematic approach to managing complex physical systems with diverse stakeholder needs and varying digital maturity levels directly parallels HDM's heterogeneous data fusion challenges.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on quality-focused design patterns for digital twin systems preprint not peer reviewed providing insights for knowledge graph development and data integration.,"This 2020 paper by Mechatronic Engineering explores quality-focused design patterns for digital twin systems preprint not peer reviewed. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,101007978-3-030-99108,Quality-focused design patterns for digital twin systems,"Humana Carlo, Basson Anton H., Kruger Karel",2023,reference-manager,,,,,,,"Application of design patterns: Design patterns focused on quality attributes were applied to three case studies (heliostat field, water distribution network, smart city) to assess effectiveness and utility.",,,"What quality-attribute focused design patterns can be developed to guide the architectural and implementation decisions for digital twin systems in complex environments, and how do these patterns address trade-offs between performance efficiency, reliability, reconfigurability, and interoperability?","The paper aims to enhance digital twin system design by introducing quality-attribute-focused design patterns. Using case studies, it shows these patterns help identify key design aspects and trade-offs, improving system design and speed. However, their quantitative impact and broader applicability require further research.","The paper’s research goal is to present four quality-attribute focused design patterns for digital twin (DT) systems, using a reference architecture approach, and the principal finding is that these patterns help design better and faster DT systems by guiding trade-offs for performance, reliability, reconfigurability, and interoperability.",,0.900,fuzzy_title
esposito_2025,"Generative AI for Software Architecture. Applications, Challenges, and Future Directions","Matteo Esposito, Xiaozhou Li, Sergio Moreschini, Noman Ahmad, Tomas Cerny, Karthik Vaidhyanathan, Valentina Lenarduzzi, Davide Taibi",2025,Yes,MEDIUM,"Medium relevance for HDM heterogeneous data integration objectives. This multivocal literature review analyzes GenAI applications in software architecture with several supporting technologies relevant to HDM. The dominant use of Retrieved-Augmented Generation (RAG) techniques (20% of studies) directly parallels HDM's challenge of integrating external knowledge sources and heterogeneous data streams. The primary application for architectural decision support (38%) aligns with HDM's need for intelligent decision-making in complex multi-source environments. Few-shot prompting and fine-tuning approaches for architectural pattern recognition could inform schema harmonization methodologies. The paper's focus on quality assessment (9%) and software comprehension provides frameworks applicable to data quality evaluation across heterogeneous sources. However, the paper is primarily focused on general software architecture rather than specific data integration architectures, with limited discussion of temporal modeling, upstream data orchestration, or PKG systems. While not directly addressing heterogeneous data fusion, the RAG methodologies and architectural decision support frameworks provide valuable supporting technologies for HDM's bespoke PKG system development.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on generative ai for software architecture. applications, challenges, and future directions providing insights for knowledge graph development and data integration.","This 2025 paper by Matteo Esposito, Xiaozhou Li, Sergio Moreschini, Noman Ahmad, Tomas Cerny, Karthik Vaidhyanathan, Valentina Lenarduzzi, Davide Taibi explores generative ai for software architecture. applications, challenges, and future directions. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,105281zenodo15032395,,,,,,,,,,,,,,,,,,,
fabr_2024,Privacy-Preserving Graph-Based Machine Learning with Fully Homomorphic Encryption for Collaborative Anti-Money Laundering,"Singapore fabr, anupa",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Achieved over 99% accuracy, F1-score, precision, and recall using XGBoost model in both unencrypted and FHE-encrypted inference settings, with graph-based features improving F1-score by 8% on imbalanced datasets while enabling computations directly on encrypted data.",Privacy-preserving collaborative machine learning framework using fully homomorphic encryption to enable secure financial data analysis across institutions while maintaining computational accuracy on encrypted graph data.,"This research addresses the complexity of combating money laundering through advanced machine learning techniques by proposing a privacy-preserving approach for collaborative anti-money laundering (AML) detection. The approach leverages Fully Homomorphic Encryption (FHE) to enable secure data sharing across financial institutions, specifically integrating FHE over the Torus (TFHE) with graph-based machine learning using Zama Concrete ML. Two main pipelines were developed: a privacy-preserving Graph Neural Network (GNN) pipeline and a privacy-preserving graph-based XGBoost pipeline leveraging Graph Feature Preprocessor (GFP).",How can financial institutions collaborate on anti-money laundering detection while maintaining data privacy and regulatory compliance through cryptographic protection of sensitive financial data?,"Utilized Fully Homomorphic Encryption (FHE) with TFHE integration, developed privacy-preserving Graph Neural Network (GNN) pipeline with quantization and pruning for FHE compatibility, created privacy-preserving graph-based XGBoost pipeline with Graph Feature Preprocessor, employed Zama Concrete ML for implementation.","XGBoost model achieved over 99% accuracy, F1-score, precision, and recall on balanced AML dataset in both unencrypted and FHE-encrypted inference settings, graph-based features improved F1-score by 8% on imbalanced dataset, successfully performed computations on encrypted data.",,"Trade-off between privacy protection and computational efficiency, potential scalability challenges with larger datasets, computational overhead from homomorphic encryption operations.",Successfully demonstrated the potential of privacy-preserving machine learning in collaborative anti-money laundering efforts while maintaining high accuracy and enabling secure multi-party computation on sensitive financial data.,,"Further optimization of FHE computational efficiency for large-scale deployment, expansion of privacy-preserving techniques to other collaborative ML applications, integration with existing regulatory compliance frameworks.",Provides practical implementation framework for secure collaborative analysis in HDM systems with focus on homomorphic encryption and graph-based feature processing for sensitive data protection.,https://arxiv.org/abs/2411.02926,10.48550/arXiv.2411.02926,"collaborative-learning, financial-security, fully-homomorphic-encryption, graph-based-ml, privacy-preserving-ml",Privacy-Preserving Graph-Based Machine Learning with Fully Homomorphic Encryption for Collaborative Anti-Money Laundering,"Effendi Fabrianne, Chattopadhyay Anupam",2024,reference-manager,,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
fafrowicz_2022,Neural spatio‑temporal patterns of information processing related to cognitive conflict and correct or false recognitions,Magdalena Fafrowicz,2022,Yes,LOW,"Low relevance for HDM heterogeneous data integration objectives. This neuroscience study investigates cognitive conflict and false memory recognition using fMRI analysis during visual short-term memory tasks with the Deese-Roediger-McDermott paradigm. While the paper employs machine learning classifiers and analyzes spatio-temporal patterns, these methods are specifically applied to brain activation data rather than heterogeneous data integration. The temporal analysis refers to neural response patterns over time, not temporal-first PKG architectures or chronological data modeling. The surface-based cortical data representation and GLM analysis methods are domain-specific to neuroscience rather than applicable to multi-source data fusion or schema harmonization. The study provides no insights into heterogeneous data integration, upstream data orchestration, PKG systems, or bespoke system designs. The machine learning approaches (AUC classifiers, Shapley values) are purely for distinguishing neural response patterns, not for data integration challenges. Despite sophisticated analytical methods, the research focus on cognitive neuroscience places it outside HDM's core objectives of developing temporal-first architectures for heterogeneous data fusion across multi-modal sources.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on neural spatio‑temporal patterns of information processing related to cognitive conflict and correct or false recognitions providing insights for knowledge graph development and data integration.,"This 2022 paper by Magdalena Fafrowicz explores neural spatio‑temporal patterns of information processing related to cognitive conflict and correct or false recognitions. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,103758s13423-019-01668-9,Neural spatio-temporal patterns of information processing related to cognitive conflict and correct or false recognitions,"Janik Romuald A., Podolak Igor T., Struski Łukasz, Ceglarek Anna, Lewandowska Koryna, Sikora-Wachowicz Barbara, Marek Tadeusz, Fafrowicz Magdalena",2022,reference-manager,10.1038/s41598-022-09141-9,,,,,Requires a large dataset for mean signal analysis to achieve statistical relevance.,,,,,,,,1.000,exact_title
fang_2020,"Deep Learning for Sequential Recommendation: Algorithms, Influential Factors, and Evaluations","Hui Fang, Danning Zhang, Yiheng Shu, Guibing Guo",2020,Yes,HIGH,Comprehensive survey of deep learning approaches for sequential recommendation providing systematic analysis of temporal modeling techniques and evaluation methodologies directly applicable to HDM temporal behavior modeling,Systematic categorization of algorithms based on three behavioral sequence types; comprehensive analysis of performance-affecting factors; extensive evaluation methodology for temporal recommendation systems; identifies key research directions for sequential modeling,Comprehensive survey systematically analyzing deep learning methods for sequential recommendation with focus on temporal behavior modeling,"This comprehensive survey addresses deep learning-based methods for sequential recommendation, providing systematic study of algorithms, influential factors, and evaluation methodologies. The survey categorizes existing algorithms based on three types of behavioral sequences, systematically summarizes key factors affecting deep learning model performance, and conducts corresponding evaluations to demonstrate factor effects. The research illustrates sequential recommendation concepts, provides algorithmic categorization, and outlines future research directions. Published in ACM Transactions on Information Systems with 41 pages, 19 figures, 6 tables, and 155 references, representing comprehensive coverage of the field.",How to design effective deep learning models for sequential recommendation and what factors influence their performance in temporal user behavior modeling?,Systematic categorization of algorithms based on three behavioral sequence types; comprehensive analysis of performance-affecting factors; extensive evaluation methodology; algorithmic design principles for sequential recommendation,Comprehensive survey surpassing traditional Markov chain and factorization methods; systematic analysis of deep learning advantages; identification of key performance factors; extensive evaluation framework,Systematic algorithmic categorization; comprehensive performance factor analysis; extensive evaluation methodology; future research direction identification,Survey scope limited to 2019 publication date; rapid evolution of deep learning may date some findings; evaluation methodologies may not cover all recent developments,Deep learning methods significantly outperform traditional approaches in sequential recommendation through superior temporal pattern modeling and flexible architecture design,Limited systematic study of deep learning methods for sequential recommendation; need for comprehensive performance factor analysis; challenges in designing effective temporal modeling architectures,Investigate transformer-based architectures; explore multi-modal sequential recommendation; develop more sophisticated evaluation metrics for temporal modeling,Provides comprehensive framework for understanding sequential recommendation; systematic analysis of temporal modeling approaches; extensive evaluation methodology applicable to HDM systems,https://arxiv.org/abs/1905.01997,10.1145/3426723,"deep-learning, sequential-recommendation, survey, temporal-modeling, user-behavior",Deep Learning for Sequential Recommendation,"Fang Hui, Zhang Danning, Shu Yiheng, Guo Guibing",2020,reference-manager,10.1145/3426723,,"Implementation Insights are summarized as follows: Side information (like images, text, and dwell time) helps address data sparsity and cold-start issues. Negative sampling size significantly impacts performance, especially increasing from 0 to 32. Embedding methods from NLP are limited; more advanced, sequential-specific embeddings and better modeling of user long-term preferences are needed.",,,,Deep Learning (DL) techniques: Used to model long sequences and improve prediction accuracy in sequential recommendation.,,,"What are the key algorithms, influential factors, and evaluation methods in deep learning-based sequential recommendation, and how can future research address current challenges such as comprehensive evaluation, explainability, and effective model design?","This survey systematically reviews deep learning (DL)-based sequential recommendation, aiming to clarify algorithms, influential factors, and evaluation methods. Using comprehensive experimental evaluations on real datasets, it proposes a new classification framework, highlights key challenges, and offers guidance and future directions for designing effective DL-based sequential recommender systems.","The research goal is to systematically survey DL-based sequential recommendation, the approach is proposing a new classification framework and empirically analyzing influential factors, and the principal finding is that these factors significantly impact recommendation accuracy, guiding future research and practice in this area.",,0.900,fuzzy_title
farshidi_2021,Knowledge sharing and discovery across heterogeneous research infrastructures,"Siamak Farshidi, Xiaofeng Liao, Na Li, Doron Goldfarb, Barbara Magagna, Markus Stocker, Keith Jeffery, Peter Thijsse, Christian Pichot, Andreas Petzold, Zhiming Zhao",2021,Yes,HIGH,Direct implementation of knowledge management system (ENVRI-KMS) for heterogeneous research infrastructures addressing fragmented knowledge from autonomous sources. Uses RDF/semantic technologies for data integration FAIR principles implementation and automated knowledge acquisition - core methodologies for HDM's multi-source data fusion objectives.,Comprehensive knowledge management system addressing heterogeneous data integration challenges across environmental research infrastructures using semantic web technologies and automated knowledge acquisition.,Environmental research communities face fragmented knowledge from heterogeneous autonomous sources with complicated relations requiring systematic integration approaches.,How to enable domain-specific research communities with asset discovery challenges based on FAIR principles across heterogeneous research infrastructures?,Mixed methods: design science research surveys (35 domain experts across 26 research infrastructures) documentation analysis structured coding for knowledge extraction from diverse sources.,Three-layer ENVRI-KMS architecture (Interface Service Storage) implementing RDF-based knowledge integration with automated ingestion from wikis catalogs documents and websites achieving semantic interoperability across heterogeneous sources.,ENVRI-KMS system with RDF Triple Store semantic search capabilities automated knowledge acquisition from multiple source types FAIR principles compliance and provenance tracking for environmental research infrastructure integration.,Restricted to environmental domain specificity limited evaluation of cross-domain applicability challenges with noisy document sets and semantically ill-formed content requiring manual curation.,Knowledge management systems require automated acquisition semantic integration of heterogeneous sources and FAIR principles implementation to address research community asset discovery challenges effectively.,Evaluation methodology for knowledge management system effectiveness cross-domain applicability assessment advanced natural language processing for unstructured content integration.,Enhanced knowledge discovery approaches for multi-domain applications integration with virtual research environments advanced semantic reasoning capabilities for cross-infrastructure interoperability.,RDF-based architecture patterns for heterogeneous data integration semantic web technologies for knowledge harmonization automated ingestion pipelines for diverse content types FAIR principles implementation frameworks for research asset management.,https://open-research-europe.ec.europa.eu/articles/1-68/v1,10.12688/openreseurope.13677.1,"knowledge management, heterogeneous data integration, semantic web, RDF, environmental research, FAIR principles, knowledge discovery","data-integration, heterogeneous-data, knowledge-graph",Knowledge sharing and discovery across heterogeneous research infrastructures,"Farshidi Siamak, Liao Xiaofeng, Li Na, Goldfarb Doron, Magagna Barbara, Stocker Markus, Jeffery Keith, Thijsse Peter, Pichot Christian, Petzold Andreas, Zhao Zhiming",2021,reference-manager,10.12688/openreseurope.13677.1,"The ENVRI-KMS system addresses over 62% of identified requirements, making its main components functional.",,,,,,,"Reproducibility: The research is only partly reproducible. Sufficient details of the code, methods, and analysis are not provided to allow replication. Information for interpreting output datasets is partly available. A related source code is referenced at https://github.com/xiaofengleo/actris.",,,,"Keywords: Knowledge base, knowledge management, search engine, research infrastructure, software development lifecycle.",1.000,exact_title
feng_2024,A contrastive learning framework with dual gates and noise awareness for temporal knowledge graph reasoning,"Siling Feng, Bolin Chen, Qian Liu, Mengxing Huang",2024,Yes,MEDIUM,"While focused on temporal knowledge graph reasoning rather than heterogeneous data integration, this paper presents sophisticated temporal-first modeling approaches that could inform PKG architectures. The DNCL framework's multi-dimensional gated mechanisms and temporal relationship modeling techniques provide valuable insights for temporal aspects of bespoke PKG systems, though it doesn't directly address multi-source data fusion or schema harmonization challenges central to HDM objectives.","Advanced temporal modeling techniques including dual-gate mechanisms for long-distance dependencies, noise-aware adversarial training, and multi-layer contrastive learning that could enhance temporal-first PKG architectures for heterogeneous data integration systems.","DNCL framework addresses three core temporal KG reasoning challenges through multi-dimensional gated updates, adversarial noise modeling, and contrastive learning, achieving 6.91% Hit@1 improvements on temporal knowledge graph datasets.","This paper presents the DNCL (Dual-gate and Noise-aware Contrastive Learning) framework for temporal knowledge graph reasoning, addressing three critical challenges: capturing long-distance dependencies in sparse environments, handling noise interference, and modeling complex temporal relationships. The framework integrates three core modules: a multi-dimensional gated update module using dual-gate mechanisms (selection + update gates) for information filtering and long-distance dependency capture, a noise-aware adversarial modeling module employing GAN-based training for robustness against data noise, and a multi-layer embedding contrastive learning module combining intra-layer and inter-layer contrastive strategies for comprehensive temporal relationship modeling. Experimental results on four temporal KG datasets (ICEWS14, ICEWS05-15, ICEWS18, GDELT) demonstrate significant performance improvements over 20 baseline models, with Hit@1 improvements of 6.91%, 4.31%, and 5.30% respectively, validating the framework's effectiveness in temporal reasoning tasks.",How can advanced temporal modeling techniques be integrated into personal knowledge graph architectures to improve temporal relationship reasoning and long-distance dependency capture in heterogeneous data environments?,"Experimental evaluation using four temporal knowledge graph datasets (ICEWS14, ICEWS05-15, ICEWS18, GDELT) with comprehensive comparison against 20 baseline models including static KG methods, interpolation models, and extrapolation approaches, plus ablation studies analyzing individual module contributions.","DNCL framework achieves state-of-the-art performance on temporal KG reasoning with Hit@1 improvements of 6.91% (ICEWS14), 4.31% (ICEWS05-15), and 5.30% (ICEWS18). Multi-dimensional gated update module effectively captures long-distance dependencies through dual-gate mechanisms. Noise-aware adversarial modeling significantly improves robustness in noisy environments (2.27% MRR improvement on GDELT dataset). Multi-layer contrastive learning provides 3.68% MRR improvement through intra-layer and inter-layer temporal relationship modeling.","DNCL framework integrating three complementary modules: multi-dimensional gated update for dependency modeling, noise-aware adversarial training for robustness, and multi-layer contrastive learning for temporal relationship capture, demonstrating superior performance over existing temporal KG reasoning approaches.","Model performance limited by dataset-specific temporal granularities (24-hour vs 15-minute intervals affecting optimal history lengths). Complex parameter tuning required for temperature coefficients and noise intensity controls. Computational complexity increases with model layers and contrastive learning operations, though still more efficient than baseline approaches.","DNCL framework successfully addresses core temporal knowledge graph reasoning challenges through innovative integration of gated mechanisms, adversarial training, and contrastive learning, providing robust solution for temporal relationship modeling in knowledge graphs with significant performance improvements over existing methods.",Framework focuses specifically on temporal reasoning rather than heterogeneous data integration. Limited exploration of multi-modal data fusion beyond temporal relationships. Schema harmonization and cross-domain entity resolution not addressed despite relevance to PKG architectures.,"Future work could explore multi-modal information integration (text, images, sensor data), optimization for ultra-large-scale and ultra-sparse datasets, and incorporation of large language models, meta-learning, and incremental learning techniques for enhanced adaptability to new events and domains.","The dual-gate mechanisms and temporal-first modeling approaches could inform temporal aspects of bespoke PKG systems, particularly for handling temporal dependencies in heterogeneous data streams. Noise-aware adversarial training techniques could enhance data quality management in upstream data orchestration pipelines for multi-source integration scenarios.",https://doi.org/10.1038/s41598-024-72010-x,10.1038/s41598-024-72010-x,"adversarial-training, contrastive-learning, gated-mechanisms, knowledge-graph-completion, multi-layer-learning, noise-modeling, temporal-knowledge-graph, temporal-reasoning",A contrastive learning framework with dual gates and noise awareness for temporal knowledge graph reasoning,"Feng Siling, Chen Bolin, Liu Qian, Huang Mengxing",2025,reference-manager,10.1038/s41598-025-00314-w,,,,,,Multi-dimensional gated update module: Optimizes the ability to capture long-distance dependencies in temporal knowledge graphs using a dual-gate selection strategy.,,,How can a dual-gate and noise-aware framework effectively model potential temporal connections in temporal knowledge graphs to improve the accuracy of extrapolative reasoning for predicting future facts?,"The paper aims to improve extrapolative reasoning for predicting future facts by proposing the DNCL model, which uses multi-layer embedding contrastive learning to enhance temporal relationship modeling. Experiments on four datasets show significant performance gains, especially from the contrastive learning module. The study concludes this module is crucial for model effectiveness.","The research goal is to improve temporal knowledge graph reasoning accuracy and robustness; the DNCL approach combines a multi-dimensional gated update module, noise-aware adversarial modeling, and multi-layer embedding contrastive learning; results show DNCL outperforms existing models on four benchmarks, especially in handling long-distance dependencies and noise.",,1.000,exact_title
ferdousi_2025,RHealthTwin: Towards Responsible and Multimodal Digital Twins for Personalized Well-being,"Rahatara Ferdousi, M. Anwar Hossain Senior Member",2025,Yes,HIGH,Direct implementation of heterogeneous data integration in bespoke digital twin healthcare systems using multimodal data fusion (EHR + wearable sensors + user inputs + knowledge bases) through Responsible Prompt Engine with slot-based schema harmonization and temporal adaptation capabilities,"Responsible Prompt Engine (RPE) with four-module architecture enables ethical multimodal data fusion for bespoke PKG-like healthcare systems, demonstrating practical heterogeneous data integration with temporal adaptation through feedback loops and schema harmonization via slot-based prompt engineering","RHealthTwin presents a responsible AI framework for building multimodal digital twins in consumer health applications, addressing heterogeneous data integration challenges through a sophisticated Responsible Prompt Engine (RPE) that processes diverse data sources including EHR records, wearable sensors, user text/image inputs, and clinical knowledge bases using slot-based prompt engineering for dynamic schema harmonization and ethical AI governance.",How can responsible AI frameworks enable effective heterogeneous data integration in consumer health digital twin systems while maintaining ethical compliance and multimodal data fusion capabilities?,"Experimental evaluation using four healthcare datasets (MentalChat16k, MTS-Dialog, NutriBench, SensorQA) with synthetic prompt generation, automated GPT-based evaluation, and comparison across prompt strategies (zero-shot, few-shot, instruction-tuned, RPE) measuring both reference-based metrics and ethical compliance scores","Responsible Prompt Engine (RPE) achieved superior performance with BLEU=0.41, ROUGE-L=0.63, BERTScore=0.89 on reference-based metrics and >90% ethical compliance (ICS>0.94, WRR>0.92) across all datasets, demonstrating effective heterogeneous data integration with WHO-aligned ethical safeguards and multimodal reasoning capabilities","RHealthTwin framework enabling responsible multimodal digital twins for healthcare through four-module RPE architecture: Context-Aware Task Personalization, Adaptive System Behavior Management, Filter Constraints, and Justification/Grounding modules with slot-based prompt engineering for dynamic schema harmonization",Limited evaluation on synthetic prompts rather than real clinical deployments; potential scalability challenges with complex multimodal data streams; feedback loop effectiveness requires longitudinal validation; integration complexity may limit adoption in resource-constrained healthcare environments,"RHealthTwin demonstrates that responsible AI frameworks can successfully integrate heterogeneous healthcare data through sophisticated prompt engineering while maintaining ethical compliance, providing a practical foundation for bespoke PKG systems in consumer health applications with superior performance across multiple evaluation metrics",Advanced schema harmonization techniques for complex multimodal healthcare data; longitudinal evaluation of temporal adaptation mechanisms; integration with federated learning for privacy-preserving multi-institutional deployment; scalability assessment for enterprise healthcare environments,Real-time multimodal data processing pipelines for consumer health applications; automated safety constraint enforcement in healthcare AI systems; longitudinal feedback-driven system adaptation; practical WHO ethics compliance implementation,Slot-based prompt engineering for dynamic schema harmonization in heterogeneous data environments; four-module RPE architecture as template for ethical AI governance in healthcare systems; multimodal data fusion strategies for temporal-aware digital twin development; practical implementation patterns for responsible AI deployment in consumer health applications,https://github.com/turna1/ResponsibleHealthTwin-RHT-,,Healthcare Digital Twins,responsible-ai,RHealthTwin: Towards Responsible and Multimodal Digital Twins for Personalized Well-being,"Ferdousi Rahatara, Hossain M. Anwar",2025,reference-manager,,,,,,,"Synthetic Prompt Generation: Created structured, context-rich prompts for both patients and care providers using dataset attributes (e.g., symptoms, sensor data) to simulate real-world health dialogues.",,,"How does the Responsible Prompt Engine (RPE) within the RHealthTwin framework enable structured, ethical, and personalized prompt generation to improve large language model response quality across diverse healthcare domains compared to standard prompting paradigms?","The study evaluates the Responsible Prompt Engine (RPE) within the RHealthTwin framework, focusing on generating ethical, structured, and personalized prompts for health-related LLM outputs. Using four benchmark datasets and various prompt strategies, RPE consistently outperformed baselines in factuality, contextual appropriateness, and responsibility, supporting its use in mid-resource healthcare settings.","The research goal is to evaluate the Responsible Prompt Engine within the RHealthTwin framework using slot-based prompting on four health datasets; the approach involves generating structured, ethical, and personalized prompts, and the principal finding is improved response quality and responsible, context-rich outputs compared to standard prompting methods.",,1.000,exact_title
ferreira_2019,A Survey on Semantic Modeling for Building Energy Management,Miracle Aniakor Vinicius V. Cogo Pedro M. Ferreira,2019,Yes,MEDIUM,Provides foundational knowledge for semantic modeling and ontology-based data integration approaches that directly inform our HDM heterogeneous data integration research,Comprehensive survey analyzing semantic modeling techniques for heterogeneous building data integration using ontologies like BOT SAREF SSN/SOSA and Brick,Survey analyzes semantic modeling approaches for building energy management providing foundational knowledge on ontology-based heterogeneous data integration.,This survey examines leading semantic modeling techniques for building energy management addressing challenges in semantic interoperability and heterogeneous data integration from diverse building systems and manufacturers. The authors analyze core ontologies including BOT (Building Topology Ontology) SAREF (Smart Applications REFerence) SSN/SOSA (Semantic Sensor Network) Brick and Project Haystack. They demonstrate how these ontologies can be combined to integrate static data (building topology from BIM) with dynamic data (sensor measurements IoT devices) to create unified building representations. The study identifies use case scenarios ranging from single-ontology applications to complex multiple-ontology integration patterns for comprehensive building energy analysis.,What semantic modeling techniques are most effective for achieving interoperability and data integration in building energy management systems?,Systematic literature review analyzing 50 papers across 6 major databases using PRISMA guidelines with focus on ontology applications in building operational phases,Core ontologies (BOT SAREF SSN/SOSA Brick Project Haystack) enable heterogeneous data integration from diverse building systems. Multiple-ontology approaches required for comprehensive building energy management applications. Semantic interoperability achievable through standardized data models and linked data approaches,Unified framework demonstrating ontology combinations for building energy applications. Classification system for single dual and multiple ontology use cases. Comprehensive analysis of semantic modeling effectiveness across different building scenarios,Individual ontologies insufficient for complete building energy management. Complexity challenges in implementing semantic models. Limited flexibility in existing schemas for new building entities and sensor types,Semantic modeling through ontologies enables effective heterogeneous data integration for building energy management. Multiple-ontology approaches necessary for comprehensive applications. Foundation established for advanced building analytics and energy optimization,Need for more flexible and extensible ontology frameworks. Development of automated ontology alignment and mapping tools. Enhanced support for real-time data integration and processing,Essential foundation for implementing ontology-based heterogeneous data integration in HDM systems. Demonstrates practical approaches for combining static and dynamic building data through semantic modeling techniques,https://example-url-to-paper,10.3030/957128,"Semantic Modeling, Building Energy Management, Ontologies, Data Integration, BOT, SAREF, SSN/SOSA, Brick, Heterogeneous Data, Building Automation","data-integration, knowledge-graph",A Survey on Semantic Modeling for Building Energy Management,"Aniakor Miracle, Cogo Vinicius V., Ferreira Pedro M.",2024,reference-manager,,,"The survey reveals a gap between theoretical knowledge and real-world use of semantic models in building energy management (BEM). It highlights the need for technical advances and user-friendly platforms, shows that linked data can streamline KPI calculations, and proposes interconnected ontologies for better, scalable, and context-aware BEM applications.",,,,"Strategic keyword search using a refined search string across six major databases (e.g., IEEE, ACM, Scopus) to identify relevant literature.",,,"What are the needs, applications, limitations, and best practices of using ontologies and semantic modeling in building operations for Building Energy Management (BEM), and how can a more unified and practical approach be developed to enhance their effectiveness and real-world adoption?","This paper surveys the use of semantic modeling and ontologies in building energy management (BEM) operations. Using a systematic literature review, it identifies key applications, benefits, limitations, and trends. The study concludes that unified, collaborative ontology development is needed to enhance practical BEM applications and interoperability.","The research goal is to survey semantic modeling in building operations, using a systematic literature review to analyze applications, methods, and limitations; the principal finding highlights ontology fragmentation and recommends unified, collaborative approaches for more effective and scalable building energy management (BEM) solutions.","Keywords or tags for this research include: marker, string, reference, air-handling unit, annotation, entity type, human-readable descriptions, ontology, energy domains, sensors, measurements, building entities, energy efficiency, smart device, home, building, city, energy, grid.",1.000,exact_title
fu_2024,Privacy-Preserving Graph Machine Learning from Data to Computation: A Survey,"Dongqi Fu, Wenxuan Bao, Ross Maciejewski, Hanghang Tong, Jingrui He",2024,Yes,HIGH,"This survey directly addresses privacy-preserving techniques for graph machine learning, covering both data generation and computation aspects essential for HDM heterogeneous data integration with privacy constraints",Comprehensive framework for privacy-preserving graph ML covering data anonymization and federated learning approaches; identifies challenges in temporal and heterogeneous graphs; proposes combining data generation and computation privacy techniques,Comprehensive survey of privacy-preserving techniques for graph machine learning covering data anonymization and federated computation approaches,"This comprehensive survey systematically reviews privacy-preserving techniques for graph machine learning from two complementary perspectives: privacy-preserving graph data generation and privacy-preserving computation. The authors analyze various privacy attackers (active/passive), protection mechanisms (k-anonymization, differential privacy), and federated learning approaches across graph-level, subgraph-level, and node-level scenarios. The work identifies key challenges in temporal and heterogeneous graphs and proposes future directions for combining data generation and computation privacy techniques.",How can privacy be preserved in graph machine learning across both data sharing and multi-party computation scenarios?,Comprehensive literature review with systematic categorization of privacy techniques across data and computation domains,Privacy attacks focus on node identity disclosure and link re-identification; protection mechanisms include k-anonymization variants and differential privacy; federated learning addresses non-IID challenges in graph data; current techniques have limitations requiring combined approaches,Unified taxonomy of privacy-preserving graph ML techniques; identification of research gaps in temporal and heterogeneous graph privacy; framework for combining data generation and computation privacy,Current techniques address either data or computation privacy separately; limited work on temporal and heterogeneous graph privacy; privacy-utility trade-offs require better analysis,"Privacy-preserving graph ML requires integrated approaches combining data generation and computation techniques; future work should address temporal graphs, heterogeneous graphs, and unified privacy frameworks",Limited privacy techniques for temporal and heterogeneous graphs; lack of unified frameworks combining data and computation privacy; insufficient privacy budget distribution analysis,Develop privacy techniques for temporal and heterogeneous graphs; create unified privacy frameworks; improve privacy-utility trade-off analysis; advance parameter information disentanglement,Differential privacy and federated learning provide complementary privacy protection; k-anonymization variants effective for structural privacy; combined approaches needed for comprehensive privacy in PKG systems,https://arxiv.org/abs/2307.04338,10.48550/arXiv.2307.04338,"data-anonymization, differential-privacy, federated-learning, graph-machine-learning, pkg-systems, privacy, survey",Privacy-Preserving Graph Machine Learning from Data to Computation: A Survey,"Fu Dongqi, Bao Wenxuan, Maciejewski Ross, Tong Hanghang, He Jingrui",2023,reference-manager,,,,,,,"Graph Summarization: Partitions the original graph into clusters, each serving as a node in an anonymized graph, with varied edge connection strategies to protect privacy.",,,"What are the main privacy threats and protection techniques in graph machine learning, and how can privacy-preserving methods be systematically classified and integrated from both data and computational perspectives to achieve a comprehensive and secure graph machine learning system?","This paper reviews privacy-preserving techniques in graph machine learning, focusing on protecting sensitive information in graph data and computations. It systematically examines attackers, protection mechanisms (like randomized and differential privacy methods), and federated learning. The study highlights current challenges and suggests future research opportunities for secure graph machine learning systems.","The paper's research goal is to systematically review privacy-preserving techniques in graph machine learning, using a comprehensive approach covering both data and computation levels, and its principal finding is a classification of methods and future directions for secure graph machine learning systems.",,1.000,exact_title
gaffineta_2002,Human Digital Twin: Systematic Literature Review and Concept Disambiguation for Industry 5.0,"Ben Gaffineta, Jana Al Haj Ali, Yannick Naudet",2023,Yes,HIGH,"This systematic literature review provides comprehensive definitional clarity for HDT concepts, addressing data integration levels, temporal synchronization, and privacy challenges essential for heterogeneous PKG architectures",Systematic review analyzing 90 HDT papers across domains; proposes categorization framework (Digital Model/Shadow/Twin) based on data integration levels; identifies consensus on human individual as twinned entity; addresses temporal data flows and privacy challenges,Comprehensive systematic literature review analyzing Human Digital Twin conceptualization across all application domains to establish domain-agnostic definition,"This systematic literature review analyzes 90 papers on Human Digital Twins across healthcare, industry, mobility, and metaverse domains. The authors identify conceptual divergence in HDT definitions and propose a unified framework categorizing HDTs by data integration levels: Human Digital Models (manual data flow), Human Digital Shadows (automatic input, manual feedback), and Human Digital Twins (bidirectional automatic data flow). The review establishes consensus that HDT twinned entities are human individuals, addresses temporal synchronization challenges, and proposes augmented HDTs for strongly coupled human-technical systems.",What is a general definition for HDTs that applies to all application areas?,Systematic literature review with comprehensive analysis of 90 primary studies across 8 databases using structured inclusion/exclusion criteria,94.4% consensus that twinned entity is human individual; data integration levels vary significantly between conceptual (76.2% true DTs) and implementation studies (42.9% true DTs); Healthcare and Industry dominate with 61.1% of publications; temporal synchronization and privacy emerge as key challenges,Domain-agnostic HDT definition framework; categorization schema based on data integration levels; identification of augmented HDT concept for human-technical system coupling; comprehensive challenge taxonomy,Current techniques address either data or computation separately; limited standardized frameworks; temporal and privacy requirements insufficiently addressed; gap between conceptual models and practical implementations,Privacy-preserving HDT requires integrated approaches; standardized frameworks needed for cross-disciplinary collaboration; temporal data synchronization essential for effectiveness; ethical guidelines critical for adoption,Limited privacy techniques for temporal data flows; lack of unified frameworks across domains; insufficient attention to strongly coupled human-technical systems; standardization gaps in data integration approaches,Develop standardized HDT frameworks; advance temporal data synchronization techniques; create ethical guidelines for HDT development; investigate augmented HDT architectures for human-technical coupling,Bidirectional automatic data flow essential for true HDTs; temporal synchronization critical for real-time applications; privacy-preserving techniques needed for personal data protection; categorization framework enables systematic HDT development,https://publications.jrc.ec.europa.eu/repository/handle/JRC130851,10.2777/308407,"data-integration, human-digital-twin, industry-50, pkg-systems, privacy, systematic-review, temporal-synchronization",Human Digital Twin: Systematic Literature Review and Concept Disambiguation for Industry 5.0,"Gaffineta Ben, Al Haj Ali Jana, Naudet Yannick, Panetto Hervé",2024,reference-manager,,,,,,"Many papers do not provide explicit definitions of HDTs, leading to varied interpretations.",,,"The research ensures reproducibility by following a defined protocol based on established guidelines, detailing search strategies, inclusion/exclusion criteria, and categorization methods. Eight databases were systematically searched. There is no mention of source code for the project.",What is a general definition for HDTs that applies to all application areas?,"The paper conducts a systematic literature review to define Human Digital Twins (HDTs), analyze their conceptual understanding, application areas, and development challenges. Using a rigorous protocol across eight databases, 90 primary studies were analyzed. Key findings highlight diverse definitions and applications, with implications for clearer taxonomy and future research directions.","The paper's research goal is to define a general concept of Human Digital Twins (HDTs) across domains, using a systematic literature review approach, and its principal finding is the identification of divergent definitions and the proposal of a coherent, general definition while summarizing key research challenges and directions.","The keywords or tags for this research are: “Human Digital Twin”, “Patient Digital Twin”, “Worker Digital Twin”, “Operator Digital Twin”, “Student Digital Twin”, “Driver Digital Twin”, “Citizen Digital Twin”, “Human Digital Shadow”, “Customer Digital Twin”, “Consumer Digital Twin”, “Elderly Digital Twin”, “Bio Digital Twin”, “Human Digital Clone”, “Human Virtual Twin”.",1.000,exact_title
galke_2021,Lifelong Learning on Evolving Graphs Under the Constraints of Imbalanced Classes and New Classes,"Lukas Galke, Iacopo Vagliano, Benedikt Franke, Tobias Zielke, Marcel Hoffmann, Ansgar Scherp",2021,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",gDOC method achieves 32% improvement in open-F1 score for new class detection; effective with minimal labeled data; addresses both new class emergence and imbalanced distributions; demonstrates robust performance across different GNN architectures,Continual learning framework for temporal graphs addressing new class detection,"This paper addresses lifelong graph learning challenges, specifically adapting graph neural networks to evolving graphs with imbalanced classes and new class emergence. The research proposes gDOC method extending DOC for new class detection in conjunction with incrementally trained GNNs. The approach uses weighted binary cross-entropy loss and k-neighborhood time difference measures to normalize temporal changes. Experimental results demonstrate effectiveness with minimal labeled data and robust performance across GraphSAGE, Simplified Graph Convolution, and Graph Attention Networks architectures.",How to adapt graph neural networks to evolving graphs while handling both new class emergence and imbalanced class distributions in continual learning settings?,gDOC method for new class detection; weighted binary cross-entropy loss function; k-neighborhood time difference measure; incremental training algorithm for GNNs,gDOC outperformed baseline DOC with 32% improvement in open-F1 score; effective performance with minimal labeled data; robust across multiple GNN architectures; successful handling of both new classes and imbalanced distributions,,Evaluation limited to specific graph datasets; computational overhead of continual learning not fully characterized; scalability to very large evolving graphs unclear,"Continual learning on evolving graphs requires specialized techniques to handle both new class emergence and imbalanced distributions, with gDOC providing effective solution for these challenges",,Investigate larger-scale temporal graph applications; optimize computational efficiency; explore domain-specific continual learning approaches,Addresses both new class detection and imbalanced data challenges; provides robust framework for evolving graph learning; applicable to dynamic personal knowledge graph evolution,https://arxiv.org/abs/2112.10558,10.48550/arXiv.2112.10558,"class-imbalance, continual-learning, graph-neural-networks, new-class-detection, temporal-graphs",Lifelong learning on evolving graphs under the constraints of imbalanced classes and new classes,"Galke Lukas, Vagliano Iacopo, Franke Benedikt, Zielke Tobias, Hoffmann Marcel, Scherp Ansgar",2023,reference-manager,10.1016/j.neunet.2023.04.022,,"Parameter reuse allows high accuracy with limited history size. Adding unlabeled data after training does not improve inductively pre-trained models. Weighted binary cross-entropy in gDOC is crucial for unseen class detection in imbalanced graphs, while the risk reduction technique is not helpful. Omitting old data may improve out-of-distribution detection.",,,,Comparison of transductive and inductive learning: Models are trained on labeled data only (inductive) versus including unlabeled data (transductive) to assess accuracy changes.,,,"Does adding unlabeled data to the graph after initial training improve the accuracy of inductively pre-trained models compared to transductive models, and how do different train-test splits affect this in static graph datasets for vertex classification?","The paper investigates graph neural network (GNN) performance on static and dynamic scientific publication datasets. Using repeated experiments, it compares pre-training, model types, and history sizes. Pre-trained GNNs outperform others in accuracy and stability. Unlimited history size yields the best results. gDOC outperforms DOC in new class detection.","The research goal is to improve unseen class detection in dynamic graphs; the approach introduces gDOC, a class-weighted extension of DOC, and results show gDOC consistently outperforms DOC in both MCC and Open F1 Macro scores, especially on imbalanced and challenging datasets.",,1.000,exact_title
galkin_2024,TGB 2.0: A Benchmark for Learning on Temporal Knowledge Graphs and Heterogeneous Graphs,"Mikhail Galkin, Erfan Loghmani, Emanuele Rossi, Ioannis Koutis, Heiner Stuckenschmidt",2024,Yes,HIGH,"Comprehensive benchmark revealing scalability challenges in temporal KG learning, crucial for evaluating HDM temporal modeling approaches.",8 novel datasets up to 53M edges across 5 domains; reveals edge-type information crucial for performance; shows most methods fail on largest datasets; simple heuristics often competitive.,Robust benchmark framework exposing scalability limitations in current temporal,"This paper introduces TGB 2.0, a comprehensive benchmark for temporal knowledge graphs and heterogeneous graphs with large-scale datasets revealing critical scalability challenges in existing methods.",How can we create a robust benchmark for evaluating machine learning methods on temporal and heterogeneous graphs at scale?,Developed 8 novel datasets spanning 5 domains; created reproducible evaluation protocols; tested existing ML methods; analyzed performance across scales; identified key factors for success.,Edge-type information crucial for performance; simple heuristic baselines often competitive; most methods cannot scale to largest datasets; highlights need for more scalable approaches.,Comprehensive benchmark revealing critical scalability gaps in temporal graph learning methods.,Limited to specific evaluation metrics; focuses on identifying problems rather than solutions; computational requirements for full evaluation high.,"TGB 2.0 exposes fundamental scalability challenges in temporal graph learning, calling for new research directions.",Develop scalable temporal graph methods; create efficient algorithms for large graphs; explore approximation techniques.,Research on scalable methods urgently needed; develop new architectures for large temporal graphs; create efficient training procedures.,"Provides essential evaluation framework for HDM temporal components, highlighting scalability as critical challenge for real-world deployment.",https://arxiv.org/abs/2406.09639,10.48550/arXiv.2406.09639,"benchmark, heterogeneous-graphs, machine-learning, scalability, temporal-graphs",TGB 2.0: A Benchmark for Learning on Temporal Knowledge Graphs and Heterogeneous Graphs,"Gastinger Julia, Huang Shenyang, Galkin Mikhail, Loghmani Erfan, Parviz Ali, Poursafaei Farimah, Danovitch Jacob, Rossi Emanuele, Koutis Ioannis, Stuckenschmidt Heiner, Rabbany Reihaneh, Rabusseau Guillaume",2024,reference-manager,,,,,,,Data was collected from online public sources using Python scripts and software APIs.,,,"What are the characteristics, collection processes, ethical considerations, and potential uses of the TGB 2.0 datasets released for benchmarking temporal knowledge graphs (TKGs) and temporal heterogeneous graphs (THGs)?","The paper introduces the TGB 2.0 benchmark datasets for temporal graph research, aiming to support academic benchmarking of methods. Data was collected from public sources and anonymized; no preprocessing was done. All datasets were tested and benchmarked. The datasets are public, intended for research, and regularly updated based on feedback.","The paper's main objective is to introduce TGB 2.0, a benchmark for evaluating multi-relational temporal graphs; the key method is providing new, large, diverse datasets and an automated evaluation pipeline; the principal finding is that existing methods struggle with scalability, and simple baselines remain competitive.",,1.000,exact_title
gambarelli_2022,PRIVAFRAME: A Frame-Based Knowledge Graph for Sensitive Personal Data,"Gaia Gambarelli, Aldo Gangemi",2022,Yes,HIGH,"Abstract only - directly addresses sensitive personal data identification using semantic frames and KGs, highly relevant to privacy aspects of HDM systems.",Addresses pervasiveness of dialogue systems and virtual conversation applications that raise potential for sharing sensitive information; uses Data Privacy Vocabulary (DPV) as reference taxonomy.,Frame-based knowledge graph for automatically identifying sensitive personal,"This paper develops PRIVAFRAME, a frame-based knowledge graph for personal data categories using the Data Privacy Vocabulary as reference taxonomy, achieving 78% accuracy in identifying personal data categories compared to 66% for transformer-based models.",How can sensitive personal information be automatically identified in text using semantic frames and knowledge graphs?,"Developed PRIVAFRAME using compositional frames from existing semantic frames, evaluated on manually labeled dataset (SPeDaC3), compared with RoBERTa transformer model.","Achieved 78% accuracy vs 66% for transformer model, provides granular context-aware approach to sensitive information detection, can identify specific text spans containing sensitive information.",Frame-based approach outperforms neural models for sensitive data detection with 78% accuracy and granular text span identification.,"Abstract only - evaluation limited to specific dataset, detailed methodology and broader applicability assessment not available.",Demonstrates superior performance of logical-symbolic approaches over neural methods for privacy-sensitive data identification.,Abstract only - broader evaluation across different domains and data types needed.,"Explore hybrid logical-symbolic and neural approaches, expand evaluation to more diverse datasets, investigate real-world deployment scenarios.",Provides semantic framework for privacy-aware data identification that could be integrated into HDM systems for automatic sensitive data detection and protection.,https://www.mdpi.com/2504-2289/6/3/90,10.3390/bdcc6030090,"knowledge-graph, personal-data, privacy, semantic-frames, sensitive-information",PRIVAFRAME: A Frame-Based Knowledge Graph for Sensitive Personal Data,"Gambarelli Gaia, Gangemi Aldo",2022,reference-manager,10.3390/bdcc6030090,,,,,,Manual annotation: The authors constructed and manually labeled a corpus of personal data categories (PDCs) for model evaluation.,,,"How can a knowledge graph-based, context-aware model like PRIVAFRAME improve the identification and fine-grained analysis of complex sensitive personal data categories in text, compared to traditional rule-based and keyword-based approaches?","The paper introduces PRIVAFRAME, a novel knowledge graph-based, logical-symbolic approach for identifying sensitive personal data categories (PDCs) using the Data Privacy Vocabulary. The methodology includes constructing a manually labeled corpus and evaluating PRIVAFRAME against transformer-based models. Results highlight improved precision in entity-level sensitive data identification and suggest hybrid approaches for future SID tasks.","The research goal is to improve sensitive information detection (SID) by introducing PRIVAFRAME, a novel frame-based knowledge graph approach, which outperforms deep learning models in accuracy for fine-grained personal data categories, demonstrating promising results and potential for hybrid SID solutions.",,1.000,exact_title
gao_2024,Large Language Models and Medical Knowledge Grounding for Diagnosis Prediction,"Yanjun Gao, Ruizhe Li, Emma Croxford, Samuel Tesch, Daniel To, John Caskey, Brian W. Patterson, Matthew M. Churpek, Timothy Miller, Dmitriy Dligach, Majid Afshar, Public Health, Wisconsin Madison",2024,Yes,HIGH,"Introduces DR.KNOWS framework for medical knowledge grounding using UMLS knowledge graphs with LLMs, achieving 66% diagnostic accuracy and >94% reasoning scores, directly relevant to HDM heterogeneous data integration from EHR sources","Novel graph-based knowledge grounding framework (DR.KNOWS) that integrates UMLS medical knowledge graphs with LLMs for EHR diagnosis prediction, achieving significant improvements in diagnostic reasoning and abstraction capabilities",Large Language Models enhanced with medical knowledge graphs demonstrate robust diagnostic capabilities with 66% accuracy and exceptional reasoning performance exceeding 94% median scores through comprehensive human evaluation,This paper addresses how to integrate structured medical knowledge graphs (UMLS) with Large Language Models to improve diagnostic accuracy and reasoning in clinical decision support systems from electronic health record data,"The study employs DR.KNOWS graph neural network architecture with trilinear and multi-head attention mechanisms, retrieval-augmented generation (RAG) framework, and comprehensive human evaluation based on SaferDX diagnostic safety instrument using ChatGPT-3.5-turbo on MIMIC-III and in-house EHR datasets","DR.KNOWS achieved superior precision (19.10 vs 13.59) and F-scores (25.20 vs 21.13) compared to concept extraction baselines, with ChatGPT demonstrating 66% diagnostic accuracy and >94% reasoning scores in human evaluation, showing enhanced abstraction and rationale capabilities when augmented with knowledge graphs","The primary outcome is the DR.KNOWS framework that successfully integrates UMLS knowledge graphs with LLMs for medical diagnosis, achieving measurable improvements in diagnostic reasoning, abstraction capabilities, and the first comprehensive human evaluation framework for LLM diagnostic systems based on SaferDX principles","Limitations include DR.KNOWS errors in selecting irrelevant pathways, computational complexity of multi-hop reasoning in large knowledge graphs (4.5M concepts, 15M relations), reliance on semantic similarity ranking without probabilistic modeling, and ChatGPT's occasional failure to incorporate beneficial knowledge paths effectively","The integration of medical knowledge graphs with LLMs shows promising results for clinical diagnostic decision support, with DR.KNOWS demonstrating enhanced diagnostic reasoning and abstraction capabilities, while comprehensive human evaluation reveals both strengths and areas for improvement in knowledge-grounded medical AI systems","Identified gaps include need for improved clinical narrative embedding, better pathway selection algorithms to reduce irrelevant knowledge paths, integration of probabilistic modeling approaches, and development of more sophisticated prompting techniques for effective knowledge utilization in open-source language models","Future work should focus on enhancing DR.KNOWS with Bayesian network integration, improving semantic similarity ranking through advanced embedding methods, exploring self-retrieval-augmented generation techniques, developing instruction tuning for open-source models, and expanding evaluation to diverse clinical domains beyond ICU settings","Implementation insights include the importance of TF-IDF weighting for relevant CUIs, benefits of trilinear attention over multi-head attention for path ranking, necessity of comprehensive human evaluation frameworks for medical AI safety, potential for knowledge graph prompting to reduce hallucinations, and requirements for HIPAA-compliant local LLM deployment in healthcare settings",https://doi.org/10.1101/2024.05.24.24307776,10.1101/2024.05.24.24307776,"Medical Knowledge Graphs, EHR Data Integration, LLM Augmentation, Diagnostic Decision Support, UMLS Integration, Graph Neural Networks, Retrieval-Augmented Generation, Healthcare AI Safety, Clinical Reasoning, Heterogeneous Medical Data","data-integration, healthcare, knowledge-graph",Large Language Models and Medical Knowledge Grounding for Diagnosis Prediction,"Gao Yanjun, Li Ruizhe, Croxford Emma, Tesch Samuel, To Daniel, Caskey John, W. Patterson Brian, M. Churpek Matthew, Miller Timothy, Dligach Dmitriy, Afshar Majid",2023,reference-manager,10.1101/2023.11.24.23298641,,,,,"Linguistic Quality was not considered, as it was deemed less relevant in the clinical setting.",,,"The research uses validated human evaluation methods (construct and content validity), detailed scoring metrics, and public (MIMIC-III) and private datasets. The evaluation framework and survey are in Supplementary Materials. No explicit mention of source code availability is provided.",,,"The research goal is to improve diagnosis summarization from daily EHR progress notes using a novel graph model, DR.KNOWS, which retrieves relevant knowledge paths from UMLS KG; results show that integrating these knowledge paths enhances ChatGPT’s diagnosis summarization performance, as measured by CUI prediction and human evaluation metrics.",,1.000,exact_title
gao_2025,HealthGenie: Empowering Users with Healthy Dietary Guidance through Knowledge Graph and Large Language Models,"Fan Gao, Xinjie Zhao, Ding Xia, Zhongyi Zhou, Rui Yang, Jinghui Lu, Hang Jiang, Chanjun Park, Irene Li",2025,Yes,HIGH,"Demonstrates heterogeneous data integration combining recipe databases (12,500 recipes), nutritional knowledge bases, and user preferences through circular LLM-KG-User workflow. Shows advanced PKG architecture with 100,000+ nodes and real-time adaptive recommendations.",HealthGenie integrates knowledge graphs with large language models to provide personalized dietary recommendations through interactive visualizations and circular workflow design.,"This paper presents HealthGenie, an interactive system that synergizes LLM-powered conversational interfaces with recipe-specific knowledge graph visualizations to provide personalized dietary recommendations. The system employs a circular workflow enabling adaptive interactions between LLMs, KGs, and users, moving beyond traditional linear text-based approaches. HealthGenie addresses critical needs for information transparency, reduced cognitive load, and personalized guidance through a curated nutritional knowledge graph with 100,000+ nodes and 45+ relation types. The system supports multiple LLMs (GPT-4o, DeepSeek-v3, Claude-3.5-Haiku, LLaMA-3.2-90B) and demonstrates effectiveness through within-subjects evaluation with 12 participants across four task scenarios.",How can LLM-KG integration enable more effective personalized dietary recommendations through interactive visualization and circular workflow design?,Within-subjects study (N=12) with counterbalanced design; formative study (N=7); four task scenarios covering personalized recommendations and recipe modification; comparative analysis against ChatGPT baseline; quantitative measurements using NASA-TLX and technology acceptance model; qualitative thematic analysis of user feedback.,"Circular LLM-KG-User workflow significantly outperformed traditional linear approaches; high user satisfaction scores (6.33/7 usefulness, 6.4/7 ease of use, 6.08/7 enjoyment); superior performance in task completion accuracy especially for constrained ingredient scenarios; effective knowledge graph visualization enhanced user comprehension and decision-making; 94.8% performance with reduced interaction effort.","HealthGenie system with integrated conversational interface and interactive knowledge graph visualization; hybrid KG storage architecture (CSV + in-memory); multi-agent pipeline for graph retrieval, relevance scoring, and language generation; real-time adaptive recommendation system; comprehensive nutritional knowledge graph with 12,500 recipes and 27,500 ingredient mentions.",Limited recipe diversity (primarily Western cuisines); high system latency due to multiple prompt processing; static pre-built knowledge graph structure; challenges with constrained ingredient scenarios; scalability concerns for large-scale knowledge graphs; need for professional nutritional validation.,"Interactive LLM-KG systems significantly enhance user experience for personalized dietary recommendations through circular workflow design, demonstrating clear advantages over traditional linear text-based approaches in task completion accuracy, user satisfaction, and decision-making efficiency.",Limited geographic recipe diversity; performance optimization needed for reduced latency; expandable knowledge graph structure; integration of real-time nutritional databases; scalability testing for larger user bases.,Extend to other cultural cuisines; implement proactive recommendation features; develop personalized knowledge graph construction capabilities; integrate real-time nutritional validation; explore adaptive triggering mechanisms for enhanced user autonomy.,Provides comprehensive framework for implementing circular LLM-KG interaction workflows in health applications; demonstrates effective integration of conversational interfaces with interactive knowledge graph visualization; offers validated approach for personalized recommendation systems with heterogeneous data sources.,https://arxiv.org/abs/2504.14594,10.18653/v1/2021.naacl-main.278,"Knowledge Graph, LLM Integration, Personalized Health, Interactive Systems, Dietary Recommendations, Circular Workflow, Heterogeneous Data Integration, PKG Architecture","data-integration, healthcare, knowledge-graph",HealthGenie: Empowering Users with Healthy Dietary Guidance through Knowledge Graph and Large Language Models,"Gao Fan, Zhao Xinjie, Xia Ding, Zhou Zhongyi, Yang Rui, Lu Jinghui, Jiang Hang, Park Chanjun, Li Irene",2025,reference-manager,,,,,,,Formative Study: Conducted to understand users’ needs for acquiring and exploring healthcare information.,,,"How effective is HealthGenie in supporting users’ needs for acquiring and exploring healthcare information through personalized recommendations, visualized knowledge graphs, and interactive dialogue compared to a baseline system, in terms of information perception, user preference support, and overall user experience?","The study aimed to understand users’ needs in exploring healthcare information and evaluate HealthGenie’s visual and personalized recommendation features. Using mixed methods, results showed users preferred rapid, visual, and structured information. HealthGenie’s outputs were rated highly for organization and interpretability, improving task efficiency and supporting user preferences.","The research goal was to empower users with healthy dietary guidance; the approach combined Knowledge Graphs and Large Language Models for structured, visual, and personalized information delivery; results showed high user satisfaction with organization, interpretability, and efficiency, though some desired greater detail (granularity).",,1.000,exact_title
garg_2022,"Knowledge Graph Completion: A Bird's Eye View on Knowledge Graph Embeddings, Software Libraries, Applications and Challenges","Satvik Garg, Dwaipayan Roy",2022,Yes,MEDIUM,"Comprehensive survey of knowledge graph embedding techniques providing foundational methods for PKG development. While focused on general KGC rather than heterogeneous data integration, the taxonomic analysis of embedding approaches (translation models, tensor factorization, neural networks), software library comparisons (AmpliGraph, PyKEEN, OpenKE), and multimodal techniques are valuable for understanding embedding foundations applicable to bespoke PKG systems requiring sophisticated entity and relation representations.","Knowledge graph embeddings enable effective vector representations of entities and relations for link prediction tasks. The survey demonstrates significant advances in translation models (TransE, TransH, TransR), tensor factorization approaches (RESCAL, DistMult, ComplEx), and neural architectures (ConvE, ConvKB) that provide foundation for more sophisticated PKG architectures. Software library analysis reveals practical implementation considerations essential for deployment of embedding systems in real-world applications.","Comprehensive survey systematically analyzing deep learning methods for knowledge graph completion with focus on embedding techniques, software libraries, and practical applications.","This comprehensive survey addresses knowledge graph completion through systematic analysis of embedding techniques, providing detailed taxonomy of algorithms based on mathematical foundations. The paper categorizes existing approaches into translation models (TransE, TransH, TransR, TransD), tensor factorization methods (RESCAL, DistMult, ComplEx), and neural network architectures (ConvE, ConvKB, HypER). It covers multimodal knowledge graphs integrating text, numeric, temporal, and uncertain information, analyzes software libraries (AmpliGraph, PyKEEN, OpenKE) for practical implementation, and discusses evaluation methodologies including negative sampling techniques. The survey represents foundational work for understanding embedding approaches applicable to knowledge graph development and provides practical guidance for implementation selection.","What are the most effective approaches for knowledge graph completion using embedding techniques, and how do different algorithmic families compare in terms of performance and practical implementation?","Systematic literature review and taxonomic analysis covering three main algorithmic families: translation models using mathematical translation principles (h + r ≈ t), tensor factorization treating KGs as 3D binary tensors with decomposition techniques, and neural network approaches employing deep learning for state-of-the-art performance. Analysis includes software library comparison and evaluation methodology assessment.","Translation models provide intuitive geometric interpretations with TransE establishing foundational approach, while TransH, TransR, and TransD address relation-specific modeling challenges. Tensor factorization methods excel in capturing latent patterns through RESCAL's full interaction modeling, DistMult's efficiency, and ComplEx's asymmetric relation handling. Neural approaches achieve state-of-the-art results with ConvE's convolutional architectures and ConvKB's translation-based convolutions outperforming traditional methods on standard benchmarks.",Comprehensive taxonomic framework for KGE algorithms organized by mathematical foundations; systematic analysis of software libraries providing implementation guidance; foundational survey enabling informed selection of embedding approaches for specific applications; extensive coverage of evaluation methodologies and negative sampling techniques essential for training effectiveness.,Survey scope limited to 2019 publication date potentially missing recent developments in transformer-based embeddings and large-scale approaches. Individual algorithm analysis lacks detailed hyperparameter sensitivity studies. Multimodal integration discussion remains at conceptual level without extensive empirical analysis. Software library evaluation focuses on functionality rather than performance benchmarking.,"Knowledge graph embeddings provide powerful foundation for link prediction and knowledge completion tasks, with different algorithmic families offering complementary strengths. Translation models offer interpretability, tensor factorization provides mathematical rigor, and neural approaches achieve superior performance. Practical deployment requires careful consideration of software library capabilities and evaluation methodologies appropriate for specific application domains.",Need for more sophisticated multimodal integration techniques combining diverse data types within unified embedding spaces. Limited exploration of temporal dynamics and evolving knowledge graph structures. Gap in understanding optimal embedding dimensionality and negative sampling strategies for specific domains. Insufficient analysis of scalability challenges for very large knowledge graphs.,"Future work should focus on developing more sophisticated multimodal embedding techniques, exploring temporal dynamics in knowledge graph evolution, investigating optimal hyperparameter selection strategies, and addressing scalability challenges for enterprise-scale knowledge graphs. Integration with large language models and transformer architectures represents promising research direction.","The survey provides essential foundation for implementing embedding systems in PKG architectures, with software library analysis (AmpliGraph for research flexibility, PyKEEN for comprehensive algorithms, OpenKE for efficiency) offering practical deployment guidance. Taxonomic understanding of algorithmic families enables informed selection based on specific requirements: translation models for interpretability, tensor factorization for mathematical rigor, neural approaches for performance. Negative sampling techniques and evaluation methodologies are crucial for effective implementation in real-world applications.",https://doi.org/10.1007/s10489-023-04764-y,10.1007/s10489-023-04764-y,"ampligraph, knowledge-graph-completion, knowledge-graph-embeddings, link-prediction, multimodal-knowledge-graphs, neural-networks, openke, pykeen, software-libraries, survey, tensor-factorization, translation-models",,,,,,,,,,,,,,,,,,,
general_2023,Privacy and Fairness in Federated Learning: On the Perspective of Tradeoff,"Huiqiang Chen, Tianqing Zhu, Tao Zhang, Wanlei Zhou, Philip S. Yu",2023,Yes,MEDIUM,Foundational survey on privacy-fairness tradeoffs in distributed learning; privacy-preserving techniques and fairness considerations applicable to HDM heterogeneous data integration scenarios,"Comprehensive taxonomy of privacy attacks (membership inference, reconstruction) and defenses (DP, cryptographic); fairness notions (algorithmic vs client-level); bilateral privacy-fairness interactions in distributed systems","Comprehensive survey examining privacy attacks, defenses, fairness notions, and their complex interactions in federated learning systems.","This comprehensive survey provides the first systematic examination of privacy-fairness interactions in federated learning, addressing a critical gap in current research that typically treats these ethical notions in isolation. The authors present detailed taxonomies of privacy attacks (membership inference, property inference, model inversion, reconstruction) and defense mechanisms (differential privacy, cryptographic approaches, trusted execution environments), alongside comprehensive coverage of fairness definitions including both algorithmic fairness (demographic parity, equal opportunity) and client-level fairness unique to federated settings. The survey reveals complex bilateral interactions between privacy and fairness, demonstrating that privacy mechanisms disproportionately harm underrepresented groups while fairness requirements can increase privacy risks through overfitting and additional data collection needs. The authors systematically analyze 230+ references spanning privacy attacks, defense strategies, fairness-aware algorithms, and emerging solutions for simultaneous privacy-fairness optimization. This work establishes foundational understanding crucial for developing ethical distributed learning systems and identifies key research directions for achieving optimal privacy-fairness tradeoffs in federated environments.","How do privacy and fairness interact in federated learning, and what are the tradeoffs between these two crucial ethical notions?","Comprehensive literature review with systematic taxonomy development, comparative analysis of 230+ papers, and theoretical framework construction for privacy-fairness interactions",Privacy degrades fairness disproportionately for underrepresented groups due to gradient clipping in DP-SGD; fairness increases privacy risk through overfitting and sensitive attribute collection; cryptographic approaches provide training privacy but fail at inference stage; client fairness differs fundamentally from algorithmic fairness in federated settings,Comprehensive taxonomies of privacy attacks and defenses in FL; systematic classification of fairness notions (algorithmic vs client-level); theoretical framework for privacy-fairness interactions; identification of mitigation strategies and open research directions,Focus on federated learning rather than broader distributed systems; limited practical implementation guidance for real-world deployment; theoretical analysis not fully validated through extensive empirical studies,Privacy and fairness are inextricably entwined in federated learning with complex bilateral interactions that require careful consideration rather than treating them as independent objectives; future research must develop integrated approaches for simultaneous optimization,Limited work on simultaneous privacy-fairness optimization techniques; insufficient exploration of individual vs group fairness compatibility with differential privacy; need for personalized privacy-fairness models; lack of multi-level fairness satisfaction frameworks,Development of better privacy-fairness tradeoff techniques; investigation of individual fairness compatibility with differential privacy; research on satisfying fairness at both algorithmic and client levels while preserving privacy; personalized federated learning for improved tradeoffs,DP mechanisms disproportionately affect underrepresented groups requiring adaptive clipping bounds; cryptographic approaches need additional inference-stage protection; personalized models may enable better privacy-fairness tradeoffs; client selection and data augmentation can improve fairness without compromising privacy,https://doi.org/10.1145/3606017,10.1145/3606017,"differential-privacy, distributed-systems, ethical-ai, fairness, federated-learning, machine-learning, privacy, survey",Privacy and Fairness in Federated Learning: On the Perspective of Tradeoff,"Chen Huiqiang, Zhu Tianqing, Zhang Tao, Zhou Wanlei, Yu Philip S.",2023,reference-manager,10.1145/3606017,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
ghani_2020b,Issues and challenges in Cloud Storage Architecture: A Survey,"Anwar Ghani, Afzal Badshah, Saeed Ullah Jan, Abdulrahman A. Alshdadi, Ali Daud",2020,Yes,MEDIUM,"Comprehensive survey of cloud storage challenges provides foundational understanding of heterogeneous data storage and management issues relevant to HDM PKG systems; covers multi-source data integration, security frameworks, and scalability challenges for ZB-scale heterogeneous data processing","State-of-the-art review identifying security (confidentiality, integrity, access control, breaches) and management (dynamics, segregation, virtualization, backup) challenges in cloud storage; proposes systematic taxonomy of countermeasures including cryptographic solutions, attribute-based access control, and multi-tier architectures for heterogeneous big data environments",Comprehensive survey examining cloud storage architecture challenges and solutions for managing heterogeneous big data at massive scale.,"This comprehensive survey systematically examines the critical challenges facing cloud storage architectures in managing heterogeneous big data, particularly as we approach an era of 175 ZB annual data processing by 75 billion devices by 2025. The authors categorize cloud storage challenges into two primary domains: data security issues (confidentiality, integrity, access control, authentication, authorization, and data breaches) and data management issues (data dynamics, segregation, virtualization vulnerabilities, backup problems, availability, and data locality). For security challenges, the survey identifies solutions including cryptographic approaches, digital signatures, proxy re-encryption, blockchain technology, and sophisticated access control mechanisms (RBAC, UBAC, ABAC). For management challenges, solutions include public auditing systems, multi-tier architectures, encryption schemes for backup data, load balancing, and regional backup servers. The paper emphasizes the complexity of managing heterogeneous data across multi-tenant environments and highlights how emerging technologies (5G, IoT, AI, blockchain) are both creating new opportunities and introducing additional challenges for cloud storage systems. The survey provides practical insights into the technological infrastructure requirements necessary for building scalable, secure, and efficient cloud storage solutions capable of handling diverse data types from multiple sources.","What are the issues and challenges involved in storing heterogeneous big data in cloud storage architectures, and what are their countermeasures and future opportunities?",Comprehensive literature review and state-of-the-art analysis methodology examining 92 references; systematic taxonomy development for categorizing security and management challenges; comparative analysis of proposed solutions and countermeasures,"Two main challenge categories identified: data security issues (confidentiality, integrity, access, authentication, breaches) and data management issues (dynamics, segregation, virtualization, backup, availability, locality); 175 ZB data processing expected by 2025; multi-tenancy creates data segregation challenges; attribute-based access control (ABAC) preferred for fine-grained access; cryptographic solutions essential for confidentiality; blockchain technology improving security and trust","Comprehensive taxonomy of cloud storage challenges categorized into security vs management domains; systematic classification framework for countermeasures and solutions; detailed analysis of emerging technology opportunities (5G, IoT, AI, blockchain) for future cloud storage evolution; practical implementation guidelines for multi-tier architectures and access control systems",Focus on general cloud storage rather than specialized knowledge graph architectures; limited discussion of temporal data management strategies; theoretical analysis without extensive empirical validation; concentration on infrastructure challenges rather than schema-level integration approaches,"Cloud storage technology remains challenged by security and management issues despite economic benefits and ease of use; comprehensive countermeasures exist but require careful implementation; emerging technologies (5G, IoT, AI, blockchain) offer significant opportunities while introducing new complexity; continued research needed to attract enterprise customers for sensitive data storage",Limited work on simultaneous privacy-security optimization in heterogeneous environments; insufficient exploration of temporal data management in multi-source cloud architectures; need for better integration frameworks for IoT device heterogeneity; lack of standardized approaches for cross-platform data segregation and access control,Research on integrated privacy-security frameworks for heterogeneous data; development of temporal-aware cloud storage architectures; investigation of standardized multi-source data integration protocols; advancement of AI-driven automated security and management systems for diverse data types,Heterogeneous data integration requires careful balance of security and management considerations; multi-tenancy demands sophisticated data segregation mechanisms; attribute-based access control (ABAC) provides optimal granularity for diverse data sources; temporal considerations critical for real-time IoT data streams; blockchain technology enhances trust but requires careful performance optimization; 5G connectivity enables real-time heterogeneous data processing,https://doi.org/10.1109/RpJC.2020.DOI,10.1109/RpJC.2020.DOI,"5g-technology, access-control, blockchain, cloud-storage, data-management, data-security, heterogeneous-data, iot-integration, multi-tenancy",Issues and challenges in Cloud Storage Architecture: A Survey,"Ghani Anwar, Badshah Afzal, Jan Saeed Ullah, Alshdadi Abdulrahman A., Daud Ali",2020,reference-manager,10.1109/RpJC.2020.DOI Number,,,,,,Encryption and decryption techniques are used to ensure data confidentiality in cloud storage systems.,,,"What are the key challenges related to data security and data management in cloud storage architecture, and what solutions have been proposed to address these issues?","The paper surveys issues and challenges in cloud storage architecture, focusing on data security and data management. Using literature review, it identifies key problems like confidentiality, integrity, access, and virtualization vulnerabilities. The study discusses solutions such as cryptography and blockchain, concluding with future opportunities and recommendations for secure cloud storage.","The research goal is to survey challenges and solutions in cloud storage, the approach reviews security and data management issues and countermeasures, and the principal finding is that while cloud storage is scalable and convenient, significant security and management challenges remain, requiring further research.",,1.000,exact_title
giunchiglia_2017,A Context Model for Personal Data Streams,"Fausto Giunchiglia, Xiaoyue Li, Matteo Busso, Marcelo Rodas-Britez",2017,Yes,HIGH,"Foundational framework for representing heterogeneous personal data streams as temporal sequences, directly addressing core temporal-first architecture principles",Personal data streams organized as temporal sequences of situational contexts using Knowledge Graphs for heterogeneous data integration,Framework for organizing heterogeneous personal data streams as temporal sequences of contexts,This paper presents a comprehensive framework for organizing massive streams of heterogeneous personal data into temporal sequences of situational contexts represented as Knowledge Graphs,"\""Personal data streams organized as temporal sequences of situational contexts using Knowledge Graphs with Entity Type Graphs (ETGs) for schema definition; validated on Smart University dataset with 158 participants and 139","239 annotations over 4 weeks; demonstrates space-time localized scenario modeling for heterogeneous data integration\""","\""Proposes Entity Type Graph (ETG) framework for representing personal data streams as temporal sequences of situational contexts using Knowledge Graphs.\""","\""This paper presents a comprehensive framework for organizing massive streams of heterogeneous personal data (sensor data", annotations, user feedback) into temporal sequences of situational contexts represented as Knowledge Graphs. The core innovation is the Entity Type Graph (ETG) - an Enhanced Entity-Relationship model that provides schema-level organization for personal data streams. The framework models situational context as space-time localized scenarios defined by location L(C) and events E(L(C)), populated by persons, objects, functions, and actions. The approach moves beyond traditional file-based data storage toward knowledge-level representation that enables real-time exploitation during data collection for person-centric services. The ETG schema defines entity types (Location, Event,person,A Context Model for Personal Data Streams,"Giunchiglia Fausto, Li Xiaoyue, Busso Matteo, Rodas-Britez Marcelo",2022,reference-manager,,,"Implementation Insights focus on representing and managing heterogeneous personal data streams as sequences of """"personal situational contexts""""—each encoding an individual's subjective perspective. Unlike prior work, this approach supports real-time, person-centric services, addressing challenges like data heterogeneity and varying abstraction levels. New insight: Emphasis on runtime exploitation.",,,,Collection of data streams from smartphone sensors and user questionnaires to capture personal situational context.,,,"How can personal data streams be represented at the knowledge level as sequences of situational contexts using Knowledge Graphs to enable user-understandable, person-centric services and improved human-machine interaction?","The paper aims to model a person's situational context by representing data streams from sensors and user input as sequences of knowledge graphs (KGs). Using the Smart University dataset, the methodology involves abstract conceptualization, schema definition (ETG), and context graph sequences. The approach enables user-understandable, real-time, person-centric services.",The research goal is to model personal situational context from data streams; the approach uses a knowledge-level representation of sensor and user-provided data collected over time; the principal finding is that this model enables real-time exploitation of heterogeneous data for person-centric services.,"Keywords: Personal Situational Context, Data Streams.",1.000,exact_title
graph_2024,Personalized Entity Resolution with Dynamic Heterogeneous Knowledge Graph Representations,"Ying Lin, Han Wang, Jiangning Chen, Tong Wang, Yue Liu, Heng Ji, Yang Liu, Premkumar Natarajan",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Customers tend to use \""implicit utterances\"" creating multiple product candidates. Framework builds \""cross-source heterogeneous knowledge graph\"" from customer purchase history with personalized features.",Novel approach to entity resolution using dynamic heterogeneous knowledge graphs with personalization for improved accuracy.,This paper proposes a framework that builds cross-source heterogeneous knowledge graphs from customer purchase history to improve entity resolution accuracy through personalized features.,How can entity resolution accuracy be improved in shopping domains where customers use implicit utterances?,Neural reranking model with cross-source heterogeneous knowledge graph construction; joint learning of customer and product embeddings.,24.6% improvement in accuracy of top ranked candidates compared to state-of-the-art; personalized entity resolution through dynamic knowledge graphs.,,Limited to shopping domain; evaluation primarily focused on product search scenarios.,Demonstrates significant accuracy improvements through personalized entity resolution with dynamic heterogeneous knowledge graphs.,,Extend to other domains; evaluate scalability; develop privacy-preserving methods.,Provides technical approach for implementing personalized entity resolution using dynamic heterogeneous knowledge graphs.,https://arxiv.org/abs/2104.02667,arXiv:2104.02667,"cross-source-integration, entity-resolution, heterogeneous-knowledge-graphs, personalization",Personalized Entity Resolution with Dynamic Heterogeneous Knowledge Graph Representations,"Lin Ying, Wang Han, Chen Jiangning, Wang Tong, Liu Yue, Ji Heng, Liu Yang, Natarajan Premkumar",2021,reference-manager,,,"The implementation shows that jointly learning customer and product embeddings from a merged graph improves performance (+32.9% Dev Acc@1, +24.6% Test Acc@1). Removing personalized features, product embeddings, or ranking degrades results. New insights: richer features (e.g., ratings) and modeling purchase behavior interactions could further enhance accuracy.",,,,"Utilized a product knowledge graph with over 24 million entities, incorporating textual and binary product attributes.",,,How can personalized features and a cross-source heterogeneous knowledge graph be leveraged to improve the accuracy of entity resolution for product ranking in the shopping domain using virtual assistants?,"The paper addresses personalized entity resolution in shopping via virtual assistants, proposing a framework that builds a cross-source heterogeneous graph from customer purchase history and product knowledge. Using a neural reranking model, it improves top-ranked product accuracy by 24.6% over QUARTS. Ablation studies confirm the importance of personalized features.","The research goal is to improve personalized entity resolution in shopping by jointly learning customer and product representations using a cross-source heterogeneous graph; the approach combines these embeddings in a neural reranking model, resulting in a 24.6% accuracy gain over the state-of-the-art product search model.",,1.000,exact_title
graphs_2018,Knowledge Graph Building Blocks: An easy-to-use Framework for developing FAIREr Knowledge Graphs,"Lars Vogt, Roman Baum, Peter Grobe, Sandra Meid, Tobias Wägele, Philipp Bhatty",2018,Yes,HIGH,"Comprehensive framework for developing FAIR (Findable, Accessible, Interoperable, Reusable) knowledge graphs using Knowledge Graph Building Blocks (KGBBs) - modular semantic units that enable systematic construction of human-actionable knowledge graphs with standardized design patterns and reusable components","Framework for creating FAIR knowledge graphs using modular Knowledge Graph Building Blocks (KGBBs) that provide standardized, reusable semantic units for systematic graph construction","Proposes Knowledge Graph Building Blocks framework for systematic development of FAIR knowledge graphs using modular, reusable semantic components.","This paper introduces Knowledge Graph Building Blocks (KGBBs), a comprehensive framework for developing FAIR (Findable, Accessible, Interoperable, Reusable) knowledge graphs that addresses the lack of systematic approaches for knowledge graph construction. KGBBs are modular semantic units consisting of classes, properties, and axioms that represent specific conceptual components and can be combined to build larger knowledge structures. The framework provides standardized design patterns, reusable components, and systematic methodologies for knowledge graph development. Key innovations include semantic modularity through pre-defined building blocks, systematic reusability across different domains, and human-actionable design that makes knowledge graphs more accessible to domain experts. The approach includes formal ontological foundations, quality assurance mechanisms, and integration protocols for combining multiple KGBBs. Implementation demonstrates effectiveness in biological and biomedical domains, showing how complex knowledge structures can be built from standardized components. The framework supports both automated and manual knowledge graph construction while maintaining semantic consistency and interoperability standards.","How can knowledge graphs be systematically constructed using modular, reusable components that ensure FAIR principles and human accessibility?",Framework design methodology; Ontological modeling and formalization; Case study implementation in biological domains; Semantic modularity evaluation; Reusability assessment across different applications,Framework successfully enables systematic knowledge graph construction; KGBBs provide effective modularity and reusability; FAIR principles successfully integrated into development process; Human-actionable design improves accessibility for domain experts; Framework demonstrates scalability across different knowledge domains,Knowledge Graph Building Blocks (KGBBs) framework with modular semantic units; Standardized design patterns for knowledge graph construction; Systematic reusability mechanisms across domains; Quality assurance and validation protocols; Integration frameworks for combining multiple KGBBs,Limited evaluation across diverse knowledge domains; Complexity of KGBB selection and combination for large-scale applications; Need for more automated tools to support KGBB-based development; Dependency on domain expertise for effective KGBB design,KGBB framework provides effective solution for systematic knowledge graph development; Modular approach successfully addresses reusability and consistency challenges; FAIR principles integration ensures long-term value and interoperability; Human-actionable design makes knowledge graphs more accessible to practitioners,Need for comprehensive evaluation across diverse knowledge domains; Limited investigation of automated KGBB discovery and recommendation; Insufficient exploration of large-scale KGBB composition and management; Missing frameworks for KGBB versioning and evolution,Develop automated KGBB discovery and recommendation systems; Create comprehensive KGBB libraries for major knowledge domains; Build tools for large-scale KGBB composition and validation; Establish KGBB versioning and lifecycle management frameworks; Design user-friendly interfaces for KGBB-based knowledge graph construction,Framework provides foundation for systematic knowledge graph engineering; Modular design principles applicable to other semantic technology development; FAIR integration approach relevant for knowledge management systems; Human-actionable design concepts transferable to other AI/semantic technologies; Approach supports development of more accessible and maintainable knowledge systems,https://link.springer.com/chapter/10.1007/978-3-030-61244-3_1,10.1007/978-3-030-61244-3_1,"fair-data, knowledge-graph, knowledge-representation, modular-design, ontology-engineering, reusable-components, semantic-web",,,,,,,,,,,,,,,,,,,
group_2009,Consistency Rationing in the Cloud: Pay only when it matters,"Tim Kraska, Martin Hentschel, Gustavo Alonso, Donald Kossmann",2009,Yes,MEDIUM,"Introduces consistency rationing paradigm for cloud storage systems that dynamically adjusts consistency guarantees at runtime based on cost-benefit analysis, categorizing data into A/B/C levels with adaptive policies for B-category data to optimize overall operational costs while minimizing inconsistency penalties","Novel approach to cloud database consistency that allows dynamic switching between strong and weak consistency based on data importance and temporal factors, demonstrated through TPC-W benchmark implementation on Amazon S3 with significant cost reductions",Proposes consistency rationing system that dynamically adjusts data consistency levels in cloud storage based on cost optimization and penalty trade-offs.,"This paper introduces consistency rationing, a novel paradigm for cloud database systems that dynamically adjusts consistency guarantees based on the trade-off between consistency costs and inconsistency penalties. The authors categorize data into three classes: A-data requiring strong consistency (high penalty for inconsistency), C-data accepting weak consistency (low penalty), and B-data with adaptive requirements based on context. They develop several adaptive policies for B-data including General policy (conflict probability-based), Time policy (deadline-based), Fixed threshold policy (value-based), Demarcation policy (distributed shares), and Dynamic policy (statistical threshold adjustment). The system implements both session consistency and serializability protocols with automatic switching mechanisms. Implementation on Amazon S3 with TPC-W benchmark demonstrates significant cost savings through the Dynamic policy, which outperforms static consistency approaches. The framework includes temporal statistics gathering, probabilistic consistency guarantees, and cost models that balance runtime transaction costs with inconsistency penalty costs. Results show the Dynamic policy achieves optimal cost-performance balance by adapting consistency levels based on real-time data patterns and usage statistics.","How can cloud database systems dynamically optimize the trade-off between consistency guarantees, operational costs, and inconsistency penalties to minimize total system cost?","Empirical evaluation using TPC-W benchmark on Amazon S3; Implementation of multiple consistency protocols (session consistency, serializability); Statistical modeling of conflict probabilities; Cost analysis framework; Prototype cloud database system with adaptive consistency switching",Dynamic policy achieves lowest overall cost among all approaches; 24% performance improvement over static strong consistency; Significant cost reduction compared to weak consistency due to penalty avoidance; Statistical policies outperform fixed threshold approaches; System successfully adapts to varying workload patterns,Consistency rationing framework enabling dynamic consistency level adjustment; Five adaptive policies for automated consistency switching; Probabilistic consistency guarantees based on temporal statistics; Cost optimization model balancing transaction and penalty costs; Cloud database implementation with automated protocol switching,Limited to specific cloud storage platforms (Amazon S3); Evaluation primarily on TPC-W benchmark scenario; Simplified penalty cost model may not reflect real-world complexity; Statistical approaches require sufficient historical data for accuracy,"Consistency rationing provides effective cost optimization for cloud databases; Dynamic adaptation significantly outperforms static consistency approaches; Statistical modeling enables intelligent consistency level selection; Framework successfully balances consistency, cost, and availability trade-offs; Approach applicable to various cloud storage and database platforms",Extension to other cloud platforms and database systems; Investigation of more sophisticated penalty cost models; Integration with modern cloud-native databases; Exploration of machine learning approaches for consistency prediction; Development of automated consistency SLA frameworks,Implement consistency rationing in modern cloud databases; Develop advanced cost modeling frameworks; Create automated consistency optimization tools; Investigate integration with serverless architectures; Build frameworks for consistency SLA management,Framework provides template for adaptive consistency management in distributed systems; Cost optimization approach applicable to modern microservices architectures; Statistical modeling techniques transferable to other cloud optimization problems; Dynamic policy adaptation relevant for edge computing scenarios; Approach supports development of intelligent cloud database management systems,https://www.vldb.org/pvldb/vol2/vldb09-302.pdf,10.14778/1687627.1687657,"adaptive-systems, cloud-computing, cost-optimization, database-consistency, distributed-systems, statistical-modeling, transaction-processing",Consistency Rationing in the Cloud: Pay only when it matters,"Kraska Tim, Hentschel Martin, Alonso Gustavo, Kossmann Donald",2009,reference-manager,10.14778/1687627.1687645,,"The paper introduces statistical policies as a first step toward probabilistic consistency guarantees. Adaptive policies like the Demarcation and Dynamic policies outperform Fixed threshold policies, especially under varying update distributions. Implementation uses efficient statistics gathering, logical logging, and supports runtime protocol switching. Consistency Rationing can be adapted to other systems.",,,,Experiments were run for 300 seconds and repeated 10 times to count oversells and measure costs.,,,"How can Consistency Rationing optimize the runtime cost of cloud-based database systems by dynamically adjusting consistency levels based on penalty costs, while maintaining acceptable performance?","The paper introduces Consistency Rationing, a method to optimize cloud database costs by dividing data into three consistency categories (A, B, C) and dynamically switching protocols. Using probabilistic guarantees and temporal statistics, the approach lowers costs and maintains performance. Experiments on Amazon S3 validate its effectiveness.","The research goal is to minimize cloud database costs while maintaining acceptable performance by introducing Consistency Rationing, an approach that adaptively assigns data to different consistency levels using statistical policies, with results showing significant cost reduction and improved performance.",,1.000,exact_title
guan_2023,Design Frameworks for Hyper-Connected Social XRI Immersive Metaverse Environments,"Jie Guan, Alexis Morris",2023,Yes,HIGH,"Comprehensive design framework for Social XR-IoT (XRI) metaverse environments that addresses the metaverse disconnect problem through hyper-connected multi-user experiences integrating extended reality, IoT, and social interaction across physical and virtual spaces with temporal-first considerations for real-time adaptation","Framework for Social XRI metaverse that combines extended reality (XR) with Internet of Things (IoT) to create hyper-connected multi-user immersive environments, addressing disconnection between virtual and physical spaces through innovative interaction paradigms",Proposes Social XRI metaverse framework combining extended reality and IoT for hyper-connected multi-user immersive experiences addressing metaverse disconnect challenges.,"This paper presents comprehensive design frameworks for Social XR-IoT (XRI) metaverse environments that address the fundamental metaverse disconnect problem - the gap between virtual and physical environments during multi-environment engagement. The authors extend previous single-user XRI frameworks to multi-user scenarios, proposing three design dimensions: Virtual Embodiment Method (avatar behavior and appearance), XRI Interaction Method (input/output systems and communication protocols), and Agency Design (intelligent agent interactions). The framework integrates extended reality technologies with IoT capabilities to create hyper-connected experiences where multiple users can interact across local/remote and physical/virtual boundaries simultaneously. Key innovations include hybrid virtual-physical objects, IoT avatar agents, context-aware adaptive systems, and multi-modal interaction paradigms supporting synchronous and asynchronous communication. The architecture enables seamless transitions between different reality levels along the virtuality continuum while maintaining social connectivity. Implementation considerations include MQTT/Socket.IO communication protocols, computer vision integration, conversational agents, and hardware support for mixed reality devices. The framework addresses scalability, latency, privacy, and integration complexity challenges while providing pathways for applications in remote work, education, entertainment, and collaborative environments.",How can metaverse systems address the disconnect problem between virtual and physical environments while supporting multi-user social interactions and IoT integration?,Design framework methodology; Comparative analysis of existing metaverse platforms; Architectural design and system integration; Scenario-based design validation; Technology integration assessment,Framework successfully addresses metaverse disconnect through hyper-connectivity; Multi-user XRI architecture enables seamless physical-virtual transitions; IoT integration provides rich context-aware interactions; Design dimensions provide comprehensive development guidance; Technology integration demonstrates feasibility with existing platforms,"Social XRI metaverse architecture supporting multi-user interactions; Three-dimensional design framework (embodiment, interaction, agency); Hybrid virtual-physical object interaction paradigms; Context-aware IoT integration system; Multi-modal communication and interaction protocols",Limited to conceptual framework without empirical user studies; Implementation complexity challenges not fully addressed; Scalability and performance considerations need more investigation; Privacy and security frameworks require deeper exploration,Social XRI framework provides viable approach to metaverse disconnect problem; Multi-user design successfully extends single-user XRI concepts; Hyper-connectivity enables rich immersive experiences; Framework supports diverse application domains and use cases; Integration approach balances functionality with technical feasibility,Need for comprehensive user experience evaluation; Limited investigation of long-term system scalability; Insufficient exploration of privacy-preserving multi-user interactions; Missing frameworks for content creation and management; Lack of standardization for cross-platform compatibility,Conduct user studies on metaverse disconnect mitigation; Develop scalable implementation architectures; Create privacy-preserving multi-user interaction protocols; Build comprehensive development toolchains; Establish interoperability standards for XRI systems,Framework provides roadmap for next-generation metaverse development; XRI integration approach applicable to diverse immersive applications; Multi-user design patterns transferable to other collaborative systems; Context-aware interaction paradigms relevant for smart environment development; Social interaction frameworks support human-centric technology design,https://ieeexplore.ieee.org/document/10132847,10.1109/MNET.005.2300129,"extended-reality, human-computer-interaction, internet-of-things, iot-integration, metaverse, mixed-reality, social-interaction, virtual-environments",,,,,,,,,,,,,,,,,,,
gupta_2021,Personalized Artificial General Intelligence (AGI) via Neuroscience-Inspired Continuous Learning Systems,"Rajeev Gupta, Suhani Gupta, Ronak Parikh, Divya Gupta, Amir Javaheri, Jairaj Singh Shaktawat",2021,Yes,HIGH,"Comprehensive neuroscience-inspired AI architecture for achieving personalized AGI on edge devices through continuous learning systems that integrate synaptic pruning, Hebbian plasticity, sparse coding, and dual memory systems to enable lifelong adaptation while maintaining computational efficiency and preventing catastrophic forgetting","Proposes Tri-Memory Continual Learning system combining neuroscience principles (synaptic pruning, Hebbian plasticity, sparse coding, dual memory) for edge-deployable personalized AGI with continuous adaptation capabilities",Proposes neuroscience-inspired Tri-Memory architecture for personalized AGI on edge devices with continuous learning and adaptation capabilities.,"This paper presents a comprehensive architecture for Personalized Artificial General Intelligence (AGI) designed for edge deployment using neuroscience-inspired continuous learning principles. The proposed Tri-Memory system extends traditional dual-memory frameworks by introducing Short-Term Memory (STM), Long-Term Memory (LTM), and Permanent Memory (PM) modules that mirror biological memory consolidation processes. Key innovations include microsleeps for lightweight synaptic decay (global offset operations), nightly offline pruning based on usage statistics, and hybrid learning combining Hebbian-like local updates with error-driven backpropagation. The architecture addresses catastrophic forgetting through selective memory consolidation, replay-based rehearsal, and graceful forgetting mechanisms that prioritize important knowledge while allowing redundant information to decay. Implementation includes sparse distributed representation using mixture-of-experts layers, context-aware expert gating, and hardware-aware design for platforms like NVIDIA Jetson. The system enables personalized adaptation through continuous learning from user interactions while maintaining bounded model size through dynamic pruning and compression techniques. Applications include personal humanoid assistants, mobile AI systems, and embodied robots that learn user preferences and environmental patterns over time.",How can artificial general intelligence systems achieve continuous personalized learning on resource-constrained edge devices while preventing catastrophic forgetting and maintaining computational efficiency?,Theoretical architecture design; Neuroscience principle integration; Conceptual evaluation framework; Application scenario analysis; Literature synthesis of continual learning and edge AI approaches,Architecture successfully integrates multiple neuroscience principles for edge deployment; Tri-Memory system addresses stability-plasticity dilemma; Microsleep mechanism provides efficient weight decay; Offline consolidation enables catastrophic forgetting prevention; Sparse representation reduces computational overhead while maintaining performance,Tri-Memory Continual Learning architecture with STM/LTM/PM modules; Microsleep-based global offset decay mechanism; Adaptive synaptic pruning with usage-based thresholds; Hybrid learning combining Hebbian and gradient-based updates; Sparse mixture-of-experts with context-aware gating; Hardware-aware implementation for edge devices,Limited to theoretical framework without empirical validation; Scalability to complex real-world scenarios unclear; Implementation complexity may challenge practical deployment; Edge device constraints may limit system capabilities,Tri-Memory architecture provides viable framework for edge-based personalized AGI; Neuroscience principles successfully address key continual learning challenges; Microsleep and offline consolidation enable efficient resource management; Architecture balances adaptation with stability for practical deployment,Need for comprehensive empirical validation on real edge devices; Limited investigation of cross-domain knowledge transfer; Insufficient exploration of multi-user and collaborative learning scenarios; Missing frameworks for handling adversarial or corrupted learning experiences,Implement and evaluate Tri-Memory system on actual edge hardware; Conduct longitudinal studies of personalized learning effectiveness; Develop cross-domain transfer learning capabilities; Create robust learning frameworks for noisy real-world environments; Build comprehensive development toolchains for practical deployment,Framework provides roadmap for next-generation personalized AI systems; Neuroscience integration approach applicable to diverse AI architectures; Continuous learning principles relevant for adaptive intelligent systems; Edge deployment strategies inform resource-constrained AI development; Personalization framework supports human-centric AI design,https://arxiv.org/abs/2504.20109,10.48550/arXiv.2504.20109,"artificial-general-intelligence, catastrophic-forgetting, continual-learning, edge-computing, hebbian-plasticity, memory-systems, neuroscience-inspired-ai, personalized-ai, synaptic-pruning",Personalized Artificial General Intelligence (AGI) via Neuroscience-Inspired Continuous Learning Systems,"Gupta Rajeev, Gupta Suhani, Parikh Ronak, Gupta Divya, Javaheri Amir, Shaktawat Jairaj Singh",2025,reference-manager,,,,,,,"Tri-Memory System: Utilizes three memory modules—Short-Term Memory (STM), Long-Term Memory (LTM), and Permanent Memory (PM)—with dynamic consolidation to manage learning at different timescales.",,,"How can a biologically inspired, energy-efficient continual learning framework enable scalable, privacy-preserving, and personalized AGI on edge devices while addressing challenges such as catastrophic forgetting, expert management, memory consolidation, and the balance between generalization and personalization?","The paper investigates a Tri-Memory System—Short-Term Memory (STM), Long-Term Memory (LTM), and Permanent Memory (PM)—inspired by neuroscience principles like synaptic pruning and sparse coding. Using dynamic consolidation and sparse neural coding, the system efficiently retains, prunes, and consolidates knowledge, improving continual learning and resource efficiency.","The paper’s research goal is to enable Personalized AGI through neuroscience-inspired continual learning; its key approach is a Tri-Memory System (Short-Term, Long-Term, Permanent Memory) for dynamic knowledge consolidation; results show that combining multiple brain-inspired strategies is essential for lifelong adaptation and efficiency.",,1.000,exact_title
gyrarda_2024,IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards for Better Well-Being,"Amelie Gyrarda, Seyedali Mohammadi, Manas Gaur, Antonio Kung",2024,Yes,HIGH,"Comprehensive framework for IoT-based preventive mental health systems using knowledge graphs, standards, and digital twins to integrate heterogeneous data sources (sensors, ontologies, clinical guidelines) for personalized mental health monitoring and intervention through semantic interoperability and multi-modal data fusion approaches",Presents Mental Health Knowledge Graph (ontology and dataset) integrated with IoT Digital Twins using domain-specific standards and semantic web technologies for preventive mental health care with heterogeneous data integration capabilities,Proposes IoT-based preventive mental health framework using knowledge graphs and standards for semantic data integration and personalized well-being monitoring.,"This paper presents a comprehensive framework for IoT-based preventive mental health care that leverages knowledge graphs, semantic web standards, and digital twin technologies to integrate heterogeneous data sources for personalized mental health monitoring and intervention. The proposed Mental Health Knowledge Graph (ontology and dataset) integrates knowledge from ontology-based mental health projects classified within the LOV4IoT catalog, supporting depression, mental health, and emotion domains. The framework addresses key challenges in healthcare digital twins including standardizing data formats, communication protocols, and data exchange mechanisms through semantic interoperability. The system combines IoT sensor data (wearables, physiological signals) with clinical knowledge bases, standards from multiple organizations (ETSI, ITU/WHO, ISO, W3C, NIST, IEEE), and existing ontologies (SNOMED-CT, FMA, RXNORM, ChEBI) to enable real-time emotion monitoring and preventive interventions. Key innovations include mapping to standardized health terminologies, integration with Large Language Models for mental health applications, and support for multi-stakeholder co-creation methodologies involving aging populations and healthcare professionals. The approach demonstrates practical applications through projects like ACCRA (social robots for aging support) and addresses UN Sustainable Development Goal 3 (Good Health and Well-Being) through digital technology integration.",How can IoT-based digital twin technologies and knowledge graphs be integrated with semantic web standards to enable preventive mental health care through heterogeneous data fusion and real-time personalized monitoring?,Systematic literature review; Standards analysis; Ontology engineering; Knowledge graph construction; Multi-source data integration methodology; Semantic mapping between ontologies and standards; Framework design for IoT-healthcare integration,Mental Health Knowledge Graph successfully integrates multiple ontology-based projects; LOV4IoT catalog provides comprehensive mental health ontology classification; Semantic mappings established between health standards and knowledge bases; Framework demonstrates successful integration of IoT data with clinical knowledge; Digital twin approach enables real-time monitoring and personalized interventions; Standards analysis reveals comprehensive coverage across multiple organizations,"Mental Health Knowledge Graph with integrated ontology and dataset; LOV4IoT ontology catalog for depression and mental health classification; Semantic mappings to standardized health terminologies (SNOMED-CT, FMA, RXNORM, ChEBI, DBpedia); Framework for IoT Digital Twin integration with preventive healthcare; Standards compliance across ETSI, ITU/WHO, ISO, W3C, NIST, IEEE; Integration architecture for heterogeneous data sources including sensors, clinical guidelines, and knowledge bases",Limited empirical validation of integrated framework in real-world healthcare settings; Complexity of maintaining semantic mappings across evolving standards; Privacy and ethical considerations for personal health data integration not fully addressed; Scalability challenges for large-scale deployment across diverse healthcare environments,Framework provides viable approach for IoT-based preventive mental health care; Knowledge graph integration successfully addresses heterogeneous data challenges; Semantic web standards enable effective interoperability across health domains; Digital twin approach offers promising foundation for personalized healthcare monitoring; Standards analysis demonstrates comprehensive foundation for implementation,Need for comprehensive empirical validation in clinical settings; Limited exploration of privacy-preserving techniques for sensitive health data; Insufficient investigation of user acceptance and usability in diverse populations; Missing frameworks for regulatory compliance and certification in healthcare applications; Need for longitudinal studies on effectiveness of preventive interventions,Conduct clinical trials to validate framework effectiveness in real healthcare environments; Develop privacy-preserving semantic integration techniques for sensitive mental health data; Create user-centered design methodologies for diverse patient populations; Establish regulatory compliance frameworks for IoT-healthcare integration; Implement comprehensive evaluation of prevention outcomes and cost-effectiveness; Develop automated ontology evolution and maintenance systems,Framework demonstrates clear pathway for next-generation personalized healthcare systems; Knowledge graph approach applicable to diverse health domains beyond mental health; Semantic interoperability principles support broader healthcare data integration challenges; IoT integration methodology relevant for smart city and ambient assisted living applications; Standards analysis provides foundation for regulatory-compliant healthcare technology development; Multi-stakeholder co-creation approach applicable to human-centered healthcare design,https://arxiv.org/abs/2406.13791,10.48550/arXiv.2406.13791,"data-integration, digital-twins, healthcare-standards, iot, knowledge-graph, mental-health, ontologies, preventive-medicine, semantic-web, wearable-sensors",,,,,,,,,,,,,,,,,,,
haindl_2022,Towards a Reference Software Architecture for Human-AI Teaming in Smart Manufacturing,"Philipp Haindl, Maqbool Khan, Georg Buchgeher, Bernhard Moser",2022,Yes,HIGH,"Comprehensive reference architecture for human-AI teaming in smart manufacturing using Lambda architecture pattern with knowledge graphs and relational machine learning, directly addressing HDM's core challenges of temporal-first architecture design and real-time heterogeneous data integration. The three-layer Lambda pattern (batch layer for model authoring, speed layer for real-time processing, serving layer for low-latency results) provides proven framework for managing different latency requirements in multi-source data environments. Knowledge graph separation into static and dynamic subgraphs demonstrates effective schema harmonization for manufacturing process data, while relational machine learning enables context-specific recommendations essential for bespoke PKG system designs. The architecture's emphasis on IIoT streaming data processing, ethical policy monitoring, and human-in-the-loop validation directly parallels HDM's upstream data orchestration and quality assurance priorities.",Lambda architecture pattern for manufacturing with knowledge graphs and relational machine learning that addresses different latency requirements for heterogeneous data processing; demonstrates practical implementation of temporal-first architecture principles with real-time IIoT data integration and context-specific decision support capabilities essential for bespoke PKG system development.,"Reference software architecture for human-AI teaming in smart manufacturing using Lambda architecture pattern, knowledge graphs, and relational machine learning to enable context-specific recommendations and real-time collaboration.","This paper presents a comprehensive reference software architecture for human-AI teaming in smart manufacturing, addressing the transition from reactive to proactive AI systems that provide context-specific support to manufacturing operators. The architecture employs Lambda architecture pattern to handle different latency requirements, organizing components into batch layer (model authoring), speed layer (knowledge graph, graph-based ML, teaming engine), and serving layer (operation support, ML experimentation, policy monitoring). The system uses knowledge graphs to capture product- and process-specific knowledge, separating static models (products, processes, experimentation) from dynamic operational data augmented by relational machine learning insights. Key innovations include real-time IIoT streaming data processing, runtime monitoring of ethical policies through ontology reasoning, orchestrated human-AI interaction via teaming engine, and integration of tracking/scene analysis for situational awareness. The architecture addresses five core challenges: monitoring teaming aspects, scalability for near-realtime processing, runtime validation of ethical policies, relational machine learning for knowledge graphs, and experimentation automation. Implementation demonstrates practical application across automotive, energy systems, and precision machining domains with focus on occupational safety and ergonomic optimization.","How can software architecture effectively support human-AI teaming in smart manufacturing environments while addressing scalability, ethics, and real-time processing requirements?","Reference architecture design methodology; Lambda architecture pattern implementation; Knowledge graph engineering with static/dynamic separation; Relational machine learning integration; Multi-domain validation planning across automotive, energy systems, and precision machining; Expert workshop analysis with researchers from software engineering, knowledge engineering, machine learning, computer vision, and human factors",Lambda architecture successfully addresses different latency requirements through three-layer organization; Knowledge graphs effectively capture manufacturing knowledge with separation of static models and dynamic operational data; Relational machine learning enables context-specific recommendations and safety warnings; Architecture demonstrates scalability potential for near-realtime IIoT data processing; Framework provides systematic approach to runtime ethical policy monitoring; Teaming engine successfully orchestrates human-AI interaction workflows,Reference software architecture for human-AI teaming in smart manufacturing; Lambda architecture pattern implementation with batch/speed/serving layers; Knowledge graph framework with static/dynamic subgraph separation; Relational machine learning integration system; Teaming engine for orchestrating human-AI collaboration; Runtime ethical policy monitoring framework; Multi-domain validation methodology across three industrial sectors,Preliminary status without comprehensive empirical validation; Implementation complexity may challenge practical deployment; Scalability claims require quantitative validation under heavy load; Limited exploration of cross-domain knowledge transfer; Ethical policy formalization methodology needs further development; Architecture framework remains technology-agnostic requiring domain-specific instantiation,Reference architecture provides viable framework for human-AI teaming in smart manufacturing; Lambda architecture pattern effectively addresses heterogeneous data processing requirements; Knowledge graph integration successfully captures manufacturing domain knowledge; Relational machine learning enables intelligent context-aware recommendations; Framework demonstrates potential for scalable real-time collaboration systems,Need for comprehensive empirical validation across diverse manufacturing contexts; Limited quantitative analysis of scalability and consistency under heavy load; Insufficient exploration of cross-domain applicability and knowledge transfer; Missing detailed ethical policy formalization methodologies; Gap between reference architecture and concrete technology implementations,"Validate reference architecture with three industrial partners in automotive, energy systems, and precision machining; Conduct expert interviews with software architects and manufacturing operators; Perform quantitative validation using runtime probes for scalability assessment; Develop concrete technology implementations; Enhance ethical policy monitoring frameworks",Lambda architecture provides proven pattern for managing different latency requirements in heterogeneous data environments; Static/dynamic knowledge graph separation offers effective schema organization for temporal-first architectures; Relational machine learning integration demonstrates practical approach for context-aware PKG systems; Teaming engine concept applicable to human-AI collaboration in HDM interfaces; Runtime policy monitoring framework relevant for ethical AI governance in personal data systems; Multi-domain validation approach provides template for bespoke PKG system evaluation,https://doi.org/10.1145/3510455.3512788,10.1145/3510455.3512788,"ethical-ai, human-ai-teaming, iot-integration, knowledge-graph, lambda-architecture, manufacturing-systems, real-time-processing, reference-architecture, relational-machine-learning, smart-manufacturing",Towards a reference software architecture for human-AI teaming in smart manufacturing,"Haindl Philipp, Buchgeher Georg, Khan Maqbool, Moser Bernhard",2022,reference-manager,10.1145/3510455.3512788,,,,,,Developed a reference software architecture as a blueprint for research and validation.,,,"How can a reference software architecture be designed and validated to enable effective, ethical, and scalable human-AI teaming in smart manufacturing across diverse industrial contexts?","The paper proposes a reference software architecture for human-AI teaming in smart manufacturing. Using the Lambda architecture pattern, it integrates batch, speed, and serving layers to manage data and support decision-making. The architecture aims to ensure scalability, interoperability, and ethical compliance, with validation planned across diverse industrial contexts.","The paper's main objective is to present an initial reference software architecture for human-AI teaming in smart manufacturing, using a Lambda architecture approach, with the principal finding being a preliminary blueprint that addresses latency, data management, and ethical compliance challenges.",,1.000,exact_title
hbscher_2020,"Integration of Knowledge and Task Management in an Evolving, Communication-intensive Environment","Gerd Hübscher, Daniel Steindl, Klaus-Dieter Schewe",2020,Yes,HIGH,"High relevance to HDM heterogeneous data integration objectives through graph-based meta-modeling approach for integrating knowledge and task management in communication-intensive environments. Demonstrates flexible schema evolution, bottom-up model creation, and runtime type model extension capabilities essential for bespoke PKG systems. Three-layered architecture (meta model, domain model, instance model) provides proven framework for temporal-first processing with adaptive schema harmonization supporting diverse data formats and user-driven knowledge structures.",Graph-based meta-modeling framework enabling flexible integration of knowledge and task management with runtime schema evolution and bottom-up model creation directly applicable to bespoke PKG system development for heterogeneous data environments.,TEAM System demonstrates effective graph-based approach to heterogeneous data integration through three-layered meta-modeling architecture supporting both administrative processes and creative knowledge work in communication-intensive environments.,"This paper presents the TEAM System (inTegrated knowlEdge and tAsk Management), a graph-based meta-modeling framework designed to flexibly integrate knowledge and task management in communication-intensive environments. The system addresses the challenge of supporting both well-defined administrative processes and creative, knowledge-intensive work through a three-layered architecture: meta model (core characteristics), domain model (domain-specific types), and instance model (actual instances). The approach enables runtime schema evolution through bottom-up model creation, allowing users to extend the type model without system recompilation. Key innovations include observable and non-observable data objects connected through relations in continuously evolving graph structures, flexible support for heterogeneous data integration, and user-driven schema adaptation mechanisms.",How can knowledge and task management be flexibly integrated in communication-intensive environments that require support for both structured administrative processes and creative knowledge work?,Design science research methodology employing graph-based meta-modeling with three-layered architecture; prototype implementation using graph database technology; evaluation through patent prosecution test cases involving knowledge workers managing complex legal documentation and workflow processes.,"Three-layered meta-modeling architecture successfully enables flexible integration of knowledge and task management; bottom-up model creation allows runtime type model extension without system recompilation; graph-based approach effectively handles both observable data objects (documents, tasks) and non-observable data objects (concepts, relationships) within unified framework; patent prosecution test cases demonstrate practical applicability for complex knowledge work scenarios.","TEAM System with three-layered meta-modeling architecture (meta model, domain model, instance model); graph-based data integration framework supporting runtime schema evolution; bottom-up model creation mechanism enabling user-driven type model extension; flexible integration framework for knowledge and task management in communication-intensive environments; prototype implementation demonstrating practical applicability for complex knowledge work scenarios.",Evaluation limited to patent prosecution domain; scalability assessment needed for larger knowledge bases; user interface complexity may challenge adoption; integration with existing enterprise systems requires further investigation; long-term evolution and maintenance of user-created type extensions not fully addressed.,TEAM System demonstrates that graph-based meta-modeling with three-layered architecture can effectively integrate knowledge and task management while providing flexible schema evolution capabilities essential for communication-intensive knowledge work environments.,Limited evaluation across diverse knowledge work domains; insufficient investigation of large-scale deployment challenges; need for comprehensive user interface design guidelines; gap between prototype implementation and production-ready enterprise integration; missing frameworks for managing long-term schema evolution in user-driven environments.,Conduct comprehensive evaluation across diverse knowledge work domains; investigate scalability for enterprise-scale deployment; develop user-centered interface design methodologies; create frameworks for enterprise system integration; establish governance models for user-driven schema evolution and long-term system maintenance.,Provides proven patterns for implementing graph-based meta-modeling in HDM systems; demonstrates effective approach to bottom-up schema creation enabling user-driven PKG evolution; offers practical framework for integrating structured and unstructured knowledge management; shows successful runtime schema adaptation techniques applicable to temporal-first architectures; validates flexible data integration approaches essential for heterogeneous data fusion in bespoke PKG systems.,https://doi.org/10.1145/3428757.3429260,10.1145/3428757.3429260,"bottom-up-design, communication-intensive-environments, graph-based-modeling, heterogeneous-data-integration, knowledge-management, meta-modeling, schema-evolution, task-management",,,,,,,,,,,,,,,,,,,
hendler_2014,Data Integration for Heterogeneous Datasets,James Hendler,2014,Yes,HIGH,Foundational work directly addressing heterogeneous data integration challenges central to HDM research objectives, covering data discovery, integration techniques, and linked data approaches essential for PKG systems,Linked data approach using URI-based unique naming enables cross-dataset integration; semantic data integration through RDF provides foundation for heterogeneous data fusion; broad data variety challenge more critical than volume/velocity for many applications,Foundational framework for integrating heterogeneous datasets using linked data and semantic web technologies,This seminal work addresses the broad data challenge where data variety rather than volume is the limiting factor. Hendler introduces linked data approaches using URI-based unique naming to enable cross-dataset integration and demonstrates practical examples of integrating government datasets and explores semantic data integration through RDF frameworks for combining structured and unstructured data sources.,How can heterogeneous datasets from diverse sources be effectively discovered integrated and analyzed when traditional database techniques are insufficient?,Technical overview with practical examples including US-China GDP comparison foreign aid analysis crime data integration and government open data exploration,Traditional database techniques inadequate for web-scale heterogeneous data integration; linked data approach using URI-based naming enables cross-dataset linking; semantic integration through RDF provides foundation for complex data relationships; data discovery requires faceted search and metadata standards,Linked data framework for heterogeneous data integration practical examples of cross-dataset analysis foundation for semantic data integration approaches,Focus on government open data examples; limited discussion of privacy and security; semantic integration complexity not fully addressed; validation techniques preliminary,The increasing need for heterogeneous data integration requires moving beyond traditional database approaches to linked data and semantic web technologies that enable flexible cross-dataset analysis and integration,Privacy-preserving integration techniques automated mapping generation real-time integration performance scalability to personal data contexts,Enhanced language processing for text-data integration improved validation techniques business-to-business data sharing protocols automated semantic mapping,uri-based-naming-critical-for-cross-system-integration-rdf-triple-stores-enable-complex-relationship-management-incremental-iteration-approach-effective-for-exploratory-data-integration-validation-through-visualization-essential-for-data-quality-assessment,,,,,,,,,,,,,,,,,,,
herath_2024,Smart City Digital Twins: A Modular and Adaptive Architecture for Real-Time Data-Driven Urban Management,"Manoj Herath, Maira Alvi, Roberto Minerva, Hrishikesh Dutta, Noel Crespi, Syed Mohsan Raza",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Modular digital twin architecture leveraging Edge-Cloud Continuum for dynamic resource management and real-time urban simulation,Adaptive digital twin framework for real-time urban data integration and management,This paper proposes a modular digital twin software architecture leveraging Edge-Cloud Continuum for flexible and scalable urban management solutions with real-time data processing and autonomous decision-making,How can a digital twin architecture be designed to enable flexible and scalable urban management solutions?,"Modular digital twin architecture, Edge-Cloud Continuum integration, dynamic resource management, real-time data processing, traffic management case study","Demonstrated framework viability through traffic management case study, showed ability to predict traffic patterns, adaptive network resource allocation",,"Focused on urban management context, scalability to personal systems not explored",Demonstrates potential for real-time multi-source data integration in complex dynamic systems,,"Develop personal digital twin frameworks, implement privacy controls, create user-centric interfaces",Agent Epsilon: Modular architecture pattern applicable to HDM real-time data integration and adaptive processing,https://ieeexplore.ieee.org/document/10814627/,10.1109/ACCESS.2024.3520255,"digital-twin, edge-cloud-computing, modular-architecture, real-time-systems, urban-management",Smart City Digital Twins: A Modular and Adaptive Architecture for Real-Time Data-Driven Urban Management,"Herath Manoj, Alvi Maira, Minerva Roberto, Dutta Hrishikesh, Crespi Noel, Raza Syed Mohsan",2024,reference-manager,10.23919/cnsm62983.2024.10814627,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
hewasinghage_2016,Managing polyglot systems metadata with hypergraphs,"Moditha Hewasinghage, Alberto Abelló, Jovan Varga, Esteban Zimányi",2016,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on managing polyglot systems metadata with hypergraphs providing insights for knowledge graph development and data integration.,"This 2016 paper by Moditha Hewasinghage, Alberto Abelló, Jovan Varga, Esteban Zimányi explores managing polyglot systems metadata with hypergraphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Managing polyglot systems metadata with hypergraphs,"Hewasinghage Moditha, Abelló Alberto, Varga Jovan, Zimányi Esteban",2021,reference-manager,10.1016/j.datak.2021.101896,,"The implementation retrieves all directly related data from the main document but must join external collections using a row-nested loop join, impacting access frequency. Algorithms 3–5 identify storage needs and access patterns, enabling cost-based schema design and query performance estimation for NoSQL systems. New insight: the approach supports multiple data store types, including graph and key–value stores.",,,,"Row-nested loop join: Used to join data across different collections outside the data store, with index and collection access frequencies calculated.",,,"How can a hypergraph-based formalization of the SOS model provide a unified conceptual framework for representing, managing, and querying metadata across heterogeneous NoSQL systems in polyglot environments?","This paper formalizes the SOS model using a hypergraph-based approach to create a unified conceptual model for metadata in NoSQL polyglot systems. Using RDF exemplars and logical definitions, the methodology enables expressive, semantically flexible metadata management. Results show improved storage statistics, query access analysis, and practical feasibility in real-world systems.","The research goal is to formally represent and manage heterogeneous, semistructured metadata in polyglot systems using a hypergraph-based extension of the SOS Model; the approach enables expressive, flexible meta-representation, and the results show improved evaluation of design alternatives in document stores regarding storage, query cost, and access patterns.",,1.000,exact_title
hildebrandt_2014,TLogic: Temporal Logical Rules for Explainable Link Forecasting on Temporal Knowledge Graphs,"Marcel Hildebrandt, Mitchell Joblin",2014,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on tlogic: temporal logical rules for explainable link forecasting on temporal knowledge graphs providing insights for knowledge graph development and data integration.,"This 2014 paper by Marcel Hildebrandt, Mitchell Joblin explores tlogic: temporal logical rules for explainable link forecasting on temporal knowledge graphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph, temporal-data",TLogic: Temporal Logical Rules for Explainable Link Forecasting on Temporal Knowledge Graphs,"Liu Yushan, Ma Yunpu, Hildebrandt Marcel, Joblin Mitchell, Tresp Volker",2022,reference-manager,,,,,,,"Experiments were conducted on three ICEWS datasets, split into training, validation, and test sets with time-aware filtering.",,,"What is the effectiveness of learning and applying temporal logical rules for link prediction in temporal knowledge graphs, as evaluated on the ICEWS datasets using metrics such as mean reciprocal rank (MRR) and hits@k?","The paper introduces TLogic, a symbolic framework for learning temporal logical rules from temporal knowledge graphs to forecast links. Using rule confidences and time differences, TLogic outperforms baselines on ICEWS datasets. The method provides interpretable predictions and shows low variance. Future work includes integrating acyclic rules and improved sampling.","The research goal is explainable link forecasting on temporal knowledge graphs; the approach introduces TLogic, a symbolic framework using temporal random walks to learn temporal logical rules; results show TLogic outperforms state-of-the-art baselines and provides human-readable, time-consistent explanations.",,1.000,exact_title
ho_2024,Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A Case Study at HCMUT,"Bao Ho, Oanh Tran, Long Nguyen, Phuong Nguyen, Thang Bui",2024,Yes,HIGH,"Demonstrates KG-augmented LLM approach for domain-specific QA systems, directly applicable to HDM conversational interfaces","KG integration improves LLM accuracy by providing factual context, reduces hallucinations, enables domain-specific knowledge management",Knowledge graph-augmented LLM system for educational question answering with,"This paper integrates LLMs with Knowledge Graphs to overcome limitations in memory, new information incorporation, and domain-specific hallucinations, implementing a case study for educational QA at HCMUT",How can knowledge graphs enhance LLM performance for domain-specific question-answering systems?,"Open intent discovery using unsupervised learning, KG construction from FAQ data, Neo4J implementation, evaluation on Banking77 and HCMUT_FAQ datasets","First Vietnamese open intent discovery approach, 613 entity-pair relationships identified, improved LLM accuracy with factual KG context",Practical KG-augmented LLM implementation for educational domain with demonstrated improvements,"Focus on educational domain, limited to Vietnamese and English datasets, some intents not detected (22 of 53)",Shows practical integration of KGs with LLMs for improved domain-specific QA performance,"Expand to other domains, improve intent detection coverage, optimize KG-LLM integration","Scale to larger datasets, develop multilingual support, enhance relationship discovery","Agent Beta: Downloaded arXiv PDF, demonstrates critical KG-LLM integration pattern for HDM conversational AI",https://arxiv.org/abs/2404.09296,10.1145/3643479.3662055,"educational-qa, intent-discovery, knowledge-graph, llm, neo4j",,,,,,,,,,,,,,,,,,,
hoang_2025,"Knowledge Graph Fusion with Large Language Models for Accurate, Explainable Manufacturing Process Planning","Danny Hoang, David Gorsich, Matthew P. Castanier, Farhad Imani",2025,Yes,HIGH,"Directly addresses knowledge graph fusion for manufacturing process planning using LLMs, demonstrating practical application of KG-LLM integration for domain-specific decision making",ARKNESS framework demonstrates significant accuracy improvements (+25 percentage points) while providing explainability; lightweight LLM integration proves sufficient for complex reasoning tasks; knowledge graph augmentation addresses LLM hallucination problems,Combines knowledge graphs and LLMs to enhance manufacturing process planning,"This paper develops ARKNESS (Augmented Retrieval Knowledge Network Enhanced Search & Synthesis), an end-to-end framework that fuses zero-shot knowledge graph construction with retrieval-augmented generation for CNC machining process planning. The research addresses precision process planning demands for rapid, context-aware decisions on tool selection, feed-speed pairs, and multi-axis routing. Conventional rule-based computer-aided process planning systems become limited when dealing with unseen topologies, novel material states, and dynamic shop-floor constraints, while LLMs promise flexible reasoning but routinely hallucinate numeric values and provide no provenance.","How to improve CNC machining process planning using knowledge graphs and LLMs to provide accurate, explainable, and context-aware manufacturing decisions?",ARKNESS framework: zero-shot KG construction + retrieval-augmented generation; integration of heterogeneous machining documents; lightweight 3B-parameter Llama-3 model usage; CNC process planning optimization,"Matches GPT-4o accuracy while achieving +25 percentage point gain in multiple-choice accuracy; provides verifiable, numerically exact CNC process planning answers; demonstrates significant improvement over traditional rule-based systems",ARKNESS framework; verifiable numerically exact CNC process planning; significant accuracy improvements; lightweight LLM integration approach,Requires integration of heterogeneous machining documents; evaluation limited to CNC machining domain; computational requirements for real-time deployment not fully characterized,LLM-augmented knowledge graphs can significantly improve process planning accuracy while providing explainability and provenance for manufacturing decisions,"Lack of flexible, provenance-tracked process planning approaches; limitations of static rule-based systems; LLM hallucination problems in manufacturing applications",Expand to more complex manufacturing scenarios; integrate with real-time shop floor systems; develop domain-adaptive frameworks,Uses lightweight 3B-parameter Llama-3 model; demonstrates practical KG-LLM integration; provides explainable manufacturing decision support,https://arxiv.org/abs/2506.13026,10.48550/arXiv.2506.13026,"cnc-machining, explainable-ai, knowledge-graph, llm, manufacturing, process-planning",,,,,,,,,,,,,,,,,,,
hofer_2023,Construction of Knowledge Graphs: State and Challenges,"Marvin Hofer, Daniel Obraczka, Alieh Saeedi, Hanna Köpcke, Erhard Rahm",2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on construction of knowledge graphs: state and challenges providing insights for knowledge graph development and data integration.,"This 2023 paper by Marvin Hofer, Daniel Obraczka, Alieh Saeedi, Hanna Köpcke, Erhard Rahm explores construction of knowledge graphs: state and challenges. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3289600.3290956.,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
hohenfellner_2025,Design for a Digital Twin in Clinical Patient Care,"Markus Hohenfellner, Physikalisches Institut",2025,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on design for a digital twin in clinical patient care providing insights for knowledge graph development and data integration.,"This 2025 paper by Markus Hohenfellner, Physikalisches Institut explores design for a digital twin in clinical patient care. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Design for a Digital Twin in Clinical Patient Care,"Nitschke Anna-Katharina, Brandl Carlos, Egersdörfer Fabian, Görtz M., Hohenfellner Markus, Weidemüller Matthias",2025,reference-manager,,,,,,,Construction of a knowledge graph using the Resource Description Framework (RDF) to integrate and visualize multimodal clinical data and model relationships.,,,"How can a modular, evolving, and interpretable Digital Twin design based on a knowledge graph using Resource Description Framework (RDF) effectively support and improve patient-centered clinical decision-making throughout the phases of the clinical patient journey?","The paper proposes a patient-centered Digital Twin (DT) system for medicine, using a knowledge graph built from multimodal data and models. The methodology includes provenance chains for interpretability and feedback loop control. Results show robust, explainable predictions. The study concludes that validation and regulatory compliance are essential for clinical translation.","The paper's main objective is to design a modular, interpretable Digital Twin (DT) for clinical patient care using a bipartite knowledge graph built from a Resource Description Framework (RDF); the key method integrates multimodal data and model provenance to ensure reliability, and principal findings show the approach meets essential requirements but needs further validation and scaling.",,1.000,exact_title
hoseini_2024,"A survey on semantic data management as intersection of ontology-based data access, semantic modeling and data lakes","Sayed Hoseini, Johannes Theissen-Lipp, Christoph Quix",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on a survey on semantic data management as intersection of ontology-based data access, semantic modeling and data lakes providing insights for knowledge graph development and data integration.","This 2024 paper by Sayed Hoseini, Johannes Theissen-Lipp, Christoph Quix explores a survey on semantic data management as intersection of ontology-based data access, semantic modeling and data lakes. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.websem.2024.100819,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
hu_2021,CODEXGRAPH: Bridging Large Language Models and Code Repositories via Code Graph Databases,"Zhiyuan Hu, Yang Liu, Zhicheng Zhang, Fei Wang, Michael Shieh, Wenmeng Zhou",2021,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on codexgraph: bridging large language models and code repositories via code graph databases providing insights for knowledge graph development and data integration.,"This 2021 paper by Zhiyuan Hu, Yang Liu, Zhicheng Zhang, Fei Wang, Michael Shieh, Wenmeng Zhou explores codexgraph: bridging large language models and code repositories via code graph databases. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1561/1500000019.,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
hu_2024,User Behavior Enriched Temporal Knowledge Graphs for Sequential Recommendation,Hengchang Hu,2024,Yes,HIGH,"Introduces temporal knowledge graphs enriched with user behavior for sequential recommendation, directly applicable to HDM systems requiring temporal knowledge representation with user interaction modeling",TKG incorporates dynamic features of user behaviors into knowledge graphs while emphasizing sequential relationships; captures patterns of both entity dynamics (nodes) and structural dynamics (edges); published at premier WSDM conference with strong validation,Temporal knowledge graph approach incorporating user behavior dynamics for improved,"This paper introduces Temporal Knowledge Graphs (TKG) for sequential recommendation, incorporating dynamic features of user behaviors into traditional knowledge graphs while emphasizing sequential relationships. The approach captures patterns of both entity dynamics (nodes) and structural dynamics (edges) within temporal knowledge representations. The TKG framework addresses limitations in existing sequential recommendation methods by integrating structured knowledge with temporal user behavior patterns. The research was published at WSDM 2024, demonstrating strong experimental validation and significant contribution to the field of temporal knowledge graph applications.",How to effectively incorporate user behavior dynamics into knowledge graphs for improved sequential recommendation while maintaining temporal relationship modeling?,Temporal Knowledge Graph (TKG) construction incorporating user behavior dynamics; entity and structural dynamics modeling; sequential relationship emphasis; integration of structured knowledge with temporal patterns,Published at premier WSDM 2024 conference; demonstrates effective integration of user behavior with knowledge graphs; captures both entity and structural dynamics in temporal setting,TKG framework for sequential recommendation; user behavior enriched knowledge graphs; temporal relationship modeling; dynamic entity and structure representation,Detailed methodology and experimental results not fully accessible; computational complexity of TKG construction not characterized; scalability to large-scale knowledge graphs unclear,Temporal knowledge graphs enriched with user behavior provide effective approach for sequential recommendation by combining structured knowledge with dynamic user interaction patterns,Limited integration of user behavior dynamics in knowledge graph construction; need for temporal knowledge representation in recommendation systems; challenges in modeling both entity and structural dynamics,Investigate scalability optimizations; explore domain-specific TKG applications; develop efficient construction algorithms for large-scale temporal knowledge graphs,Combines knowledge graphs with user behavior dynamics; provides temporal relationship modeling; addresses both entity and structural dynamics in sequential recommendation,https://dl.acm.org/doi/10.1145/3616855.3635762,10.1145/3616855.3635762,"dynamic-systems, knowledge-representation, sequential-recommendation, temporal-knowledge-graph, user-behavior",User Behavior Enriched Temporal Knowledge Graphs for Sequential Recommendation,"Hu Hengchang, Guo Wei, Liu Xu, Liu Yong, Tang Ruiming, Zhang Rui, Kan Min-Yen",2024,reference-manager,10.1145/3616855.3635762,,,,,,"Construction of temporal knowledge graphs (KGs) from user behavior, incorporating time-aware properties and interest transition relations.",,,"How can incorporating time-aware, behavior-centric knowledge from a Temporal Knowledge Graph (TKG) improve the identification of relevant information and enhance the performance of sequential recommendation models compared to traditional item-centric and user-centric knowledge distillation methods?","The paper investigates how popularity-based statistics and knowledge graphs (KGs) can improve sequential recommendation (SR) through knowledge distillation. Using experiments on four public datasets, the study finds that their proposed KEN and TKG-SRec frameworks outperform traditional methods, especially in modeling sequential relevance and handling KG complexity, enhancing recommendation accuracy.","The research goal is to improve sequential recommendation by introducing Temporal Knowledge Graphs (TKGs); the approach uses a two-phase TKG-SRec framework with a Knowledge Evolution Network (KEN) to learn dynamic entity embeddings, and the principal finding is that TKG-SRec outperforms state-of-the-art baselines by 5% on average.",,1.000,exact_title
huaman_2012,Steps to Knowledge Graphs Quality Assessment,Elwin Huaman,2012,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on steps to knowledge graphs quality assessment providing insights for knowledge graph development and data integration.,"This 2012 paper by Elwin Huaman explores steps to knowledge graphs quality assessment. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3233/SW-170275,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
huang_2021,"1+1>2: Programming Know-What and Know-How Knowledge Fusion, Semantic Enrichment and Coherent Application","Qing Huang, Zhiqiang Yuan, Zhenchang Xing, Zhengkang Zuo, Changjing Wang, Xin Xia",2021,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on 1+1>2: programming know-what and know-how knowledge fusion, semantic enrichment and coherent application providing insights for knowledge graph development and data integration.","This 2021 paper by Qing Huang, Zhiqiang Yuan, Zhenchang Xing, Zhengkang Zuo, Changjing Wang, Xin Xia explores 1+1>2: programming know-what and know-how knowledge fusion, semantic enrichment and coherent application. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/1294261.1294276,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
hur_2023,Unifying context with labeled property graph: A pipeline-based system for comprehensive text representation in NLP,"Ali Hur, Naeem Janjua, Mohiuddin Ahmed",2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on unifying context with labeled property graph: a pipeline-based system for comprehensive text representation in nlp providing insights for knowledge graph development and data integration.,"This 2023 paper by Ali Hur, Naeem Janjua, Mohiuddin Ahmed explores unifying context with labeled property graph: a pipeline-based system for comprehensive text representation in nlp. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.eswa.2023.122269,"data-integration, knowledge-graph",Unifying context with labeled property graph: A pipeline-based system for comprehensive text representation in NLP,"Hur Ali, Janjua Naeem, Ahmed Mohiuddin",2024,reference-manager,10.1016/j.eswa.2023.122269,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
ilievski_2018,Identifying and Consolidating Knowledge Engineering Requirements,"Filip Ilievski, Saurav Joshi, Bradley P. Allen",2018,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on identifying and consolidating knowledge engineering requirements providing insights for knowledge graph development and data integration.,"This 2018 paper by Filip Ilievski, Saurav Joshi, Bradley P. Allen explores identifying and consolidating knowledge engineering requirements. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3442188.,"data-integration, knowledge-graph",Identifying and Consolidating Knowledge Engineering Requirements,"Allen Bradley Paul, Ilievski Filip, Joshi Saurav",2023,reference-manager,,,,,,,Surveys were used to evaluate and prioritize requirements from stakeholders.,,,What are the consolidated requirements and quality attributes necessary for developing a comprehensive reference architecture for knowledge engineering that addresses the needs of diverse stakeholders and knowledge engineering eras?,"The paper aims to identify and consolidate knowledge engineering (KE) requirements across stakeholders and eras, analyzing gaps between current KE and reference architecture (RA) practices. Using requirement analysis and architecture evaluation, it finds no existing architecture fully meets all needs. The study proposes iterative, community-driven RA development for comprehensive KE support.","The paper's research goal is to identify and consolidate knowledge engineering (KE) requirements across stakeholders and eras; its approach profiles stakeholder needs, derives quality attributes and functional requirements, and evaluates existing architectures; the principal finding is that no current architecture fully satisfies all requirements, especially socio-technical ones.",,1.000,exact_title
ilkou_2022a,Personal Knowledge Graphs: Use Cases in e-learning Platforms,Eleni Ilkou,2022,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on personal knowledge graphs: use cases in e-learning platforms providing insights for knowledge graph development and data integration.,"This 2022 paper by Eleni Ilkou explores personal knowledge graphs: use cases in e-learning platforms. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3487553.3524196,"data-integration, educational-technology, knowledge-graph, personal-knowledge",,,,,,,,,,,,,,,,,,,
intel_2017,"Large Scale Multimodal Data Capture, Evaluation and Maintenance Framework for Autonomous Driving Datasets",Nitheesh K. Lakshminarayana Intel,2017,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on large scale multimodal data capture, evaluation and maintenance framework for autonomous driving datasets providing insights for knowledge graph development and data integration.","This 2017 paper by Nitheesh K. Lakshminarayana Intel explores large scale multimodal data capture, evaluation and maintenance framework for autonomous driving datasets. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
isws_2019,Knowledge Graphs Evolution and Preservation,A Technical Report from ISWS,2019,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on knowledge graphs evolution and preservation providing insights for knowledge graph development and data integration.,"This 2019 paper by A Technical Report from ISWS explores knowledge graphs evolution and preservation. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1007/978-3-642-41338-4,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
janakiramal_2024,A Hybrid Optimization and Machine Learning Framework for Urban Traffic Management Using Cyber-Physical Digital Twin Architecture,"India janakiramal, India eanbalagan",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",CPDT architecture integrates PSO and ABC algorithms with Transformer networks achieving 20% reduction in traffic delays and 15% prediction accuracy increase,Hybrid optimization framework using digital twins for urban system management,"This paper develops a Cyber-Physical Digital Twin (CPDT) architecture integrating data from multiple sources using hybrid optimization combining Particle Swarm Optimization, Artificial Bee Colony algorithms, and Transformer networks",How can advanced technologies improve urban traffic management and reduce congestion?,"CPDT architecture, hybrid PSO-ABC optimization, Transformer networks for prediction, multi-source data integration","20% reduction in average traffic delays, 15% increase in prediction accuracy, demonstrated effective hybrid optimization approach",,"Limited to traffic management domain, computational complexity not discussed",Shows promise for intelligent system optimization using advanced computational techniques,,"Apply to personal schedule optimization, integrate with HDM planning systems, develop user-friendly interfaces",Agent Epsilon: Hybrid optimization techniques applicable to HDM predictive modeling and resource optimization,https://ieeexplore.ieee.org/document/10983125/,10.1109/TEM.2024.3520255,"cyber-physical-systems, digital-twin, hybrid-optimization, machine-learning, traffic-management",A Hybrid Optimization and Machine Learning Framework for Urban Traffic Management Using Cyber-Physical Digital Twin Architecture,"Ramal P.Janaki, Anbalagan E.",2024,reference-manager,10.1109/upcon62832.2024.10983125,,"The implementation leverages Google Maps APIs for real-time, multi-source traffic data collection, including traffic density, lane counts, and road conditions. Integrating AI and ML, especially ANN, improves prediction accuracy and signal optimization. Challenges include data integration, algorithm scalability, and handling unexpected traffic surges.",,,,"Real-time traffic data collection using Google Maps APIs and SDKs, including Street View, Elevation, and Aerial View APIs, to gather comprehensive traffic and infrastructure data.",,,"How can the Cyber-Physical Digital Twin (CPDT) architecture, integrating real-time data and hybrid optimization algorithms, be used to model and optimize urban traffic systems for improved traffic flow and reduced congestion?","The paper aims to improve urban traffic management by optimizing signal timings and traffic flow using Artificial Bee Colony and Particle Swarm Optimization algorithms. Using real-world data and machine learning, the proposed model reduced average vehicle waiting time from 120 seconds (traditional) to 75 seconds, enhancing traffic efficiency.","The research goal was to improve urban traffic management using a hybrid approach combining Artificial Bee Colony, Particle Swarm Optimization, and Transformers; results showed reduced average vehicle waiting time from 120 to 75 seconds compared to traditional methods.",,1.000,exact_title
jeunehomme_2020,The temporal compression of events during episodic future thinking,"Olivier Jeunehomme, Nathan Leroy, Arnaud D'Argembeau",2020,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on the temporal compression of events during episodic future thinking providing insights for knowledge graph development and data integration.,"This 2020 paper by Olivier Jeunehomme, Nathan Leroy, Arnaud D'Argembeau explores the temporal compression of events during episodic future thinking. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.cognition.2020.104416,"data-integration, knowledge-graph, temporal-data",The temporal compression of events during episodic future thinking,"Jeunehomme Olivier, Leroy Nathan, D'Argembeau Arnaud",2020,reference-manager,10.1016/j.cognition.2020.104416,,"Verbal reports were segmented into """"experience units"""" using verbal cues and silences. Robust statistical methods were used due to data violations. The study found that both memory and imagination compress events similarly, with higher density of experience units leading to longer duration estimates. Compression rates vary by event type and context.",,,,"Memory and future simulation tasks: Participants either remembered experienced events or mentally simulated future events, involving both action sequences and spatial displacements.",,,"How do the rates and mechanisms of temporal compression differ between episodic memories and future event simulations, and how are these differences influenced by the nature of events and related to duration judgments?","The study investigated whether real-world events are structured and compressed similarly when imagining the future and remembering the past. Using verbal reports and robust statistical methods, results showed both processes use temporal compression, but past events have a higher density of experience units. Compression rates vary by event type.","The research goal was to examine whether real-world events are temporally structured and compressed similarly when imagining the future and remembering the past; using memory and future simulation tasks, results showed both processes involve temporal compression via discrete experience units, but compression rates differ by event type and temporal orientation.",,1.000,exact_title
jiang_2024,Digital twin system for manufacturing processes based on a multi-layer knowledge graph model,Dongsheng Jiang,2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on digital twin system for manufacturing processes based on a multi-layer knowledge graph model providing insights for knowledge graph development and data integration.,"This 2024 paper by Dongsheng Jiang explores digital twin system for manufacturing processes based on a multi-layer knowledge graph model. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.jmsy.2021.05.010,"data-integration, knowledge-graph",Digital twin system for manufacturing processes based on a multi-layer knowledge graph model,"Su Chang, Tang Xin, Jiang Qi, Han Yong, Wang Tao, Jiang Dongsheng",2025,reference-manager,10.1038/s41598-024-85053-0,,,,,,"Comparative experiment: Compared the proposed three-layer knowledge model with OpenIE, Bi-LSTM, and BERT-Bi-LSTM-CRF for extracting knowledge triples from manufacturing documents.",,,"How does the proposed three-layer knowledge model, with its concept layer ontology framework, enhance the extraction, integration, and application of domain-specific knowledge in industrial manufacturing, particularly for supporting digital twin models and outperforming existing knowledge extraction methods?","The paper aims to validate a three-layer knowledge model for extracting knowledge triples from unstructured manufacturing data. Using standard metrics (Precision, Recall, F1 Score), the proposed model outperformed BERT-Bi-LSTM-CRF, Bi-LSTM, and OpenIE. The model supports digital twin applications, enhancing decision-making in aero-engine blade production.","The research goal is to validate a three-layer knowledge model for extracting knowledge triples from manufacturing documents; using an ontology-based approach, the model outperforms OpenIE, Bi-LSTM, and BERT-Bi-LSTM-CRF methods, achieving the highest Precision (77.38%), Recall (83.14%), and F1 Score (80.15%).",,1.000,exact_title
jinheonbae_2024,Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion,"South Korea jinheon.bae, USA niru, USA allen, USA silvi, USA sjauha",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Constructs entity-centric knowledge store for users based on search and browsing activities, leverages existing search log infrastructure to provide contextually relevant LLM prompt augmentations while mitigating privacy, compliance, and scalability concerns.",LLM personalization framework using lightweight user-specific knowledge projections onto public knowledge graphs for contextual query suggestion without extensive re-training.,"This paper proposes augmenting Large Language Models with user-specific context from search and browsing histories to create personalized query suggestions. The approach constructs an entity-centric knowledge store for each user based on their search and browsing activities on the web, which is then leveraged to provide contextually relevant LLM prompt augmentations. The knowledge store is lightweight, producing user-specific aggregate projections of interests onto public knowledge graphs while leveraging existing search log infrastructure, thereby mitigating privacy, compliance, and scalability concerns associated with building deep user profiles.",How can LLMs be personalized without extensive re-training while maintaining user privacy and generating contextually relevant suggestions for web search applications?,"Constructed entity-centric knowledge store for users, leveraged search log infrastructure, created lightweight user-specific knowledge projections, validated on contextual query suggestion task through human evaluation experiments.","Significantly outperformed existing LLM-powered baselines in human evaluation studies, generated query suggestions that were contextually more relevant, personalized, and useful, demonstrated effective privacy-preserving personalization approach.",,"Potential privacy concerns in user profiling, scalability challenges in knowledge store creation, evaluation limited to specific query suggestion domain.","Successfully demonstrates that personalized LLM generations can be achieved through lightweight, privacy-preserving knowledge augmentation that maintains competitive performance while addressing practical deployment constraints.",,"Expand personalization techniques to broader application domains, investigate advanced privacy preservation methods, develop more sophisticated user modeling approaches.",Provides practical framework for implementing intelligent query interfaces in HDM systems with focus on lightweight knowledge projection and existing infrastructure utilization.,https://arxiv.org/abs/2311.06318,10.48550/arXiv.2311.06318,"contextual-query-suggestion, knowledge-augmentation, llm-personalization, privacy-preserving-user-modeling, search-log-mining",Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion,"Baek Jinheon, Chandrasekaran Nirupama, Cucerzan Silviu, Herring Allen, Jauhar Sujay Kumar",2024,reference-manager,10.1145/3589334.3645404,,"K-LaMP consistently outperforms baselines in Relatedness, Usefulness, and Ranking, especially as interaction history grows. Its entity-centric knowledge store enables richer personalization than linear histories. Using only “unfamiliar” entities boosts Relatedness and Usefulness. Automatic evaluation metrics correlate well with human judgments. Retrieval relevance is higher for entity-centric stores.",,,,Query Suggestion: Uses the current query and historical queries from the same session to suggest the next query.,,,No information available,"The paper introduces a new approach for contextual query suggestion, aiming to generate personalized search queries by considering the user's current search context and personal interests. Using human evaluation, the study finds that traditional metrics are insufficient, highlighting the need for richer context and personalization in query suggestion systems.","The paper’s main objective is to improve personalized query suggestion by leveraging user-specific knowledge; its key method is the K-LaMP framework, which augments large language models with personal entity-centric knowledge; principal finding is K-LaMP significantly outperforms baselines in relatedness, usefulness, and ranking metrics.",,1.000,exact_title
joosse_2023,Sustainable Development Goal indicator for measuring availability and affordability of medicines for children: a proof-of-concept study,"Iris R Joosse, Fatima Suleman",2023,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on sustainable development goal indicator for measuring availability and affordability of medicines for children: a proof-of-concept study providing insights for knowledge graph development and data integration.,"This 2023 paper by Iris R Joosse, Fatima Suleman explores sustainable development goal indicator for measuring availability and affordability of medicines for children: a proof-of-concept study. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1136/bmjopen-2022-065929,"data-integration, knowledge-graph",Sustainable Development Goal indicator for measuring availability and affordability of medicines for children: a proof-of-concept study,"Joosse Iris R, Mantel-Teeuwisse Aukje K, Suleman Fatima, van den Ham Hendrika A",2023,reference-manager,10.1136/bmjopen-2022-065929,,,,,,"Data collection in six geographical survey areas, including a main urban center and five other areas, using systematic selection of health facilities across public, private, and up to two other sectors.",,,"How can a standardized, child-specific methodology based on SDG indicator 3.b.3 be developed and applied to measure the availability and affordability of age-appropriate medicines for children across different countries?","The study aimed to adapt and validate a WHO/HAI methodology to measure the availability and affordability of medicines for children. Using historical, quality-assured datasets from several countries, the adapted tool showed proof of concept but was limited by small sample size and outdated data. Further research is needed.",The research goal was to adapt the WHO/HAI methodology for measuring access to medicines for children; the approach involved developing child-specific core medicine sets and a new affordability parameter (NUNT); results showed successful proof of concept using historical data from three countries.,,1.000,exact_title
kalmuk_2024,Native Cloud Object Storage in Db2 Warehouse:,"David Kalmuk, Kostas Rakopoulos, Robert C. Hooper, Patrick Perez, Daniel C. Zilio, Christian Garcia-Arellano, Hamdi Roumani, Matthew Emmerton, Aleksandrs Santars, Imran Sayyid, Krishna K. Ramachandran, Ronald Barber, William Minor, Zach Hoggard, Michael Chen, Humphrey Li, Yiren Shen, Richard Sidle, Alexander Cheung, Scott Walkty, Matthew Olan, Ketan Rampurkar",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on native cloud object storage in db2 warehouse: providing insights for knowledge graph development and data integration.,"This 2024 paper by David Kalmuk, Kostas Rakopoulos, Robert C. Hooper, Patrick Perez, Daniel C. Zilio, Christian Garcia-Arellano, Hamdi Roumani, Matthew Emmerton, Aleksandrs Santars, Imran Sayyid, Krishna K. Ramachandran, Ronald Barber, William Minor, Zach Hoggard, Michael Chen, Humphrey Li, Yiren Shen, Richard Sidle, Alexander Cheung, Scott Walkty, Matthew Olan, Ketan Rampurkar explores native cloud object storage in db2 warehouse:. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3626246.3653393,"data-integration, knowledge-graph",Native Cloud Object Storage in Db2 Warehouse: Implementing a Fast and Cost-Efficient Cloud Storage Architecture,"Kalmuk David, Garcia-Arellano Christian, Barber Ronald, Sidle Richard, Rakopoulos Kostas, Roumani Hamdi, Minor William, Cheung Alexander, Hooper Robert C., Emmerton Matthew, Hoggard Zach, Walkty Scott, Perez Patrick, Santars Aleksandrs, Chen Michael, Olan Matthew, Zilio Daniel C., Sayyid Imran, Li Humphrey, Rampurkar Ketan, Ramachandran Krishna K., Shen Yiren",2024,reference-manager,10.1145/3626246.3653393,,"Implementation Insights focus on integrating LSM trees for optimized data organization, asynchronous write tracking, and efficient bulk inserts. KeyFile was developed for better Db2 integration, replacing RocksDB-Cloud. Experiments show similar insert performance for columnar and PAX clustering, 4x compression, and 2 GB/s write rates. Future work targets broader optimization and adaptive clustering.",,,,Use of various clustering keys for data pages to optimize data organization and query performance via LSM trees.,,,"How can the integration of an LSM tree-based storage layer with object storage in Db2 Warehouse optimize data page storage, minimize latency and amplification factors, and improve performance compared to traditional storage subsystems?","The paper aims to integrate an LSM tree storage layer into Db2 to optimize data organization and query performance, using KeyFile as an abstraction over RocksDB. Methodology includes clustering keys, asynchronous write tracking, and bulk load techniques. Experiments show improved performance and storage efficiency. The study concludes with positive implications for cloud data warehousing.",The research goal is to modernize Db2 Warehouse storage for cloud object storage using an LSM tree-based approach; the method integrates LSM trees and optimizations to minimize latency and amplification; results show improved performance and cost savings while retaining existing database capabilities.,,0.900,fuzzy_title
kaplan_2021,A Classification for Managing Software Engineering Knowledge,"Angelika Kaplan, Maximilian Walter, Robert Heinrich",2021,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a classification for managing software engineering knowledge providing insights for knowledge graph development and data integration.,"This 2021 paper by Angelika Kaplan, Maximilian Walter, Robert Heinrich explores a classification for managing software engineering knowledge. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3463274.3463357,"data-integration, knowledge-graph",A Classification for Managing Software Engineering Knowledge,"Kaplan Angelika, Walter Maximilian, Heinrich Robert",2021,reference-manager,10.1145/3463274.3463357,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
karras_2020,Divide and Conquer the EmpiRE: A Community-Maintainable Knowledge Graph of Empirical Research in Requirements Engineering,Oliver Karras,2020,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on divide and conquer the empire: a community-maintainable knowledge graph of empirical research in requirements engineering providing insights for knowledge graph development and data integration.,"This 2020 paper by Oliver Karras explores divide and conquer the empire: a community-maintainable knowledge graph of empirical research in requirements engineering. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.48366/r255464,"data-integration, knowledge-graph",Divide and Conquer the EmpiRE: A Community-Maintainable Knowledge Graph of Empirical Research in Requirements Engineering,"Karras Oliver, Wernlein Felix, Klünder Jil, Auer Sören",2023,reference-manager,,,,,,,Case studies and experiments have been the main research methods for empirical research in RE and SE for over 20 years.,,,"How can the ORKG be used to organize, publish, and evaluate an openly available and sustainable knowledge graph of empirical research in requirements engineering to enable comprehensive, up-to-date, and long-term literature reviews on the state and evolution of the field?","The paper aims to organize and evaluate empirical research in Requirements Engineering (RE) using the ORKG knowledge graph. It analyzes related publications, focusing on themes like research methods and data collection. Findings show evolving research methods but limited data sharing. The study highlights the need for standardized terminology and sustainable literature reviews.","The research goal is to organize and evaluate empirical research in Requirements Engineering (RE) using a knowledge graph; the approach involves systematic data extraction from related publications, and the principal finding is a positive trend in empirical methods and data sharing, with 71.3% of recent studies providing their data.",,1.000,exact_title
karray_2023,Secure Federated Learning With Fully Homomorphic Encryption for IoT Communications,Fakhri Karray,2023,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on secure federated learning with fully homomorphic encryption for iot communications providing insights for knowledge graph development and data integration.,"This 2023 paper by Fakhri Karray explores secure federated learning with fully homomorphic encryption for iot communications. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1109/JIOT.2023.3302065,"data-integration, educational-technology, knowledge-graph",Secure Federated Learning With Fully Homomorphic Encryption for IoT Communications,"Hijazi Neveen Mohammad, Aloqaily Moayad, Guizani Mohsen, Ouni Bassem, Karray Fakhri",2024,reference-manager,10.1109/jiot.2023.3302065,,,,,,"Federated Learning (FL): Each user trains a local model on their own data, keeping data private, and only shares model updates.",,,"How can federated learning (FL) combined with fully homomorphic encryption (FHE) be used to address security and privacy issues in IoT-enabled smart cities, and how effective are the proposed approaches in detecting intrusions and injection attacks in the Internet of Medical Things?","The paper aims to address security and privacy in IoT systems by proposing four scenarios using federated learning (FL) and encryption techniques. Experiments on benchmark IoT data sets show high accuracy (above 0.997% for most approaches), with MECM performing best. The approaches enhance IoT security and privacy.","The research goal is to address privacy and security in IoT-enabled smart cities using Federated Learning (FL) and Fully Homomorphic Encryption (FHE); the approach involves clustering users, local model training, encryption, and secure aggregation; results show effective security and efficiency in four evaluated scenarios.",,1.000,exact_title
kejriwal_2023,Named Entity Resolution in Personal Knowledge Graphs,Mayank Kejriwal,2023,Yes,HIGH,"Directly addresses the entity resolution gap in HDM systems, tackling the 78% accuracy limitation in cross-source entity matching.","The paper defines entity resolution as ""the problem of determining when two entities refer to the same underlying entity"" in personal knowledge graphs, addressing critical integration challenges.",Comprehensive analysis of entity resolution challenges specific to personal,This paper provides a formal definition of entity resolution in personal knowledge graphs and discusses components necessary for high-quality and efficient entity resolution at Web-scale.,How can entity resolution be effectively implemented in personal knowledge graphs to handle cross-source entity matching?,Literature review and formal problem definition for entity resolution in personal knowledge graphs.,Formal framework for entity resolution in PKGs; identification of components for high-quality entity resolution; analysis of Web-scale challenges.,Framework for implementing entity resolution in personal knowledge graph systems.,Limited technical details on specific algorithms or performance metrics in the abstract.,Establishes foundational framework for addressing entity resolution challenges in personal knowledge graphs.,Need for specific algorithms and performance evaluation; scalability solutions for Web-scale deployment.,Develop specific entity resolution algorithms; conduct empirical evaluation; address scalability challenges.,Provides foundational guidance for implementing entity resolution systems in personal knowledge graph architectures.,https://arxiv.org/abs/2307.12173,arXiv:2307.12173,"cross-source-matching, data-integration, entity-resolution, personal-knowledge-graph",,,,,,,,,,,,,,,,,,,
kerkemeier_2024,nekCRF: A next generation high-order reactive low Mach flow solver for direct numerical simulations,"Stefan Kerkemeier, Christos E. Frouzakis, Ananias G. Tomboulides, Paul Fischer, Mathis Bodee",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on nekcrf: a next generation high-order reactive low mach flow solver for direct numerical simulations providing insights for knowledge graph development and data integration.,"This 2024 paper by Stefan Kerkemeier, Christos E. Frouzakis, Ananias G. Tomboulides, Paul Fischer, Mathis Bodee explores nekcrf: a next generation high-order reactive low mach flow solver for direct numerical simulations. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
khan_2024,Data Management Opportunities in Unifying Large Language Models+Knowledge Graphs,"Arijit Khan, Tianxing Wu, Xi Chen",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on data management opportunities in unifying large language models+knowledge graphs providing insights for knowledge graph development and data integration.,"This 2024 paper by Arijit Khan, Tianxing Wu, Xi Chen explores data management opportunities in unifying large language models+knowledge graphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Data Management Opportunities in Unifying Large Language Models+Knowledge Graphs,"Khan Arijit, Wu Tianxing, Chen Xi",2024,reference-manager,,,,,,,"Data and Input Modeling: Techniques for serializing graph structures for LLM input, integrating multi-modal data, extracting relevant subgraphs, and designing prompts with graph data.",,,"How can the unification of Large Language Models (LLMs) and Knowledge Graphs (KGs) advance data management by improving data modeling, integration, augmentation, validation, explainability, and addressing interoperability and reasoning challenges across multi-modal and domain-specific tasks?","The papers and panel discuss integrating Large Language Models (LLMs) and Knowledge Graphs (KGs) to improve data management, accuracy, and explainability. Methodologies include neural-symbolic systems, few-shot learning, graph machine learning, and ontology-guided approaches. Key findings highlight challenges in scalability, bias, privacy, and multi-modal data, with implications for more efficient, fair, and explainable AI systems.","The workshop's main objective is to explore the synergy between large language models and knowledge graphs, using approaches like neural-symbolic collaboration and multi-modality, with the principal finding that integrating knowledge graphs can enhance LLM performance, accuracy, and application in data management.",,1.000,exact_title
khatib_2024,"Patient-Centric Knowledge Graphs: A Survey of Current Methods, Challenges, and Applications","Hassan S. Al Khatib, Subash Neupane, Harish Kumar Manchukonda, Noorbakhsh Amiri Golilarz, Sudip Mittal, Amin Amirlatifi, Shahram Rahimi",2024,Yes,SUPER,"This paper directly addresses core aspects of heterogeneous data integration in knowledge graphs, providing critical insights for PKG architectures and temporal data management strategies that align perfectly with our research objectives.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Comprehensive survey exploring patient-centric knowledge graphs as transformative,"This 2024 paper by Hassan S. Al Khatib, Subash Neupane, Harish Kumar Manchukonda, Noorbakhsh Amiri Golilarz, Sudip Mittal, Amin Amirlatifi, Shahram Rahimi explores patient-centric knowledge graphs: a survey of current methods, challenges, and applications. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3389/frai.2024.1388479,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
khovricheva_2019,Intelligent Approach for Heterogeneous Data Integration: Information Processes Analysis Engine in Clinical Remote Monitoring Systems,"Mikhail Khovricheva, Liubov Elkhovskaya, Vladimir Fonin, Marina Balakhontceva",2019,Yes,SUPER,"This paper directly addresses core aspects of heterogeneous data integration in knowledge graphs, providing critical insights for PKG architectures and temporal data management strategies that align perfectly with our research objectives.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on intelligent approach for heterogeneous data integration: information processes analysis engine in clinical remote monitoring systems providing insights for knowledge graph development and data integration.,"This 2019 paper by Mikhail Khovricheva, Liubov Elkhovskaya, Vladimir Fonin, Marina Balakhontceva explores intelligent approach for heterogeneous data integration: information processes analysis engine in clinical remote monitoring systems. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.procs.2019.08.188,"data-integration, heterogeneous-data, knowledge-graph",Intelligent Approach for Heterogeneous Data Integration: Information Processes Analysis Engine in Clinical Remote Monitoring Systems,"Khovrichev Mikhail, Elkhovskaya Liubov, Fonin Vladimir, Balakhontceva Marina",2019,reference-manager,10.1016/j.procs.2019.08.188,,"The paper proposes an intelligent approach for integrating heterogeneous data into a unified event log for remote monitoring of arterial hypertension and chronic heart failure. By analyzing event cycles (meta-states), it enables process optimization, critical transition identification, and development of personalized predictive models. New insight: meta-states enhance process analysis.",,,,Automated integration of heterogeneous data and knowledge sources into a single event log for process analysis.,,,How can an intelligent approach for automated integration of heterogeneous data and knowledge sources be designed and implemented to optimize remote monitoring and treatment processes for patients with arterial hypertension and chronic heart failure in personalized healthcare?,"The paper aims to develop an intelligent approach for integrating heterogeneous data in clinical remote monitoring systems. Using data mining, process mining, and knowledge formalization, the methodology consolidates event logs to design accurate process models. The main finding is improved detection and elimination of data errors, enhancing process compliance and patient safety.","The research goal was to design an intelligent approach for integrating heterogeneous data in personalized healthcare; the method involved developing a software component for event log analysis in remote monitoring systems, and results showed successful process reconstruction and identification of critical transitions for optimizing patient care.",,1.000,exact_title
kim_2023,Guidelines for designing an automated multimodal textual annotation system,"Joshua Y. Kim, Kalina Yacef",2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on guidelines for designing an automated multimodal textual annotation system providing insights for knowledge graph development and data integration.,"This 2023 paper by Joshua Y. Kim, Kalina Yacef explores guidelines for designing an automated multimodal textual annotation system. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3610661.3616182,"data-integration, knowledge-graph",Guidelines for designing and building an automated multimodal textual annotation system,"Kim Joshua Y, Yacef Kalina",2023,reference-manager,10.1145/3610661.3616182,,"Implementation Insights highlight the need for expert annotators for sensitive content, a two-pass annotation process (automated then manual), and the importance of balancing technical and layman annotations. Early supervised learning tests save time, but features useful for algorithms may not benefit human users. Annotation is labor-intensive, requiring 4–5 hours per hour of data.",,,,Use of multiple existing multimodal research datasets to test and inform extraction algorithms before collecting new data.,,,"What are the key guidelines for designing an automated multimodal textual annotation system to address user needs, reduce bias, and improve the efficiency and accuracy of multimodal feature extraction and presentation?","The paper aims to design and build an automated multimodal annotation system for interpreting various communication cues. Using multiple existing datasets and extraction algorithms, the study compares systems, highlights challenges like bias, and recommends a two-pass (automated and manual) approach. Early supervised learning tests help validate features and save resources.","The research goal is to design automated multimodal annotation systems tailored to user needs; the approach involves proposing guidelines and comparing existing systems, and the principal finding is that user-focused customization and usability are crucial, with MONAH achieving higher usability but lacking some technical features.",,0.937,fuzzy_title
kim_2024,Leveraging Knowledge Graph-Based Human-Like Memory Systems to Solve Partially Observable Markov Decision Processes,"Taewoon Kim, Michael Cochez",2024,Yes,HIGH,"Explores human-like memory systems using dynamic knowledge graphs for POMDP environments, directly relevant to temporal knowledge management in HDM.",Dynamic KGs represent hidden states in POMDP; enables human- and machine-readable memory tracking; demonstrates learning of memory management policies similar to human cognitive processes.,AI can learn and utilize long-term memory through knowledge graph-based memory,"This paper investigates how AI can develop human-like long-term memory capabilities using knowledge graph-based hidden states in POMDP environments, where agents navigate mazes and answer questions while managing memory.",How can AI learn and utilize long-term memory similar to human cognitive processes in partially observable environments?,Developed POMDP environment with KG-based hidden states; agents navigate maze and answer questions; repurposed learning objective as memory management policy learning; compared agents with different memory systems.,Demonstrated AI can learn memory management policies; captured most likely hidden states through KG representation; provided interpretable and reusable memory state tracking.,Knowledge graph-based memory systems enable transparent tracking of agent memory in POMDP environments.,Abstract lacks specific performance metrics; evaluation details limited; scalability considerations not addressed.,"By using dynamic KGs as memory representation, AI agents can develop human-like memory management capabilities with interpretable state tracking.",Expand evaluation metrics; test on diverse POMDP tasks; investigate scalability; explore different KG structures for memory representation.,Further exploration of memory systems in AI agents; optimize KG structures for different tasks; develop benchmarks for memory-based POMDP solving.,"Demonstrates practical approach for implementing human-like memory in AI using KGs, applicable to HDM systems requiring interpretable memory management.",https://arxiv.org/abs/2408.05861,10.48550/arXiv.2408.05861,"cognitive-computing, human-like-ai, knowledge-graph, memory-systems, pomdp",Leveraging Knowledge Graph-Based Human-Like Memory Systems to Solve Partially Observable Markov Decision Processes,"Kim Taewoon, François-Lavet Vincent, Cochez Michael",2024,reference-manager,,,,,,,"KG-based Environment Design: Developed a Knowledge Graph (KG)-based simulation environment for agents to navigate and answer questions, enabling systematic study of memory management.",,,"How can an agent effectively manage and utilize long-term memory, represented as a dynamic knowledge graph, to optimize exploration and question answering in partially observable environments with biased sampling and large state spaces?","The paper aims to improve AI agents’ ability to solve partially observable tasks by modeling human-like long-term memory using knowledge graph-based systems. Using a custom Rooms Environment, the HumemAI agent, which integrates episodic and semantic memory, outperforms a baseline. The study suggests further improvements in memory management and exploration strategies.","The research goal is to improve AI memory management in partially observable environments using a knowledge graph-based human-like memory system; the approach involves HumemAI agents with episodic and semantic memory in a configurable maze, and results show these agents outperform baselines by better capturing hidden states.",,1.000,exact_title
kimmathematics_2016,Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System,Kibaek KimMathematics,2016,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on advances in privacy preserving federated learning to realize a truly learning healthcare system providing insights for knowledge graph development and data integration.,"This 2016 paper by Kibaek KimMathematics explores advances in privacy preserving federated learning to realize a truly learning healthcare system. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, healthcare, knowledge-graph",Advances in Privacy Preserving Federated Learning to Realize a Truly Learning Healthcare System,"Madduri Ravi, Li Zilinghan, Nandi Tarak, Rodriguez Alex, Ryu Minseok, Kim Kibaek",2024,reference-manager,,,,,,,"Multimodal learning: Integrates different data types (e.g., images, tabular data, text) to improve predictions by capturing complementary information from each modality.",,,How can Privacy-Preserving Federated Learning (PPFL) be integrated into the healthcare ecosystem to enable collaborative analysis of multimodal biomedical data across diverse sources while safeguarding patient privacy and advancing the vision of a learning healthcare system?,"The paper addresses challenges in integrating multimodal biomedical data across disparate sources for improved healthcare AI. Using embedding techniques and federated learning, it enables secure, privacy-preserving data analysis. The study highlights improved model performance and data readiness assessment, concluding that such integration enhances personalized prognosis, diagnosis, and treatment planning.","The paper's main objective is to integrate Privacy-Preserving Federated Learning (PPFL) into healthcare systems using a collaborative approach, with the principal finding that PPFL can overcome data sharing and privacy challenges to enable a truly learning healthcare system.",,1.000,exact_title
kimura_2025,InfoMAE: Pair-Efficient Cross-Modal Alignment for Multimodal Time-Series Sensing Signals,"Tomoyoshi Kimura, Yizhuo Chen Denizhan Kara, Shengzhong Liu, Xinlin Li, Osama Hanna, Mani Srivastava Suhas Diggavi, Yatong Chen, Xiaomin Ouyang",2025,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on infomae: pair-efficient cross-modal alignment for multimodal time-series sensing signals providing insights for knowledge graph development and data integration.,"This 2025 paper by Tomoyoshi Kimura, Yizhuo Chen Denizhan Kara, Shengzhong Liu, Xinlin Li, Osama Hanna, Mani Srivastava Suhas Diggavi, Yatong Chen, Xiaomin Ouyang explores infomae: pair-efficient cross-modal alignment for multimodal time-series sensing signals. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3696410.3714853,"data-integration, knowledge-graph",InfoMAE: Pair-Efficient Cross-Modal Alignment for Multimodal Time-Series Sensing Signals,"Kimura Tomoyoshi, Li Xinlin, Hanna Osama, Chen Yatong, Chen Yizhuo, Kara Denizhan, Wang Tianshi, Li Jinyang, Ouyang Xiaomin, Liu Shengzhong, Srivastava Mani, Diggavi Suhas, Abdelzaher Tarek",2025,reference-manager,10.1145/3696410.3714853,,"InfoMAE jointly optimizes encoders and decoders with AdamW and Cosine scheduler, using discriminators for density-ratio estimation. It achieves real-time inference (<1s) on low-end devices. Ablation studies show shared, private, and temporal components are crucial. InfoMAE remains robust under sparse data and augmentations, outperforming baselines but increases training overhead.",,,,Joint multimodal pretraining: Pretraining on large-scale synchronized multimodal data to align representations across modalities.,,,How can information theory-based factorization enable efficient and effective distributional alignment of multimodal representations for self-supervised learning with limited multimodal data in IoT sensing applications?,"InfoMAE is a multi-stage self-supervised learning framework for multimodal IoT sensing. It pretrains modality-specific encoders, then aligns cross-modal representations using information theory-based objectives. Experiments show InfoMAE outperforms baselines, is robust under sparse data, and enables efficient, high-quality multimodal learning with minimal performance degradation.","The research goal is to develop InfoMAE, a pairing-efficient multi-stage self-supervised learning approach for multimodal IoT sensing; the method uses information theory-based optimization for cross-modal alignment with limited pairs, and results show superior efficiency and effectiveness over existing frameworks in real-world applications.","Keywords: Multimodal sensing, Self-supervised learning, Internet of Things",1.000,exact_title
korobko_2019,Matching disparate dimensions for analytical integration of heterogeneous data sources,"Anna Korobko, New York",2019,Yes,SUPER,"This paper directly addresses core aspects of heterogeneous data integration in knowledge graphs, providing critical insights for PKG architectures and temporal data management strategies that align perfectly with our research objectives.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on matching disparate dimensions for analytical integration of heterogeneous data sources providing insights for knowledge graph development and data integration.,"This 2019 paper by Anna Korobko, New York explores matching disparate dimensions for analytical integration of heterogeneous data sources. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3297662.3365809,"data-integration, heterogeneous-data, knowledge-graph",Matching disparate dimensions for analytical integration of heterogeneous data sources,"Korobko Anna, Korobko Aleksei",2019,reference-manager,10.1145/3297662.3365809,,,,,,"Integration of OLAP (On-Line Analytical Processing), FCA (Formal Concept Analysis), and semantic analysis methods to reconcile and merge heterogeneous data sources.",,,How can an original integration methodology based on the integral analytical model (IAM) be developed to automatically reconcile and merge heterogeneous data sources for enhanced online analytical processing (OLAP)?,"The paper aims to develop a new integration methodology for heterogeneous data using an Integral Analytical Model (IAM) and a Simplified Multidimensional Model (SMM). It combines OLAP, FCA, and semantic analysis to match and merge disparate data dimensions. Results support automated integration and exploratory analysis, enabling self-service analytical queries.","The research goal is to develop an original integration methodology for heterogeneous data using a simplified multidimensional model and IAM; the approach uses reference dimensions and matching algorithms; results show successful merging of disparate sources, supporting automatic data integration and exploratory analysis.",,1.000,exact_title
koutsoubisa_2017,Privacy Preserving Federated Learning in Medical Imaging with Uncertainty Estimation,"Nikolas Koutsoubisa, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool, Machine Learning, Cancer Center, Cancer Epidemiology, South Florida",2017,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on privacy preserving federated learning in medical imaging with uncertainty estimation providing insights for knowledge graph development and data integration.,"This 2017 paper by Nikolas Koutsoubisa, Yasin Yilmaz, Ravi P. Ramachandran, Matthew Schabath, Ghulam Rasool, Machine Learning, Cancer Center, Cancer Epidemiology, South Florida explores privacy preserving federated learning in medical imaging with uncertainty estimation. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, healthcare, knowledge-graph",,,,,,,,,,,,,,,,,,,
kumar_2021,Data Harmonization for Heterogeneous Datasets: A Systematic Literature Review,"Ganesh Kumar, Shuib Basri, Abdullahi Abubakar Imam, Sunder Ali Khowaja, Luiz Fernando Capretz, Abdullateef Oluwagbemiga Balogun",2021,Yes,SUPER,"This paper directly addresses core aspects of heterogeneous data integration in knowledge graphs, providing critical insights for PKG architectures and temporal data management strategies that align perfectly with our research objectives.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on data harmonization for heterogeneous datasets: a systematic literature review providing insights for knowledge graph development and data integration.,"This 2021 paper by Ganesh Kumar, Shuib Basri, Abdullahi Abubakar Imam, Sunder Ali Khowaja, Luiz Fernando Capretz, Abdullateef Oluwagbemiga Balogun explores data harmonization for heterogeneous datasets: a systematic literature review. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3390/app11178275,"data-integration, heterogeneous-data, knowledge-graph",Data Harmonization for Heterogeneous Datasets: A Systematic Literature Review,"Kumar Ganesh, Basri Shuib, Imam Abdullahi Abubakar, Khowaja Sunder Ali, Capretz Luiz Fernando, Balogun Abdullateef Oluwagbemiga",2021,reference-manager,10.3390/app11178275,,,,,"Limited data availability and domain context due to broad use of """"harmonization"""" keyword.",,,"The research follows a systematic literature review process with clear protocols for study selection, data extraction, and quality assessment. No information about the availability of source code for the project is provided.",,,"The research goal is to systematically review methods for harmonizing heterogeneous big textual data; the approach is a three-phase Systematic Literature Review (SLR); the principal finding is that various ML, DL, and NLP techniques address data heterogeneity, harmonization, and performance in large-scale textual datasets.","Keywords or tags for this research include: Data Integration, Data Fusion, Data Harmonization, Heterogeneous Data, Heterogeneity, Textual Data, Text Data, Text Preprocessing, Preprocessing, Techniques, Algorithm. These terms relate to combining and processing different types of text data using various methods and algorithms.",1.000,exact_title
lee_2024,Multimodal Reasoning with Multimodal Knowledge Graph,"Junlin Lee, Yequan Wang, Jing Li, Min Zhang",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Achieves state-of-the-art performance in multimodal question answering and analogical reasoning while training on only ~2.25% of LLM parameters through MR-MKG approach using relation graph attention networks and cross-modal alignment modules for comprehensive multimodal understanding.,Efficient approach to enhance large language model multimodal reasoning using multimodal knowledge graphs with significant parameter efficiency and performance improvements across diverse reasoning tasks.,"This paper proposes MR-MKG (Multimodal Reasoning with Multimodal Knowledge Graph), the first method to expand multimodal reasoning capabilities of Large Language Models using multimodal knowledge graphs (MMKGs). The approach leverages rich multimodal knowledge across text, image, and video modalities to significantly enhance LLM reasoning capabilities through relation graph attention networks and cross-modal alignment modules while maintaining exceptional parameter efficiency in training and deployment.",How can multimodal knowledge graphs be effectively integrated with large language models to enhance multimodal reasoning capabilities while maintaining computational efficiency and cross-modal understanding?,"Developed MR-MKG framework with multimodal knowledge graph encoder, implemented relation graph attention network (RGAT) for MMKG encoding, designed cross-modal alignment module for image-text matching, constructed MMKG-grounded dataset from Visual Genome, evaluated on ScienceQA and MARS benchmarks across multiple LLMs.","Achieved state-of-the-art performance on multimodal question answering (ScienceQA) and multimodal analogical reasoning (MARS) tasks, demonstrated exceptional parameter efficiency training only ~2.25% of LLM parameters, showed significant improvements in cross-modal reasoning and multimodal understanding capabilities.",,"Knowledge retrieval effectiveness depends on retrieval strategy quality, computational resource constraints limited evaluation to four LLMs, performance may vary across different datasets and application domains, limited exploration of complex multimodal reasoning scenarios.","Provides significant advancement in multimodal knowledge integration essential for comprehensive personal data understanding across text, image, and multimedia content with exceptional computational efficiency and reasoning capabilities.",,"Extend evaluation to additional LLMs and multimodal reasoning tasks, optimize knowledge retrieval mechanisms for improved effectiveness, develop adaptive multimodal fusion techniques, explore integration with real-world personal data management systems requiring multimodal understanding.","Offers practical framework for implementing multimodal personal knowledge systems with dramatic computational efficiency improvements, enabling comprehensive understanding of diverse personal data types including text, images, and multimedia content through enhanced reasoning capabilities.",https://arxiv.org/html/2406.02030v1,arXiv:2406.02030,"cross-modal-reasoning, llm-enhancement, multimodal-knowledge-graphs, parameter-efficiency, personal-data-integration",Multimodal Reasoning with Multimodal Knowledge Graph,"Lee Junlin, Wang Yequan, Li Jing, Zhang Min",2024,reference-manager,10.xxxx/xxxxxxx.xxxxxxx,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
leixiawan_2024,PriPL-Tree: Accurate Range Query for Arbitrary Distribution under Local Differential Privacy,"Accurate Range Query for Arbitrary Distribution under Local Differential Privacy Leixia Wang Renmin University of China leixiawan, Haibo Hu Hong Kong Polytechnic University haibo.h, preserving the privacy of their Qingqing Ye Hong Kong Polytechnic University qqing.y, Renmin University of China xfmen",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Introduces PriPL-Tree data structure combining hierarchical trees with piecewise linear functions to precisely model arbitrary data distributions, achieving more accurate range query estimates while maintaining local differential privacy guarantees.",Novel privacy-preserving data structure for accurate range queries under local differential privacy that handles arbitrary data distributions through piecewise linear modeling and adaptive grid partitioning.,"This paper addresses limitations in existing Local Differential Privacy (LDP) solutions for range queries that assume uniform data distribution within domain partitions. The proposed PriPL-Tree combines hierarchical tree structures with piecewise linear functions to accurately model arbitrary data distributions using few line segments, extending to multi-dimensional cases with novel data-aware adaptive grids that leverage marginal distribution insights for optimal partitioning.",How can range query accuracy be improved under Local Differential Privacy when dealing with arbitrary data distributions that violate uniform distribution assumptions?,Developed PriPL-Tree data structure using hierarchical trees with piecewise linear functions; implemented data-aware adaptive grids for multi-dimensional extension; conducted extensive experiments on real and synthetic datasets with comparative analysis against state-of-the-art solutions.,Demonstrates superior performance over existing LDP solutions for range queries across arbitrary data distributions; achieves more accurate estimates through precise distribution modeling with reduced tree height and fewer leaf nodes enabling better privacy budget allocation.,,Specific performance metrics and detailed implementation architecture not available from abstract; requires further evaluation on diverse application domains beyond demonstrated datasets.,"Successfully advances local differential privacy for range queries by moving beyond uniform distribution assumptions, providing more accurate and practical privacy-preserving query mechanisms.",,Expand evaluation to additional data types and application scenarios; optimize computational efficiency for large-scale deployment; investigate integration with existing privacy-preserving database systems.,Provides practical privacy-preserving query mechanism for HDM systems requiring accurate range queries over personal data while maintaining strong privacy guarantees through local differential privacy.,https://arxiv.org/abs/2407.13532,arXiv:2407.13532,"data-distribution, local-differential-privacy, piecewise-linear-modeling, privacy-preserving-data, range-queries",PriPL-Tree: Accurate Range Query for Arbitrary Distribution under Local Differential Privacy,"Wang Leixia, Ye Qingqing, Hu Haibo, Meng Xiaofeng",2024,reference-manager,XX.XX/XXX.XX,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
leroy_2024,The role of working memory capacity in the temporal compression of episodic memories: An individual differences approach,"Nathan Leroy, Steve Majerus, Arnaud D'Argembeau",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on the role of working memory capacity in the temporal compression of episodic memories: an individual differences approach providing insights for knowledge graph development and data integration.,"This 2024 paper by Nathan Leroy, Steve Majerus, Arnaud D'Argembeau explores the role of working memory capacity in the temporal compression of episodic memories: an individual differences approach. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1037/xlm0001350,"data-integration, knowledge-graph, temporal-data",The role of working memory capacity in the temporal compression of episodic memories: An individual differences approach.,"Leroy Nathan, Majerus Steve, D'Argembeau Arnaud",2025,reference-manager,10.1037/xlm0001350,,,,,,"Used the DAStau procedure from the robustlmm package to estimate robust linear mixed-effects models, handling outliers and missing values.",,,"How does event segmentation ability influence episodic memory performance, and what are the methodological considerations for measuring these constructs in online behavioral research platforms?",,The research goal was to examine working memory (WM) task performance and its relation to temporal compression rates using robust linear mixed-effects models; the approach involved robust statistical modeling with random effects for participants and stimuli; results showed descriptive statistics and correlations among WM tasks and outcome variables.,,1.000,exact_title
leskinen_2015,Integrating Historical Person Registers as Linked Open Data in the WarSampo Knowledge Graph,"Petri Leskinen, Digital Humanities",2015,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on integrating historical person registers as linked open data in the warsampo knowledge graph providing insights for knowledge graph development and data integration.,"This 2015 paper by Petri Leskinen, Digital Humanities explores integrating historical person registers as linked open data in the warsampo knowledge graph. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.5281/zenodo.3431121.,"data-integration, knowledge-graph",Integrating Historical Person Registers as Linked Open Data in the WarSampo Knowledge Graph,"Koho Mikko, Leskinen Petri, Hyvönen Eero",2020,reference-manager,10.1007/978-3-030-59833-4\_8,,"The implementation uses probabilistic record linkage (RL) with weighted metadata comparisons (e.g., names, dates, military unit) to link person records from heterogeneous registers. Aggregated data enriches person profiles in an actor ontology, enabling unified biographies and research. Military rank and unit are key for disambiguation.",,,,"A repeatable data transformation pipeline converts source spreadsheets into RDF, mapping columns to RDF properties.",,,"How can heterogeneous historical person registers about Finnish Second World War soldiers be integrated into a unified knowledge graph using probabilistic record linkage, and what metadata fields are most effective for disambiguating person identities in the military history context?","The paper aims to integrate heterogeneous military historical person registers using probabilistic record linkage, demonstrated with data on 100,000 Finnish WWII soldiers in WarSampo. Using logistic regression to weigh metadata fields, the method creates a unified knowledge graph, enhancing biographical research and public exploration. The solution is scalable and openly available.","The paper's research goal is to integrate heterogeneous historical person registers using a probabilistic record linkage approach, resulting in a reconciled knowledge graph; key findings show that metadata fields like military rank and unit are crucial for disambiguation, enabling richer biographical research and open data publication.",,1.000,exact_title
li_2018,AIstorian lets AI be a historian: A KG-powered multi-agent system for accurate biography generation,"Fengyu Li, Yilin Li, Junhao Zhu, Lu Chen, Yanfei Zhang, Jia Zhou",2018,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on aistorian lets ai be a historian: a kg-powered multi-agent system for accurate biography generation providing insights for knowledge graph development and data integration.,"This 2018 paper by Fengyu Li, Yilin Li, Junhao Zhu, Lu Chen, Yanfei Zhang, Jia Zhou explores aistorian lets ai be a historian: a kg-powered multi-agent system for accurate biography generation. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.18653/v1/2024.emnlp-main.845,"data-integration, knowledge-graph",AIstorian lets AI be a historian: A KG-powered multi-agent system for accurate biography generation,"Li Fengyu, Li Yilin, Zhu Junhao, Chen Lu, Zhang Yanfei, Zhou Jia, Zu Hui, Zhao Jingwen, Gao Yunjun",2025,reference-manager,,,,,,,"Regex-driven relation extraction: Prompts a language model to generate regular expressions (regex) for extracting biographical facts as triplets (entity, relation, value) from text chunks.",,,How can a knowledge graph-powered multi-agent system be designed to generate accurate historical biographies from large corpora while minimizing factual errors and hallucinations?,"The paper addresses automatic biography generation, aiming to improve stylistic adherence and factual fidelity using a two-step training strategy: supervised fine-tuning and stylistic preference optimization. The proposed method, AIstorian, outperforms baselines in ROUGE scores and reduces factual errors, demonstrating significant advancements in biography generation for historical documents.","The research goal is to generate accurate, stylistically consistent historical biographies using a knowledge-grounded large language model (AIstorian); the approach combines KG-based indexing, two-step training, and error-aware generation; results show AIstorian outperforms Qwen2.5-72B-Instruct in factual fidelity and stylistic consistency.",,1.000,exact_title
li_2020,On a Factorial Knowledge Architecture for Data Science-powered Software Engineering,Zheng Li,2020,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on on a factorial knowledge architecture for data science-powered software engineering providing insights for knowledge graph development and data integration.,"This 2020 paper by Zheng Li explores on a factorial knowledge architecture for data science-powered software engineering. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1371/journal.pone.0021101.,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
li_2021,Temporal Knowledge Graph Reasoning Based on Evolutional Representation Learning,Wei Li,2021,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on temporal knowledge graph reasoning based on evolutional representation learning providing insights for knowledge graph development and data integration.,"This 2021 paper by Wei Li explores temporal knowledge graph reasoning based on evolutional representation learning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3404835.3462963,"data-integration, educational-technology, knowledge-graph, temporal-data",Temporal Knowledge Graph Reasoning Based on Evolutional Representation Learning,"Li Zixuan, Jin Xiaolong, Li Wei, Guan Saiping, Guo Jiafeng, Shen Huawei, Wang Yuanzhuo, Cheng Xueqi",2021,reference-manager,10.1145/3404835.3462963,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
li_2022,Microservice extraction based on knowledge graph from monolithic applications,"Zhiding Li, Chenqi Shang, Jianjie Wu, Yuan Li",2022,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on microservice extraction based on knowledge graph from monolithic applications providing insights for knowledge graph development and data integration.,"This 2022 paper by Zhiding Li, Chenqi Shang, Jianjie Wu, Yuan Li explores microservice extraction based on knowledge graph from monolithic applications. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,https://doi.org/10.1016/j.infsof.2022.106992,10.1016/j.infsof.2022.106992,"data-integration, knowledge-graph",Microservice extraction based on knowledge graph from monolithic applications,"Li Zhiding, Shang Chenqi, Wu Jianjie, Li Yuan",2022,reference-manager,10.1016/j.infsof.2022.106992,,"The paper introduces a knowledge-graph-based method for microservice extraction, using four entity types and relationships, and a constrained Louvain algorithm. It reduces reliance on human experience, improves team size reduction, cohesion, and coupling, but currently lacks field-level data splitting and comprehensive resource node extraction. Future work targets these limitations.",,,,"Automatic extraction of function nodes by analyzing control classes, identifying business logic and functional components.",,,"How can a knowledge-graph-based method, guided by the AKF principle and using a constrained Louvain algorithm, effectively support microservice extraction from monolithic applications while addressing key quality metrics such as cohesion, coupling, code redundancy, and team size reduction?","The paper aims to propose and evaluate a novel microservice extraction method for migrating monolithic applications. Using entity analysis and similarity calculations, the study focuses on cohesion, coupling, and hardware resource considerations. Results show improved microservice quality, performance, and logical business grouping. The approach enhances scalability and resource allocation.","The research goal is to improve microservice extraction from monolithic systems using a knowledge-graph-based approach that considers hardware resources; the method employs a constrained Louvain community detection algorithm, and results show superior performance in team size reduction, cohesion, coupling, and code redundancy compared to three typical methods.",,1.000,exact_title
li_2022a,"Toward the Tradeoffs between Privacy, Fairness and Utility in Federated Learning",Jianhua Li,2022,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on toward the tradeoffs between privacy, fairness and utility in federated learning providing insights for knowledge graph development and data integration.","This 2022 paper by Jianhua Li explores toward the tradeoffs between privacy, fairness and utility in federated learning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph",,,,,,,,,,,,,,,,,,,
li_2022b,Auditing Privacy Defenses in Federated Learning via Generative Gradient Leakage,"Zhuohang Li, Jiaxin Zhang, Luyang Liu, Jian Liu",2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Addresses rapid knowledge updates in computer domains; integrates theoretical and practical learning; uses SmartKG tool for knowledge storage and visualization.,Educational knowledge graph construction from multiple heterogeneous data sources for computer networking courses using keyword and relationship extraction techniques.,This paper constructs a knowledge graph for computer networking courses in secondary vocational schools by integrating multi-source heterogeneous data to address challenges in computer science education and bridge theoretical-practical knowledge gaps.,How can knowledge graphs constructed from multi-source heterogeneous data improve computer science education by integrating theoretical and practical knowledge?,"Used data acquisition from multiple heterogeneous sources, keyword extraction techniques, relationship extraction, and SmartKG tool for knowledge storage and visualization.",Provides new ideas for teaching computer courses and helps cultivate high-quality skilled talents by integrating theoretical and practical knowledge more effectively.,,Abstract only - detailed evaluation of educational effectiveness and scalability not available.,Demonstrates practical application of KG construction from heterogeneous data sources in educational domain.,,"Evaluate educational effectiveness, expand to other technical subjects, assess student learning outcomes.",Provides practical example of heterogeneous data integration for knowledge graph construction relevant to HDM system design.,https://ieeexplore.ieee.org/document/10086288/,10.1109/ITME56794.2022.00031,"educational-technology, heterogeneous-data, knowledge-graph-construction, smartkg",Auditing Privacy Defenses in Federated Learning via Generative Gradient Leakage,"Li Zhuohang, Zhang Jiaxin, Liu Luyang, Liu Jian",2022,reference-manager,,,,,,,"Differential Privacy (DP): A technique that adds random noise to gradients to limit privacy leakage, providing theoretical guarantees about information disclosure.",,,How can privacy-preserving defenses in federated learning effectively prevent data reconstruction attacks from degraded gradients while maintaining model utility?,"The paper investigates privacy preservation in federated learning, comparing cryptography-based and gradient-degradation-based methods. Using various defenses, it evaluates image reconstruction attacks and proposes new optimization strategies. Results show that current defenses, including Soteria, are insufficient, as high-quality image reconstruction from gradients remains possible, highlighting ongoing privacy risks.","The research goal is to achieve privacy preservation in federated learning; the key approach compares cryptography-based and gradient-degradation-based defenses, highlighting Soteria, which perturbs data representations; the principal finding is that while such defenses limit information leakage, they may reduce model utility and struggle with out-of-distribution data.",,1.000,exact_title
li_2023a,A Blockchain-Based Personal Health Knowledge Graph for Secure Integrated Health Data Management,"Juan Li, Vikram Pandey, Rasha Hendawi",2023,Yes,HIGH,"Abstract only - directly relevant to HDM healthcare applications by combining blockchain, PKGs, and health data management with focus on privacy and interoperability.","Addresses challenges in managing personal health data around interoperability, privacy, and security; blockchain enables patients to grant access to specific entities as needed.",Blockchain-based approach for integrating diverse health data types using knowledge,"This paper proposes a blockchain-based knowledge graph approach to integrate diverse health data types (EHR, sensing, insurance) while addressing challenges of data interoperability, privacy, and security with patient-controlled access.","How can blockchain and knowledge graphs address challenges in managing personal health data regarding interoperability, privacy, and security?",Proposed blockchain-based knowledge graph approach to integrate diverse health data types with patient-controlled access mechanisms.,"Blockchain enables patient-controlled access to specific entities, knowledge graphs structure and integrate different health data sources, addresses interoperability, privacy, and security challenges.",Blockchain-based framework for secure and interoperable personal health data management with patient-controlled access.,"Abstract only - implementation details, scalability analysis, and practical deployment considerations not available.",Demonstrates integration of blockchain and knowledge graphs for secure personal health data management with patient control.,Abstract only - technical implementation details and real-world deployment challenges not addressed.,"Implement prototype system, evaluate scalability and performance, explore integration with existing health information systems.",Provides architectural approach combining blockchain and PKGs for secure health data management that could inform HDM healthcare system design.,https://ieeexplore.ieee.org/document/10218032/,10.1109/ISCC58397.2023.10218032,"blockchain, health-data-management, interoperability, personal-health-knowledge-graphs, privacy",A Blockchain-Based Personal Health Knowledge Graph for Secure Integrated Health Data Management,"Li Juan, Pandey Vikram, Hendawi Rasha",2023,reference-manager,10.1109/iscc58397.2023.10218032,,"The implementation uses blockchain and personal health knowledge graphs to integrate data from EHRs, wearable devices, and apps, ensuring privacy, security, and interoperability. HL7 FHIR-based ontology is extended for standardization. Patients control data access. Evaluations show the system is secure, scalable, and effective for data sharing.",,,,"Data integration from multiple sources (EHRs, wearable devices, health apps) and mapping to an ontology for interoperability.",,,"How can a decentralized system integrating personal health knowledge graphs and blockchain technology address the scalability, privacy, and security challenges of managing and sharing personal health data in the healthcare domain?","The paper aims to develop a secure, scalable system for managing and sharing personal health data using knowledge graphs and blockchain technology. It constructs a personal health ontology and uses Ethereum-based smart contracts for access control. Results show effective, secure data integration and sharing, with enhanced privacy and security for patients.","The paper's main objective is to develop a blockchain-based personal health knowledge graph using a standardized ontology to integrate diverse personal health data; the key method combines knowledge graphs and blockchain for secure, interoperable data management, and the principal finding is enhanced privacy, security, and comprehensive health insights for patients.",,1.000,exact_title
li_2023b,"Knowledge Graphs in Practice: Characterizing their Users, Challenges, and Visualization Opportunities","Harry Li, Gabriel Appleby, Camelia Daniela Brumar, Remco Chang, Ashley Suh",2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,"Research on knowledge graphs in practice: characterizing their users, challenges, and visualization opportunities providing insights for knowledge graph development and data integration.","This 2023 paper by Harry Li, Gabriel Appleby, Camelia Daniela Brumar, Remco Chang, Ashley Suh explores knowledge graphs in practice: characterizing their users, challenges, and visualization opportunities. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1109/TVCG.2023.3326904,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
li_2024,Construction and Application Research of Intelligent Education Knowledge Graph Based on Multi-modal Learning,"Haiping Li, Wenjing Duan",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Achieves 87% knowledge graph construction accuracy and 27% learning efficiency improvement using deep learning algorithms for feature extraction and relationship modeling on multi-modal learning materials (text, images, videos) with 120 entities and 100 relationships",Multi-modal intelligent education knowledge graph construction approach that integrates diverse learning materials for personalized learning path recommendations,"This paper explores methods for constructing an intelligent education knowledge graph using multi-modal learning materials including text, images, and videos. The research uses deep learning algorithms for feature extraction and relationship modeling to construct a knowledge graph containing 120 entities and 100 relationships. The approach addresses personalized learning path recommendations while considering the \""uncanny valley\"" phenomenon to avoid user discomfort with AI interactions, demonstrating effectiveness in adapting to individual learning styles while maintaining positive user experience.",How can multi-modal learning materials be integrated into intelligent education knowledge graphs to provide effective personalized learning path recommendations while maintaining positive user experience?,Deep learning algorithms for multi-modal feature extraction and relationship modeling; knowledge graph construction with 120 entities and 100 relationships; personalized learning path recommendation system development; user experience optimization considering uncanny valley phenomenon,Knowledge graph construction accuracy of 87%; learning efficiency improvement of 27%; successful creation of multi-modal knowledge graph with 120 entities and 100 relationships; effective personalized learning path recommendations,,Limited scale evaluation with 120 entities and 100 relationships; specific focus on avoiding uncanny valley may limit AI interaction sophistication; computational requirements for multi-modal processing not fully characterized,Successfully demonstrates effective approach to creating intelligent education knowledge graphs that adapt to individual learning styles while maintaining positive user experience through multi-modal learning integration,,Scale evaluation to larger knowledge graphs and diverse educational domains; investigate advanced multi-modal integration techniques; develop adaptive user experience optimization for diverse learner populations,Provides practical framework for implementing multi-modal educational knowledge graphs with demonstrated performance improvements; shows effective integration of diverse learning materials for HDM educational applications,https://ieeexplore.ieee.org/document/10624590/,10.1109/IECA63684.2024.10624590,"educational-technology, intelligent-education, knowledge-graph-construction, multi-modal-learning, personalized-learning",Construction and Application Research of Intelligent Education Knowledge Graph Based on Multi-modal Learning,"Li Haiping, Duan Wenjing",2024,reference-manager,10.1109/ieca62822.2024.00029,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
li_2025,KnowCoder-V2: Deep Knowledge Analysis,"Zixuan Li, Wenxuan Liu, Long Bai, Chunmao Zhang, Wei Li, Fenghui Zhang, Quanxin Jin, Ruoyun He, Zhuo Chen, Zhilei Hu, Fei Wang, Bingbing Xu, Xuhui Jiang, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng",2025,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on knowcoder-v2: deep knowledge analysis providing insights for knowledge graph development and data integration.,"This 2025 paper by Zixuan Li, Wenxuan Liu, Long Bai, Chunmao Zhang, Wei Li, Fenghui Zhang, Quanxin Jin, Ruoyun He, Zhuo Chen, Zhilei Hu, Fei Wang, Bingbing Xu, Xuhui Jiang, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng explores knowcoder-v2: deep knowledge analysis. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.jbi.2012.04.008.,"data-integration, knowledge-graph",KnowCoder-V2: Deep Knowledge Analysis,"Li Zixuan, Liu Wenxuan, Bai Long, Zhang Chunmao, Li Wei, Zhang Fenghui, Jin Quanxin, He Ruoyun, Chen Zhuo, Hu Zhilei, Wang Fei, Xu Bingbing, Jiang Xuhui, Jin Xiaolong, Guo Jiafeng, Cheng Xueqi",2025,reference-manager,,,,,,,"Knowledge Organization Phase: Involves ontology expansion, knowledge extraction (using Information Extraction tasks like Named Entity Recognition, Relation Extraction, and Event Extraction), and continuous knowledge update from multiple documents.",,,"How can the Knowledgeable Deep Research (KDR) framework systematically extract, organize, and reason over large-scale, heterogeneous research data to enable deep knowledge analysis and generate comprehensive research reports?","The paper presents a framework for extracting, organizing, and reasoning over structured knowledge from unstructured documents using ontologies and Python classes. It decomposes research tasks into subtasks, applies information extraction methods, and uses reasoning to generate comprehensive reports. The approach yields deeper insights and improved analysis compared to existing frameworks.","The research goal was to analyze Geoffrey Hinton's papers from 2015–2024, using ontology-based methods to organize and summarize his evolving focus from foundational neural network techniques to hierarchical representations and biologically plausible, efficient, and interpretable learning models, concluding with a clear trend toward self-supervision and neuroscience-inspired approaches.",,1.000,exact_title
liang_2021,MULTIBENCH: Multiscale Benchmarks for Multimodal Representation Learning,"Paul Pu Liang, Yiwei Lyu, Xiang Fan, Zetian Wu, Yun Cheng, Jason Wu, Leslie Chen, Peter Wu, Michelle A. Lee, Yuke Zhu, Ruslan Salakhutdinov, Philippe Morency, Johns Hopkins",2021,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on multibench: multiscale benchmarks for multimodal representation learning providing insights for knowledge graph development and data integration.,"This 2021 paper by Paul Pu Liang, Yiwei Lyu, Xiang Fan, Zetian Wu, Yun Cheng, Jason Wu, Leslie Chen, Peter Wu, Michelle A. Lee, Yuke Zhu, Ruslan Salakhutdinov, Philippe Morency, Johns Hopkins explores multibench: multiscale benchmarks for multimodal representation learning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph",MULTIBENCH: Multiscale Benchmarks for Multimodal Representation Learning,"Liang Paul Pu, Lyu Yiwei, Fan Xiang, Wu Zetian, Cheng Yun, Wu Jason, Chen Leslie, Wu Peter, Lee Michelle A., Zhu Yuke, Salakhutdinov Ruslan, Morency Louis-Philippe",2021,reference-manager,,,,,,,"Temporal alignment (WORDALIGN): Aligns information from different modalities to the same time granularity, especially for time-series data involving text.",,,"How can MULTIBENCH serve as a unified, large-scale benchmark to comprehensively evaluate and accelerate the development of general-purpose multimodal machine learning models across domains, modalities, and tasks, considering generalization, complexity, and robustness to noisy or missing modalities?","The paper introduces MULTIBENCH, a large-scale benchmark designed to evaluate general-purpose multimodal models. Using 15 datasets across 10 modalities and 20 prediction tasks in 6 research areas, it assesses generalization, training/inference complexity, and robustness to noisy/missing data. MULTIBENCH aims to unify and advance multimodal learning research.","The research goal is to accelerate multimodal machine learning by introducing MULTIBENCH, a comprehensive benchmark; the approach involves evaluating diverse models across multiple modalities and tasks; results show simple fusion methods perform competitively, highlighting tradeoffs between performance and complexity.",,1.000,exact_title
liao_2023,GenTKG: Generative Forecasting on Temporal Knowledge Graph with Large Language Models,"Ruotong Liao, Xu Jia, Yangzhe Li, Yunpu Ma, Volker Tresp, Donald Trump, Joe Biden",2023,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on gentkg: generative forecasting on temporal knowledge graph with large language models providing insights for knowledge graph development and data integration.,"This 2023 paper by Ruotong Liao, Xu Jia, Yangzhe Li, Yunpu Ma, Volker Tresp, Donald Trump, Joe Biden explores gentkg: generative forecasting on temporal knowledge graph with large language models. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.18653/v1/2023.nlrse-1.7,"data-integration, knowledge-graph, temporal-data",GenTKG: Generative Forecasting on Temporal Knowledge Graph with Large Language Models,"Liao Ruotong, Jia Xu, Li Yangzhe, Ma Yunpu, Tresp Volker",2024,reference-manager,,,"GenTKG integrates temporal logical rule-based retrieval (TLR) and few-shot instruction tuning (FIT), both boosting performance. Index prompts outperform lexical ones, easing data leakage concerns. GenTKG remains strong even with minimal training data and few-shot samples, showing robust generalizability and efficient alignment for temporal relational forecasting with large language models.",,,,Cross-domain generalizability experiments: 16 cross-checking experiments were conducted to evaluate model performance across different datasets.,,,"How can the GenTKG framework align large language models with generative temporal knowledge graph forecasting, and how does its performance, generalizability, and component effectiveness compare to existing embedding-based, rule-based, and LLM-based methods?","The paper introduces GenTKG, a framework aligning large language models (LLMs) with generative forecasting on temporal knowledge graphs (tKGs). Using few-shot, parameter-efficient instruction tuning, GenTKG achieves superior temporal link prediction (Hits@1/3/10) across four benchmark datasets, outperforming conventional methods. GenTKG generalizes well and reduces training needs.","The research goal is to improve temporal knowledge graph forecasting; the approach uses a retrieval-augmented large language model (GenTKG) with temporal logical rule-based retrieval and parameter-efficient instruction tuning; results show GenTKG achieves state-of-the-art performance, surpassing embedding-based, rule-based, and LLM-based methods on key benchmarks.","Temporal knowledge graphs, generative forecasting, recommendation systems, anomaly detection, knowledge graph reasoning, large language models, embedding-based models, rule-based methods, zero-shot learning, few-shot inductive learning, entity alignment, in-context learning, open-source datasets, data protection, generalizability.",1.000,exact_title
lim_2010,Key Management for Large-Scale Distributed Storage Systems,Hoon Wei Lim,2010,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on key management for large-scale distributed storage systems providing insights for knowledge graph development and data integration.,"This 2010 paper by Hoon Wei Lim explores key management for large-scale distributed storage systems. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
lin_2022,Knowledge Management System with NLP-Assisted Annotations: A Brief Survey and Outlook,Baihan Lin,2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on knowledge management system with nlp-assisted annotations: a brief survey and outlook providing insights for knowledge graph development and data integration.,"This 2022 paper by Baihan Lin explores knowledge management system with nlp-assisted annotations: a brief survey and outlook. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
lin_2024a,Human Digital Twin: A Survey,"Yujia Lin, Liming Chen, Aftab Ali, Christopher Nugent, Cleland Ian, Rongyang Li, Dazhi Gao, Hang Wang, Yajie Wang, Huansheng Ning",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on human digital twin: a survey providing insights for knowledge graph development and data integration.,"This 2024 paper by Yujia Lin, Liming Chen, Aftab Ali, Christopher Nugent, Cleland Ian, Rongyang Li, Dazhi Gao, Hang Wang, Yajie Wang, Huansheng Ning explores human digital twin: a survey. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Human Digital Twin: A Survey,"Lin Yujia, Chen Liming, Ali Aftab, Nugent Christopher, Cleland Ian, Li Rongyang, Gao Dazhi, Wang Hang, Wang Yajie, Ning Huansheng",2021,reference-manager,,,"The paper reviews Human Digital Twin (HDT) technologies, their architectures, and applications in healthcare, daily life, and industry. It highlights advances in sensing, modeling, and behavior representation, but notes the lack of a universal HDT modeling approach. Future research should focus on generic, adaptable HDT models.",,,,"Comprehensive literature review: Analyzed the state-of-the-art of HDT, underpinning technologies, and established typical frameworks for core HDT functions or components.",,,"What are the current state-of-the-art technologies, frameworks, applications, and future challenges in the development and implementation of human digital twin (HDT) systems?","This paper reviews the state-of-the-art in human digital twin (HDT) technologies, proposes a comprehensive HDT framework using multi-modal and multi-source data, and discusses future trends and challenges. Methodology includes literature review and framework proposal. Key findings highlight HDT applications and open issues; the study concludes HDT is a promising research area.","The research goal is to review and analyze the state-of-the-art in human digital twin (HDT) technologies, propose a comprehensive HDT framework using multi-modal and multi-source data, and identify future trends and challenges; the principal finding is that HDT is promising but generic modeling approaches remain an open issue.","“Human Digital Twin”, “patient Digital Twin”, “Digital Twin for mental”, “Digital Twin in human”, “digital athlete”, “digital twin for employees”, “digital twin as human representation”",1.000,exact_title
lin_2024b,LinkGuard: Link Locally Privacy-Preserving Graph Neural Networks with Integrated Denoising and Private Learning,Xi Lin,2024,Yes,HIGH,"Addresses critical privacy challenges in graph neural networks with focus on link protection using Local Differential Privacy, highly relevant to HDM systems requiring privacy-preserving graph processing and personal network analysis.","Solves under-denoising problem in noisy topology through dynamic adaptive Link LDP framework that integrates denoising and private learning, achieving 7% performance improvement under strong privacy strength.",Dynamic privacy-preserving framework for graph neural networks that protects,"This paper presents LinkGuard, a dynamic adaptive Link Local Differential Privacy (LDP) framework for graph neural networks that addresses the under-denoising problem in privacy-preserving graph learning. The approach integrates noisy topology denoising and GNN private learning into a unified framework, performing denoising dynamically on the server side to mitigate the impact of local noise on training processes. The method focuses on protecting sensitive link information in decentralized settings while maintaining better privacy-utility trade-offs.",How can graph neural networks effectively protect sensitive link information using Local Differential Privacy while maintaining model performance through integrated denoising and private learning?,"Dynamic adaptive Link LDP framework, unified noise generation and private training processes, server-side dynamic denoising, experimental evaluation on graph learning tasks with privacy strength analysis.","Achieved around 7% performance improvement under strong privacy strength, demonstrated better trade-off between utility and privacy, solved under-denoising problem in noisy graph topology, integrated approach reduces uncertainty from local noise.",Dynamic privacy-preserving framework that unifies denoising and private learning for graph neural networks with improved privacy-utility balance.,"Challenges in balancing privacy and utility in decentralized node environments, computational overhead from dynamic denoising processes, limited details on scalability with large-scale graphs.",Successfully demonstrates that dynamic integration of denoising and private learning can significantly improve privacy-preserving graph neural network performance while maintaining strong privacy guarantees.,"Need for evaluation on larger-scale graphs, broader assessment of different graph learning tasks, investigation of adaptive privacy parameter selection mechanisms.","Extend framework to larger graph datasets, evaluate on diverse graph learning applications, develop adaptive privacy budget allocation strategies, investigate integration with federated graph learning.","Provides practical approach for implementing privacy-preserving graph processing in HDM systems, particularly relevant for personal network analysis and sensitive relationship protection in personal knowledge graphs.",https://dl.acm.org/doi/10.1145/3589335.3651533,10.1145/3589335.3651533,"denoising, graph-neural-networks, hdm-privacy, link-protection, local-differential-privacy, privacy-preserving-learning",LinkGuard: Link Locally Privacy-Preserving Graph Neural Networks with Integrated Denoising and Private Learning,"Qi Yuxin, Lin Xi, Liu Ziyao, Li Gaolei, Wang Jingyu, Li Jianhua",2024,reference-manager,10.1145/3589335.3651533,,"The implementation integrates denoising directly into GNN learning under link LDP, dynamically adjusting edge weights using node similarity (cosine similarity) and noisy embeddings. This unified approach consistently improves accuracy across various models and privacy budgets, outperforming previous methods and enhancing the privacy-utility trade-off.",,,,"Topology denoising during GNN training: A dynamic, training-adaptive denoising method is applied on the server side to improve privacy and utility.",,,How can an integrated denoising and private learning framework improve the balance between privacy and utility in graph neural networks under link-level local differential privacy guarantees?,"The paper addresses under-denoising in Link LDP GNNs by integrating permuted topology denoising with GNN private learning. Using Cora and Citeseer datasets, the proposed dynamic denoising framework consistently improves accuracy across various GNNs and privacy levels, achieving a better balance between privacy and utility than existing methods.","The research goal is to improve the utility-privacy trade-off in Link LDP GNNs by dynamically integrating topology denoising with private learning; the approach adaptively combines denoising and GNN training, and results show consistent accuracy improvements across datasets and backbones, demonstrating better privacy and utility balance.","Privacy-Preserving, Differential Privacy, Graph Neural Network",1.000,exact_title
liu_2020,Web of Scholars: A Scholar Knowledge Graph,"Jiaying Liu, Ivan Lee",2020,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on web of scholars: a scholar knowledge graph providing insights for knowledge graph development and data integration.,"This 2020 paper by Jiaying Liu, Ivan Lee explores web of scholars: a scholar knowledge graph. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3397271.3401405,"data-integration, knowledge-graph",Web of Scholars: A Scholar Knowledge Graph,"Liu Jiaying, Ren Jing, Zheng Wenqing, Chi Lianhua, Lee Ivan, Xia Feng",2020,reference-manager,10.1145/3397271.3401405,,,,,,"Construction and use of a knowledge graph to extract, integrate, and profile explicit and implicit scholar relationships.",,,"How can a knowledge graph-based system be designed to efficiently extract, integrate, and analyze both explicit and implicit relationships among scholars to enable comprehensive scholar profiling, relationship mining, and personalized academic services in large-scale academic networks?","The paper presents Web of Scholars, a knowledge graph-based system designed to extract, integrate, and profile both explicit and implicit relationships among scholars. Using data mining and visualization techniques on Microsoft Academic Graph data, it enables intelligent search, scholar ranking, and relationship analysis, supporting personalized academic services and open API access.","The research goal is to efficiently mine and visualize implicit scholar relationships; the approach uses a knowledge graph-based system called Web of Scholars, integrating data mining and visualization techniques; results show comprehensive profiling and interactive analysis of over 1.7 million researchers and their relationships in Computer Science.",,1.000,exact_title
liu_2021,A Study on Temporal Knowledge Graph Enrichment,"Yu Liu, Wen Hua, Xiaofang Zhou",2021,Yes,SUPER,"This paper directly addresses core aspects of heterogeneous data integration in knowledge graphs, providing critical insights for PKG architectures and temporal data management strategies that align perfectly with our research objectives.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on a study on temporal knowledge graph enrichment providing insights for knowledge graph development and data integration.,"This 2021 paper by Yu Liu, Wen Hua, Xiaofang Zhou explores a study on temporal knowledge graph enrichment. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1007/978-3-030-12079-5_2,"data-integration, knowledge-graph, temporal-data",,,,,,,,,,,,,,,,,,,
liu_2022,Developing Knowledge Graph Based System for Urban Computing,"Yu Liu, Jingtao Ding, Yong Li",2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on developing knowledge graph based system for urban computing providing insights for knowledge graph development and data integration.,"This 2022 paper by Yu Liu, Jingtao Ding, Yong Li explores developing knowledge graph based system for urban computing. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3557990.3567586,"data-integration, knowledge-graph",Developing knowledge graph based system for urban computing,"Liu Yu, Ding Jingtao, Li Yong",2022,reference-manager,10.1145/3557990.3567586,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
liu_2024a,Personalized and Privacy-Preserving Federated Graph Neural Network,"Yanjun Liu, Hongwei Li, Meng Hao",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on personalized and privacy-preserving federated graph neural network providing insights for knowledge graph development and data integration.,"This 2024 paper by Yanjun Liu, Hongwei Li, Meng Hao explores personalized and privacy-preserving federated graph neural network. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3389/fphy.2024.1383276,"data-integration, knowledge-graph, personal-knowledge",Personalized and privacy-preserving federated graph neural network,"Liu Yanjun, Li Hongwei, Hao Meng",2024,reference-manager,10.3389/fphy.2024.1383276,,,,,,"Node classification tasks were performed on three graph-structured datasets (Cora, Pubmed, Citeseer) to evaluate model accuracy.",,,"How can a personalized federated graph neural network framework effectively address graph data heterogeneity and privacy challenges by leveraging graph similarity estimation, attention-based model aggregation, and function encryption techniques?","The paper aims to address data heterogeneity and privacy issues in federated graph neural networks. It proposes an attention aggregation-based function encryption algorithm (PFGNN), evaluated on Cora, Pubmed, and Citeseer datasets. PFGNN outperforms traditional methods in accuracy and provides strong privacy guarantees through function-hiding MIFE encryption.","The research goal is to improve federated graph neural network performance; the approach uses a function encryption optimization algorithm with attentive aggregation (PFGNN); results show PFGNN achieves higher accuracy and efficiency than traditional methods, with a 5.4% average accuracy improvement over FedAvg in node classification tasks.",No information available,1.000,exact_title
liu_2024b,Deep Learning Methods for Biomedical Data Integration,"Ting Liu, K. Anton Feenstra, Zhisheng Huang, Jaap Heringa",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Biomedical data integration faces challenges from data heterogeneity, missing values, and high dimensionality; deep learning offers powerful approaches for feature learning and data fusion.",Deep learning approaches for integrating diverse biomedical data types to improve analysis and prediction tasks.,"This paper explores deep learning methods for biomedical data integration, addressing challenges in combining heterogeneous biomedical data sources for improved analysis and clinical applications.",How can deep learning methods effectively integrate heterogeneous biomedical data to improve analysis and clinical predictions?,Deep learning architectures for multi-modal data fusion; handling missing data and heterogeneity; evaluation on biomedical prediction tasks.,Demonstrates effective deep learning approaches for biomedical data integration; improves prediction accuracy; handles data heterogeneity effectively.,,Computational requirements for deep learning; need for large training datasets; interpretability challenges.,Provides state-of-the-art approaches for biomedical data integration using deep learning applicable to HDM systems.,,Develop interpretable deep learning models; clinical trial validation; integrate with existing healthcare systems.,Offers technical framework for implementing deep learning-based biomedical data integration in HDM healthcare applications.,https://academic.oup.com/bioinformatics/article/doi/10.1093/bioinformatics/btad771/7499340,10.1093/bioinformatics/btad771,"biomedical-data-integration, deep-learning, healthcare-ai, multi-modal-fusion",,,,,,,,,,,,,,,,,,,
liu_2025,A Temporal Knowledge Graph Reasoning Model Based on Recurrent Encoding and Contrastive Learning,"Weitong Liu, Khairunnisa Hasikin, Anis Salwa Mohd Khairuddin, Meizhen Liu, Xuechen Zhao",2025,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on a temporal knowledge graph reasoning model based on recurrent encoding and contrastive learning providing insights for knowledge graph development and data integration.,"This 2025 paper by Weitong Liu, Khairunnisa Hasikin, Anis Salwa Mohd Khairuddin, Meizhen Liu, Xuechen Zhao explores a temporal knowledge graph reasoning model based on recurrent encoding and contrastive learning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.7717/peerj-cs.2595,"data-integration, educational-technology, knowledge-graph, temporal-data",A temporal knowledge graph reasoning model based on recurrent encoding and contrastive learning,"Liu Weitong, Hasikin Khairunnisa, Khairuddin Anis Salwa Mohd, Liu Meizhen, Zhao Xuechen",2025,reference-manager,10.7717/peerj-cs.2595,,,,,,"Used time-aware filtering setting for temporal knowledge graph reasoning, separating quadruples by query time.",,,How can a Temporal Reasoning with Recurrent Encoding and Contrastive Learning (TRCL) model effectively capture the dynamic relationships among historical facts and address the positive and negative influences of repeated historical facts to improve extrapolation reasoning in temporal knowledge graphs?,"The paper proposes TRCL, a new temporal knowledge graph (TKG) reasoning model focused on extrapolation reasoning. Using a recurrent encoder, global historical matrix, and contrastive learning, TRCL improves entity prediction. Experiments on four datasets show TRCL outperforms existing methods. Optimal performance occurs with α = 0.3 and learning rate 0.001.","The research goal is to improve temporal knowledge graph (TKG) extrapolation reasoning; the key method is the proposed TRCL model combining sequential information, a history matrix, contrastive learning, and a time decoder; results show TRCL is effective but needs better data efficiency for complex datasets like ICEWS05-15.",,1.000,exact_title
liyitong_2024,A Unified Temporal Knowledge Graph Reasoning Model Towards Interpolation and Extrapolation,nudt.edu.cn liyitong,2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Proposes Temporal PAth-based Reasoning (TPAR) model that performs neural-driven symbolic reasoning robust to ambiguous and noisy temporal data while providing fine interpretability, outperforming SOTA methods in link prediction for both interpolation and extrapolation settings.",Novel unified approach to temporal knowledge graph reasoning that handles both interpolation (historical analysis) and extrapolation (future prediction) through neural-driven symbolic reasoning with enhanced robustness and interpretability.,"This paper addresses limitations in existing temporal knowledge graph (TKG) reasoning methods that are designed specifically for either interpolation or extrapolation reasoning but not both. The proposed Temporal PAth-based Reasoning (TPAR) model provides a unified approach that performs neural-driven symbolic reasoning, designed to be robust to ambiguous and noisy temporal data while maintaining fine interpretability. The approach addresses temporal correlations and chronological knowledge that existing methods have de-emphasized or ignored.",How can we develop a unified reasoning model that effectively handles both interpolation and extrapolation in temporal knowledge graphs while maintaining robustness to noisy data and providing interpretable results?,"Developed Temporal PAth-based Reasoning (TPAR) model using neural-driven symbolic reasoning approach, designed for robustness to ambiguous and noisy temporal data, implemented pipeline experimental setting for unified evaluation, comprehensive experiments on link prediction tasks.","TPAR outperformed state-of-the-art methods in link prediction tasks for both interpolation and extrapolation settings, demonstrated effective integration of temporal reasoning capabilities, showed robustness to noisy temporal data with enhanced interpretability.",,"Previous methods de-emphasized temporal correlations, existing approaches ignored inferring clues from missing past facts, limited handling of temporal data complexity in unified frameworks.",The TPAR model provides a unified approach to temporal knowledge graph reasoning that successfully addresses previous methodological constraints while maintaining robustness and interpretability for practical applications.,,"Further refinement of TPAR model capabilities, exploration of more diverse temporal reasoning scenarios, integration with real-world temporal knowledge systems.",Provides architectural framework for implementing temporal reasoning capabilities in HDM systems with focus on unified interpolation/extrapolation and robust handling of noisy temporal data.,https://arxiv.org/abs/2405.18106,10.48550/arXiv.2405.18106,"interpolation-extrapolation, neural-symbolic-reasoning, temporal-knowledge-graph, temporal-modeling, unified-reasoning",A Unified Temporal Knowledge Graph Reasoning Model Towards Interpolation and Extrapolation,"Chen Kai, Wang Ye, Li Yitong, Li Aiping, Yu Han, Song Xin",2024,reference-manager,,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
llms_2024,LLM4EduKG: LLM for Automatic Construction of Educational Knowledge Graph,"means of the context understanding ability of LLMs, extracting EduTriples with the help of Prompt Tuning represents not only an important attempt for semi-automatic knowledge graph to highly automatic construction of EduKGs, but also offers a more user-oriented approach to addressing the challenges faced by traditional methods. It also greatly alleviates the cross-sentence problem commonly encountered in information extraction tasks.",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Proposes LLM-based automatic construction method with structured prompt framework to automatically extract and evaluate educational triples, addressing traditional labor-intensive and time-consuming knowledge graph construction challenges",Novel LLM-based framework for automatic educational knowledge graph construction that reduces manual effort and computational resource requirements,"This paper addresses challenges in constructing educational knowledge graphs that are traditionally labor-intensive, time-consuming, and require substantial computational resources. The research proposes an LLM-based automatic construction method with a structured prompt framework to automatically extract and evaluate educational triples. The approach focuses on improving transferability across different tasks and models with experimental validation using two Chinese datasets and four advanced LLMs, representing a significant attempt to leverage LLM capabilities for educational knowledge representation and transformation.",How can large language models be effectively utilized to automatically construct educational knowledge graphs while reducing manual effort and computational resource requirements?,LLM-based automatic construction methodology; structured prompt framework for educational triple extraction and evaluation; experimental validation using two Chinese datasets and four advanced LLMs; transferability assessment across different tasks and models,Demonstrated effectiveness of LLM-based knowledge graph construction; successful reduction of manual effort in knowledge graph creation; validated approach across multiple LLMs and Chinese-language datasets; improved transferability across different educational tasks,,Resource constraints in traditional knowledge graph construction; limited evaluation to Chinese-language datasets; need for broader validation across diverse educational domains and languages,Represents significant advancement in leveraging LLM capabilities for educational knowledge graph construction with potential to transform educational knowledge representation,,Expand evaluation to multilingual educational datasets; optimize computational efficiency for real-time knowledge graph construction; investigate integration with existing educational platforms and systems,Provides practical framework for implementing automated educational knowledge graph construction using LLMs; demonstrates significant potential for reducing manual effort in knowledge representation for HDM educational applications,https://ieeexplore.ieee.org/document/10679814/,10.1109/NaNA63151.2024.00028,"automatic-construction, educational-knowledge-graphs, educational-technology, knowledge-extraction, llm",LLM4EduKG: LLM for Automatic Construction of Educational Knowledge Graph,"Sun Jianing, Zhang Zhichao, He Xueli",2024,reference-manager,10.1109/nana63151.2024.00051,,"Implementation Insights focus on maximizing precision in EduTriples extraction, prioritizing correctness over recall. Few-shot and chain of thought (CoT) techniques significantly improve performance. ERNIE and GLM4 achieve the highest precision (>90%). Fine-tuning boosts precision by ~20% and F1 by ~15%, but base models still lag behind.",,,,Structured prompt framework: Guided Large Language Models (LLMs) to extract and evaluate educational triples from text.,,,How can structured prompt frameworks be used to automatically extract and evaluate educational triples from unstructured educational text data to construct high-quality educational knowledge graphs (EduKGs)?,"The paper aims to automate the construction of educational knowledge graphs (EduKGs) using Large Language Models (LLMs) with a structured prompt framework. Experiments on four models and various techniques showed high precision, especially for GLM4 and ERNIE. The method is effective, enabling richer knowledge systems and potential for personalized education.","The research goal is to automatically construct educational knowledge graphs using a structured prompt framework with Large Language Models; the approach involves extracting and evaluating educational triples from text, and results show high precision (up to 95.48%) and effectiveness, especially with GLM4 and ERNIE models.",,1.000,exact_title
longo_2019,Ubiquitous Knowledge empowers the Smart Factory: the impacts of a Service-oriented Digital Twin on enterprises' performance,"Longo, F., Nicoletti, L., Padovano, A.",2019,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on ubiquitous knowledge empowers the smart factory: the impacts of a service-oriented digital twin on enterprises' performance providing insights for knowledge graph development and data integration.,"This 2019 paper by Longo, F., Nicoletti, L., Padovano, A. explores ubiquitous knowledge empowers the smart factory: the impacts of a service-oriented digital twin on enterprises' performance. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.arcontrol.2019.01.001.,"data-integration, knowledge-graph",Ubiquitous knowledge empowers the Smart Factory: The impacts of a Service-oriented Digital Twin on enterprises' performance,"Longo F., Nicoletti L., Padovano A.",2019,reference-manager,10.1016/j.arcontrol.2019.01.001,,"The implementation required strong collaboration and structured knowledge. A Service-oriented Digital Twin prototype was deployed in two enterprises, leading to significant reductions in setup and cycle times (e.g., 28.62% decrease in setup time, 44.5% in the first step). Fisher’s LSD test confirmed statistical significance. Human-centric knowledge delivery was key.",,,,"Deployment of an application prototype in two industrial manufacturing case studies (one large, one small enterprise) to evaluate the hypothesis.",,,"How can a human-centric manufacturing paradigm, enabled by a Service-oriented Digital Twin delivering ubiquitous knowledge to manufacturing employees, be integrated within Industry 4.0 to improve production and business performance in smart factories?","The paper aims to shift Industry 4.0 from a technology-focused to a human-centric paradigm by introducing the Industrial Internet pyramid and a Service-oriented Digital Twin. Using two test-beds, the study shows that delivering ubiquitous manufacturing knowledge to employees improves time, costs, and process quality, validating this approach.","The paper's main objective is to propose a human-centric Smart Factory model using a Service-oriented Digital Twin; the key method is developing and testing a prototype leveraging augmented reality and vocal interaction, and the principal finding is significant improvements in time, costs, and process quality for enterprises.",Industry 4.0; Human-centric Industrial Internet; Smart Factory; Ubiquitous Knowledge; Service-oriented Digital Twin,1.000,exact_title
lu_2024,A Survey on Benchmarks of Multimodal Large Language Models,"Weiheng Lu, Hao Fei, Meng Luo, Ming Dai, Min Xia, Yizhang Jin, Zhenye Gan, Ding Qi, Chaoyou Fu, Ying Tai, Wankou Yang, Yabiao Wang, Chengjie Wang",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a survey on benchmarks of multimodal large language models providing insights for knowledge graph development and data integration.,"This 2024 paper by Weiheng Lu, Hao Fei, Meng Luo, Ming Dai, Min Xia, Yizhang Jin, Zhenye Gan, Ding Qi, Chaoyou Fu, Ying Tai, Wankou Yang, Yabiao Wang, Chengjie Wang explores a survey on benchmarks of multimodal large language models. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
luo_2024,Chain of History: Learning and Forecasting with LLMs for Temporal Knowledge Graph Completion,"Ruilin Luo, Tianle Gu, Haoling Li, Junzhe Li, Zicheng Lin, Jiayi Li, Yujiu Yang",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on chain of history: learning and forecasting with llms for temporal knowledge graph completion providing insights for knowledge graph development and data integration.,"This 2024 paper by Ruilin Luo, Tianle Gu, Haoling Li, Junzhe Li, Zicheng Lin, Jiayi Li, Yujiu Yang explores chain of history: learning and forecasting with llms for temporal knowledge graph completion. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.48550/ARXIV.2309.16609,"data-integration, educational-technology, knowledge-graph, temporal-data",Chain of History: Learning and Forecasting with LLMs for Temporal Knowledge Graph Completion,"Luo Ruilin, Gu Tianle, Li Haoling, Li Junzhe, Lin Zicheng, Li Jiayi, Yang Yujiu",2024,reference-manager,,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
lyu_2021,Privacy-preserving Federated Learning Based on Multi-Key Homomorphic Encryption,"Xixiang Lyu, Jing Ma, Si-Ahmed Naas, Stephan Sigg",2021,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on privacy-preserving federated learning based on multi-key homomorphic encryption providing insights for knowledge graph development and data integration.,"This 2021 paper by Xixiang Lyu, Jing Ma, Si-Ahmed Naas, Stephan Sigg explores privacy-preserving federated learning based on multi-key homomorphic encryption. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph",,,,,,,,,,,,,,,,,,,
m_2024,Privacy-preserving in Blockchain-based Federated Learning Systems,"Sameera K. M., Marco Arazzi, Serena Nicolazzo, Antonino Nocera, Rafidha Rehiman K. A., Vinod P., Mauro Conti",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Investigates how PKGs can support personalized nutrition recommendations by integrating individual health data, dietary preferences, and nutritional knowledge to enable precision nutrition approaches tailored to individual needs and health conditions",Cross-disciplinary application of personal knowledge graphs to precision nutrition for personalized health and dietary recommendations,"This paper explores how Personal Knowledge Graphs can contribute to precision nutrition by integrating individual health data, dietary preferences, genomic information, and nutritional knowledge to create personalized nutrition recommendations. The research investigates the potential of PKGs to support precision nutrition approaches that are tailored to individual needs, health conditions, and personal circumstances, addressing the growing demand for personalized healthcare and nutrition solutions that go beyond one-size-fits-all dietary guidelines.",How can personal knowledge graphs be leveraged to support precision nutrition by integrating diverse health and dietary data for personalized nutrition recommendations?,"Cross-disciplinary analysis of PKG applications in precision nutrition; integration framework for health data, dietary preferences, and nutritional knowledge; personalized recommendation system development for nutrition applications",Demonstrated potential of PKGs for precision nutrition applications; successful integration of diverse health and dietary data types; framework for personalized nutrition recommendations based on individual characteristics and preferences,,Limited empirical evaluation of precision nutrition outcomes; challenges in integrating diverse health data sources; privacy and security considerations for sensitive health information not fully addressed,Successfully demonstrates potential of PKGs for advancing precision nutrition through personalized data integration and recommendation systems,,Conduct empirical evaluation of nutrition outcomes; develop privacy-preserving health data integration methods; expand integration to include more diverse health data sources and nutritional factors,Provides practical framework for implementing personalized nutrition systems using PKGs; addresses growing demand for individualized healthcare solutions; demonstrates cross-disciplinary application of knowledge graph technology for health applications,https://link.springer.com/chapter/10.1007/978-3-031-75702-0_6,10.1007/978-3-031-75702-0_6,"dietary-recommendations, healthcare-applications, personal-knowledge-graph, personalized-health, precision-nutrition",PRIVACY-PRESERVING IN BLOCKCHAIN-BASED FEDERATED LEARNING SYSTEMS,"Nicolazzo Serena, M. Sameera K., Arazzi Marco, Nocera Antonino, A. Rafidha Rehiman K., P. Vinod, Conti Mauro",2024,reference-manager,,,"The paper surveys Blockchain-enabled Federated Learning (FL), focusing on privacy-preserving solutions across industries like healthcare, Industry 5.0, and the Internet of Vehicles. It highlights privacy threats, state-of-the-art defenses, and open research challenges, offering a systematic categorization and suggesting promising future research directions in privacy and security.",,,,"Systematic literature review: Used a structured process (PRISMA flow diagram) to identify, screen, and select 102 relevant papers from databases between 2018 and 2023.",,,"What are the primary privacy challenges, threats, and solutions in Blockchain-enabled Federated Learning systems, and how can privacy-preserving mechanisms be effectively integrated and applied across various domains to address open issues and guide future research?","This paper systematically reviews privacy-preserving methods in Blockchain-enabled Federated Learning (BCFL). Using a structured search and selection process, it analyzes privacy threats, mitigation strategies, and application scenarios. Key findings highlight open challenges and future research directions, emphasizing the importance of robust privacy solutions in BCFL systems.","The paper’s main objective is to systematically review privacy-preserving methods in Blockchain-enabled Federated Learning (BCFL), using a structured literature analysis approach, and its principal finding is the identification of key privacy threats, mitigation strategies, and open research challenges in BCFL systems.","Keywords or tags for this research include: Blockchain, Federated Learning, privacy, privacy-preserving, privacy attack, inference attack, homomorphic encryption, differential privacy, secure multiparty computation, privacy-preserving in healthcare, internet of things.",1.000,exact_title
ma_2017,Integrate Any Omics: Towards genome-wide data integration for patient stratification,Shihao Ma,2017,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on integrate any omics: towards genome-wide data integration for patient stratification providing insights for knowledge graph development and data integration.,"This 2017 paper by Shihao Ma explores integrate any omics: towards genome-wide data integration for patient stratification. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Integrate Any Omics: Towards genome-wide data integration for patient stratification,"Ma Shihao, Zeng Andy G.X., Haibe-Kains Benjamin, Goldenberg Anna, Dick John E., Wang Bo",2024,reference-manager,,,,,,"Most methods require complete data across samples, which is often not available due to experimental or financial constraints.",,,,"How can IntegrAO, an integrative framework, effectively address the challenges of incomplete and heterogeneous multi-omics data to improve patient stratification and facilitate the practical application of precision medicine in clinical settings?",,"The research goal is to address challenges in multi-omics analysis; the approach is IntegrAO, an integrative framework for handling incomplete, heterogeneous data; the principal finding is that IntegrAO identifies distinct subtypes and regulatory patterns, enhancing survival prediction in patient cohorts.",No information available,1.000,exact_title
maack_2025,The order of multisensory associative sequences is reinstated as context feature during successful recognition,"Marike Christiane Maack, Jan Ostrowski, Michael Rose",2025,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on the order of multisensory associative sequences is reinstated as context feature during successful recognition providing insights for knowledge graph development and data integration.,"This 2025 paper by Marike Christiane Maack, Jan Ostrowski, Michael Rose explores the order of multisensory associative sequences is reinstated as context feature during successful recognition. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.7554/eLife.91033.1,"data-integration, knowledge-graph",The order of multisensory associative sequences is reinstated as context feature during successful recognition,"Maack Marike Christiane, Ostrowski Jan, Rose Michael",2025,reference-manager,,"The study reveals that the brain actively integrates temporal and sensory information during multisensory memory formation, with modality sequence serving as a key contextual feature.",,,,,,,The raw EEG and behavioral data are available at https://www.fdr.uni-hamburg.de/record/17120. There is no mention of source code availability.,,,"The research goal was to investigate neural mechanisms of multisensory memory retrieval using an explicit learning paradigm; the approach involved behavioral and EEG measures with modality sequence as a context feature, and the principal finding is that encoding modality sequence directly affects memory retrieval, cognitive control, and learning processes.",,1.000,exact_title
mahmud_2025,Digital twins as global learning health and disease models for preventive and personalized medicine,Firoj Mahmud,2025,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on digital twins as global learning health and disease models for preventive and personalized medicine providing insights for knowledge graph development and data integration.,"This 2025 paper by Firoj Mahmud explores digital twins as global learning health and disease models for preventive and personalized medicine. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, healthcare, knowledge-graph, personal-knowledge",Digital twins as global learning health and disease models for preventive and personalized medicine,"Li Xinxiu, Loscalzo Joseph, Mahmud A. K. M. Firoj, Aly Dina Mansour, Rzhetsky Andrey, Zitnik Marinka, Benson Mikael",2025,reference-manager,10.1186/s13073-025-01435-7,,,,,,Analysis of longitudinal electronic medical records and biobank data to identify disease evolution and initiating mechanisms.,,,"How can digital twins be developed and implemented to address the dynamic, multi-scale characterization of health and disease, while overcoming social, psychological, organizational, ethical, regulatory, and financial challenges to advance predictive, preventive, and personalized medicine?","The paper examines how integrating genetic, environmental, and multi-omics data—especially through digital twins (DTs) and explainable AI—can improve disease prediction, prevention, and personalized treatment. It highlights methodological advances, key challenges (e.g., explainability, ethics, privacy), and calls for cross-sector collaboration to realize DTs’ healthcare potential.","The paper’s main objective is to accelerate scientific discovery and revolutionize health care using digital twins by advancing mathematical, statistical, and computational foundations; its key method is integrating explainability techniques like attribution maps; the principal finding highlights the need for cross-sector harmonization and solutions for transparency, ethics, and privacy.",,1.000,exact_title
majerus_2009,Working memory capacity for continuous events: The root of temporal compression in episodic memory?,"Steve Majerus, Arnaud D'Argembeau",2009,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on working memory capacity for continuous events: the root of temporal compression in episodic memory? providing insights for knowledge graph development and data integration.,"This 2009 paper by Steve Majerus, Arnaud D'Argembeau explores working memory capacity for continuous events: the root of temporal compression in episodic memory?. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.cognition.2024.105789,"data-integration, knowledge-graph, temporal-data",Working memory capacity for continuous events: The root of temporal compression in episodic memory?,"Leroy Nathan, Majerus Steve, D'Argembeau Arnaud",2024,reference-manager,10.1016/j.cognition.2024.105789,,"The study preregistered its design and analysis, ensured transparency by sharing all data and scripts, and used both classical and robust statistical analyses—finding similar results. Analyses with all data (N=107, N observations=2675) confirmed the main conclusions. New insight: robust estimation methods did not alter hypothesis outcomes.",,,,Sample size was determined a priori using power analysis based on Monte-Carlo simulations to ensure at least 90% statistical power.,,,No information available,,"The research goal was to investigate how events are temporally compressed in episodic memory; using a mental replay task with videos, the approach measured replay duration, and the principal finding was that participants recalled events as shorter than their actual duration, supporting temporal compression in memory.",,1.000,exact_title
majesty_2024,Developing a proof-of-concept curriculum foundation model for industry 5.0: A primary data survey of built environment academics,"His Majesty, John J Posillico",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on developing a proof-of-concept curriculum foundation model for industry 5.0: a primary data survey of built environment academics providing insights for knowledge graph development and data integration.,"This 2024 paper by His Majesty, John J Posillico explores developing a proof-of-concept curriculum foundation model for industry 5.0: a primary data survey of built environment academics. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1177/09504222231224090,"data-integration, knowledge-graph",Developing a proof-of-concept curriculum foundation model for industry 5.0: A primary data survey of built environment academics,"Posillico John J, Edwards David J",2024,reference-manager,10.1177/09504222231224090,,,,,,"Structured questionnaire survey: Developed using job advertisements and industry indices, including closed Likert scale and open-ended questions to collect quantitative and qualitative data.",,,"What are the core interpersonal and technical skills and competencies required of a contemporary construction management graduate, and how can these be incorporated into an optimized higher education curriculum?","The study aimed to identify core interpersonal and technical skills needed by construction management graduates for curriculum development. Using a mixed-methods approach with descriptive and inferential statistics, findings show interpersonal skills are rated more important than technical skills. The research proposes a model to optimize higher education curricula.","The research goal was to identify core interpersonal and technical skills for construction management graduates using a mixed-methods approach; results show interpersonal skills are more important than technical ones, leading to a proof-of-concept curriculum model prioritizing communication, teamwork, leadership, and listening/understanding.",,1.000,exact_title
majumdar_2013,Smart Knowledge Transfer using Google-like Search,"Srijoni Majumdar, Partha Pratim Das",2013,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on smart knowledge transfer using google-like search providing insights for knowledge graph development and data integration.,"This 2013 paper by Srijoni Majumdar, Partha Pratim Das explores smart knowledge transfer using google-like search. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Smart Knowledge Transfer using Google-like Search,"Das Partha Pratim, Majumdar Srijoni",2023,reference-manager,,,"Implementation Insights highlight that SMARTKT integrates multiple knowledge sources—such as source code, runtime traces, comments, version and bug trackers, and design documents—using SPARQL queries and word vector semantics for intelligent responses. The prototype supports entity-based, list, and template queries, addressing fragmented knowledge transfer and program comprehension challenges for developers.",,,,Knowledge Primitive Extraction: Extracts atomic units of knowledge (Primitives) from sources using natural language processing and instrumentation frameworks.,,,"How can an integrated search framework like SMARTKT extract, associate, and represent knowledge from multiple software sources to improve program comprehension and support maintenance engineers in addressing software maintenance challenges?","SMARTKT is a search framework designed to improve program comprehension by extracting and integrating knowledge from multiple sources into a semantic graph. Using natural language processing and instrumentation, it supports various query types, helping maintenance engineers answer syntax and semantic questions efficiently. The framework aims to reduce software maintenance costs.","The research goal is to improve program comprehension by proposing SMARTKT, a search framework that extracts and integrates knowledge from multiple software sources into a semantic graph, enabling effective syntax and semantic queries; results show SMARTKT provides direct and intelligent responses to various query types for maintenance engineers.","Program Comprehension, Knowledge Transfer, Machine Learning, Natural Language Processing, Semantic Graph",1.000,exact_title
malec_2022,Causal feature selection using a knowledge graph combining structured knowledge from the biomedical literature and ontologies: a use case studying depression as a risk factor for Alzheimer's disease,"Scott A. Malec, Sanya B. Taneja, Steven M. Albert, C. Elizabeth Shaaban, Helmet T. Karim, Arthur S. Levine, Paul Munro, Tiffany J. Callahan, Richard D. Boyce",2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on causal feature selection using a knowledge graph combining structured knowledge from the biomedical literature and ontologies: a use case studying depression as a risk factor for alzheimer's disease providing insights for knowledge graph development and data integration.,"This 2022 paper by Scott A. Malec, Sanya B. Taneja, Steven M. Albert, C. Elizabeth Shaaban, Helmet T. Karim, Arthur S. Levine, Paul Munro, Tiffany J. Callahan, Richard D. Boyce explores causal feature selection using a knowledge graph combining structured knowledge from the biomedical literature and ontologies: a use case studying depression as a risk factor for alzheimer's disease. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.5281/zenodo.6785307.,"data-integration, healthcare, knowledge-graph",Causal feature selection using a knowledge graph combining structured knowledge from the biomedical literature and ontologies: a use case studying depression as a risk factor for Alzheimer's disease,"Malec Scott Alexander, Taneja Sanya B, Albert Steven M, Shaaban C. Elizabeth, Karim Helmet T, Levine Art S, Munro Paul Wesley, Callahan Tiffany J, Boyce Richard David",2022,reference-manager,10.1101/2022.07.18.500549,,"The implementation combines machine and human strategies: machines extract and link large-scale knowledge, while humans assess variable relevance. Ontology-grounded knowledge graphs help remove errors and provide explanations. The approach enables discovery of novel biomarkers and supports causal feature selection, but the small, non-systematic corpus limits comprehensiveness.",,,,"Machine reading systems (SemRep, EIDOS, REACH in the INDRA ecosystem) were used to extract triples from biomedical literature.",,,How can a biomedical knowledge graph be used to identify and select confounders for estimating the total effect of depression on Alzheimer's disease risk from observational data?,"The study aimed to estimate depression's effect on Alzheimer's disease risk using observational data. Researchers built a knowledge graph from PubMed articles using machine reading systems, then identified confounders through graph searches. Results showed ontology-grounded graphs improved accuracy, but search depth and terminology mapping limited recall. Future work is needed.","The research goal was to identify confounding, colliding, and mediating variables between depression and Alzheimer’s disease using a knowledge graph approach, which combined machine reading and ontology grounding; results showed KGs efficiently automate reasoning and generate mechanistic hypotheses, though further research is needed for definitive conclusions.",,1.000,exact_title
mandal_2013,LLMasMMKG: LLM Assisted Synthetic Multi-Modal Knowledge Graph Creation For Smart City Cognitive Digital Twins,Sukanya Mandal,2013,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on llmasmmkg: llm assisted synthetic multi-modal knowledge graph creation for smart city cognitive digital twins providing insights for knowledge graph development and data integration.,"This 2013 paper by Sukanya Mandal explores llmasmmkg: llm assisted synthetic multi-modal knowledge graph creation for smart city cognitive digital twins. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",LLMasMMKG: LLM Assisted Synthetic Multi-Modal Knowledge Graph Creation For Smart City Cognitive Digital Twins,"Mandal Sukanya, O'Connor Noel E.",2024,reference-manager,10.1609/aaaiss.v4i1.31795,,"The implementation features a modular, scalable pipeline for constructing multi-modal knowledge graphs (MMKGs) using large language models (LLMs) and synthetic data. Key insights include the potential for advanced reasoning, explainability, schema alignment, and integration of diverse data types, supporting flexible, transparent, and extensible smart city applications.",,,,Synthetic data generation: Creating and using artificial data for both text and sensor modalities to construct the MMKG.,,,"How can large language models be leveraged to construct comprehensive, robust, and explainable multimodal knowledge graphs for smart city digital twins, addressing challenges such as data fusion, parameter optimization, scalability, robustness to noise, and integration of real-world and synthetic data?","This paper aims to enhance smart city digital twins (SC CDTs) by using large language models (LLMs) to construct synthetic multi-modal knowledge graphs (MMKGs). The methodology integrates diverse data sources, addresses data scarcity and privacy, and demonstrates improved explainability. Results show promise for more sustainable, citizen-centric urban management.","The paper's main objective is to develop a novel LLM-based approach for constructing synthetic MMKGs to enhance SC CDTs; the key method integrates heterogeneous data using LLMs for entity recognition, relationship extraction, and synthetic data generation; principal finding: this approach addresses data sparsity, privacy, and integration challenges in urban environments.",,1.000,exact_title
mandreoli_2010,"Dealing With Data Heterogeneity in a Data Fusion Perspective: Models, Methodologies, and Algorithms","Federica Mandreoli, Scienze Fisiche",2010,Yes,SUPER,"This paper directly addresses core aspects of heterogeneous data integration in knowledge graphs, providing critical insights for PKG architectures and temporal data management strategies that align perfectly with our research objectives.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on dealing with data heterogeneity in a data fusion perspective: models, methodologies, and algorithms providing insights for knowledge graph development and data integration.","This 2010 paper by Federica Mandreoli, Scienze Fisiche explores dealing with data heterogeneity in a data fusion perspective: models, methodologies, and algorithms. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Dealing With Data Heterogeneity in a Data Fusion Perspective,"Mandreoli Federica, Montangero Manuela",2019,reference-manager,10.1016/b978-0-444-63984-4.00009-0,,,,,,Schema mapping: Addresses structural differences between data sources to solve heterogeneity at the structure level.,,,How can systematic computer science solutions address data heterogeneity challenges in integrating disparate life science data sources to improve knowledge and support novel application scenarios such as big data and crowdsourcing?,"The paper reviews computer science-based models, methodologies, and algorithms for addressing data heterogeneity in life science data integration. It overviews key data sources, discusses schema mapping, entity resolution, and data fusion techniques, highlights recent advances, and concludes that systematic approaches are essential for effective integration and future research.","The research goal is to address data heterogeneity in life science data integration using computer science solutions; the approach reviews models, methodologies, and algorithms for entity resolution and data fusion; the principal finding is that systematic computer science methods can effectively tackle heterogeneity challenges in life science applications.",,0.900,fuzzy_title
mao_2024,A Question-Answering Assistant over Personal Knowledge Graph,Xinyu Mao,2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",PKGQA integrates information from multiple mobile applications into unified query interface achieving high accuracy on complex personal questions,Practical PKG-based question answering system for mobile personal data integration,This paper presents Personal Knowledge Graph Question-Answering (PKGQA) assistant that seamlessly integrates information from multiple mobile applications into a unified query interface for personalized knowledge services,How can personal knowledge graphs support effective question-answering for personalized information retrieval across multiple mobile applications?,"Fine-grained schema for PKG, Symbolic Semantic Parsing, FAQ Semantic Matching, Neural Semantic Parsing modules, Android implementation","PKGQA achieves high accuracy on constructed dataset, demonstrates good performance on complex questions, successfully deployed as Android application",,"Abstract lacks specific accuracy metrics, limited to mobile application context",Proves feasibility of PKG-based conversational interfaces for personal information management,,"Implement for HDM with broader data sources, develop cross-platform support, enhance privacy controls",Agent Epsilon: Critical paper - practical PKG implementation with conversational interface highly relevant to HDM,https://dl.acm.org/doi/10.1145/3626772.3657665,10.1145/3626772.3657665,"android, mobile-applications, natural-language-interface, personal-knowledge-graph, question-answering",A Question-Answering Assistant over Personal Knowledge Graph,"Liu Lingyuan, Du Huifang, Zhang Xiaolian, Guo Mengying, Wang Haofen, Wang Meng",2024,reference-manager,10.1145/3626772.3657665,,"Implementation Insights are as follows: Data from various Android applications is simulated and processed using Large Language Models (LLMs) for Information Extraction. A task decomposition method based on Chain of Thought (CoT) improves extraction. The system integrates Symbolic Semantic Parsing, FAQ Matching, and Neural Semantic Parsing for efficient, flexible QA.",,,,"Simulated user data generation using a large language model (LLM) to mimic text from various Android applications, considering distinct textual styles.",,,"How can a unified PKGQA system integrate data from various applications to provide accurate, efficient, and flexible personalized question answering for users?","The paper presents a unified PKGQA system that integrates data from various Android applications to enable accurate, personalized question answering. Using LLM-based information extraction and a modular approach (Symbolic Semantic Parsing, FAQ Semantic Matching, Neural Semantic Parsing), the system achieves efficient, flexible, and accurate responses. Experimental results confirm its effectiveness.","The research goal is to build a unified PKGQA system for integrating multi-application data; the approach combines Symbolic Semantic Parsing, FAQ Semantic Matching, and Neural Semantic Parsing; results show accurate, efficient, and flexible question answering with strong performance on multi-hop and multi-conditional queries.",,1.000,exact_title
maoa_2023,A Survey on Semantic Processing Techniques,"Rui Maoa, Kai Hec, Xulang Zhangb, Guanyi Chend, Jinjie Nib, Zonglin Yanga, Erik Cambriaa",2023,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a survey on semantic processing techniques providing insights for knowledge graph development and data integration.,"This 2023 paper by Rui Maoa, Kai Hec, Xulang Zhangb, Guanyi Chend, Jinjie Nib, Zonglin Yanga, Erik Cambriaa explores a survey on semantic processing techniques. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.5683/SP2/QPOJSI,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
martinez_2022,Lessons Learnt from a Multimodal Learning Analytics Deployment In-the-Wild,"Roberto Martinez, Vanessa Echeverria, Gloria Fernandez-Nieto, Lixiang Yan, Linxuan Zhao, Riordan Alfredo, Xinyu Li, Samantha Dix, Hollie Jaggard, Rosie Wotherspoon, Abra Osborne, Simon Buckingham Shum, Dragan Gašević",2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on lessons learnt from a multimodal learning analytics deployment in-the-wild providing insights for knowledge graph development and data integration.,"This 2022 paper by Roberto Martinez, Vanessa Echeverria, Gloria Fernandez-Nieto, Lixiang Yan, Linxuan Zhao, Riordan Alfredo, Xinyu Li, Samantha Dix, Hollie Jaggard, Rosie Wotherspoon, Abra Osborne, Simon Buckingham Shum, Dragan Gašević explores lessons learnt from a multimodal learning analytics deployment in-the-wild. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3622784,"data-integration, educational-technology, knowledge-graph",Lessons Learnt from a Multimodal Learning Analytics Deployment In-the-Wild,"Martinez-Maldonado Roberto, Echeverria Vanessa, Fernandez-Nieto Gloria, Yan Lixiang, Zhao Linxuan, Alfredo Riordan, Li Xinyu, Dix Samantha, Jaggard Hollie, Wotherspoon Rosie, Osborne Abra, Shum Simon Buckingham, Gašević Dragan",2023,reference-manager,10.1145/3622784,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
mazzuto_2023,The resurrection of digital triplet: A cognitive pillar of human-machine integration at the dawn of industry 5.0,"Hassan Alimam  Giovanni Mazzuto, Nicola Tozzi, Filippo Emanuele Ciarapica, Maurizio Bevilacqua",2023,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on the resurrection of digital triplet: a cognitive pillar of human-machine integration at the dawn of industry 5.0 providing insights for knowledge graph development and data integration.,"This 2023 paper by Hassan Alimam  Giovanni Mazzuto, Nicola Tozzi, Filippo Emanuele Ciarapica, Maurizio Bevilacqua explores the resurrection of digital triplet: a cognitive pillar of human-machine integration at the dawn of industry 5.0. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.jksuci.2023.101846,"data-integration, knowledge-graph",The resurrection of digital triplet: A cognitive pillar of human-machine integration at the dawn of industry 5.0,"Alimam Hassan, Mazzuto Giovanni, Tozzi Nicola, Emanuele Ciarapica Filippo, Bevilacqua Maurizio",2023,reference-manager,10.1016/j.jksuci.2023.101846,,"Implementation Insights highlight that current industrial AI systems are still preliminary. Integrating AI and machine learning is crucial for advancing digital twins to digital triplets, enabling deeper understanding, interoperability, and human–machine symbiosis. New insights include the importance of human-centric approaches and cognitive augmentation for Industry 5.0.",,,,Bibliometric analysis: Used to retrieve and analyze peer-reviewed articles from databases like Scopus and Web of Science.,,,"How does the evolution from digital twins to digital triplet architecture, integrating intelligent activities and human–machine symbiosis, contribute to the advancement of Industry 5.0 and address the challenges and opportunities in intelligent manufacturing and human cyber-physical systems?","The paper aims to clarify the evolution from digital twins to digital triplets within Industry 5.0, focusing on human–machine symbiosis. Using a systematic literature review and bibliometric analysis of 186 papers (2018–2023), it defines key concepts, identifies research gaps, and proposes a hierarchical framework for digital triplets.","The research goal is to review and classify literature on Digital Twin, Cognitive Digital Twin, and Digital Triplet, using bibliometric analysis; the approach involved systematic screening and classification of 186 relevant papers; the principal finding highlights hierarchical levels and enabling technologies for intelligent digital twins in Industry 5.0.","Keywords or tags for this research include: cyber-physical system, cyber-physical, digital twin, e-learning, engineering process, industry 4, industry 5, artificial intelligence, neural network, intelligent activity, knowledge, kaizen, learning factory, production system, deep learning, computer vision, and learning systems.",1.000,exact_title
memoro_2024,Memoro: Using Large Language Models to Realize a Concise Interface for Real-Time Memory Augmentation,Figure 1: Architecture of Memoro,2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on memoro: using large language models to realize a concise interface for real-time memory augmentation providing insights for knowledge graph development and data integration.,"This 2024 paper by Figure 1: Architecture of Memoro explores memoro: using large language models to realize a concise interface for real-time memory augmentation. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3613904.3642450,"data-integration, knowledge-graph",Memoro: Using Large Language Models to Realize a Concise Interface for Real-Time Memory Augmentation,"Zulfikar Wazeer Deen, Chan Samantha, Maes Pattie",2024,reference-manager,10.1145/3613904.3642450,,,,,,"Within-subject user study: 20 participants experienced four different conditions to evaluate interaction, usability, and user experience with Memoro.",,,"How can a memory assistant system be designed and evaluated to support users in conversational recall tasks by providing concise, context-aware memory cues during interactions?","The paper introduces Memoro, an audio-based wearable assistant using large language models to help users retrieve personal information through concise suggestions. In a study with 20 participants, Memoro improved recall confidence and conversational quality. Query Mode responses were 85% shorter than baseline, and most participants preferred Memoro.","The research goal was to design a minimally disruptive wearable memory assistant using LLMs; the approach involved developing Memoro with Query and Queryless modes for concise, context-aware memory retrieval; results showed Memoro improved recall confidence, reduced disruption, and was preferred by most participants, especially for concise responses.",,1.000,exact_title
menschikov_2025,PersonalAI: Towards digital twins in the graph form,"Mikhail Menschikov, Dmitry Evseev, Ruslan Kostoev, Ilya Perepechkin, Ilnaz Salimov, Victoria Dochkina, Petr Anokhin, Evgeny Burnaev, Nikita Semenov",2025,Yes,HIGH,"Directly addresses personalized AI using knowledge graphs and temporal modeling, crucial for Human-Digital Middleware (HDM) development with combined graph architecture featuring standard edges and hyperedges.",Utilizes external memory as knowledge graphs constructed and updated by LLM itself; introduces combined graph with standard and hyperedges; incorporates temporal dependencies in dialogue systems.,Novel framework for creating personal digital twins using knowledge graphs that,"This paper addresses the challenge of personalizing language models by creating digital twins using knowledge graphs, proposing a novel approach with combined graph architecture featuring both standard edges and hyperedges for unified knowledge extraction.",How can language models retain and effectively utilize extensive personal information during interactions to generate personalized responses?,"Expanded AriGraph architecture with combined graph featuring standard edges and two types of hyperedges; experiments on TriviaQA, HotpotQA, and DiaASQ benchmarks; temporal parameter incorporation.",Demonstrated robust performance across benchmarks; unified graph construction and knowledge extraction approach; successful handling of temporal and contradictory information.,Combined graph architecture with hyperedges enabling unified and robust knowledge extraction for personalized AI systems.,Technical details on hyperedge implementation not fully available from abstract; scalability considerations for large-scale personal data not extensively discussed.,Provides breakthrough solution for personal digital twins using knowledge graphs with dynamic LLM-driven construction and maintenance.,Deeper exploration of long-term personal information retention; privacy-preserving mechanisms for personal KGs; integration with federated learning approaches.,Extend to multi-modal personal data; develop privacy-preserving architectures; explore federated personal KG systems; optimize hyperedge representations.,Offers practical architectural approach with combined graph structure and LLM-driven construction for implementing personal digital twins in HDM systems.,https://arxiv.org/abs/2506.17001,10.48550/arXiv.2506.17001,"hyperedges, knowledge-graph, llm-personalization, personal-digital-twins, temporal-modeling",PersonalAI: Towards digital twins in the graph form,"Menschikov Mikhail, Evseev Dmitry, Kostoev R., Perepechkin Ilya, Salimov Ilnaz, Dochkina Victoria, Anokhin Petr, Burnaev Evgeny, Semenov Nikita",2025,reference-manager,,,"Implementation Insights are as follows: The study integrates multiple retrieval algorithms (A\*, WaterCircles, BeamSearch, and their combinations) to enhance knowledge graph extraction for QA tasks. The mixed algorithm combines their strengths, improving triplet extraction. Evaluation uses DiaASQ, HotpotQA, and TriviaQA datasets, with accuracy and ExactMatch as main metrics. New insight: Combining diverse retrieval strategies increases relevant data extraction, supporting more robust personalized QA pipelines.",,,,"Mixed algorithm: Combines A\*, WaterCircles, and BeamSearch strategies to improve extraction of relevant data from knowledge graphs.",,,"How can a knowledge graph-based external memory architecture, exemplified by the AriGraph method, enhance question answering systems by enabling efficient extraction, management of temporal dependencies, and personalized response generation compared to existing RAG and GraphRAG methods?","The paper proposes a method to construct a graph-based knowledge base from weakly structured text, using large language models (LLMs) to extract and store information as triplets and thesis statements. This enables effective question answering by matching questions to relevant subgraphs, improving LLMs’ long-context reasoning and answer accuracy.","The research goal is to enhance LLM question answering by building a knowledge graph from weakly structured text using LLM-extracted triplets and thesis statements; the approach combines multiple extraction algorithms, and the principal finding is improved relevant data extraction for personalized LLM responses.",,1.000,exact_title
messner_2015,Temporal Knowledge Graph Completion Using Box Embeddings,"Johannes Messner, Ralph Abboud",2015,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on temporal knowledge graph completion using box embeddings providing insights for knowledge graph development and data integration.,"This 2015 paper by Johannes Messner, Ralph Abboud explores temporal knowledge graph completion using box embeddings. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.5281/zenodo.22558,"data-integration, knowledge-graph, temporal-data",Temporal Knowledge Graph Completion Using Box Embeddings,"Messner Johannes, Abboud Ralph, Ceylan Ismail Ilkan",2022,reference-manager,10.1609/aaai.v36i7.20746,,"BoxTE is a temporal knowledge graph embedding model that is fully expressive and captures many temporal inference patterns, except composition. It achieves state-of-the-art results on benchmarks, is robust under parameter constraints, and naturally extends to higher-arity knowledge bases. New benchmarks for higher-arity temporal data are needed.",,,,"BoxTE: A method that models temporal knowledge graphs by defining time-induced relation head and tail boxes, enabling the capture of cross-time inference patterns using box containment and intersection.",,,"How does the BoxTE temporal knowledge graph embedding model achieve full expressiveness and capture a rich class of temporal inference patterns, and how does its inductive capacity and robustness contribute to state-of-the-art performance in temporal knowledge graph completion tasks?","The paper introduces BoxTE, a temporal knowledge graph embedding model designed for temporal knowledge graph completion (TKGC). Using empirical evaluation, BoxTE achieves state-of-the-art results, demonstrating full expressiveness, strong inductive capacity, and robustness. The study highlights the need for benchmarks on higher-arity temporal knowledge bases.","The paper's research goal is temporal knowledge graph completion; it introduces BoxTE, a fully expressive embedding model, and demonstrates through empirical results that BoxTE achieves state-of-the-art performance and robustness on benchmark datasets, even under bounded-parameter constraints.",,1.000,exact_title
mia_2020,QuanCrypt-FL: Quantized Homomorphic Encryption with Pruning for Secure Federated Learning,"Md Jueal Mia, M. Hadi Amini, Senior Member, IEEE",2020,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on quancrypt-fl: quantized homomorphic encryption with pruning for secure federated learning providing insights for knowledge graph development and data integration.,"This 2020 paper by Md Jueal Mia, M. Hadi Amini, Senior Member, IEEE explores quancrypt-fl: quantized homomorphic encryption with pruning for secure federated learning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph",QuanCrypt-FL: Quantized Homomorphic Encryption with Pruning for Secure Federated Learning,"Mia Md Jueal, Amini M. Hadi",2024,reference-manager,,,,,,"Strict privacy laws (GDPR, CCPA) complicate large-scale data collection, slowing research.",,,,How can quantized homomorphic encryption with pruning (QuanCrypt-FL) enhance security and efficiency in federated learning by mitigating inference attacks such as gradient inversion and membership inference while maintaining model accuracy and reducing communication overhead?,,"The paper's main objective is to enhance federated learning security and efficiency by introducing QuanCrypt-FL, which combines homomorphic encryption, low-bit quantization with mean-based dynamic layerwise clipping, and unstructured pruning; results show improved model accuracy, storage, and robustness against attacks compared to previous privacy-preserving methods.","Federated Learning, Homomorphic Encryption, Quantization, Pruning, Gradient Inversion, Security.",1.000,exact_title
mishra_2024,Knowledge graph driven medicine recommendation system using graph neural networks on longitudinal medical records,"R. Mishra, S. Shridevi",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Proposes KGDNet using longitudinal EHR data with ontologies and Drug-Drug Interaction knowledge to construct admission-wise clinical and medicine Knowledge Graphs for every patient, achieving improved personalization through temporal modeling and relational data processing.",Novel knowledge graph-driven medicine recommendation system that leverages graph neural networks on longitudinal medical records for personalized healthcare interventions.,"This paper proposes KGDNet, a Knowledge Graph-Driven Medicine Recommendation System using Graph Neural Networks that utilizes longitudinal Electronic Health Record (EHR) data along with ontologies and Drug-Drug Interaction knowledge to construct admission-wise clinical and medicine Knowledge Graphs for every patient. The approach addresses limitations in traditional recommendation systems by creating individual patient knowledge graphs rather than shared memory banks, aligning more closely with the personalized nature of healthcare interventions.",How can knowledge graphs combined with graph neural networks effectively leverage longitudinal medical records to provide personalized medicine recommendations while considering drug interactions and patient history?,"Developed KGDNet framework using Relational Graph Convolutional Networks (RGCN) for multi-relational clinical data, implemented RNNs for temporal feature learning from medical record embeddings, constructed admission-wise knowledge graphs with clinical and medicine streams, evaluated on longitudinal EHR datasets.","Demonstrated superior performance of longitudinal-based models considering patient historical information with current clinical state, achieved improved PR-AUC scores and optimal DDI rates through personalized knowledge graph approach, showed effectiveness of RGCN for modeling patient clinical KG embeddings.",,"Evaluation limited to specific datasets, computational complexity considerations for real-time clinical deployment, potential challenges in scaling to diverse patient populations and healthcare systems requiring broader validation.",Successfully demonstrates that individual patient knowledge graphs combined with graph neural networks can significantly improve personalized medicine recommendations by leveraging longitudinal patient data and temporal patterns.,,"Expand evaluation to multi-institutional datasets, optimize computational efficiency for real-time deployment, integrate with existing electronic health record systems, develop clinical validation studies.","Provides practical framework for implementing personalized medicine recommendation systems using patient-specific knowledge graphs, demonstrating temporal modeling capabilities essential for HDM healthcare applications requiring longitudinal patient analysis.",https://www.nature.com/articles/s41598-024-75784-5,10.1038/s41598-024-75784-5,"drug-drug-interactions, graph-neural-networks, knowledge-graph-driven-medicine, longitudinal-medical-records, personalized-healthcare",Knowledge graph driven medicine recommendation system using graph neural networks on longitudinal medical records,"Mishra Rajat, Shridevi S.",2024,reference-manager,10.1038/s41598-024-75784-5,,"KGDNet outperforms all baselines on the MIMIC-IV dataset across PRAUC, F1, Jaccard, and DDI rate metrics. Its DDI rate can be controlled using the λ hyperparameter, balancing safety and accuracy. Ablation studies confirm the importance of KGDNet’s modules. KGDNet reliably mimics clinician prescriptions in real-world scenarios.",,,,"Instance-based models: Recommend medicines using only the current admission record, without considering patient medical history.",,,No information available,"The paper aims to improve medicine recommendation by leveraging patient medical history using longitudinal-based models and Electronic Health Records (EHRs) like MIMIC-IV. Using knowledge graphs and attention mechanisms, the proposed KGDNet model outperforms baselines in safety and accuracy, supporting safer, more personalized medication recommendations for complex cases.","The research goal is to improve safe and effective medicine recommendation; the approach is the novel KGDNet framework using personalized knowledge graphs, GNNs, RNNs, and Transformer-based attention; the results show KGDNet outperforms baselines on MIMIC-IV EHR data in accuracy and minimizing Drug-Drug Interactions.",,1.000,exact_title
models_2016,Time-R1: Towards Comprehensive Temporal Reasoning in LLMs,"Large Language Models, Temporal Reasoning",2016,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on time-r1: towards comprehensive temporal reasoning in llms providing insights for knowledge graph development and data integration.,"This 2016 paper by Large Language Models, Temporal Reasoning explores time-r1: towards comprehensive temporal reasoning in llms. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph, temporal-data",Time-R1: Towards Comprehensive Temporal Reasoning in LLMs,"Liu Zijia, Han Peixuan, Yu Haofei, Li Haoru, You Jiaxuan",2025,reference-manager,,,,,,Evaluation limited to Time-Bench; broader validation on external benchmarks and diverse datasets needed.,,,The research is reproducible: the Time-Bench dataset and models will be released to the research community. No explicit mention of source code release is provided in the context.,"How can structured prompting and reinforcement learning be leveraged to enhance large language models’ temporal reasoning abilities, particularly for future event prediction and scenario generation, using datasets constructed from publicly available news articles?",,"The paper’s main objective is to advance temporal reasoning research by introducing Time-Bench, a large-scale dataset, and training Time-R1 using a three-stage reinforcement learning approach; results show strong performance for smaller models, with evidence that the method could scale to larger models for even greater gains.",,1.000,exact_title
models_2018,Affordable AI Assistants with Knowledge Graph of Thoughts,Large Language Models,2018,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on affordable ai assistants with knowledge graph of thoughts providing insights for knowledge graph development and data integration.,"This 2018 paper by Large Language Models explores affordable ai assistants with knowledge graph of thoughts. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.48550/arXiv.2307.11278,"data-integration, knowledge-graph",Affordable AI Assistants with Knowledge Graph of Thoughts,"Besta Maciej, Paleari Lorenzo, Jiang Jia Hao Andrea, Gerstenberger Robert, Wu You, Iff Patrick, Kubíček Aleš, Nyczyk Piotr, Khimey Diana, Hannesson J'on Gunnar, Kwa'sniewski Grzegorz, Copik Marcin, Niewiadomski H., Hoefler Torsten",2025,reference-manager,,,,,,,Direct Retrieval: Used for broad contextual understanding by extracting relevant information directly from the knowledge graph.,,,"How can prompt engineering techniques, specifically the use of generic few-shot examples embedded in prompt templates, improve decision-making processes and accuracy in solving problems using knowledge graphs?",No information available,Research goal: reduce AI task execution costs while maintaining high success rates; approach: iteratively build a structured knowledge graph (KG) from unstructured data for efficient reasoning; results: KGoT enables smaller models to match larger models' performance at lower cost by leveraging structured KG-based reasoning.,,1.000,exact_title
modoni_2023,A Human Digital-Twin-Based Framework Driving Human Centricity towards Industry 5.0,"Gianfranco E. Modoni, Marco Sacco",2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a human digital-twin-based framework driving human centricity towards industry 5.0 providing insights for knowledge graph development and data integration.,"This 2023 paper by Gianfranco E. Modoni, Marco Sacco explores a human digital-twin-based framework driving human centricity towards industry 5.0. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3390/s23136054,"data-integration, knowledge-graph",A Human Digital-Twin-Based Framework Driving Human Centricity towards Industry 5.0,"Modoni Gianfranco E., Sacco Marco",2023,reference-manager,10.3390/s23136054,,,,,,Implementation and evaluation of a lightweight prototype based on the Human-CENTRO architecture in real assembly scenarios.,,,"How can the Human-CENTRO reference architecture enable and validate a human-centric model of collaborative intelligence (CI) interaction between humans and machines in manufacturing, in alignment with Industry 5.0 principles?","The paper introduces Human-CENTRO, a reference architecture enabling collaborative intelligence (CI) interactions between humans and machines in manufacturing, aligned with Industry 5.0. Using a real factory case study and quantitative surveys, the framework showed improved user confidence, guidance, and system scalability. Human-CENTRO supports human-centric, scalable, and adaptable applications.","The research goal was to implement a human-centric CI interaction model in manufacturing using the Human-CENTRO reference architecture; the approach involved deploying and validating an AR-based application, which resulted in improved user confidence, clearer guidance, fewer errors, reduced assembly time, and demonstrated system scalability.",,1.000,exact_title
mohammadi_2024,Balancing privacy and performance in federated learning: A systematic literature review on methods and metrics,"Samaneh Mohammadi, Ali Balador, Sima Sinaei, Francesco Flammini",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on balancing privacy and performance in federated learning: a systematic literature review on methods and metrics providing insights for knowledge graph development and data integration.,"This 2024 paper by Samaneh Mohammadi, Ali Balador, Sima Sinaei, Francesco Flammini explores balancing privacy and performance in federated learning: a systematic literature review on methods and metrics. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.jpdc.2024.104918,"data-integration, educational-technology, knowledge-graph",Balancing privacy and performance in federated learning: A systematic literature review on methods and metrics,"Mohammadi Samaneh, Balador Ali, Sinaei Sima, Flammini Francesco",2024,reference-manager,10.1016/j.jpdc.2024.104918,,"Implementation Insights highlight the need to balance privacy, utility, and efficiency in Federated Learning (FL). Encryption and differential privacy are widely used but introduce computational overhead. New insights include adaptive, hybrid privacy methods and context-sensitive metrics, with advances like clustering-based DP and dynamic privacy budgets improving the privacy-utility trade-off.",,,,"Encryption techniques in Federated Learning (FL), such as Homomorphic Encryption (HE) and Secure Multi-Party Computation (SMPC), to protect data confidentiality.",,,"What are the main categories of mechanisms for preserving privacy in federated learning, the primary methods and metrics used to assess privacy, and how can privacy requirements be balanced with other performance-related application requirements in federated learning?","The paper systematically reviews privacy-preserving mechanisms in federated learning (FL), focusing on encryption-based, perturbation-based, blockchain-based, and hybrid methods. Using a multi-phase screening and quality assessment, 260 papers were analyzed. Encryption techniques are widely used, especially in healthcare and finance, but present computational challenges. Balancing privacy and performance remains a key issue.","The research goal is to systematically review privacy-preserving mechanisms in federated learning (FL); the approach involves screening, quality assessment, and analysis of 260 papers; the principal finding is that encryption-based methods are prevalent, especially in sensitive sectors, but balancing privacy and computational overhead remains a key challenge.",,1.000,exact_title
mohammed_2024,A Human Digital Twin Architecture for Knowledge-based Interactions and Context-Aware Conversations,"Abdul Mannan Mohammed, Azhar Ali Mohammad, Jason A. Ortiz, Carsten Neumann, Grace Bochenek",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a human digital twin architecture for knowledge-based interactions and context-aware conversations providing insights for knowledge graph development and data integration.,"This 2024 paper by Abdul Mannan Mohammed, Azhar Ali Mohammad, Jason A. Ortiz, Carsten Neumann, Grace Bochenek explores a human digital twin architecture for knowledge-based interactions and context-aware conversations. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.cmpbup.2021.100014,"data-integration, knowledge-graph",A Human Digital Twin Architecture for Knowledge-based Interactions and Context-Aware Conversations,"Mohammed Abdul Mannan, Mohammad Azhar Ali, Ortiz Jason A., Neumann Carsten, Bochenek Grace, Reiners Dirk, Cruz-Neira Carolina",2024,reference-manager,,,,,,,"Performance evaluation using scenario-based testing: The HDT system was assessed across multiple phases (e.g., pre-check, identification, instructional guidance) with success, conditional success, and failure rates recorded.",,,"How can an HDT system that integrates metacognition, affective computing, and advanced conversational agents provide effective instructional guidance, problem-solving, and emotional support during assembly tasks while addressing performance, usability, and data privacy challenges?","The paper investigates the HDT system’s ability to assist users in gun assembly tasks. Using scenario-based testing, HDT provided accurate instructions, solutions, and emotional support, achieving high success rates. The study concludes that HDT is effective and plans future improvements in performance, user studies, and data privacy.","The paper's main objective is to enhance Human Digital Twin (HDT) systems for Human-Autonomy Teams (HATs) using an open architecture with Large Language Models and metacognition; the key method integrates multimodal data and modular components, and the principal finding is improved task accuracy, user experience, and adaptability, with optimization needed.",,1.000,exact_title
mohbat_2025,KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models,"Fnu Mohbat, Mohammed J. Zaki",2025,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on kerl: knowledge-enhanced personalized recipe recommendation using large language models providing insights for knowledge graph development and data integration.,"This 2025 paper by Fnu Mohbat, Mohammed J. Zaki explores kerl: knowledge-enhanced personalized recipe recommendation using large language models. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph, personal-knowledge",KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models,"Mohbat Fnu, Zaki Mohammed J.",2025,reference-manager,,,,,,,"Fine-tuned LoRA (Low-Rank Adaptation) adapters were used for each task, with specific hyperparameters (r = 64, α = 16, dropout = 0.5).",,,"How can the integration of food knowledge graphs and large language models be leveraged to provide personalized food recommendations, generate recipes, and deliver comprehensive nutritional information based on user queries with dietary constraints and preferences?","The paper introduces KERL, a system for recipe recommendation, generation, and nutrition estimation using knowledge graphs and large language models. Using benchmarks and metrics like BLEU, Rouge, and F1, KERL-Recom outperforms state-of-the-art LLMs, achieving a 56-point F1 improvement over Phi-3-mini-128K. The approach demonstrates superior constraint handling and recipe personalization.","The paper's research goal is recipe recommendation under complex constraints; it introduces KERL, a knowledge graph-based approach using fine-tuned LLMs, and finds that KERL-Recom significantly outperforms state-of-the-art models in F1 score for constrained recipe retrieval.",,1.000,exact_title
namesurnam_2023,HHT: An Approach for Representing Temporally-Evolving Historical Territories,de Toulouse name.surnam,2023,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Introduces HHT ontology for hierarchical historical territorial divisions using building blocks approach, provides algorithm for detecting territorial changes creating knowledge graphs of changes at multiple levels including basic and composite changes",Novel ontological approach for representing temporal evolution of historical territories without geometric constraints using hierarchical building blocks methodology,"This paper addresses representation of territories as spatio-temporal objects and computation of changes occurring in historical contexts where geometric data is not available. The research proposes HHT (Hierarchical Historical Territory) ontology to represent hierarchical historical territorial divisions without requiring geometric data, using building blocks to replace polygonal geometry. The approach provides an algorithm to detect and characterize territorial changes in knowledge graphs, creating knowledge graphs of changes at multiple levels encompassing basic changes in single territories and composite changes representing abstractions of multiple smaller changes. The methodology produced three knowledge graphs demonstrated territorial evolution analysis during specific historical periods.",How to represent and analyze temporal evolution of historical territories when geometric data is unavailable using ontological approaches?,HHT ontology for hierarchical historical territorial divisions; building blocks approach replacing polygonal geometry; algorithm for detecting and characterizing territorial changes; knowledge graph construction at multiple levels,Produced three knowledge graphs demonstrating territorial evolution analysis; successful representation of territorial divisions without geometric data; effective detection of basic and composite territorial changes,,Limited evaluation on diverse historical contexts; dependency on availability of historical territorial data; computational complexity for large-scale historical analysis not characterized,HHT provides innovative solution for temporal territorial representation and analysis when traditional geometric approaches are not feasible,,Expand evaluation to more diverse historical periods and regions; investigate scalability for large-scale historical analysis; develop interactive visualization tools,Uses building blocks as alternative to polygonal geometry; enables analysis of territorial evolution without precise geometric information; supports both basic and composite change detection,https://hal.science/hal-04283672v1,10.1007/978-3-031-33455-9_25,"eswc-2023, historical-territories, knowledge-graph, spatial-temporal-modeling, temporal-ontologies",HHT: An Approach for Representing Temporally-Evolving Historical Territories,"Charles W., Aussenac-Gilles N., Hernandez N.",2023,reference-manager,,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
nath_2024,Knowledge Graph Generation and Enabling Multidimensional Analytics on Bangladesh Agricultural Data,Rudra Pratap Deb Nath,2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",BDAKG integrates fragmented agricultural data using semantic technologies and links to LOD Cloud for comprehensive multidimensional analysis,Knowledge graph construction for agricultural data with semantic integration and analytics,"This paper develops Bangladesh Agricultural Knowledge Graph (BDAKG) through semantic integration of agricultural open data, adhering to FAIR principles and enabling multidimensional analytics for sustainable development",How can agricultural data in Bangladesh be semantically integrated and analyzed to support sustainable development?,"Semantic integration of open data, conceptual modeling, RDF transformation, linking to LOD Cloud, OLAP-compliant multidimensional analysis","Created comprehensive KG supporting data-driven analysis for CO2 reduction, economic growth, and sustainable forestry recommendations",,"Domain-specific to Bangladesh agriculture, scalability to other domains not explored",Shows practical approach to heterogeneous data integration using semantic technologies and FAIR principles,,"Apply semantic integration patterns to HDM personal data sources, implement FAIR principles",Agent Epsilon: Good example of practical KG construction from open data - patterns applicable to HDM,https://ieeexplore.ieee.org/document/10559964/,10.1109/ACCESS.2024.3409957,"agricultural-data, fair-principles, knowledge-graph-construction, multidimensional-analytics, semantic-integration",Knowledge Graph Generation and Enabling Multidimensional Analytics on Bangladesh Agricultural Data,"Pratap Deb Nath Rudra, Rani Das Tithi, Chandro Das Tonmoy, Shafkat Raihan S. M.",2024,reference-manager,10.1109/access.2024.3416388,,Implementation Insights are:,,,,,,,,,,,1.000,exact_title
naudet_2023,Preliminary Systemic Model of (Human) Digital Twin,Yannick Naudet,2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on preliminary systemic model of (human) digital twin providing insights for knowledge graph development and data integration.,"This 2023 paper by Yannick Naudet explores preliminary systemic model of (human) digital twin. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3594806.3596596,"data-integration, knowledge-graph",Preliminary Systemic Model of (Human) Digital Twin,"Naudet Yannick, Stahl Christoph, Gallais Marie",2023,reference-manager,10.1145/3594806.3596596,,"Implementation Insights from the paper highlight the need for a systemic, unified model for Human Digital Twin (HDT), grounded in General Systems Theory. Key considerations include regulation, transparency, flexibility, behavior modeling, and environmental context. New insight: HDT models must integrate both human and technical system perspectives for coherence.",,,,"Literature review: The study conducted a literature review focused exclusively on the """"Human Digital Twin"""" keyword to summarize recent research advances.",,,"What is a generic and unifying systemic model and definition of the Human Digital Twin (HDT) concept, distinguishing it from technical Digital Twins and grounded in systems theory, to guide future research across application domains?","The paper aims to establish a generic, systemic model and definition of the Human Digital Twin (HDT), grounded in systems theory. Using a literature review, it distinguishes HDT from technical Digital Twins, proposes a conceptual model, and highlights key aspects like regulation, transparency, adaptability, and human behavior.","The research goal is to establish a generic, systemic model of the Human Digital Twin (HDT) using systems theory; the approach involves a literature review and conceptual modeling; the principal finding is a unifying, systemics-grounded definition and model of HDT as a specific class of Digital Twin.","Digital Twin, Human Model, Industry4.0",1.000,exact_title
nguyen_2022,Multimodal Object Detection Using Depth and Image Data for Manufacturing Parts,"Vinh Nguyen, Engineering Mechanics",2022,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on multimodal object detection using depth and image data for manufacturing parts providing insights for knowledge graph development and data integration.,"This 2022 paper by Vinh Nguyen, Engineering Mechanics explores multimodal object detection using depth and image data for manufacturing parts. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.neucom.2021.11.097.,"data-integration, knowledge-graph",Multimodal Object Detection Using Depth and Image Data for Manufacturing Parts,"Mahjourian Nazanin, Nguyen Vinh",2025,reference-manager,,,,,,,Multimodal object detection: Uses data from multiple sensor types (image and depth) to improve accuracy and reliability.,,,How can an early fusion multimodal object detection model combining RGB images and 3D point cloud data improve the reliability and accuracy of object detection in manufacturing environments compared to RGB-only and depth-only approaches?,"The paper aims to improve object detection in manufacturing by integrating RGB images and 3D depth data using early sensor fusion within a modified Faster R-CNN model. The proposed multimodal approach significantly outperforms RGB-only and depth-only baselines, increasing mAP by up to 78%, enabling more robust and reliable detection.","The research goal is to improve object detection in manufacturing by using early sensor fusion of RGB and depth data with a single shared backbone; the approach modifies Faster R-CNN to accept four-channel RGB-D inputs, and results show the RGB-D model outperforms RGB-only and Depth-only variants.",,1.000,exact_title
noise_2024,DPSUR: Accelerating Differentially Private Stochastic Gradient Descent Using Selective Update and Release,"adding random noise, we can achieve differential privacy for a function : X → R according to Definition 2.1. The sensitivity determines how much noise is needed, is defined as follow.",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Proposes differentially private training framework with selective updates that evaluates gradient quality and applies only convergence-leading updates, achieving faster convergence and improved model utility compared to traditional DPSGD while maintaining privacy guarantees.",Novel differentially private training framework using selective gradient updates to improve convergence speed and model utility while maintaining privacy guarantees through strategic update filtering and threshold mechanisms.,"This paper addresses utility loss problems in differentially private stochastic gradient descent (DPSGD) by proposing DPSUR, a framework that applies selective updates based on validation tests. The approach evaluates each gradient iteration and only applies updates that lead to convergence, discarding harmful or useless updates. The method introduces clipping strategies for update randomization and threshold mechanisms for gradient selection to ensure training proceeds in the right direction.",How can differentially private machine learning training be accelerated while maintaining privacy guarantees by selectively applying only beneficial gradient updates?,"Developed DPSUR framework with gradient evaluation and selective update mechanisms; implemented clipping strategy for update randomization and threshold mechanism for gradient selection; evaluated on MNIST, FMNIST, CIFAR-10, and IMDB datasets with privacy budgets epsilon={1,2,3,4} and delta=1e-5.",Significantly outperforms DPSGD in convergence speed and model utility across multiple datasets; demonstrates faster convergence by discarding harmful updates and focusing training in beneficial directions; maintains differential privacy guarantees.,,Computational overhead from gradient evaluation and validation processes not fully characterized; scalability to larger models and datasets requires further investigation; limited evaluation to specific privacy budget ranges.,Successfully demonstrates that selective update mechanisms can significantly improve differentially private training efficiency while maintaining strong privacy guarantees through strategic gradient filtering.,,Optimize computational efficiency of validation processes; extend evaluation to larger-scale models and datasets; investigate adaptive threshold selection mechanisms.,"Provides practical framework for privacy-preserving model training in HDM systems, particularly relevant for training personal AI models while protecting sensitive user data through improved differential privacy mechanisms.",https://arxiv.org/abs/2311.14056,arXiv:2311.14056,"differential-privacy, gradient-descent, machine-learning, privacy-preserving-training, selective-updates",DPSUR: Accelerating Differentially Private Stochastic Gradient Descent Using Selective Update and Release,"Fu Jie, Ye Qingqing, Hu Haibo, Chen Zhili, Wang Lulu, Wang Kuncan, Ran Xun",2024,reference-manager,10.14778/3648160.3648164,,"The implementation insights highlight that differential privacy (DP) mechanisms, such as DPSGD and DPSUR, are used to protect sensitive data in deep learning. Utility analysis in high-dimensional spaces is crucial, and enhancements to local differential privacy (LDP) mechanisms improve performance. New insight: Adaptive techniques and noise calibration are key for balancing privacy and utility.",,,,Experimental evaluation using four real datasets and popular machine learning models to assess DPSUR's performance.,,,"How can the proposed DPSUR framework, which incorporates selective updates and release mechanisms, achieve rigorous differential privacy guarantees while maximizing model accuracy compared to state-of-the-art solutions?","The paper proposes DPSUR, an algorithm designed to improve differentially private model training. It combines traditional DPSGD with a selective update mechanism, using minimal clipping and Gaussian noise. Experiments show DPSUR outperforms competitors in classification accuracy while maintaining strong privacy guarantees, especially on image datasets.","The research goal is to improve differentially private deep learning; the approach, DPSUR, combines DPSGD with a selective update mechanism using minimal clipping and Gaussian noise; results show DPSUR achieves better utility than DPSGD while maintaining rigorous privacy guarantees.",,1.000,exact_title
nye_2023,Digital Twins for Patient Care via Knowledge Graphs and Closed-Form Continuous-Time Liquid Neural Networks,Logan Nye,2023,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on digital twins for patient care via knowledge graphs and closed-form continuous-time liquid neural networks providing insights for knowledge graph development and data integration.,"This 2023 paper by Logan Nye explores digital twins for patient care via knowledge graphs and closed-form continuous-time liquid neural networks. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
olusanya_2023,Digital Personal Health Coaching Platform for Promoting Human Papillomavirus Infection Vaccinations and Cancer Prevention: Knowledge Graph-Based Recommendation System,"Olufunto A Olusanya, Lokesh Chinthala, Xiaolei Huang, Brianna M White",2023,Yes,HIGH,Highly relevant to HDM healthcare - demonstrates KG-based personalized health recommendation system for preventive care,Platform uses knowledge graphs to provide personalized HPV vaccination recommendations and cancer prevention guidance,Knowledge graph-powered digital health coaching for personalized preventive,This paper presents a digital personal health coaching platform using knowledge graph-based recommendation system to promote HPV vaccinations and cancer prevention through personalized guidance,How can knowledge graphs enable personalized digital health coaching for preventive care and vaccination promotion?,"Knowledge graph-based recommendation engine, personalized health coaching algorithms, HPV and cancer prevention knowledge integration",Developed functional platform for personalized health recommendations using KG technology for preventive care guidance,Practical KG application for personalized preventive healthcare recommendations,"Limited details available from title/URL, specific evaluation metrics not accessible",Demonstrates KG application for personalized health interventions and preventive care,"Expand to other health domains, evaluate user engagement, integrate with health records","Adapt recommendation approach for HDM health monitoring, implement privacy-preserving personalization",Agent Epsilon: Important healthcare KG application - personalization patterns valuable for HDM health features,https://formative.jmir.org/2023/1/e50210,10.2196/50210,"digital-health, hpv-prevention, knowledge-graph-recommendations, personal-health-coaching, personalized-medicine",Digital Personal Health Coaching Platform for Promoting Human Papillomavirus Infection Vaccinations and Cancer Prevention: Knowledge Graph-Based Recommendation System,"Ammar Nariman, Olusanya Olufunto A, Melton Chad, Chinthala Lokesh, Huang Xiaolei, White Brianna M, Shaban-Nejad Arash",2023,reference-manager,10.2196/50210,,,,,,"Collection and analysis of vaccine-related data from Reddit using the Reddit API and Python Reddit API Wrapper, including sentiment and content analysis to identify misinformation.",,,"How can a personal health library (PHL) that integrates multimodal data and semantic technologies be developed and optimized to promote HPV vaccinations and cancer screening, address barriers to vaccination and healthcare delivery, and provide personalized support to improve health outcomes?",,"The paper's main objective is to promote HPV vaccinations and cancer screening using a Personal Health Library (PHL); the key method is developing a PHL prototype to deliver personalized health messaging, and the principal finding is that the PHL shows potential to improve vaccination outcomes and health behaviors.",,1.000,exact_title
oss_2024,Graph Neural Networks for Heart Failure Prediction on an EHR-Based Patient Similarity Graph,"Heloisa Oss, Ali Amirahmadi, Amira Soliman, Stefan Byttner, Mariana Recamonde",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Achieves superior performance with Graph Transformer model (F1 score: 0.5361, AUROC: 0.7925, AUPRC: 0.5168) by leveraging patient similarity graphs created from MIMIC-III data using K-Nearest Neighbors algorithm with embeddings from diagnoses, procedures, and medications.",Novel approach using graph neural networks and patient similarity graphs for heart failure prediction that captures complex relationships in electronic health record data beyond traditional machine learning approaches.,"This study introduces a novel approach using graph neural networks (GNNs) and a Graph Transformer (GT) to predict the incidence of heart failure (HF) on a patient similarity graph at the next hospital visit. The researchers used electronic health records from the MIMIC-III dataset and applied the K-Nearest Neighbors algorithm to create a patient similarity graph using embeddings from diagnoses, procedures, and medications, implementing three models: GraphSAGE, Graph Attention Network (GAT), and Graph Transformer (GT) to predict HF incidence.",How can graph neural networks effectively leverage patient similarity graphs derived from electronic health records to predict heart failure incidence while capturing complex patient relationships?,"Used MIMIC-III electronic health records dataset, applied K-Nearest Neighbors algorithm for patient similarity graph creation, generated embeddings from diagnoses, procedures, and medications, implemented three graph-based models: GraphSAGE, GAT, and Graph Transformer, evaluated on 4,760 patients with 8,891 unique visits.","Graph Transformer model demonstrated best performance with F1 score: 0.5361, AUROC: 0.7925, AUPRC: 0.5168, provided enhanced interpretability by capturing patient relationships, demonstrated effectiveness of graph-based approaches for heart failure prediction compared to traditional methods.",,"Evaluation limited to MIMIC-III dataset requiring broader validation, focus on heart failure prediction may limit generalizability to other cardiovascular conditions, computational complexity considerations for real-time clinical deployment not fully addressed.",Demonstrates that graph-based approaches using GNNs provide effective framework for predicting heart failure by leveraging patient similarity graphs to capture complex relationships in EHR data beyond traditional machine learning approaches.,,"Expand evaluation to multi-institutional datasets and additional cardiovascular conditions, optimize computational efficiency for real-time clinical deployment, develop integration capabilities with electronic health record systems.",Provides practical framework for implementing graph neural network-based prediction systems in healthcare using patient similarity modeling essential for HDM applications requiring relationship-aware predictive analytics in clinical settings.,https://arxiv.org/abs/2411.19742,arXiv:2411.19742,"electronic-health-records, graph-neural-networks, healthcare-predictive-analytics, heart-failure-prediction, patient-similarity-graphs",Graph Neural Networks for Heart Failure Prediction on an EHR-Based Patient Similarity Graph,"Boll Heloisa Oss, Amirahmadi Ali, Soliman Amira, Byttner Stefan, Recamonde-Mendoza Mariana",2024,reference-manager,,,"Implementation Insights highlight several points: The Graph Transformer (GT) outperformed other models, especially in recall for minority, HF-positive cases. Prescription codes (NDC standard) were most predictive. GT’s graph-based approach uncovers relational insights missed by RF. Limitations include reliance on MIMIC-III data, ICD code accuracy, and fixed thresholds.",,,,"Used the MIMIC-III dataset, encoding diagnoses and procedures with ICD-9 and medications with NDC, and processed data using Pandas and PyHealth.",,,"How can graph-based deep learning models, particularly Graph Transformers, improve the identification and interpretation of heart failure in clinical data compared to traditional methods, considering the roles of diagnosis, procedure, and prescription codes?","The paper aims to predict heart failure (HF) using patient data from the MIMIC-III dataset, employing graph neural networks (GNNs) and comparing architectures. The Graph Transformer model outperformed others, especially in recall. Prescription codes were most predictive. The study highlights the complexity of healthcare predictions and the value of graph-based interpretability.","The research goal was to predict heart failure using patient similarity graphs; the approach compared three GNN architectures (GraphSAGE, GAT, GT) on MIMIC-III data, finding that the Graph Transformer (GT) with focal loss performed best, especially in identifying high-risk patients, with medications as the most relevant features.",,1.000,exact_title
pan_2021,HGE: Embedding Temporal Knowledge Graphs in a Product Space of Heterogeneous Geometric Subspaces,"Jiaxin Pan, Mojtaba Nayyeri, Yinan Li",2021,Yes,SUPER,"This paper directly addresses core aspects of heterogeneous data integration in knowledge graphs, providing critical insights for PKG architectures and temporal data management strategies that align perfectly with our research objectives.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on hge: embedding temporal knowledge graphs in a product space of heterogeneous geometric subspaces providing insights for knowledge graph development and data integration.,"This 2021 paper by Jiaxin Pan, Mojtaba Nayyeri, Yinan Li explores hge: embedding temporal knowledge graphs in a product space of heterogeneous geometric subspaces. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, heterogeneous-data, knowledge-graph, temporal-data",Embedding Temporal Knowledge Graphs in a Product Space of Heterogeneous Geometric Subspaces,"Pan Jiaxin, Nayyeri Mojtaba, Li Yinan, Staab Steffen",2023,reference-manager,,,"Implementation Insights highlight that some factors considered during training were missed during testing, causing bias in scores. The re-implementation revealed much lower LCGE results than originally reported (e.g., ICEWS14 MRR: 61.6 vs. 92.5). HGE improves backbone models efficiently, especially on dense datasets, with fewer parameters.",,,,Re-implementation of baseline models: The study re-implemented codes for comparison and attached them in the supplementary material.,,,"How can the proposed HGE model effectively represent and predict complex temporal patterns, such as temporal (anti-)symmetry, temporal inverse, evolution, and temporary relations, in temporal knowledge graphs compared to existing baseline models?","The paper aims to improve temporal knowledge graph embeddings by introducing HGE, a temporal-geometric attention mechanism. Using attention-based product space and vector sharing, HGE efficiently fuses relational and temporal information. Experiments show HGE consistently enhances backbone models, especially on dense datasets, demonstrating improved link prediction performance.","The research goal is to improve temporal knowledge graph (TKG) link prediction; the approach introduces HGE, a temporal-geometric attention mechanism, which, when added to various backbone models, consistently enhances performance—especially on dense datasets—demonstrating HGE’s effectiveness and efficiency in combining temporal and relational information.",,0.900,fuzzy_title
pan_2024,Unifying Large Language Models and Knowledge Graphs: A Roadmap,"Shirui Pan, Senior Member, Linhao Luo, Yufei Wang, Chen Chen, Jiapu Wang, Xindong Wu",2024,Yes,HIGH,"Abstract only - highly relevant as roadmap for integrating LLMs with KGs, directly applicable to HDM systems that need natural language interfaces.",LLMs are black-box models that often fall short of capturing factual knowledge; KGs explicitly store factual information making integration mutually beneficial; proposes three frameworks.,Comprehensive roadmap for integrating large language models and knowledge graphs,"This paper presents a roadmap for integrating large language models (LLMs) and knowledge graphs (KGs), addressing how LLMs' black-box nature and knowledge limitations can be complemented by KGs' explicit factual knowledge storage.",How can large language models and knowledge graphs be effectively integrated to leverage their complementary strengths?,"Proposes three integration frameworks: KG-enhanced LLMs, LLM-augmented KGs, and Synergized LLMs + KGs.",Integration addresses LLMs' knowledge limitations while leveraging KGs' explicit factual knowledge storage for improved performance.,Three-framework approach for LLM-KG integration with high citation impact (353 citations).,Abstract only - specific implementation details and evaluation methodologies not available.,Provides comprehensive roadmap for LLM-KG integration with significant research impact.,Abstract only - practical implementation guidance and specific use cases need further development.,"Develop practical implementation frameworks, evaluate integration effectiveness across different domains, explore real-world applications.",Provides strategic roadmap for integrating natural language processing capabilities with knowledge graphs in HDM systems.,https://ieeexplore.ieee.org/document/10387715/,10.1109/TKDE.2024.3352100,"generative-pre-training, knowledge-graph, llm, natural-language-processing",Unifying Large Language Models and Knowledge Graphs: A Roadmap,"Pan Shirui, Luo Linhao, Wang Yufei, Chen Chen, Wang Jiapu, Wu Xindong",2024,reference-manager,,,,,,,KG-enhanced LLM pre-training: Uses knowledge graphs (KGs) during the pre-training stage to improve large language models' (LLMs) knowledge expression.,,,How can large language models (LLMs) and knowledge graphs (KGs) be synergistically integrated to improve knowledge representation and reasoning for tasks such as question answering?,"The paper investigates methods for unifying large language models (LLMs) and knowledge graphs (KGs) to enhance knowledge representation and reasoning. It categorizes integration approaches, describes frameworks like KG-enhanced LLMs and Synergized LLMs + KGs, and highlights improved performance and interpretability in downstream tasks through synergistic models.","The paper's research goal is to unify large language models (LLMs) and knowledge graphs (KGs) using a roadmap of three integration frameworks; its approach categorizes and reviews methods for KG-enhanced LLMs, LLM-augmented KGs, and synergized LLMs+KGs; results highlight complementary strengths and future research directions.",,1.000,exact_title
pan_2025,Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs,"Tengfei Pan, Artificial Intelligence",2025,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on structural entropy guided agent for detecting and repairing knowledge deficiencies in llms providing insights for knowledge graph development and data integration.,"This 2025 paper by Tengfei Pan, Artificial Intelligence explores structural entropy guided agent for detecting and repairing knowledge deficiencies in llms. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.18653/v1/2023.findings-acl.551,"data-integration, knowledge-graph",Structural Entropy Guided Agent for Detecting and Repairing Knowledge Deficiencies in LLMs,"Wei Yifan, Yu Xiaoyan, Pan Tengfei, Li Angsheng, Du Li",2025,reference-manager,,,,,,,Monte Carlo Tree Search (MCTS): An algorithm used to explore the knowledge graph and generate data by simulating different entity trajectories.,,,"How can synthetic data generation and filtering techniques, as implemented in SENATOR, improve the quality and reliability of medical question-answer datasets for training and evaluating large language models?","The paper introduces SENATOR, a framework to identify and address knowledge gaps in large language models (LLMs) for the medical domain. Using synthetic data generation and targeted evaluation, SENATOR efficiently supplements missing knowledge, improving LLM performance on medical benchmarks by 11.98% (Llama-3-8B) and 9.15% (Qwen2-7B).","The research goal is to efficiently detect and repair knowledge deficiencies in medical domain LLMs; the SENATOR framework identifies gaps and synthesizes targeted data for fine-tuning, resulting in average performance improvements of 11.98% (Llama-3-8B) and 9.15% (Qwen2-7B) across four medical benchmarks.",,1.000,exact_title
paperbased_2021,The effects of university students' fragmented reading on cognitive development in the new media age: evidence from Chinese higher education,Methods. Paper-based,2021,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on the effects of university students' fragmented reading on cognitive development in the new media age: evidence from chinese higher education providing insights for knowledge graph development and data integration.,"This 2021 paper by Methods. Paper-based explores the effects of university students' fragmented reading on cognitive development in the new media age: evidence from chinese higher education. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.7717/peerj.13861,"healthcare, machine-learning, mental-health, temporal",The effects of university students’ fragmented reading on cognitive development in the new media age: evidence from Chinese higher education,"Liu Wei, Huang Heng, Saleem Atif, Zhao Zhongping",2022,reference-manager,10.7717/peerj.13861,,,,,,Structural equation modeling (SEM) was used to analyze survey data and examine relationships between variables.,,,"How do the three dimensions of fragmented reading—content fragmentation, temporal fragmentation, and attentional fragmentation—affect the cognitive breadth and cognitive depth of Chinese university students?","The study aimed to examine how fragmented reading (content, time, attention) affects Chinese university students’ cognitive development. Using questionnaires and structural equation modeling (SEM) on 916 students, results showed fragmented reading increases cognitive breadth but decreases cognitive depth. The study suggests balancing fragmented and in-depth reading for optimal learning.","The research goal was to examine how fragmented reading affects Chinese university students' cognitive development using SEM; results showed fragmented reading increases cognitive breadth but decreases cognitive depth, especially with higher temporal fragmentation.",,1.000,exact_title
pareja_2020,EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs,"Aldo Pareja, Giacomo Domeniconi, Jie Chen, Tengfei Ma, Toyotaro Suzumura, Hiroki Kanezashi, Tim Kaler, Tao B. Schardl, Charles E. Leiserson",2020,Yes,HIGH,"Directly addresses temporal graph neural networks for dynamic graphs, providing foundational techniques for HDM systems requiring temporal relationship modeling and evolving personal knowledge representation","Novel approach using RNN to evolve GCN parameters rather than static node embeddings; handles completely different node sets across time steps; demonstrates superior performance on link prediction, edge classification, and node classification tasks",Temporal graph convolutional network that adapts parameters over time using,"This paper proposes EvolveGCN, a method that adapts graph convolutional networks along temporal dimensions without relying on node embeddings. The approach addresses limitations of existing temporal graph methods that require complete node knowledge across time spans and struggle with changing node sets. EvolveGCN uses RNNs to evolve GCN parameters, capturing graph dynamism through parameter adaptation rather than node feature evolution. The method evaluates on multiple temporal graph tasks and demonstrates generally higher performance compared to related approaches.",How to effectively model temporal dynamics in graphs where node sets change over time without requiring complete temporal node knowledge?,RNN-based parameter evolution for GCNs; two architectural variants for parameter adaptation; dynamic graph representation without node embeddings; temporal modeling through weight evolution rather than feature evolution,"Superior performance on link prediction, edge classification, and node classification; effective handling of evolving node sets; successful parameter evolution approach for temporal graphs; generally higher performance than related methods",EvolveGCN framework for temporal graph learning; RNN-based GCN parameter evolution; dynamic graph modeling without static embeddings; robust performance across multiple temporal tasks,Evaluation limited to specific temporal graph datasets; computational overhead of parameter evolution not fully characterized; scalability to very large dynamic graphs unclear,Parameter evolution approach effectively captures temporal graph dynamics and outperforms traditional node embedding methods for evolving graph structures,Limited approaches for handling completely changing node sets in temporal graphs; challenges in modeling graph evolution without static representations; need for flexible temporal graph architectures,Investigate scalability optimizations; explore parameter evolution for other graph neural architectures; evaluate on larger-scale industrial datasets,Uses RNN to evolve GCN parameters over time; handles dynamic node sets effectively; provides foundation for temporal personal knowledge graph architectures,https://arxiv.org/abs/1902.10191,10.48550/arXiv.1902.10191,"dynamic-systems, graph-neural-networks, parameter-evolution, rnn, temporal-graphs",EvolveGCN: Evolving Graph Convolutional Networks for Dynamic Graphs,"Pareja Aldo, Domeniconi Giacomo, Chen Jie, Ma Tengfei, Suzumura Toyotaro, Kanezashi Hiroki, Kaler Tim, Schardl Tao B., Leiserson Charles E.",2019,reference-manager,,,"Implementation Insights are as follows: EvolveGCN uses recurrent neural networks (GRU or LSTM) to evolve GCN weights over time, adapting to dynamic graphs. Summarization condenses node embeddings to match required dimensions. The -O version extends LSTM to matrices. Choice between -H and -O depends on node feature informativeness.",,,,"Use of recurrent neural networks (GRU and LSTM) to evolve GCN parameters over time, enabling temporal modeling in dynamic graphs.",,,How can evolving the parameters of a graph convolutional network (GCN) using recurrent neural networks (RNNs) improve the modeling and prediction of dynamic graphs across various tasks and data sets?,"The paper introduces EvolveGCN, aiming to improve dynamic graph learning. Using recurrent neural networks (GRU/LSTM) to evolve GCN parameters over time, experiments on multiple datasets and tasks show EvolveGCN outperforms baselines in edge and node classification, and link prediction. The method is effective for dynamic graphs, especially with informative node features.","The paper's main objective is to capture dynamic graph changes for tasks like edge and node classification using EvolveGCN, which combines graph convolutional networks with recurrent neural networks; experiments show EvolveGCN outperforms baseline methods, confirming its effectiveness.",,1.000,exact_title
parsers_2024,Docs2KG: Unified Knowledge Graph Construction from Heterogeneous Documents Assisted by Large Language Models,"combining parsers, document segmentation models, Doc2KG can parse different heterogeneous, unstructured documents for subsequent integration into a unified KG. The modualised approach we are taking allow for flexible configuration, combination of the processing modules to optimise computation resource usage.",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","\""80% of enterprise data reside in unstructured files\""; classical search engines inadequate for complex information exploration; knowledge graphs reduce cognitive load in data integration.",Framework for extracting multimodal information from diverse document types and dynamically generating unified knowledge graphs using LLMs.,"This paper introduces Docs2KG, a novel framework designed to extract multimodal information from diverse and heterogeneous unstructured documents, including emails, web pages, PDF files, and Excel files, dynamically generating a unified knowledge graph that represents the extracted key information.","How to efficiently extract and integrate knowledge from diverse, unstructured enterprise documents using knowledge graphs?","Develop unified framework (Docs2KG) for extracting multimodal information; support heterogeneous document types: emails, web pages, PDFs, Excel files; dynamically generate knowledge graphs using large language models.","Flexible, extensible knowledge graph construction; supports multiple document structures and content types; improved domain interpretability; enables efficient querying of document data lakes.",,Not explicitly stated in the abstract.,Provides practical solution for enterprise knowledge management from unstructured documents.,,Potential for broader enterprise knowledge management; exploring more diverse document integration techniques.,Demonstrates practical approach to heterogeneous document integration using LLMs for knowledge graph construction in enterprise environments.,https://arxiv.org/abs/2406.02962,10.48550/arXiv.2406.02962,"data-integration, enterprise-data, heterogeneous-documents, information-retrieval, knowledge-graph, llm",Docs2KG: Unified Knowledge Graph Construction from Heterogeneous Documents Assisted by Large Language Models,"Sun Qiang, Luo Yuanyi, Zhang Wenxiao, Li Sirui, Li Jichunyang, Niu Kai, Kong Xiangrui, Liu Wei",2024,reference-manager,,,,,,No explicit limitations or shortcomings are stated in the provided context.,,,"Docs2KG’s reproducibility is partially supported. The project’s source code is not explicitly provided in the context. However, it uses the open-source library Markdownify (source: https://github.com/matthewwithanm/python-markdownify). No direct link or repository for Docs2KG itself is mentioned.","How can a unified knowledge graph framework, such as Docs2KG, effectively extract, integrate, and represent multimodal information from heterogeneous unstructured documents to enable meaningful data-driven analysis and support Retrieval Augmented Generation (RAG) applications?","The paper proposes Docs2KG, a system that integrates heterogeneous unstructured documents (PDF, Excel, etc.) into a unified Knowledge Graph. Using dual-path data processing, it extracts and merges multimodal data. The system enables dynamic, source-referenced queries, improving information retrieval and reducing hallucination in knowledge applications.","The research goal is to unify multimodal unstructured data extraction using the Docs2KG framework, which integrates deep learning-based layout analysis and structured parsing; the principal finding is that Docs2KG dynamically constructs knowledge graphs from diverse document types, enabling effective semantic and structural queries across heterogeneous data.","Unstructured Data, Heterogeneous Data, Knowledge Graph",1.000,exact_title
pascual_2022,A Systematic Review on Human Modeling: Digging into Human Digital Twin Implementations,"Heribert Pascual, Xavi Masip-Bruin, Albert Alonso, Judit Cerdá",2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a systematic review on human modeling: digging into human digital twin implementations providing insights for knowledge graph development and data integration.,"This 2022 paper by Heribert Pascual, Xavi Masip-Bruin, Albert Alonso, Judit Cerdá explores a systematic review on human modeling: digging into human digital twin implementations. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1109/ACCESS.2019.2953499,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
peng_2019,A literature review of current technologies on health data integration for patient-centered health management,"Cong Peng, Prashant Goswami, Guohua Bai",2019,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on a literature review of current technologies on health data integration for patient-centered health management providing insights for knowledge graph development and data integration.,"This 2019 paper by Cong Peng, Prashant Goswami, Guohua Bai explores a literature review of current technologies on health data integration for patient-centered health management. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1177/1460458219892387,"data-integration, healthcare, knowledge-graph",A literature review of current technologies on health data integration for patient-centered health management,"Peng Cong, Goswami Prashant, Bai Guohua",2019,reference-manager,10.1177/1460458219892387,,,,,,Snowballing sampling method: A recursive process of identifying relevant articles from references (backward snowballing) and citations (forward snowballing).,,,"What are the existing approaches for integrating and collaboratively utilizing heterogeneous health data, how can these approaches be classified, and what are the main challenges affecting health data integration and utilization?","The paper aims to review methods and technologies for integrating and utilizing health data from multiple sources for patient healthcare management. Using a snowballing literature review, 32 peer-reviewed articles (2008–2018) were analyzed. Most approaches achieve structural interoperability, with varying integration effort. Security and privacy remain underexplored.","The research goal was to review and classify approaches for integrating heterogeneous health data, using a snowballing literature review method, and found that most studies focus on General Healthcare Information Management, with interoperability standards being crucial for successful integration.",,1.000,exact_title
peng_2021,Knowledge Graphs: Opportunities and Challenges,"Ciyuan Peng, Mehdi Naseriparsa, Francesco Osborne, Computing Technologies",2021,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on knowledge graphs: opportunities and challenges providing insights for knowledge graph development and data integration.,"This 2021 paper by Ciyuan Peng, Mehdi Naseriparsa, Francesco Osborne, Computing Technologies explores knowledge graphs: opportunities and challenges. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Knowledge Graphs: Opportunities and Challenges,"Peng Ciyuan, Xia Feng, Naseriparsa Mehdi, Osborne Francesco",2023,reference-manager,10.1007/s10462-023-10465-9,,,,,,"Comprehensive survey: The study conducts a thorough review and analysis of existing knowledge graph research, technologies, and applications.",,,"What are the opportunities and challenges of using knowledge graphs for question-answering systems, particularly in addressing simple and multi-hop questions, knowledge reasoning, and the verification of inferred knowledge?","This paper surveys knowledge graphs, aiming to analyze their technological advancements, applications, and challenges. Using a comprehensive literature review, it highlights knowledge graphs’ benefits for AI systems and diverse fields, but also details technical challenges in areas like knowledge acquisition and reasoning. The study concludes by encouraging future research and development.","The research goal is to comprehensively survey knowledge graphs, the approach is an in-depth analysis of their technologies, applications, opportunities, and challenges, and the principal finding is that while knowledge graphs offer significant benefits for AI and various fields, they face major technical limitations.",,1.000,exact_title
piechocki_2022,Multimodal sensor fusion in the latent representation space,"Robert J. Piechocki, Xiaoyang Wang, Mohammud J. Bocus",2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on multimodal sensor fusion in the latent representation space providing insights for knowledge graph development and data integration.,"This 2022 paper by Robert J. Piechocki, Xiaoyang Wang, Mohammud J. Bocus explores multimodal sensor fusion in the latent representation space. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1038/s41598-022-24754-w,"data-integration, knowledge-graph",Multimodal sensor fusion in the latent representation space,"Piechocki Robert J., Wang Xiaoyang, Bocus Mohammud J.",2023,reference-manager,10.1038/s41598-022-24754-w,,,,,Performance depends heavily on high-quality training data.,,,,"How can a novel multimodal sensor fusion method, inspired by the Bayesian brain hypothesis and implemented via Multimodal Variational Autoencoder (M-VAE), effectively estimate latent causes and reconstruct signals from subsampled, lossy, or noisy data for applications such as human activity recognition in E-Health?","The paper introduces a novel multimodal sensor fusion method for tasks like human activity recognition, using a self-supervised generative model in latent space. The method excels under subsampled and noisy data, outperforming existing techniques in classification and reconstruction. It enables robust fusion, but relies on high-quality training data.","The research goal is to develop a novel sensor fusion method (SFLR) for human activity recognition, using latent representation fusion and compressed sensing; results show SFLR outperforms baselines in classification and reconstruction tasks, especially under subsampled or noisy data conditions.",No information available,1.000,exact_title
plailly_2019,Incorporation of fragmented visuoolfactory episodic memory into dreams and its association with memory performance,"J. Plailly, M.Villalba, R.Vallat, A. Nicolas & P. Ruby",2019,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on incorporation of fragmented visuoolfactory episodic memory into dreams and its association with memory performance providing insights for knowledge graph development and data integration.,"This 2019 paper by J. Plailly, M.Villalba, R.Vallat, A. Nicolas & P. Ruby explores incorporation of fragmented visuoolfactory episodic memory into dreams and its association with memory performance. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1038/s41598-019-51497-y,"data-integration, knowledge-graph",Incorporation of fragmented visuo-olfactory episodic memory into dreams and its association with memory performance,"Plailly J., Villalba M., Vallat R., Nicolas A., Ruby P.",2019,reference-manager,10.1038/s41598-019-51497-y,,,,,"Low statistical power due to small sample sizes (participants or dreams), limiting interpretation and generalization.",,,,"To what extent do dreams incorporate elements of recently learned multisensory episodes, and how does the method of scoring learning-related content in dream reports affect the observed relationship between dreaming and memory consolidation?",,"The research goal was to examine how elements from a learning phase are incorporated into dreams; the approach involved analyzing dream reports for learning-related content using strict and liberal scoring; results showed recent learning episodes were incorporated into dreams, supporting a link between dreaming and memory consolidation.",,0.995,fuzzy_title
pokrywka_2024,Evaluating Transformer Models for Suicide Risk Detection on Social Media,"Jakub Pokrywka, Jeremi I. Kaczmarek, Edward J. Gorzelańczyk",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Fine-tuned GPT-4o achieved highest performance with weighted F1 score of 75.5% and demonstrated that general-purpose models can achieve state-of-the-art results in suicide risk detection, securing second place in IEEE BigData 2024 Cup competition.","Comparative analysis of transformer-based models for suicide risk detection from social media posts using natural language processing to classify risk categories including indicator, ideation, behavior, and attempt.","This paper explores using natural language processing to detect suicide risk in social media posts through transformer-based models. The researchers experimented with three configurations: fine-tuned DeBERTa (base and large models), GPT-4o with Chain of Thought prompting, and fine-tuned GPT-4o. The goal was to classify social media posts into four risk categories: indicator, ideation, behavior, and attempt, using a Reddit-sourced dataset with 2,000 posts during the COVID-19 pandemic period.",Which natural language processing method would work best for suicide risk detection on social media while balancing accuracy and practical deployment constraints?,"Used three transformer model configurations including fine-tuned DeBERTa base and large models, GPT-4o with few-shot prompting and Chain of Thought reasoning, fine-tuned GPT-4o model, evaluated on Reddit-sourced dataset with 2,000 posts.","Fine-tuned GPT-4o achieved highest performance with weighted F1 score of 75.5%, achieved second place in IEEE BigData 2024 Cup, demonstrated that general-purpose models can achieve state-of-the-art results with minimal specialized tuning.",,"Dataset restricted to Reddit posts, collected during COVID-19 pandemic creating potential temporal bias, limited contextual information available, potential bias in data collection methodology.","Simple, robust pre-trained models can effectively detect suicide risk with minimal specialized tuning, providing practical approach for early intervention systems.",,"Develop dataset based on clinical assessments, collaborate with healthcare institutions for validation, expand to multi-platform analysis for comprehensive risk assessment.",Provides technical framework for implementing mental health monitoring in HDM systems with focus on social media analysis while highlighting importance of clinical validation and multi-modal data integration.,https://arxiv.org/html/2410.08375v1,10.48550/arXiv.2410.08375,"mental-health-tech, nlp-for-healthcare, social-media-analysis, suicide-risk-detection, transformer-models",Evaluating Transformer Models for Suicide Risk Detection on Social Media,"Kaczmarek Jeremi I., Pokrywka Jakub, Gorzelanczyk Edward J.",2024,reference-manager,,,"The implementation used straightforward, general-purpose neural models without advanced techniques. Fine-tuned GPT-4o (a decoder-only model) outperformed other methods. Despite model simplicity, the approach achieved second place, highlighting the effectiveness of robust pre-trained models and simple methodologies for suicide risk detection on social media.",,,,Fine-tuning DeBERTa models (base and large) on the provided training dataset.,,,"How can general-purpose neural language models be leveraged to effectively detect and classify suicide risk levels in social media texts, while addressing challenges such as label imbalance and ensuring ethical standards in data collection and participant anonymity?","The paper addresses suicide risk detection on social media, aiming to improve public health strategies. It evaluates three machine learning approaches, finding that a fine-tuned decoder-only model performed best, achieving second place in a competition. The study highlights ethical and data challenges, emphasizing collaboration with healthcare institutions.","The research goal was to detect suicide risk on social media; the approach compared encoder-only and decoder-only models (with in-context learning and fine-tuning), finding that a fine-tuned decoder-only model (GPT-4o) achieved the best results, earning second place in the IEEE BigData 2024 Cup.",,1.000,exact_title
prahlad_2025,Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph,Deeksha Prahlad,2025,Yes,HIGH,"Addresses LLM personalization through RAG and knowledge graphs for on-device applications, directly relevant to HDM systems requiring personalized LLM capabilities with private data protection and continuous knowledge updates","Achieves significant performance improvements with 35.15% increase in ROUGE-1, 65.57% in ROUGE-2, 35.82% in ROUGE-L, 61.11% in BLEU-1 scores, and 8.931% reduction in execution time through knowledge graph-based personalization approach",Novel approach to personalizing LLMs using knowledge graphs and retrieval augmented,"This paper addresses LLM hallucinations and personalization challenges by using retrieval augmented generation (RAG) with knowledge graphs to store and update personal information, focusing on calendar data personalization. The research generates personalized datasets using ChatGPT, creates knowledge graphs from calendar and conversation data, uses embedding models for vector representations, and utilizes Llama-2-Chat models for response generation. The approach enables domain-specific LLM adaptation while supporting on-device deployment with continuously updating knowledge and reduced risk of sending sensitive personal information to cloud providers.",How can retrieval augmented generation and knowledge graphs be combined to personalize large language models for on-device applications while protecting sensitive personal data?,Personalized dataset generation using ChatGPT; knowledge graph creation from calendar and conversation data; embedding models for vector representation conversion; Llama-2-Chat model utilization for response generation; comprehensive evaluation across multiple metrics,"Improved response accuracy across all evaluation metrics; average increases of 35.15% in ROUGE-1, 65.57% in ROUGE-2, 35.82% in ROUGE-L, 61.11% in BLEU-1; achieved 8.931% reduction in execution time; successful on-device LLM personalization",On-device LLM personalization framework; knowledge graph-based personal information management; retrieval augmented generation system; private data protection mechanism through local processing,Currently focused on calendar data applications; requires generating custom datasets for domain adaptation; privacy protection limited to preventing data combination rather than comprehensive privacy preservation,Enables domain-specific LLM adaptation with on-device deployment supporting continuously updating knowledge while reducing risks of cloud-based sensitive data transmission,Limited scope to calendar data personalization; challenges in comprehensive privacy preservation; need for custom dataset generation for different domains,Expand to additional personal data types beyond calendar information; develop comprehensive privacy preservation mechanisms; investigate automated dataset generation for diverse domains,Provides innovative framework for on-device LLM personalization using knowledge graphs essential for HDM systems requiring private data protection and continuous personal knowledge updates,https://arxiv.org/html/2505.09945v1,arXiv:2505.09945,"knowledge-graph, llm-personalization, on-device-ai, private-data-protection, retrieval-augmented-generation",Personalizing Large Language Models using Retrieval Augmented Generation and Knowledge Graph,"Prahlad Deeksha, Lee Chanhee, Kim Dongha, Kim Hokeun",2025,reference-manager,10.1145/3701716.3715473,,,,,,"Knowledge Graphs (KGs): Used to structure and store factual data, enabling accurate and context-aware responses while reducing hallucinations.",,,"How does integrating knowledge graphs with retrieval augmented generation improve the personalization, accuracy, and efficiency of large language models in generating responses for domain-specific applications such as calendar datasets?","The paper aims to personalize large language models (LLMs) using retrieval augmented generation (RAG) and knowledge graphs (KGs). Using calendar and conversation datasets, the approach builds KGs and leverages embeddings for efficient retrieval. Results show improved accuracy (ROUGE/BLEU scores), reduced hallucinations, and faster execution compared to the baseline.","The research goal is to personalize large language models using Retrieval Augmented Generation and Knowledge Graphs; the approach integrates knowledge graphs to guide LLMs, and results show improved text generation quality, higher ROUGE and BLEU scores, and reduced execution time compared to the baseline.",,1.000,exact_title
presutti_2019,Pattern-based Visualization of Knowledge Graphs,"Valentina Presutti, Luigi Asprino, Christian Colonna, Misael Mongiovì, Margherita Porena",2019,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on pattern-based visualization of knowledge graphs providing insights for knowledge graph development and data integration.,"This 2019 paper by Valentina Presutti, Luigi Asprino, Christian Colonna, Misael Mongiovì, Margherita Porena explores pattern-based visualization of knowledge graphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
pugliese_2024,"Agentic Publications: An LLM-Driven Framework for Interactive Scientific Publishing, Supplementing Traditional Papers with AI-Powered Knowledge Systems","Roberto Pugliese, George Kourousias, Francesco Venier, Grazia Garlatti Costa, Via Alfonso Valerio",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on agentic publications: an llm-driven framework for interactive scientific publishing, supplementing traditional papers with ai-powered knowledge systems providing insights for knowledge graph development and data integration.","This 2024 paper by Roberto Pugliese, George Kourousias, Francesco Venier, Grazia Garlatti Costa, Via Alfonso Valerio explores agentic publications: an llm-driven framework for interactive scientific publishing, supplementing traditional papers with ai-powered knowledge systems. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.34965/agenticpublication.3567a,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
qin_2024,Multi-behavior Session-based Recommendation via Graph Reinforcement Learning,Shuo Qin,2024,Yes,HIGH,"Combines graph neural networks with reinforcement learning for multi-behavior session recommendation, providing advanced techniques for HDM systems to model complex user interaction patterns and predict behavior across multiple activity types",MB-GRL framework addresses incomplete differentiation between behavior types; unified model predicts interactions across multiple behaviors; graph neural networks encode item transitions while attention networks generate session representations; DQN regularization improves behavior-specific performance,Multi-behavior graph reinforcement learning approach for session-based recommendation,"This paper introduces Multi-behavior Graph Reinforcement Learning Network (MB-GRL) for session-based recommendation addressing limitations in existing multi-behavior methods. The approach tackles incomplete differentiation between behavior types and lack of unified models for predicting interactions across multiple behaviors. MB-GRL uses graph neural networks to encode item transition information, attention networks for session representation, and Deep Q-Network (DQN) as regularizer to improve behavior-specific performance. Experimental validation on public benchmark datasets demonstrates superior performance compared to other multi-behavior session-based recommendation models.",How to create unified models for predicting user interactions across multiple behavior types while properly differentiating between different behaviors in session-based recommendation?,Graph neural networks for item transition encoding; attention networks for session representation; Deep Q-Network (DQN) regularization; multi-behavior unified prediction framework,Superior performance on public benchmark datasets; effective unified modeling across multiple behaviors; successful integration of reinforcement learning with graph neural networks; improved behavior-specific recommendations,MB-GRL framework for multi-behavior recommendation; unified prediction across behavior types; graph-based session modeling; reinforcement learning integration,Computational complexity of reinforcement learning integration not fully characterized; evaluation limited to specific benchmark datasets; scalability to real-time applications unclear,Graph reinforcement learning effectively addresses multi-behavior session recommendation by providing unified modeling framework while maintaining behavior-specific performance through reinforcement learning regularization,Limited unified approaches for multi-behavior session recommendation; challenges in differentiating between behavior types; need for models handling diverse interaction patterns,Investigate real-time deployment optimizations; explore domain-specific behavior modeling; develop more sophisticated reinforcement learning integration,Combines graph neural networks with reinforcement learning; addresses multiple behavior types in unified framework; provides advanced session-based recommendation capabilities,https://proceedings.mlr.press/v222/qin24a.html,N/A,"deep-q-network, graph-neural-networks, multi-behavior-recommendation, reinforcement-learning, session-based-recommendation",Multi-behavior Session-based Recommendation via Graph Reinforcement Learning,"Qin Shuo, Feng Lin, Xu Lingxiao, Deng Bowen, Li Siwen, Yang Fancheng",2023,reference-manager,,,,,,"The recommendation is limited to a specific target behavior, reducing generalizability to other behavior types.",,,"The context provides detailed implementation settings (e.g., optimizer, batch size, hyperparameters) for reproducibility. However, there is no mention of the availability or location of source code for the project.",,,"The research goal is to improve multi-behavior session-based recommendation; the approach is MB-GRL, which combines graph neural networks and reinforcement learning; the principal finding is that MB-GRL outperforms all baselines on multiple datasets and behavior types, especially in distinguishing different user behavior tendencies.",,1.000,exact_title
rad_2024,Personalized Diabetes Management with Digital Twins: A Patient-Centric Knowledge Graph Approach,"Fatemeh Sarani Rad, Rasha Hendawi, Xinyi Yang, Juan Li",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on personalized diabetes management with digital twins: a patient-centric knowledge graph approach providing insights for knowledge graph development and data integration.,"This 2024 paper by Fatemeh Sarani Rad, Rasha Hendawi, Xinyi Yang, Juan Li explores personalized diabetes management with digital twins: a patient-centric knowledge graph approach. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3390/jpm14040359,"data-integration, knowledge-graph, personal-knowledge",Personalized Diabetes Management with Digital Twins: A Patient-Centric Knowledge Graph Approach,"Sarani Rad Fatemeh, Hendawi Rasha, Yang Xinyi, Li Juan",2024,reference-manager,10.3390/jpm14040359,,,,,,"Comprehensive data collection and integration from sources like electronic health records, wearable devices, mobile health applications, and patient-generated data.",,,"How can a comprehensive digital twin framework, integrating ontology development, data collection, and personal health knowledge graph construction, be developed to enable personalized diabetes management through dynamic, patient-centered virtual representations?","The paper introduces a novel approach to personalized diabetes management using digital twins and patient-centric knowledge graphs (PHKGs). By integrating diverse healthcare data and standardized ontologies, the methodology enables comprehensive, adaptable, and patient-centered care. The findings highlight improved personalization and knowledge sharing in diabetes management.","The research goal was to improve personalized diabetes management using digital twins and patient-centric knowledge graphs; the approach integrated diverse healthcare data with standardized ontologies, and results showed highly precise glucose prediction and control, highlighting adaptability, patient-centricity, and potential for broader healthcare applications.",,1.000,exact_title
rakuten_2020,Towards Temporal Knowledge Graph Embeddings with Arbitrary Time Precision,"Julien Leblay Rakuten, Xin Liu, Julien Leblay",2020,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on towards temporal knowledge graph embeddings with arbitrary time precision providing insights for knowledge graph development and data integration.,"This 2020 paper by Julien Leblay Rakuten, Xin Liu, Julien Leblay explores towards temporal knowledge graph embeddings with arbitrary time precision. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3340531.,"data-integration, knowledge-graph, temporal-data",Towards Temporal Knowledge Graph Embeddings with Arbitrary Time Precision,"Leblay Julien, Chekol Melisachew Wudage, Liu Xin",2020,reference-manager,10.1145/3340531.3412028,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
ramonell_2023,Knowledge graph-based data integration system for digital twins of built assets,"Carlos Ramonell, Rolando Chacon, ´ H´ector Posada",2023,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on knowledge graph-based data integration system for digital twins of built assets providing insights for knowledge graph development and data integration.,"This 2023 paper by Carlos Ramonell, Rolando Chacon, ´ H´ector Posada explores knowledge graph-based data integration system for digital twins of built assets. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.autcon.2023.105109,"data-integration, knowledge-graph",Knowledge graph-based data integration system for digital twins of built assets,"Ramonell Carlos, Chacón Rolando, Posada Héctor",2023,reference-manager,10.1016/j.autcon.2023.105109,,"The implementation centers on a dynamic knowledge graph integrating BIM, IoT, and process data for digital twins. It uses ontologies for semantic linking, supports varied asset types, and employs a microservice architecture. New insight: unified semantic integration enables adaptable, asset-agnostic digital twin solutions for diverse stakeholders and requirements.",,,,Central knowledge graph: A data structure that organizes and connects information about built assets for unified access and analysis.,,,"How can a universally applicable digital twin system be developed to seamlessly integrate virtual models of built assets with diverse data sources, enabling unified utilization and decision-making across varied infrastructure typologies, stages, and stakeholder requirements?","The paper aims to develop a system that integrates virtual models of built assets with diverse data sources using a central knowledge graph, semantic data integration, and a microservice architecture. Tested on ten varied infrastructure assets, the system enables comprehensive digital twins, improving data-driven decision-making in the built environment.","The research goal is to create a system that unifies virtual models of built assets with diverse data sources using a central knowledge graph, semantic integration, and microservice architecture; the approach was validated on ten varied infrastructure assets, demonstrating universal applicability for digital twin solutions.",,1.000,exact_title
rao_2016,A Selective Homomorphic Encryption Approach for Faster Privacy-Preserving Federated Learning,Abdulkadir Korkmaz · Praveen Rao,2016,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a selective homomorphic encryption approach for faster privacy-preserving federated learning providing insights for knowledge graph development and data integration.,"This 2016 paper by Abdulkadir Korkmaz · Praveen Rao explores a selective homomorphic encryption approach for faster privacy-preserving federated learning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph",A Selective Homomorphic Encryption Approach for Faster Privacy-Preserving Federated Learning,"Korkmaz Abdulkadir, Rao P.",2025,reference-manager,,,,,,,"Implementation of Security Techniques: Three security mechanisms—Homomorphic Encryption (HE), differential privacy, and the proposed Fast and Secure Homomorphic Encryption (FAS)—were implemented within a federated learning framework.",,,"How can a federated learning framework integrate selective encryption, differential noise addition, and bitwise scrambling to achieve strong privacy protection and computational efficiency across diverse, privacy-sensitive domains without sacrificing model utility or requiring precomputed sensitivity masks?","The paper introduces FAS, a Fast and Secure Homomorphic Encryption method for federated learning (FL), integrating selective encryption, noise injection, and scrambling. Through comprehensive experiments, FAS demonstrates strong security, reduced computational overhead, and robustness to data skew, outperforming conventional methods and offering practical guidelines for secure, efficient FL deployment.","The research goal is to enhance privacy in federated learning; the approach introduces FAS, combining selective encryption, noise injection, and bitwise scrambling; results show FAS achieves strong security with significantly reduced computational overhead, outperforming traditional methods and maintaining high model utility, especially in healthcare applications.",,1.000,exact_title
rashahendaw_2024,Comprehensive Personal Health Knowledge Graph for Effective Management and Utilization of Personal Health Data,USA rasha.hendaw,2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Addresses massive amounts of personal health data from EHRs and wearable devices; offers comprehensive view of individual's health through integration and analysis of different PHD types.,"Knowledge graph approach for integrating diverse personal health data sources including EHRs, wearable sensors, insurance data, and social determinants of health.","This paper proposes Personal Health Knowledge Graph (PHKG) to address challenges in managing personal health data by integrating data from electronic health records, wearable device sensors, insurance data, and social determinants of health.",How can knowledge graphs effectively manage and integrate personal health data from diverse sources for comprehensive health understanding?,"Utilized knowledge graphs to structure and integrate health data from multiple sources including EHRs, wearable sensors, insurance data, and social determinants of health.",Proposed approach offers comprehensive view of individual's health through integration and analysis of different types of personal health data.,,"Abstract only - detailed methodology, evaluation results, and implementation specifics not available.",Demonstrates comprehensive approach to personal health data management using knowledge graph technology.,,"Develop prototype implementation, evaluate integration effectiveness, assess scalability with real-world health data.",Provides framework for comprehensive health data integration using knowledge graphs that could inform HDM healthcare system architecture.,https://ieeexplore.ieee.org/document/10504339/,10.1109/AIMHC59811.2024.00026,"electronic-health-records, health-data-integration, personal-health-knowledge-graphs, wearable-devices",Comprehensive Personal Health Knowledge Graph for Effective Management and Utilization of Personal Health Data,"Hendawi Rasha, Li Juan",2024,reference-manager,10.1109/aimhc59811.2024.00026,,"The PHKG enables integration of diverse personal health data into a unified knowledge graph, supporting detailed personal profiling and improved healthcare decisions. Semantic search and standardized ontologies (HL7, FHIR) enhance usability and interoperability. New insights include enhanced user control, data security, and the potential for personalized health interventions.",,"The PHKG (Personal Health Knowledge Graph) enables comprehensive integration and management of diverse personal health data, addressing challenges like interoperability, privacy, and security.",,No information available,,,"How can a Personal Health Knowledge Graph (PHKG) be developed to effectively integrate, manage, and utilize diverse personal health data sources for improved healthcare outcomes and research?","The paper proposes a Personal Health Knowledge Graph (PHKG) to integrate and organize diverse personal health data from sources like EHRs and wearable devices. Using semantic technologies and ontologies, the PHKG enables comprehensive health profiling. Results show improved data integration, with implications for personalized care and healthcare research.","The research goal is to address challenges in personal health data management by proposing a Personal Health Knowledge Graph (PHKG) approach that integrates diverse data sources, with results showing PHKG enables comprehensive health profiling and offers significant potential for improved healthcare outcomes and research.",,1.000,exact_title
rastogi_2020,Personal Health Knowledge Graphs for Patients,"Nidhi Rastogi, Mohammed J. Zaki",2020,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Existing patient data platforms \""fail to incorporate information that has context, is personal, and topical to patients\"". Recommendation systems need to consider patient's health history, personal preferences, locations, and life choices.","Review of challenges in designing, building, and operationalizing personal health knowledge graphs for personalized healthcare.","This paper reviews and critiques existing literature on personal health knowledge graphs (PHKG), highlighting how current patient data analytics platforms fail to incorporate contextual, personal, and topical health information effectively.","How can patient data analytics platforms incorporate contextual, personal, and topical health information more effectively?",Review and critique of existing literature on personal health knowledge graphs (PHKG).,"Identified research challenges in designing, building, and operationalizing PHKGs; highlighted need for more personalized health data integration.",,Lack of contextual and personalized health data representation; limited approaches for integrating diverse patient information.,Highlights critical need for more sophisticated health data modeling that incorporates personal context and preferences.,,Develop more sophisticated PHKG architectures; improve data fusion techniques for heterogeneous health data.,"Provides guidance for healthcare PKG implementation focusing on contextual, personal, and topical health information integration.",https://arxiv.org/abs/2004.00071,10.48550/arXiv.2004.00071,"ai, data-integration, health-informatics, patient-centered-care, personal-health-knowledge-graphs, personal-knowledge-graph",Personal Health Knowledge Graphs for Patients,"Rastogi Nidhi, Zaki Mohammed J.",2023,reference-manager,,,,,,,Literature review and critique of Knowledge Graph (KG) approaches for extracting personal context from patient data.,,,"How can Personal Health Knowledge Graphs (PHKGs) be effectively generated, represented, and integrated with existing knowledge bases to provide personalized health recommendations while addressing challenges related to data heterogeneity, scalability, validation, and patient-specific requirements?","The paper reviews and critiques approaches for extracting personal context from patient data using small-sized Personal Health Knowledge Graphs (PHKGs). It discusses methodologies like inferring preferences from general KGs and dynamic PHKG creation. Key findings highlight challenges in scalability, representation, and integration. The study concludes more research is needed for effective personal health recommendations.",The research goal is to critique existing literature and discuss challenges in designing personal health knowledge graphs (PHKGs) for patients; the approach is a literature review; the principal finding is that current methods are limited and several research questions remain for effective PHKG development and use.,"Personal Health Knowledge Graphs, Knowledge Graphs, Diabetes.",1.000,exact_title
ren_2023,Recommendation System Based on Temporal Knowledge Graph Path Reasoning,"Haoyuan Ren, Liangzhong Cui",2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on recommendation system based on temporal knowledge graph path reasoning providing insights for knowledge graph development and data integration.,"This 2023 paper by Haoyuan Ren, Liangzhong Cui explores recommendation system based on temporal knowledge graph path reasoning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3630138.3630436,"data-integration, knowledge-graph, temporal-data",Recommendation System Based on Temporal Knowledge Graph Path Reasoning,"Ren Haoyuan, Cui Liangzhong",2023,reference-manager,10.1145/3630138.3630436,,,,,,Embedding-based method: Represents entities and their relationships in the Knowledge Graph using embeddings to enrich semantic information and explore user preferences.,,,"How can temporal knowledge graph path reasoning, incorporating time information from user-item interactions, improve the accuracy and interpretability of recommendation systems compared to existing static knowledge graph-based methods?","The paper aims to improve recommendation systems by integrating temporal information into knowledge graph path reasoning. Using a graph neural network combined with LSTM and reinforcement learning, the model encodes time-aware relationships and user behaviors. Experiments on three datasets show superior performance over existing static and temporal knowledge graph-based methods.","The paper's main objective is to improve recommendation accuracy by proposing a temporal knowledge graph path reasoning model that combines relationship-aware graph neural networks and reinforcement learning; experiments on three datasets show the approach outperforms existing methods in NDCG@10, Recall@10, and Precision@10.",,1.000,exact_title
ren_2025,Enhancing Repository-Level Software Repair via Repository-Aware Knowledge Graphs,"Jiadong Ren, Shunfu Jin, Yang Liu, Feng Liu, Bach Le",2025,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on enhancing repository-level software repair via repository-aware knowledge graphs providing insights for knowledge graph development and data integration.,"This 2025 paper by Jiadong Ren, Shunfu Jin, Yang Liu, Feng Liu, Bach Le explores enhancing repository-level software repair via repository-aware knowledge graphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/nnnnnnn.nnnnnnn,"data-integration, knowledge-graph",Enhancing Repository-Level Software Repair via Repository-Aware Knowledge Graphs,"Yang Bo, Tian Haoye, Ren Jiadong, Jin Shunfu, Liu Yang, Liu Feng, Le Bach",2025,reference-manager,,,,,,,Knowledge Graph Mining: Constructs a knowledge graph from codebases and GitHub artifacts to identify top candidate bug locations using both graph analysis and LLM suggestions.,,,"How can repository-aware knowledge graphs be leveraged to enhance repository-level software repair by improving bug localization, patch generation, and decision interpretability compared to existing LLM-based approaches?","The paper aims to improve repository-level software repair by constructing a knowledge graph that models structural and semantic relationships among code and repository entities. Using AST parsing and regular expressions, it extracts and connects entities, then ranks function relevance. Results show enhanced bug localization and patch ranking, increasing repair accuracy to 45.67%.","The research goal is to improve repository-level software repair by addressing semantic ambiguity; the approach integrates repository-aware knowledge graphs (KGCompass) to connect issues and code entities, and the principal finding is that KGCompass achieves state-of-the-art repair accuracy (45.67%) and superior bug localization (51.33%) on SWE-bench-lite.",,1.000,exact_title
reyna_2022,Heart Murmur Detection from Phonocardiogram Recordings: The George B. Moody PhysioNet Challenge 2022,"Matthew A. Reyna, Yashar Kiarashi, Andoni Elola, Jorge Oliveira, Francesco Renna, Annie Gu, Erick A. Perez Alday, Ashish Sharma, Sandra Mattos, Miguel T. Coimbra, Reza Sameni, Ali Bahrami Rad, Biomedical Informatics, Universidade Portucalense, Medicina Fetal, Biomedical Engineering",2022,Yes,MEDIUM,Addresses automated medical diagnostic screening using machine learning on phonocardiogram data; relevant to HDM healthcare applications for diagnostic data integration and automated health monitoring.,Cardiac auscultation is accessible but requires experts to interpret recordings; automated approaches can provide accessible pre-screening for less-resourced populations; focuses on pediatric cardiac screening.,Machine learning challenge for automated heart murmur detection from multi-location,"This paper presents the PhysioNet Challenge 2022 focused on developing automated approaches to detect abnormal heart function from multi-location phonocardiogram (PCG) recordings, particularly targeting pediatric populations in resource-constrained environments.",How can automated approaches detect abnormal heart function from multi-location phonocardiogram (PCG) recordings to enable accessible cardiac screening?,"Sourced 5,272 PCG recordings from 1,568 pediatric patients in rural Brazil; required participants to submit complete code for training and running models; developed cost-based evaluation metric.",Over 80 teams submitted more than 600 algorithms; demonstrated potential for automated approaches to provide accessible pre-screening; full analysis of results pending.,Successful machine learning challenge demonstrating feasibility of automated cardiac screening from phonocardiogram data.,Focus limited to pediatric population; results pending full analysis; specific algorithm performance not detailed in available summary.,Demonstrates feasibility of automated medical diagnostics using machine learning on physiological signals for resource-constrained healthcare.,Need for broader population validation; integration with clinical workflows; real-world deployment evaluation.,Extend to adult populations; integrate with electronic health records; develop clinical decision support systems.,Provides framework for medical signal processing and automated diagnostic screening applicable to HDM healthcare monitoring systems.,http://medrxiv.org/lookup/doi/10.1101/2022.08.11.22278688,10.1101/2022.08.11.22278688,"heart-murmur-detection, machine-learning, medical-diagnostics, phonocardiogram, physionet-challenge",Heart murmur detection from phonocardiogram recordings: The George B. Moody PhysioNet Challenge 2022,"Reyna Matthew A., Kiarashi Yashar, Elola Andoni, Oliveira Jorge, Renna Francesco, Gu Annie, Perez Alday Erick A., Sadr Nadi, Sharma Ashish, Kpodonu Jacques, Mattos Sandra, Coimbra Miguel T., Sameni Reza, Rad Ali Bahrami, Clifford Gari D.",2022,reference-manager,10.1101/2022.08.11.22278688,,,,,,Use of open-source algorithms for identifying heart murmurs and clinical outcomes from phonocardiogram (PCG) recordings.,,,"How can open-source algorithms using phonocardiogram (PCG) recordings be developed and evaluated to enable automated pre-screening for heart murmurs and abnormal clinical outcomes, particularly in resource-constrained environments?","The paper describes a Challenge focused on developing open-source algorithms to identify heart murmurs and clinical outcomes from phonocardiogram recordings, aiming to improve pre-screening in resource-limited settings. The methodology involved algorithm submissions evaluated with novel metrics. Results and conclusions are pending, as the Challenge is ongoing.","The research goal was to develop open-source algorithms for detecting heart murmurs and clinical outcomes from phonocardiogram recordings using novel evaluation metrics; the approach involved a Challenge with 294 entries from 81+ teams, and results are pending as the official phase is ongoing.",,1.000,exact_title
reznik_2021,Exploring the role of dimensionality transformation in episodic memory,Daniel Reznik,2021,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on exploring the role of dimensionality transformation in episodic memory providing insights for knowledge graph development and data integration.,"This 2021 paper by Daniel Reznik explores exploring the role of dimensionality transformation in episodic memory. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1101/2023.02.04.,"data-integration, knowledge-graph",Exploring the role of dimensionality transformation in episodic memory,"Kerrén Casper, Reznik Daniel, Doeller Christian F., Griffiths Benjamin J.",2025,reference-manager,10.1016/j.tics.2025.01.007,,,,,,Principal Component Analysis (PCA) and demixed PCA (dPCA): Linear methods that reduce dimensionality by maximizing variance and separating components based on experimental parameters.,,,"How does dimensionality transformation across neural regions support the encoding, storage, and retrieval of episodic memories, and what are its mechanisms, effects, and implications for memory function and cross-species differences?","The paper investigates how dimensionality transformation—reducing and expanding neural representations—supports episodic memory and other cognitive functions. Using insights from psychology, neuroscience, and computational models, it finds that low-dimensional representations enable efficient storage and flexible retrieval, though some memory detail is inevitably lost during this process.","The paper's main objective is to highlight how dimensionality transformation supports memory and cognition; using empirical and computational approaches, it shows that reducing complex information into low-dimensional representations enables efficient storage, flexible retrieval, and generalization, with results emphasizing its importance across episodic memory, object recognition, and goal-directed behavior.",,1.000,exact_title
rilling_2008,Beyond Information Silos — An Omnipresent Approach to Software Evolution,"Juergen Rilling, Rene Witte, Philipp Schuegerl, Philippe Charland",2008,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on beyond information silos — an omnipresent approach to software evolution providing insights for knowledge graph development and data integration.,"This 2008 paper by Juergen Rilling, Rene Witte, Philipp Schuegerl, Philippe Charland explores beyond information silos — an omnipresent approach to software evolution. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",BEYOND INFORMATION SILOS — AN OMNIPRESENT APPROACH TO SOFTWARE EVOLUTION,"RILLING JUERGEN, WITTE RENÉ, SCHUEGERL PHILIPP, CHARLAND PHILIPPE",2008,reference-manager,10.1142/s1793351x08000567,,,,,,"Unified ontological representation: Used to model and integrate process, tasks, and resources information for software maintenance.",,,"How can an integrated, ontology-based and context-sensitive knowledge management environment support software maintenance and evolution by providing dynamic guidance and automated reasoning across diverse knowledge resources and processes?","The paper investigates how ontology-based approaches support program comprehension strategies—bottom-up, top-down, and as-needed—during software evolution. Using case studies, it shows that ontologies help programmers identify, specify, and verify concepts and relationships in code, thereby improving understanding and accelerating maintenance tasks.",The research goal is to improve software maintenance by integrating semantic traceability links and contextual knowledge; the approach uses a unified process model and ontology-based queries; results show enriched knowledge bases and improved guidance for maintenance tasks in case studies involving component substitution and bug fixing.,,1.000,exact_title
rossi_2020,Temporal Graph Networks for Deep Learning on Dynamic Graphs,Emanuele Rossi,2020,Yes,HIGH,"Provides generic framework for temporal graph networks that significantly outperforms previous approaches while being computationally efficient, directly applicable to HDM temporal relationship modeling and dynamic personal knowledge evolution",TGN framework generalizes Message Passing Neural Networks to temporal graphs; incorporates memory modules for compressed node state representation; achieves state-of-the-art performance on transductive and inductive tasks; more computationally efficient than existing methods,Generic temporal graph network framework combining memory modules and graph,"This paper presents Temporal Graph Networks (TGNs), a generic framework for deep learning on dynamic graphs represented as sequences of timed events. TGNs combine memory modules with graph-based operators to significantly outperform previous approaches while maintaining computational efficiency. The framework generalizes Message Passing Neural Networks to temporal graphs by introducing node memory that represents compressed node states over time. The research demonstrates that several previous temporal graph models can be viewed as specific instances of the TGN framework, making it the most general approach for temporal graph learning.","How to develop a generic, efficient framework for deep learning on dynamic graphs that can handle evolving features and connectivity over time?",Memory modules for compressed node state representation; graph-based computational operators; sequences of timed events representation; generalization of Message Passing Neural Networks to temporal domain,Significantly outperforms previous temporal graph approaches; more computationally efficient than existing methods; state-of-the-art performance on transductive and inductive prediction tasks; generalizes multiple previous models as special cases,Generic TGN framework for temporal graphs; memory-based node state compression; efficient temporal graph processing; superior performance across multiple tasks,Framework complexity may require careful hyperparameter tuning; memory module design choices impact performance; evaluation primarily on recommendation and social network datasets,"TGN provides most comprehensive framework for temporal graph learning, demonstrating significant improvements in both accuracy and computational efficiency compared to existing approaches",Limited frameworks for handling diverse temporal graph learning tasks; need for generic approaches that can adapt to various dynamic graph scenarios; computational efficiency challenges in temporal modeling,Extend framework to larger-scale temporal graphs; investigate adaptive memory mechanisms; explore domain-specific temporal graph applications,Introduces memory modules for temporal state compression; provides generic framework applicable to diverse temporal graph tasks; enables efficient processing of dynamic graph sequences,https://arxiv.org/abs/2006.10637,10.48550/arXiv.2006.10637,"deep-learning, dynamic-systems, graph-neural-networks, memory-networks, temporal-graphs",Temporal Graph Networks for Deep Learning on Dynamic Graphs,"Rossi Emanuele, Chamberlain Ben, Frasca Fabrizio, Eynard Davide, Monti Federico, Bronstein Michael",2020,reference-manager,,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
rushangeng_2014,Learning temporal granularity with quadruplet networks for temporal knowledge graph completion,"RushanGeng, Cuicui Luo",2014,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on learning temporal granularity with quadruplet networks for temporal knowledge graph completion providing insights for knowledge graph development and data integration.,"This 2014 paper by RushanGeng, Cuicui Luo explores learning temporal granularity with quadruplet networks for temporal knowledge graph completion. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph, temporal-data",Learning temporal granularity with quadruplet networks for temporal knowledge graph completion,"Geng Rushan, Luo Cuicui",2025,reference-manager,10.1038/s41598-025-00446-z,,,,,,"Utilized five publicly available Temporal Knowledge Graph (TKG) datasets, enriched with temporal annotations, for model validation.",,,How can leveraging fine-grained temporal information and advanced feature aggregation mechanisms improve the accuracy and adaptability of Temporal Knowledge Graph Completion models across diverse datasets?,"The paper addresses challenges in Temporal Knowledge Graph Completion by proposing a model that uses triaffine mechanisms and CNNs for feature aggregation and dissemination. Experiments on five datasets show improved performance, especially in capturing temporal granularity, with evaluation based on Mean Reciprocal Rank and Hits@N metrics.","The research goal is to improve Temporal Knowledge Graph Completion by leveraging temporal granularity; the approach uses triaffine transformations, CNNs, and a gating mechanism for feature aggregation and dissemination; results show enhanced model accuracy on multiple benchmark datasets.","Keywords: Timestamps mapping, Triaffine, Dynamic convolutional neural networks, Temporal knowledge graph, Temporal knowledge graph completion.",1.000,exact_title
saad_2025,SENAI: Towards Software Engineering Native Generative Artificial Intelligence,Mootez Saad,2025,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on senai: towards software engineering native generative artificial intelligence providing insights for knowledge graph development and data integration.,"This 2025 paper by Mootez Saad explores senai: towards software engineering native generative artificial intelligence. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/nnnnnnn.nnnnnnn,"data-integration, knowledge-graph",SENAI: Towards Software Engineering Native Generative Artificial Intelligence,"Saad Mootez, López José Antonio Hernández, Chen Boqi, Ernst Neil, Varró Dániel, Sharma Tushar",2025,reference-manager,10.1145/nnnnnnn.nnnnnnn,,,,,,"Refactoring code snippets with low cohesion and high coupling to improve these attributes, evaluated using test suite execution and software metrics (e.g., lcom, cbo).",,,"How can evaluation strategies and training processes for large language models be adapted to assess and improve their understanding and application of core software engineering principles such as modularity, cohesion, coupling, and abstraction, beyond mere functional correctness?","The paper aims to adapt evaluation strategies for language models to assess their understanding of software engineering (SE) principles like cohesion and coupling. Using taxonomy-based frameworks and new benchmarks, the study proposes tasks such as code refactoring and analysis. Findings highlight current limitations and suggest improvements for SE-native AI models.","The paper's main objective is to align large language models with software engineering (SE) principles by proposing taxonomy-based evaluation methods that assess design quality, and its principal finding is that current models lack SE knowledge, necessitating new benchmarks focused on maintainability, cohesion, and coupling.",,1.000,exact_title
saharghassab_2023,Leveraging Knowledge Graphs for Matching Heterogeneous Entities and Explanation,"Iran sahar.ghassab, Iran behkama, Canada mostafa.milan",2023,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",EXKG technique achieves competitive performance and generates explanations to help users understand matching decisions,Novel approach combining knowledge graphs and pre-trained language models for explainable entity matching,"This paper presents EXKG, a technique that leverages knowledge graphs (KGs) and pre-trained language models (PLMs) to perform record linkage while offering explanatory insights into matching decisions",How can knowledge graphs and pre-trained language models be combined to perform entity matching with explanations?,"EXKG technique combining knowledge graphs and pre-trained language models, focus on generating explanations for matching decisions, addresses transparency limitations","EXKG achieves competitive performance in entity matching, provides explanatory insights for matching decisions, integrates external knowledge sources",,"Limited evaluation details available from abstract, specific performance metrics not accessible",Demonstrates practical approach to explainable entity matching leveraging both KGs and PLMs,,"Expand evaluation to diverse domains, optimize explanation generation, integrate with real-world systems","Agent Beta: Addresses entity resolution with explainability, critical for HDM cross-source matching transparency",https://ieeexplore.ieee.org/document/10386157/,10.1109/BigData59044.2023.10386157,"entity-resolution, explainable-ai, knowledge-graph, plms, record-linkage",Leveraging Knowledge Graphs for Matching Heterogeneous Entities and Explanation,"Ghassabi Sahar, Behkamal Behshid, Milani Mostafa",2023,reference-manager,10.1109/bigdata59044.2023.10386157,,"The study refines existing evaluation methods to assess explanation quality in EM, using both direct (user feedback) and indirect (behavioral change) approaches. It leverages knowledge graph paths to improve and explain DITTO and HIERGAT models, addressing challenges like feature interaction and explanation granularity. Superior performance and high explanation quality are reported.",,,,"Combined direct and indirect evaluation methods, including user/expert feedback and behavioral observations, to assess explanation quality.",,,"How can explanation quality in heterogeneous entity matching be comprehensively evaluated and improved, particularly through the EXKG approach, considering challenges such as cross-record interaction effects, explanation of non-match cases, and sensitivity variation?","The paper aims to comprehensively evaluate explanation quality in Entity Matching (EM) using knowledge graphs (KG). It combines direct user feedback and indirect behavioral measures across six aspects: trust, understandability, usefulness, satisfaction, soundness, and completeness. Results show high user satisfaction, usefulness, and soundness, affirming the approach’s effectiveness.","The research goal is to enhance explainability in entity matching (EM) by integrating knowledge graph (KG) paths into DITTO and HIERGAT models; the approach combines quantitative and qualitative evaluation of explanation quality, and results show improved model performance and highly rated, user-friendly explanations across multiple dimensions.",,1.000,exact_title
sandovalarrayga_2024,Temporal heterogeneity in cognitive architectures,"Carlos Johnnatan Sandoval-Arrayga, Gustavo Palacios-Ramirez, Felix Francisco Ramos-Corchado",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on temporal heterogeneity in cognitive architectures providing insights for knowledge graph development and data integration.,"This 2024 paper by Carlos Johnnatan Sandoval-Arrayga, Gustavo Palacios-Ramirez, Felix Francisco Ramos-Corchado explores temporal heterogeneity in cognitive architectures. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.cogsys.2024.101265,"machine-learning, temporal",Temporal heterogeneity in cognitive architectures,"Sandoval-Arrayga Carlos Johnnatan, Palacios-Ramirez Gustavo, Ramos-Corchado Felix Francisco",2024,reference-manager,10.1016/j.cogsys.2024.101265,,The implementation demonstrates that temporal heterogeneity enables faster parameter optimization and greater resilience to noise compared to temporal homogeneity. The peek-end rule heuristic further stabilizes the system and leverages long-term memory. Ongoing work aims to dynamically regulate input quantities and improve agent interoception.,,,,"Comparison of two cognitive architectures: one with temporal heterogeneity and one with temporal homogeneity, using a constant topology.",,,"Does modeling temporal heterogeneity in cognitive architectures, inspired by human brain properties, enhance the autonomy and human-like behavior of virtual agents compared to architectures with temporal homogeneity?","The paper investigates whether incorporating temporal heterogeneity—different processing speeds in cognitive modules—into cognitive architectures leads to more human-like behavior. Using an evolutionary algorithm, two models (heterogeneous vs. homogeneous) were compared on adaptation steps and energy use. Results suggest temporal heterogeneity supports more efficient, human-like learning and behavior.",The research goal is to explore if modeling temporal heterogeneity in cognitive architectures creates more human-like behavior; the approach uses a bio-inspired model tested in a virtual world; results show that temporal heterogeneity can aid in achieving more stable and human-like agent behavior.,"Keywords: Cognitive architectures, Temporal, Heterogeneity, Reference frameworks.",1.000,exact_title
saxena_2021,Question Answering Over Temporal Knowledge Graphs,"Apoorv Saxena, Soumen Chakrabarti, Partha Talukdar",2021,Yes,HIGH,"Pioneers temporal question answering in KGs with significant dataset expansion and transformer-based solutions, directly relevant to HDM temporal query capabilities",Temporal scoping is crucial for accurate knowledge representation; Transformer models can effectively handle complex temporal queries; Temporal KG embeddings significantly improve QA performance,Improved question answering in temporal knowledge graphs through novel dataset,"Temporal Knowledge Graphs (Temporal KGs) extend traditional knowledge graphs by adding temporal dimensions to graph edges. This research addresses the underexplored area of Question Answering over Temporal KGs by introducing CRONQUESTIONS, a significantly expanded dataset. The researchers developed CRONKGQA, a transformer-based solution that leverages recent advances in Temporal KG embeddings. By stratifying the dataset into complexity buckets, they demonstrated substantial performance improvements over existing methods.",How to effectively perform question answering over temporal knowledge graphs (Temporal KGQA),"Presented CRONQUESTIONS dataset; Proposed CRONKGQA, a transformer-based solution; Exploited recent advances in Temporal KG embeddings",Expanded previous dataset by 340x; Achieved 120% accuracy increase over next best method; State-of-the-art KGQA methods performed poorly on new dataset,CRONQUESTIONS dataset; CRONKGQA solution; Released research code,Not explicitly detailed in the abstract,Demonstrated significant improvements in Temporal KGQA performance,Limited research in Question Answering over Temporal Knowledge Graphs; Lack of broad coverage datasets,Not explicitly specified,Transformer-based approach with temporal KG embeddings; Dataset stratification by complexity improves evaluation,https://arxiv.org/abs/2106.01515,10.48550/arXiv.2106.01515,"cronquestions, question-answering, temporal-embeddings, temporal-kgqa, transformer",Question Answering Over Temporal Knowledge Graphs,"Saxena Apoorv, Chakrabarti Soumen, Talukdar Partha",2021,reference-manager,,,,,,,"Creation of question templates for different reasoning structures, followed by human and machine paraphrasing to increase linguistic diversity.",,,"How can large-scale, diverse temporal question answering datasets and enhanced temporal knowledge graph embedding models improve the performance of knowledge graph question answering systems on complex temporal reasoning tasks?","The paper introduces a large dataset for temporal knowledge graph question answering (KGQA), focusing on both simple and complex reasoning. Using human and machine-generated paraphrases, the study categorizes questions, applies temporal KG embeddings, and proposes CRONKGQA. Results show temporal embeddings improve performance, supporting the dataset’s value for temporal reasoning research.","The research goal is to create a large, diverse temporal knowledge graph question answering dataset using human and machine-generated paraphrases; the approach involves slot-filling templates and paraphrasing, and the principal finding is a dataset with 654 templates and strict train-test entity separation for robust temporal reasoning evaluation.",,1.000,exact_title
schatz_2023,BUILD-KG: Integrating Heterogeneous Data Into Analytics-Enabling Knowledge Graphs,"Kara Schatz, Pei-Yu Hou, Alexey V. Gulyuk, Yaroslava G. Yingling, Rada Chirkova",2023,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Workflow can significantly reduce data-integration time and resource burden while potentially resulting in higher-quality KG data for rule mining and ML,Domain-agnostic framework for automated heterogeneous data integration into unified knowledge graphs,"This paper presents BUILD-KG, a domain-agnostic workflow for integrating heterogeneous scientific and experimental data from multiple sources (spreadsheets, text, figures) into analytics-enabling knowledge graphs with domain experts as humans-in-the-loop",How can domain experts efficiently integrate heterogeneous data from multiple sources into unified knowledge graphs for complex analytics?,"Domain-agnostic workflow accepting multiple data formats, automated integration with human-in-the-loop validation, focus on enabling rule mining and machine learning applications","Automated option for integrating heterogeneous data reduces expert time/resources, improves data quality for downstream analytics, enables meaningful rule mining and ML",,"Limited evaluation details available, specific performance metrics not accessible from abstract",Provides practical workflow for heterogeneous data integration addressing real-world challenges in scientific data management,,"Empirical validation across domains, performance benchmarking, integration with existing KG platforms",Agent Beta: Addresses critical heterogeneous data fusion challenges relevant to HDM systems handling diverse data types,https://ieeexplore.ieee.org/document/10386570/,10.1109/BigData59044.2023.10386570,"analytics, data-integration, heterogeneous-data, human-in-the-loop, knowledge-graph",BUILD-KG: Integrating Heterogeneous Data Into Analytics-Enabling Knowledge Graphs,"Schatz Kara, Hou Pei-Yu, Gulyuk Alexey V., Yingling Yaroslava G., Chirkova Rada",2023,reference-manager,10.1109/bigdata59044.2023.10386570,,"BUILD-KG is a domain-agnostic, human-in-the-loop workflow for integrating heterogeneous scientific and experimental data (e.g., spreadsheets, annotated images, regularized text) into a unified knowledge graph (KG). It combines structured and unstructured data, involves domain experts for accuracy, and enables richer analytics and accelerated scientific discovery.",,,,BUILD-KG workflow: A domain-agnostic process for integrating heterogeneous scientific and experimental data into a unified knowledge graph (KG).,,,"How can a domain-agnostic, human-in-the-loop workflow be developed to integrate heterogeneous scientific and experimental data from multiple sources into a single unified knowledge graph that enables richer analytics and accelerates scientific discovery?","The paper introduces BUILD-KG, a domain-agnostic workflow for integrating heterogeneous scientific and experimental data into a unified knowledge graph (KG). The methodology involves human-in-the-loop collaboration with domain scientists. Applied to STEPS-center data, BUILD-KG enables richer analytics and accelerates scientific discovery by unifying diverse data sources.","The paper's main objective is to develop BUILD-KG, a domain-agnostic workflow for integrating diverse scientific data into a unified knowledge graph (KG); the key method involves human-in-the-loop processing and semantic tagging; principal finding: BUILD-KG enables accurate, domain-aware KG construction, accelerating scientific discovery.",,1.000,exact_title
schjetnan_2021,Cognitive boundary signals in the human medial temporal lobe shape episodic,"Palacio Schjetnan, Clayton Mosher",2021,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on cognitive boundary signals in the human medial temporal lobe shape episodic providing insights for knowledge graph development and data integration.,"This 2021 paper by Palacio Schjetnan, Clayton Mosher explores cognitive boundary signals in the human medial temporal lobe shape episodic. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1101/2021.01.16.426538;,"data-integration, knowledge-graph, temporal-data",Cognitive boundary signals in the human medial temporal lobe shape episodic memory representation,"Zheng Jie, Gómez Palacio Schjetnan Andrea, Yebra Mar, Mosher Clayton, Kalia Suneil, Valiante Taufik A., Mamelak Adam N., Kreiman Gabriel, Rutishauser Ueli",2021,reference-manager,10.1101/2021.01.16.426538,,,,,,"Behavioral tasks: Subjects completed encoding (memorizing video clips), scene recognition (identifying previously seen frames), and time discrimination tasks.",,,"How do different types of event boundaries within video clips (no boundary, soft boundary, hard boundary) affect memory encoding, scene recognition, and time discrimination in human subjects?","The study investigates how cognitive boundaries define the beginning and end of memory episodes. Using tasks involving video clip encoding, scene recognition, and time discrimination, the researchers analyzed neural responses to different boundary types. Findings show that neural activity changes at boundaries, influencing memory formation and recognition.","The research goal was to investigate how cognitive boundaries affect episodic memory; using a task with video clips containing different boundary types, the study found that neural state shifts at boundaries enhance recognition memory but impair temporal order memory, revealing a trade-off in memory organization.",,0.900,fuzzy_title
schmitt_2020a,"Gifts, Contexts, Means, and Ends Differing: Informing Task Scenarios to Serve Knowledge Workers' Needs in Dynamic Complex Settings","Ulrich Schmitt, T. Grandon Gill",2020,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on gifts, contexts, means, and ends differing: informing task scenarios to serve knowledge workers' needs in dynamic complex settings providing insights for knowledge graph development and data integration.","This 2020 paper by Ulrich Schmitt, T. Grandon Gill explores gifts, contexts, means, and ends differing: informing task scenarios to serve knowledge workers' needs in dynamic complex settings. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.28945/4667,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
schmitt_2020b,Scalability of generative knowledge management systems: designing for individuals' and institutions' mutual benefit,Ulrich Schmitt,2020,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on scalability of generative knowledge management systems: designing for individuals' and institutions' mutual benefit providing insights for knowledge graph development and data integration.,"This 2020 paper by Ulrich Schmitt explores scalability of generative knowledge management systems: designing for individuals' and institutions' mutual benefit. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1108/K-05-2020-0324,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
schpfeld_2019,Solving problems of research information heterogeneity during integration – using the European CERIF and German RCD standards as examples,Joachim Schöpfeld,2019,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on solving problems of research information heterogeneity during integration – using the european cerif and german rcd standards as examples providing insights for knowledge graph development and data integration.,"This 2019 paper by Joachim Schöpfeld explores solving problems of research information heterogeneity during integration – using the european cerif and german rcd standards as examples. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3233/ISU-180030,"data-integration, knowledge-graph",Solving problems of research information heterogeneity during integration – using the European CERIF and German RCD standards as examples,"Azeroual Otmane, Saake Gunter, Abuosba Mohammad, Schöpfel Joachim",2019,reference-manager,10.3233/isu-180030,,,,,,Extraction: Selecting and replicating research information from various heterogeneous source systems using defined interfaces.,,,"How can problems of data heterogeneity and distribution across different systems be solved, and which methods, processes, and techniques can ensure the long-term and sustainable quality of research information during its integration into research information management systems (RIMS)?","The paper examines how to solve data heterogeneity and ensure long-term quality during research information integration into RIMS. Using empirical studies and literature review, it discusses methods like data transformation, harmonization, and merging. The study concludes that RIMS improve information supply but face challenges in data integration and quality management.","The paper's main objective is to address research information heterogeneity during integration into RIMS by empirically examining methods for harmonizing and merging heterogeneous data, concluding that harmonization and integration processes are essential for reliable, high-quality research information management.",,1.000,exact_title
schultes_2022,FAIR Digital Twins for Data-Intensive Research,"Erik Schultes, Marco Roos, Luiz Olavo Bonino da Silva Santos, Giancarlo Guizzardi, Jildau Bouwman, Thomas Hankemeier, Arie Baak, Barend Mons",2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on fair digital twins for data-intensive research providing insights for knowledge graph development and data integration.,"This 2022 paper by Erik Schultes, Marco Roos, Luiz Olavo Bonino da Silva Santos, Giancarlo Guizzardi, Jildau Bouwman, Thomas Hankemeier, Arie Baak, Barend Mons explores fair digital twins for data-intensive research. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3389/fdata.2022.883341/full,"data-integration, knowledge-graph",FAIR Digital Twins for Data-Intensive Research,"Schultes Erik, Roos Marco, Bonino da Silva Santos Luiz Olavo, Guizzardi Giancarlo, Bouwman Jildau, Hankemeier Thomas, Baak Arie, Mons Barend",2022,reference-manager,10.3389/fdata.2022.883341,,,,,,"Use of Knowlets: Knowlets are used to represent machine awareness of context, enabling rapid rationalization of real-world observations using curated knowledge.",,,"How can we transition from traditional, human-driven scientific research to a machine-assisted environment where precisely defined real-world semantics and globally unique and persistent identifiers enable fully AI-ready, FAIR data and services?","The paper argues that precise definition of scientific concepts and real-world semantics is essential for fully AI-ready scholarly communication. Using ontological analysis and tools like nanopublications, the authors propose reducing ambiguity for both humans and machines. The main barrier is conceptual, not technological, with implications for more effective FAIR data environments.",The paper’s main objective is to enable fully AI-ready FAIR Digital Twins by clarifying foundational concepts; its key method is ontological analysis to define precise real-world semantics; the principal finding is that precise semantic definitions are essential for both machine and human scientific communication.,No information available,1.000,exact_title
science_2022,Knowledge graph construction for computer networking course group in secondary vocational school based on multi-source heterogeneous data,"Information Science, Shandong Normal, University Jinan, Jingdong Bookstore, Baidu Encyclopedia, In Jingdong, Content Introduction, Author Introduction, Computer Network",2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Addresses rapid knowledge updates in computer domains; integrates theoretical and practical learning; uses SmartKG tool for knowledge storage and visualization.,Educational knowledge graph construction from multiple heterogeneous data sources for computer networking courses using keyword and relationship extraction techniques.,This paper constructs a knowledge graph for computer networking courses in secondary vocational schools by integrating multi-source heterogeneous data to address challenges in computer science education and bridge theoretical-practical knowledge gaps.,How can knowledge graphs constructed from multi-source heterogeneous data improve computer science education by integrating theoretical and practical knowledge?,"Used data acquisition from multiple heterogeneous sources, keyword extraction techniques, relationship extraction, and SmartKG tool for knowledge storage and visualization.",Provides new ideas for teaching computer courses and helps cultivate high-quality skilled talents by integrating theoretical and practical knowledge more effectively.,,Abstract only - detailed evaluation of educational effectiveness and scalability not available.,Demonstrates practical application of KG construction from heterogeneous data sources in educational domain.,,"Evaluate educational effectiveness, expand to other technical subjects, assess student learning outcomes.",Provides practical example of heterogeneous data integration for knowledge graph construction relevant to HDM system design.,https://ieeexplore.ieee.org/document/10086288/,10.1109/ITME56794.2022.00031,"educational-technology, heterogeneous-data, knowledge-graph-construction, smartkg",Knowledge graph construction for computer networking course group in secondary vocational school based on multi-source heterogeneous data,"Li Gang, Wang Hong, Liu Hong",2022,reference-manager,10.1109/itme56794.2022.00031,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
sciences_2019,Computers and Geosciences,"- NASEM (National Academies of Sciences, Engineering, Medicine), 2020. A Vision for NSF Earth Sciences 2020-2030: Earth in Time. The National Academies Press, Washington, DC, p. 172. [https://doi.org/10.17226/25761.](https://doi.org/10.17226/25761",2019,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on computers and geosciences providing insights for knowledge graph development and data integration.,"This 2019 paper by - NASEM (National Academies of Sciences, Engineering, Medicine), 2020. A Vision for NSF Earth Sciences 2020-2030: Earth in Time. The National Academies Press, Washington, DC, p. 172. [https://doi.org/10.17226/25761.](https://doi.org/10.17226/25761 explores computers and geosciences. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.cageo.2022.105082,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
seneviratne_2021,Personal Health Knowledge Graph for Clinically Relevant Diet Recommendations,"Oshani Seneviratne, Jonathan Harris, Hua Chen",2021,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on personal health knowledge graph for clinically relevant diet recommendations providing insights for knowledge graph development and data integration.,"This 2021 paper by Oshani Seneviratne, Jonathan Harris, Hua Chen explores personal health knowledge graph for clinically relevant diet recommendations. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.2337/dc20-Sint.,"data-integration, healthcare, knowledge-graph, personal-knowledge",,,,,,,,,,,,,,,,,,,
seo_2020,Structural Quality Metrics to Evaluate Knowledge Graph Quality,"Sumin Seo, Heeseon Cheon, Hyunho Kim, Dongseok Hyun",2020,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on structural quality metrics to evaluate knowledge graph quality providing insights for knowledge graph development and data integration.,"This 2020 paper by Sumin Seo, Heeseon Cheon, Hyunho Kim, Dongseok Hyun explores structural quality metrics to evaluate knowledge graph quality. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1007/978-3-540-76298-0_52,"data-integration, knowledge-graph",Structural Quality Metrics to Evaluate Knowledge Graph Quality,"Seo Sumin, Cheon Heeseon, Kim Hyunho, Hyun Dongseok",2022,reference-manager,,,"The paper proposes six structural quality metrics to evaluate knowledge graphs: Instantiated Class Ratio, Instantiated Property Ratio, Class Instantiation, Subclass Property Acquisition, Subclass Property Instantiation, and Inverse Multiple Inheritance. These metrics reveal that a detailed ontology and high instantiation indicate higher quality, beyond just graph size.",,,,"Structure-based evaluation: Assesses knowledge graphs using metrics reflecting structure or statistical properties, such as schema, class, graph, and complexity metrics.",,,How can structural quality metrics be used to numerically evaluate and compare the internal quality of cross-domain knowledge graphs based on their ontology structure and usage?,"This paper aims to define what makes a """"good knowledge graph"""" and introduces six structural quality metrics to numerically evaluate internal quality. Using these metrics, the study compares major web-based and Naver’s knowledge graphs, revealing characteristics not captured by traditional size-based indicators.","The research goal is to define and quantify """"good knowledge graph"""" quality; the approach introduces a structural quality metric focusing on ontology structure rather than just size or data distribution; the principal finding is that this metric enables more meaningful comparison of knowledge graphs' internal quality.","Keywords or tags for this research include: data driven evaluation, application/task based evaluation, user based evaluation, structure based evaluation, data quality evaluation, knowledge graphs, ontology, schema metric, class metric, property metric, graph metric, data quality, DBpedia, Wikidata, YAGO, Google Knowledge Graph, Freebase.",1.000,exact_title
seo_2022,Platform Development for Proof-of-Concept of Smartphone-based Continuous Complex Positioning,"Seonghun Seo, Kyunghyun Park, Daesub Yoon, JaeJun Yoo, Yonghyun Kim, Yangkoo Lee, Jiwoo Han",2022,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on platform development for proof-of-concept of smartphone-based continuous complex positioning providing insights for knowledge graph development and data integration.,"This 2022 paper by Seonghun Seo, Kyunghyun Park, Daesub Yoon, JaeJun Yoo, Yonghyun Kim, Yangkoo Lee, Jiwoo Han explores platform development for proof-of-concept of smartphone-based continuous complex positioning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Platform Development for Proof-of-Concept of Smartphone-based Continuous Complex Positioning,"Seo Seonghun, Yoo JaeJun, Lee Yangkoo, Park Kyunghyun, Kim Yonghyun, Han Jiwoo, Yoon Daesub",2024,reference-manager,10.1109/ictc62082.2024.10827363,,,,,,,,,,,,"Keywords—seamless positioning, smartphones, GNSS, Wi-Fi, BLE, IMU",1.000,exact_title
sesana_2024,New generation Energy Performance Certificate: development and application in an Italian case study as an EU proof of concept,"Marta Maria Sesana, Ilaria Isacco",2024,Yes,LOW,"While focused on energy performance certificates for buildings, has minimal relevance to PKG/HDM systems. The paper addresses building decarbonization efforts not personal knowledge management.",Explores new generation of Energy Performance Certificates (EPC) for residential buildings to overcome current barriers in EPC procedures across Europe and align with EU Green Deal climate neutrality goals.,Development of improved Energy Performance Certificate methodology for building,"This paper explores a new generation of Energy Performance Certificates (EPC) for residential buildings, aiming to overcome current barriers in EPC procedures across Europe and align with EU Green Deal climate neutrality goals.",How can the Energy Performance Certificate be improved to better support building decarbonization efforts?,Testing a new EPC methodology by comparing it with standard national procedures in different EU partner countries and applying it to an Italian case study.,The work aims to prove the applicability and potential of an innovative EPC approach by providing a clear assessment methodology.,Proof of concept for new generation Energy Performance Certificate methodology applied to Italian case study.,Not explicitly stated in the abstract; focused on building energy assessment rather than knowledge management.,Demonstrates innovative approach to energy performance assessment but limited relevance to personal knowledge graphs or HDM systems.,Expand methodology to broader building types; integrate with digital twin technologies for real-time monitoring.,Further validation across different EU countries; development of standardized implementation guidelines.,"Agent Alpha: While interesting for building assessment, this paper has minimal relevance to PKG/HDM development and should be given lower priority.",https://www.e3s-conferences.org/10.1051/e3sconf/202452306001,10.1051/e3sconf/202452306001,"building-decarbonization, energy-efficiency, energy-performance-certificate, eu-green-deal",New generation Energy Performance Certificate: Development and application in an Italian case study as an EU proof of concept,"Salvalai Graziano, Sesana Marta Maria, Isacco Ilaria",2024,reference-manager,10.1051/e3sconf/202452306001,,,,,,Application of eight Evaluation Strategies: Each case study used one of eight strategies based on its characteristics and preliminary data analysis to assess the EPC RECAST approach.,,,"How does the EPC RECAST testing method compare the standard national EPC procedure with the new generation EPC in terms of user-friendliness, reliability, and effectiveness for building energy performance assessment and renovation roadmap creation?","The paper aims to verify the user-friendliness and reliability of the EPC RECAST methodology for energy performance assessment. Using case studies across six EU countries, it benchmarks a new generation EPC process against standard procedures. Results highlight applicability and improvement potential, concluding the method is effective and reliable.","The research goal is to verify the user-friendliness and reliability of the EPC RECAST methodology by benchmarking it against standard national EPC procedures using case studies in six EU countries; the approach involves multi-step testing and comparative evaluation, and results highlight the methodology's applicability and potential for improvement.",,1.000,exact_title
shaik_2024,"S3LLM: Large-Scale Scientific Software Understanding with LLMs using Source,Metadata, and Document","Kareem Shaik, Dali Wang, Weijian Zheng, Qinglei Cao, Heng Fan, Peter Schwartz, Yunhe Feng",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on s3llm: large-scale scientific software understanding with llms using source,metadata, and document providing insights for knowledge graph development and data integration.","This 2024 paper by Kareem Shaik, Dali Wang, Weijian Zheng, Qinglei Cao, Heng Fan, Peter Schwartz, Yunhe Feng explores s3llm: large-scale scientific software understanding with llms using source,metadata, and document. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
shao_2023,StreamE: Lightweight Updates of Representations for Temporal Knowledge Graphs in Streaming Scenarios,"Jie Shao, Jiasheng Zhang",2023,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on streame: lightweight updates of representations for temporal knowledge graphs in streaming scenarios providing insights for knowledge graph development and data integration.,"This 2023 paper by Jie Shao, Jiasheng Zhang explores streame: lightweight updates of representations for temporal knowledge graphs in streaming scenarios. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3539618.3591772,"data-integration, knowledge-graph, temporal-data",StreamE: Lightweight Updates of Representations for Temporal Knowledge Graphs in Streaming Scenarios,"Zhang Jiasheng, Shao Jie, Cui Bin",2023,reference-manager,10.1145/3539618.3591772,,,,,,"Inductive forecasting task: Predicts future knowledge for unseen entities using observed knowledge, evaluating with mean reciprocal rank (MRR) and Hit@k metrics.",,,How can the proposed StreamE framework effectively forecast future knowledge in temporal knowledge graphs by modeling both direct and propagated influence of newly arriving knowledge on entity representations?,"The paper proposes StreamE, a framework for inductive forecasting of future knowledge for unseen entities. Using entity representation as memory, StreamE outperforms baselines on four datasets, achieving up to 16.7% higher mean reciprocal rank. The study demonstrates StreamE's robustness and effectiveness through ablation and hyperparameter analysis.","The research goal is to improve inductive forecasting on temporal knowledge graphs; the approach is StreamE, which uses entity representations as memory and a propagation unit to model knowledge influence; results show StreamE outperforms baselines by up to 16.7% on key metrics, demonstrating superior robustness and accuracy.",,1.000,exact_title
shen_2020,Networking Architecture and Key Supporting Technologies for Human Digital Twin in Personalized Healthcare: A Comprehensive Survey,"Xuemin (Sherman) Shen, Fellow, IEEE",2020,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on networking architecture and key supporting technologies for human digital twin in personalized healthcare: a comprehensive survey providing insights for knowledge graph development and data integration.,"This 2020 paper by Xuemin (Sherman) Shen, Fellow, IEEE explores networking architecture and key supporting technologies for human digital twin in personalized healthcare: a comprehensive survey. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, healthcare, knowledge-graph, personal-knowledge",Networking Architecture and Key Supporting Technologies for Human Digital Twin in Personalized Healthcare: A Comprehensive Survey,"Chen Jiayuan, Yi Changyan, Okegbile Samuel D., Cai Jun, Shen Xuemin",2023,reference-manager,,,"Implementation Insights focus on data cleaning, outlier detection, imputation, feature selection, data fusion, storage, and security. New insights include the superiority of deep learning-based imputation for discrete data and the need for novel resource allocation and incentive mechanisms in edge-cloud HDT environments to address computational and privacy challenges.",,,,Comprehensive literature survey: The study reviews existing research on Human Digital Twin (HDT) and networking architecture in personalized healthcare (PH) applications.,,,"What are the key networking architectures and supporting technologies required to enable human digital twin (HDT) systems for personalized healthcare (PH) applications, and how do these differ from conventional digital twin approaches in addressing current healthcare challenges?","This paper surveys the networking architecture and key technologies for Human Digital Twin (HDT) in Personalized Healthcare (PH) applications. Using a comprehensive literature review, it analyzes design requirements, challenges, and a five-layered architecture. Key findings highlight enhanced security, privacy, and future research directions for HDT in PH.","The research goal is to survey the networking architecture and key technologies for human digital twin (HDT) in personalized healthcare (PH); the approach is a comprehensive review and analysis of HDT frameworks, layers, and enabling technologies; the principal finding is a detailed guideline and future directions for HDT networking in PH.","Keywords or tags for this research include: Human digital twin, personalized healthcare, artificial intelligence, reinforcement learning, federated learning, networking architecture, life-cycle data management, pervasive sensing, on-body communications, tactile Internet, semantic communications, multi-access edge computing, edge-cloud collaboration, blockchain, Metaverse.",1.000,exact_title
shen_2021,Deriving Design Knowledge Graph for Complex Sociotechnical Systems Using the AIA Design Thinking,"Tao Shen, Chan Gao, Yukari Nagai, Wei Ou",2021,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on deriving design knowledge graph for complex sociotechnical systems using the aia design thinking providing insights for knowledge graph development and data integration.,"This 2021 paper by Tao Shen, Chan Gao, Yukari Nagai, Wei Ou explores deriving design knowledge graph for complex sociotechnical systems using the aia design thinking. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Deriving Design Knowledge Graph for Complex Sociotechnical Systems Using the AIA Design Thinking,"Shen Tao, Gao Chan, Nagai Yukari, Ou Wei",2021,reference-manager,10.1155/2021/6416061,,,,,,Experiment: Participants were divided into two groups to design ideas for sustainable communities using either a knowledge graph with the AIA design thinking framework or a traditional knowledge graph.,,,How can an integrated approach using the AIA design thinking framework and knowledge graph construction technology support idea generation and improve design outcomes for complex sociotechnical systems?,"The paper aims to develop an integrated approach for structuring a design knowledge graph using the AIA design thinking framework to support idea generation in complex sociotechnical systems. Through a controlled experiment with 28 design students, results show improved idea quality and idea space extension compared to traditional methods.",The research goal is to support idea generation for complex sociotechnical systems; the approach integrates a design knowledge graph using the AIA design thinking framework; results show this method improves idea space extension and idea quality compared to traditional knowledge graphs.,,1.000,exact_title
shimizu_2021,An Ontology Design Pattern for Role-Dependent Names,"Cogan Shimizu, Pascal Hitzler",2021,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on an ontology design pattern for role-dependent names providing insights for knowledge graph development and data integration.,"This 2021 paper by Cogan Shimizu, Pascal Hitzler explores an ontology design pattern for role-dependent names. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1007/978-3-030-77385-4,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
shirai_2021,Applying Personal Knowledge Graphs to Health,"Sola Shirai, Oshani Seneviratne, Deborah L. McGuinness",2021,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","\""Personal health knowledge graphs (PHKG) can help enable personalized health care\"" but development of PHKGs remains \""under-explored\"".",Short survey identifying challenges in personal health knowledge graph development and applications.,"This paper conducts a short survey of existing work on personal knowledge graphs in healthcare, finding that personal health knowledge graphs can enable personalized healthcare but their development remains under-explored.",How can personal health knowledge graphs enable personalized healthcare in knowledge-driven systems?,Short survey of existing work on personal knowledge graphs in healthcare.,"Challenges in collecting personal health knowledge, difficulties in linking and maintaining personal health information, limited exploration of PHKG paradigms.",,"\""A range of challenges surrounding the collection, linkage, and maintenance of personal health knowledge remains to be addressed to fully realize PHKGs.\",Emphasizes the potential of PHKGs for personalized healthcare while acknowledging significant development challenges.,,"Develop more robust methods for personal health knowledge graph creation, address challenges in data integration and maintenance, explore personalization techniques in healthcare knowledge systems.","Provides roadmap for healthcare PKG development focusing on data collection, linkage, and maintenance challenges.",https://arxiv.org/abs/2104.07587,10.48550/arXiv.2104.07587,"healthcare-ai, knowledge-graph, personal-health-knowledge-graphs, personal-knowledge-graph, personalized-healthcare",Applying Personal Knowledge Graphs to Health,"Shirai Sola, Seneviratne Oshani, McGuinness Deborah L.",2021,reference-manager,,,"Implementation Insights highlight that PHKGs (Personal Health Knowledge Graphs) face challenges in update timing, privacy, and maintenance. Trade-offs exist between up-to-date patient knowledge and privacy. New insights: PHKGs require solutions for structuring, collecting, and linking personal health data while ensuring privacy and practical access. No concrete PHKG implementations exist yet.",,,,"Collection and storage of personal health knowledge: Developing infrastructure to gather and process data from various sources, ensuring privacy and consistent storage.",,,"How can personal health knowledge graphs (PHKGs) be effectively developed, linked, and maintained to enable personalized, knowledge-driven decision-making in health care while addressing challenges of data collection, integration, and privacy?","The paper explores the concept of Personal Health Knowledge Graphs (PHKGs) for personalized healthcare. It reviews existing work, highlights challenges in collecting, linking, and maintaining personal health data, and concludes that significant research is needed to develop PHKGs for effective, privacy-respecting, knowledge-driven healthcare decision-making tools.","The paper's research goal is to explore the use of personal health knowledge graphs (PHKGs) for personalized, knowledge-driven healthcare; its approach is a review of existing work and identification of key challenges; the principal finding is that significant research is needed to address collection, linkage, and privacy issues for effective PHKG implementation.",,1.000,exact_title
singhal_2019,Procreation of training data using cognitive science in temporal data processing for burnt paddy fields mapping,"Mragank Singhal, Ashish Payal, Anil Kumar",2019,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on procreation of training data using cognitive science in temporal data processing for burnt paddy fields mapping providing insights for knowledge graph development and data integration.,"This 2019 paper by Mragank Singhal, Ashish Payal, Anil Kumar explores procreation of training data using cognitive science in temporal data processing for burnt paddy fields mapping. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.rsase.2021.100516,"data-integration, knowledge-graph, temporal-data",Procreation of training data using cognitive science in temporal data processing for burnt paddy fields mapping,"Singhal Mragank, Payal Ashish, Kumar Anil",2021,reference-manager,10.1016/j.rsase.2021.100516,,"The implementation used cognitive science to generate training data for temporal datasets, enabling mapping of burnt paddy fields using the Modified Possibilistic c-Means (MPCM) algorithm. The approach achieved 98% overall accuracy and an F-Score of 0.96, with minimal differences between training and testing membership values.",,,,"Cognitive science-based methodology was used to generate and expand training data from temporal datasets, utilizing field-collected geo-tagged samples.",,,"How can cognitive science be applied to generate training data for future or past temporal data sets to improve the mapping accuracy of MPCM classifiers in identifying frequently occurring classes, such as paddy stubble burnt fields, using remote sensing imagery?","The paper investigates using cognitive science to generate training data for temporal datasets in mapping burnt paddy fields. Using seed data from field visits, the study applies cognitive science principles and the Modified Possibilistic c-Means (MPCM) algorithm, achieving 98% overall accuracy and an F-Score of 0.96.",The research goal was to use cognitive science to generate temporal training datasets for MPCM classifiers; the approach involved using seed training data and Class-Based Sensor-Independent Indices (CBSI); results showed 98% overall accuracy and an F-Score of 0.96 in mapping burnt paddy fields.,"Keywords: Cognitive science, Soft classification, Modified possibilistic c-means",1.000,exact_title
skjveland_2024,An Ecosystem for Personal Knowledge Graphs: A Survey and Research Roadmap,"Martin G. Skjæveland, Krisztian Balog, Nolwenn Bernard, Weronika Łajewska, Trond Linjordet",2024,Yes,HIGH,Provides foundational research for understanding personal knowledge graph ecosystems and their potential for HDM systems.,"PKGs are ""resources of structured information about entities related to an individual"" with emphasis on data ownership by a single individual and delivery of personalized services.",Comprehensive survey that establishes PKG definitions and ecosystem components,"This paper provides a comprehensive understanding of Personal Knowledge Graphs (PKGs), their ecosystem, challenges, and potential for personalized services. It proposes a unified framework for PKGs and maps existing work into the proposed ecosystem.",How can Personal Knowledge Graphs be developed to unlock their full potential for personalized services?,"Proposed a unified framework for PKGs, conducted comprehensive survey of existing work, and mapped surveyed work into proposed ecosystem.",Multiple interpretations of PKG exist; holistic view needed to unlock full potential; proposed ecosystem with clear interfaces to data services/sources.,Unified PKG framework and comprehensive ecosystem mapping for personalized services.,"Challenges in defining precise PKG boundaries, population of knowledge graphs, representation and management, effective utilization of personal data.",Provides foundational research establishing PKG definitions and ecosystem requirements for personalized applications.,"Need for more sophisticated PKG interfaces, personalization techniques, addressing data privacy and ownership concerns.","Develop more sophisticated PKG interfaces, explore personalization techniques, address data privacy and ownership concerns.",Framework provides clear architectural guidance for PKG implementation with focus on user data ownership and service personalization.,https://arxiv.org/abs/2304.09572,10.1016/j.aiopen.2024.01.003,"ai-research, data-management, knowledge-representation, personal-knowledge-graph, personalization",An ecosystem for personal knowledge graphs: A survey and research roadmap,"Skjæveland Martin G., Balog Krisztian, Bernard Nolwenn, Łajewska Weronika, Linjordet Trond",2024,reference-manager,10.1016/j.aiopen.2024.01.003,,"The paper surveys personal knowledge graphs (PKGs), highlighting gaps and challenges in practical deployment. Key insights include: lack of consensus on PKG definition, need for holistic ecosystem approaches, and difficulty integrating existing components. The authors propose a new PKG definition emphasizing individual data ownership and personalized services.",,,,Comprehensive survey: The study systematically reviews and synthesizes existing research on personal knowledge graphs (PKGs).,,,"How can the challenges of constructing, populating, and managing Personal Knowledge Graphs (PKGs) from diverse and unstructured data sources be addressed to enable effective integration, standardization, and adoption within a PKG ecosystem?","The paper surveys current research on personal knowledge graphs (PKGs), aiming to clarify definitions, identify challenges, and propose a unifying architecture. It highlights gaps in holistic approaches, emphasizes data ownership and personalized services, and notes difficulties in integrating PKG components. Establishing standards and adoption remain key challenges.","The research goal is to survey and synthesize work on personal knowledge graphs (PKGs); the approach is a comprehensive literature review focusing on population, representation, and utilization; the principal finding is a lack of consensus on PKG definitions and the need for holistic, integrated solutions.",,1.000,exact_title
software_2023,Defining a Knowledge Graph Development Process Through a Systematic Review,CCS Concepts: • Software,2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on defining a knowledge graph development process through a systematic review providing insights for knowledge graph development and data integration.,"This 2023 paper by CCS Concepts: • Software explores defining a knowledge graph development process through a systematic review. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3522586,"data-integration, knowledge-graph",Defining a Knowledge Graph Development Process Through a Systematic Review,"Tamašauskaitė Gytė, Groth Paul",2023,reference-manager,10.1145/3522586,,"The Implementation Insights highlight the need for more industry case studies, expert evaluations, and comparisons with existing methodologies. Most literature focuses on initial knowledge graph development, not continuous updates. The proposed process offers a structured, evidence-based framework, but its validity is limited by article selection and research design.",,,,"Systematic review: The study conducted a systematic review of literature on knowledge graph development processes, following PRISMA guidelines for transparency.",,,"What are the main steps in the knowledge graph development process, how are they interrelated, and to what extent can the proposed unified process be applied and generalized across different contexts and populations?","The paper systematically reviews knowledge graph development processes, synthesizing them into an evidence-based, structured framework. Using PRISMA guidelines, it identifies six main steps: data identification, ontology construction, knowledge extraction and processing, graph construction, and maintenance. The study concludes with recommendations for future research and practical evaluation.","The research goal was to synthesize and structure knowledge graph development processes through a systematic review; the approach involved conceptual analysis of literature workflows, resulting in an evidence-based framework that unifies key steps and guides researchers and practitioners in constructing and managing knowledge graphs.",,1.000,exact_title
song_2019,Temporal reasoning for timeline summarisation in social media,"Jiayu Song, Mahmud Akhter, Maria Liakata",2019,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on temporal reasoning for timeline summarisation in social media providing insights for knowledge graph development and data integration.,"This 2019 paper by Jiayu Song, Mahmud Akhter, Maria Liakata explores temporal reasoning for timeline summarisation in social media. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3115/V1/P14-2082,"data-integration, knowledge-graph, temporal-data",Temporal reasoning for timeline summarisation in social media,"Song Jiayu, Akhter Mahmud, Atzil-Slonim Dana, Liakata Maria",2025,reference-manager,,,,,,,Knowledge Distillation (KD): Temporal reasoning knowledge is transferred from a teacher model (LLaMA-3 or Phi) to a smaller student model (Phi) for timeline summarization.,,,How can temporal reasoning knowledge be effectively transferred to large language models to improve the generation of accurate and comprehensive mental health-related timeline summaries from social media data?,"The paper investigates enhancing mental health timeline summarization by combining temporal reasoning with large language models (LLMs). Using knowledge distillation and fine-tuning, the L-Phi model outperformed others in factual consistency and usefulness, reducing hallucinations. Human evaluators preferred L-Phi summaries, highlighting the benefit of distilling knowledge from larger models.","The research goal is to improve mental health timeline summarization by combining temporal reasoning with knowledge distillation; the approach fine-tunes a teacher model on temporal reasoning, distills this knowledge into a student model, and results show L-Phi achieves the highest factual consistency and usefulness, reducing hallucinations in summaries.",,1.000,exact_title
sowi_2020,Overview of Current Challenges in Multi-Architecture Software Engineering and a Vision for the Future,Piotr Sowi,2020,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on overview of current challenges in multi-architecture software engineering and a vision for the future providing insights for knowledge graph development and data integration.,"This 2020 paper by Piotr Sowi explores overview of current challenges in multi-architecture software engineering and a vision for the future. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1007/978-3-540-92913-0,"data-integration, knowledge-graph",Overview of Current Challenges in Multi-Architecture Software Engineering and a Vision for the Future,"Sowiński Piotr, Lacalle Ignacio, Vaño Rafael, Palau Carlos E., Ganzha Maria, Paprzycki Marcin",2024,reference-manager,,,,,,,"Use of knowledge graphs for representing use case logic and requirements, aiding explainability in machine learning.",,,"How can a holistic, ontology-based system leveraging AI, autonomy, and knowledge representation accelerate and automate software engineering tasks for multi-architecture applications across all stages of the software lifecycle?","The paper addresses challenges in developing multi-architecture applications, accelerating and automating software engineering (SE) processes, and software modeling. It proposes a comprehensive system architecture using WebAssembly, AI, and knowledge representation to automate SE tasks across the software lifecycle, aiming for a paradigm shift in next-generation software development.","The research goal is to address challenges in multi-architecture applications, software engineering process automation, and software modeling by proposing a unified system architecture using WebAssembly; the approach leverages AI and knowledge representation, and the principal finding is its potential to transform next-generation software development.",,1.000,exact_title
spens_2023,nature human behaviour,"Eleanor Spens, Neil Burgess",2023,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on nature human behaviour providing insights for knowledge graph development and data integration.,"This 2023 paper by Eleanor Spens, Neil Burgess explores nature human behaviour. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1038/s41562-023-01799-z,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
storage_2023,Blind Multimodal Quality Assessment of Low-Light Images,"Storage, transmission",2023,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on blind multimodal quality assessment of low-light images providing insights for knowledge graph development and data integration.,"This 2023 paper by Storage, transmission explores blind multimodal quality assessment of low-light images. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Blind Multimodal Quality Assessment of Low-Light Images,"Wang Miaohui, Xu Zhuowei, Xu Mai, Lin Weisi",2024,reference-manager,10.1007/s11263-024-02239-9,,,,,Subjectivity and variability in verbal descriptions hinder standardized assessment.,,,"The datasets are available upon reasonable request and at https://charwill.github.io/bmqa.html. There is no mention of source code availability. For Xiang2020TMM, the authors used their own re-implementation due to unavailable official code. No further information on code reproducibility is provided.","How can QSD-based text descriptions, guided by human visual perception principles, be used to assess and analyze the relationship between image quality attributes (such as luminance and content) and subjective quality scores in low-light images?",,"The research goal is to develop a verbal description paradigm for low-light image quality, using quality semantic description (QSD) principles; the approach collects and analyzes 3,600 human-generated text descriptions focusing on perceptual attributes, and the results show strong correlations between text features (like luminance) and image quality scores.",,1.000,exact_title
su_2024,Temporal Knowledge Graph Question Answering: A Survey,"Miao Su, Zixuan Li, Zhuo Chen, Long Bai, Xiaolong Jin, Jiafeng Guo",2024,Yes,HIGH,Comprehensive survey of TKGQA methods providing taxonomy and systematic categorization essential for understanding temporal aspects of PKG/HDM systems,Ambiguities in temporal question definition need resolution; Systematic categorization of TKGQA methods reveals semantic parsing vs embedding approaches; Temporal dynamics crucial for evolving knowledge bases,A systematic survey exploring methodological approaches and taxonomies in Temporal Knowledge Graph Question Answering,"The paper addresses the emerging field of Temporal Knowledge Graph Question Answering (TKGQA), which focuses on answering questions within evolving knowledge bases. By establishing a comprehensive taxonomy of temporal questions and reviewing existing methodological approaches, the research aims to provide clarity and structure to this nascent domain. The survey critically examines two primary methodological approaches: semantic parsing-based and TKG embedding-based techniques, highlighting the field's current challenges and potential future research directions.",Understanding and systematically categorizing approaches to answering temporal questions in knowledge graphs,Established taxonomy of temporal questions; Comprehensive review of TKGQA techniques; Two primary method categories: semantic parsing-based and TKG embedding-based,Identified ambiguities in defining temporal questions; Lack of systematic categorization in existing TKGQA methods,Detailed taxonomy of temporal questions; Comprehensive review of TKGQA techniques; Potential research directions for advancing TKGQA,Not explicitly stated in available metadata,Aims to serve as a comprehensive reference for TKGQA and to stimulate further research,Ambiguities in temporal question definition; Lack of systematic method categorization,Outlined potential research directions to advance TKGQA field,Need for systematic approaches to temporal question handling; Importance of capturing temporal dynamics in knowledge representation,https://arxiv.org/abs/2406.14191,https://doi.org/10.48550/arXiv.2406.14191,"semantic-parsing, taxonomy, temporal-questions, tkg-embeddings, tkgqa-survey",Temporal Knowledge Graph Question Answering: A Survey,"Su Miao, Li Zixuan, Chen Zhuo, Bai Long, Jin Xiaolong, Guo Jiafeng",2025,reference-manager,,,,,,Finer-grained granularities are underexplored.,,,,,,"The paper’s main objective is to provide a comprehensive survey of Temporal Knowledge Graph Question Answering (TKGQA), systematically categorizing temporal question types and TKGQA methods, and concludes by identifying research gaps and future directions to stimulate further innovation in the field.",,1.000,exact_title
sun_2024a,Knowledge Graph Tuning: Real-time Large Language Model Personalization,"Jingwei Sun, Zhixu Du, Yiran Chen",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","\""KGT offers effective, efficient, and interpretable real-time LLM personalization during user interactions\"" without requiring back-propagation, significantly reducing computational costs while maintaining performance.","Innovative approach that personalizes LLMs through knowledge graph optimization rather than model parameter modification, enabling efficient real-time adaptation.","This paper proposes Knowledge Graph Tuning (KGT), a novel approach for real-time LLM personalization that extracts personalized factual knowledge triples from user interactions and optimizes knowledge graphs without modifying LLM parameters.",How can LLMs be personalized in real-time based on user feedback without high computational costs of traditional fine-tuning approaches?,"Developed KGT framework that extracts personalized knowledge triples, optimizes knowledge graphs without back-propagation, tested with GPT-2, Llama2, and Llama3.",Demonstrated significant improvements in personalization performance with reduced latency and lower GPU memory consumption compared to traditional fine-tuning methods.,,Traditional personalization methods require expensive back-propagation; need for more extensive evaluation across diverse domains.,"Provides breakthrough solution for efficient, interpretable real-time LLM personalization through knowledge graph optimization.",,Extend approach to multi-modal knowledge graphs; develop adaptive knowledge extraction mechanisms; explore integration with federated learning.,Offers practical implementation framework for real-time personalization with significant computational efficiency gains applicable to personal HDM systems.,https://arxiv.org/abs/2405.19686,10.48550/arXiv.2405.19686,"efficient-computing, hdm-systems, knowledge-graph-tuning, llm, real-time-personalization",Knowledge Graph Tuning: Real-time Large Language Model Personalization based on Human Feedback,"Sun Jingwei, Du Zhixu, Chen Yiran",2024,reference-manager,,,Implementation Insights Summary:,,,,,,,,,,,0.900,fuzzy_title
sun_2025,TimelineKGQA: A Comprehensive Question-Answer Pair Generator for Temporal Knowledge Graphs,Qiang Sun,2025,Yes,HIGH,"Addresses temporal knowledge graph question answering through comprehensive QA pair generation, directly relevant to HDM systems requiring sophisticated temporal query capabilities and understanding of evolving facts and relationships over time","Proposes novel categorization framework based on timeline-context relationships and develops TimelineKGQA as universal temporal QA generator applicable to any temporal knowledge graphs, addressing limited datasets and difficulties in generating custom QA pairs",Universal temporal question-answer pair generator for temporal knowledge graphs,"This paper addresses challenges in question answering over temporal knowledge graphs (TKGs), specifically the limited datasets and difficulties in generating custom QA pairs. The research proposes a novel categorization framework based on timeline-context relationships and develops TimelineKGQA, a universal temporal QA generator applicable to any TKGs. The approach provides a generalizable method for generating question-answer pairs in temporal knowledge graphs, potentially improving understanding of evolving facts and relationships while offering an open-source Python package for practical implementation.",How can comprehensive question-answer pair generation be achieved for temporal knowledge graphs to improve understanding of evolving facts and relationships over time?,Novel categorization framework based on timeline-context relationships; development of TimelineKGQA universal temporal QA generator; comprehensive evaluation across multiple temporal knowledge graph datasets; open-source Python package implementation,Created comprehensive approach to generating question-answer pairs for temporal knowledge graphs; developed universal temporal QA generator applicable to any TKGs; provided generalizable method for temporal knowledge graph question answering,Universal temporal QA generation framework; timeline-context relationship categorization system; open-source Python package for temporal knowledge graph question answering; generalizable methodology for temporal fact understanding,Limited details on evaluation metrics and performance comparisons; scalability considerations for large temporal knowledge graphs not fully characterized; specific temporal reasoning capabilities not extensively detailed,Provides generalizable method for generating question-answer pairs in temporal knowledge graphs with potential to significantly improve understanding of evolving facts and relationships,Limited datasets for temporal knowledge graph question answering; difficulties in generating custom QA pairs for temporal contexts; challenges in understanding evolving facts and relationships over time,Expand evaluation to larger and more diverse temporal knowledge graphs; develop advanced temporal reasoning capabilities; investigate integration with real-time temporal data sources,Provides practical open-source framework for temporal knowledge graph question answering essential for HDM systems requiring sophisticated temporal query and understanding capabilities,https://arxiv.org/abs/2501.04343,arXiv:2501.04343,"open-source-tools, question-answering, temporal-knowledge-graph, temporal-reasoning, timeline-analysis",TimelineKGQA: A Comprehensive Question-Answer Pair Generator for Temporal Knowledge Graphs,"Sun Qiang, Li Sirui, Huynh Du, Reynolds Mark, Liu Wei",2025,reference-manager,10.1145/3701716.3715308,,,,,,,,,,,,"knowledge graph, temporal knowledge graph, question answering",1.000,exact_title
szekely_2014,Building and Using a Knowledge Graph to Combat Human Trafficking,"Pedro Szekely, Craig A. Knoblock, Jason Slepicka, Andrew Philpot, Amandeep Singh, Chengye Yin, Dipsy Kapoor, Prem Natarajan, Daniel Marcu, Kevin Knight, David Stallard, Subessware S. Karunamoorthy, Rajagopal Bojanapalli, Steven Minton, Brian Amanatullah, Todd Hughes, Mike Tamayo, David Flynt, Rachel Artiss, Fu Chang, Tao Chen, Gerald Hiebel, Lidia Ferreira",2014,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on building and using a knowledge graph to combat human trafficking providing insights for knowledge graph development and data integration.,"This 2014 paper by Pedro Szekely, Craig A. Knoblock, Jason Slepicka, Andrew Philpot, Amandeep Singh, Chengye Yin, Dipsy Kapoor, Prem Natarajan, Daniel Marcu, Kevin Knight, David Stallard, Subessware S. Karunamoorthy, Rajagopal Bojanapalli, Steven Minton, Brian Amanatullah, Todd Hughes, Mike Tamayo, David Flynt, Rachel Artiss, Fu Chang, Tao Chen, Gerald Hiebel, Lidia Ferreira explores building and using a knowledge graph to combat human trafficking. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1007/s00778-008-0098-x,"data-integration, knowledge-graph",Building and Using a Knowledge Graph to Combat Human Trafficking,"Szekely Pedro, Knoblock Craig A., Slepicka Jason, Philpot Andrew, Singh Amandeep, Yin Chengye, Kapoor Dipsy, Natarajan Prem, Marcu Daniel, Knight Kevin, Stallard David, Karunamoorthy Subessware S., Bojanapalli Rajagopal, Minton Steven, Amanatullah Brian, Hughes Todd, Tamayo Mike, Flynt David, Artiss Rachel, Chang Shih-Fu, Chen Tao, Hiebel Gerald, Ferreira Lidia",2023,reference-manager,,,,,,,Data acquisition using Apache Nutch to crawl and extract information from relevant web pages at scale.,,,"How can Semantic Web technologies be used to build scalable, high-quality knowledge graphs that integrate heterogeneous data sources to support combating human trafficking?","The paper presents the DIG system, which uses Semantic Web technologies to build a knowledge graph for combating human trafficking. Using a common ontology and tools like Karma, it integrates diverse data sources, enabling large-scale, provenance-rich analysis. The approach is scalable and adaptable to other domains beyond human trafficking.","The research goal is to rapidly build knowledge graphs for domains like human trafficking using Semantic Web technologies; the approach integrates diverse data sources into a common ontology with tools like Karma; the principal finding is that this method enables scalable, flexible knowledge graph construction for complex problem-solving.",,1.000,exact_title
tan_2020,Multimodal Sensor Fusion Framework for Residential Building Occupancy Detection,"Sin Yong Tan, Margarite Jacoby, Homagni Saha, Anthony Florita, Gregor Henze, Soumik Sarkar",2020,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on multimodal sensor fusion framework for residential building occupancy detection providing insights for knowledge graph development and data integration.,"This 2020 paper by Sin Yong Tan, Margarite Jacoby, Homagni Saha, Anthony Florita, Gregor Henze, Soumik Sarkar explores multimodal sensor fusion framework for residential building occupancy detection. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1109/ISCSIC.2017.15.,"data-integration, knowledge-graph",Multimodal sensor fusion framework for residential building occupancy detection,"Tan Sin Yong, Jacoby Margarite, Saha Homagni, Florita Anthony, Henze Gregor, Sarkar Soumik",2022,reference-manager,10.1016/j.enbuild.2021.111828,,"The implementation insights highlight a modular, scalable framework using low-powered, wireless sensors (possibly solar-powered) and embedded devices like Raspberry Pi. This approach allows independent inference for each data stream, making the system robust to missing data and easier to deploy on resource-limited hardware. New insight: modularity enhances flexibility and resilience.",,,,"Multimodal data acquisition: Sensor hubs collected temperature, humidity, eCO2, TVOC, ambient light, audio, and images in six homes over 4–8 weeks, focusing on common areas for privacy.",,,"How can a multimodal sensor fusion framework, integrating environmental, image, and acoustic data, be developed and evaluated to achieve accurate, transferable, and privacy-preserving occupancy detection in residential buildings?","The paper aims to develop a high-performing, transferable multimodal occupancy detection framework for residential buildings using sensor fusion of environmental, image, and audio data. Using ensemble methods and new spatiotemporal models, the study demonstrates accurate, privacy-preserving occupancy detection, validated on multiple datasets, with implications for smart energy-saving building systems.","The research goal is to develop a high-performing, transferable multimodal occupancy detection framework for residential buildings using sensor fusion and Occ-STPN models; the approach combines environmental, image, and acoustic data with feature/decision-level fusion; results show strong prediction accuracy and transferability across multiple datasets.",,1.000,exact_title
tang_2023,Human Body Digital Twin: A Master Plan,"Chenyu Tang, Shuo Gao, Luigi G. Occhipinti",2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on human body digital twin: a master plan providing insights for knowledge graph development and data integration.,"This 2023 paper by Chenyu Tang, Shuo Gao, Luigi G. Occhipinti explores human body digital twin: a master plan. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Human Body Digital Twin: A Master Plan,"Tang Chenyu, Gao Shuo, Occhipinti Luigi G.",2023,reference-manager,,,,,,,"Use of advanced nanotechnology for designing and fabricating sensitive, adaptable, and comfortable sensors to collect human data over long periods.",,,"What is a comprehensive, five-level roadmap for the development and deployment of human body digital twins (DTs) in healthcare, and what are the key technological, security, cost, and ethical challenges that must be addressed to advance this field?","The paper proposes a five-level roadmap for modeling the human body Digital Twin (DT), aiming to improve healthcare. It highlights Level 5 models, which focus on explainability using interpretability techniques and causal inference. Although still early, these models promise deeper insights and future clinical impact.","The paper's main objective is to propose a five-level roadmap for human body digital twin (DT) modeling; it introduces explainable models using advanced interpretability techniques as the key method, concluding that such models can enhance understanding but are still in early stages and not yet clinically guiding.",,1.000,exact_title
tang_2024,DHyper: A Recurrent Dual Hypergraph Neural Network for Event Prediction in Temporal Knowledge Graphs,"Xing Tang, Ling Chen, Hongyu Shi, Dandan Lyu",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on dhyper: a recurrent dual hypergraph neural network for event prediction in temporal knowledge graphs providing insights for knowledge graph development and data integration.,"This 2024 paper by Xing Tang, Ling Chen, Hongyu Shi, Dandan Lyu explores dhyper: a recurrent dual hypergraph neural network for event prediction in temporal knowledge graphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3653015,"data-integration, knowledge-graph, temporal-data",DHyper: A Recurrent Dual Hypergraph Neural Network for Event Prediction in Temporal Knowledge Graphs,"Tang Xing, Chen Ling, Shi Hongyu, Lyu Dandan",2024,reference-manager,10.1145/3653015,,"DHyper consistently outperforms all compared methods on ICEWS18, ICEWS18C, and GDELT18 across MRR and Hits@k metrics, with improvements up to 30.25%. Its design leverages low-rank factorization, sparse thresholding, and attentive temporal encoding for efficiency and effectiveness. DHyper’s superiority is statistically significant. No new insights beyond performance and complexity are stated.",,,,"Hypergraph modeling: DHyper uses hypergraph modeling to capture high-order correlations among entities and relations, improving representation learning.",,,How can hypergraph modeling be used to simultaneously capture high-order correlations among entities and relations in temporal knowledge graphs to improve event prediction performance?,"The paper investigates DHyper, a recurrent dual hypergraph neural network for event prediction in temporal knowledge graphs. Using hypergraph modeling and deep neural networks, DHyper captures high-order correlations among entities and relations. Experiments show DHyper outperforms baselines, with best results at two DHMP layers, reducing overfitting and improving representation learning.","The research goal is to improve temporal knowledge graph reasoning; the approach, DHyper, uses hypergraph neural networks with sparse thresholding and attentive aggregation; results show DHyper achieves the best performance across multiple benchmarks, significantly outperforming prior methods in MRR and Hits@k metrics.",,1.000,exact_title
tehran_2020,Cognitive Ledger Project: Towards Building Personal Digital Twins Through Cognitive Blockchain,Amir Reza Asadi Humind Labs Tehran,2020,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on cognitive ledger project: towards building personal digital twins through cognitive blockchain providing insights for knowledge graph development and data integration.,"This 2020 paper by Amir Reza Asadi Humind Labs Tehran explores cognitive ledger project: towards building personal digital twins through cognitive blockchain. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1109/MC.2018.2876181.,"data-integration, knowledge-graph, personal-knowledge",,,,,,,,,,,,,,,,,,,
teraoka_2011,Aggregation and Exploration of Heterogeneous Data Collected from Diverse Information Sources,Teruhiko Teraoka,2011,Yes,SUPER,"This paper directly addresses core aspects of heterogeneous data integration in knowledge graphs, providing critical insights for PKG architectures and temporal data management strategies that align perfectly with our research objectives.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on aggregation and exploration of heterogeneous data collected from diverse information sources providing insights for knowledge graph development and data integration.,"This 2011 paper by Teruhiko Teraoka explores aggregation and exploration of heterogeneous data collected from diverse information sources. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, heterogeneous-data, knowledge-graph",,,,,,,,,,,,,,,,,,,
truong_2021,Privacy preservation in federated learning: An insightful survey from the GDPR perspective,"Nguyen Truong, Kai Sun, Siyao Wang, Florian Guitton, YiKe Guo",2021,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on privacy preservation in federated learning: an insightful survey from the gdpr perspective providing insights for knowledge graph development and data integration.,"This 2021 paper by Nguyen Truong, Kai Sun, Siyao Wang, Florian Guitton, YiKe Guo explores privacy preservation in federated learning: an insightful survey from the gdpr perspective. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.cose.2021.102402,"data-integration, educational-technology, knowledge-graph",Privacy preservation in federated learning: An insightful survey from the GDPR perspective,"Truong Nguyen, Sun Kai, Wang Siyao, Guitton Florian, Guo YiKe",2021,reference-manager,10.1016/j.cose.2021.102402,,Implementation Insights are:,,,,,,,,,,,1.000,exact_title
tu_2020,SKG: A Versatile Information Retrieval and Analysis Framework for Academic Papers with Semantic Knowledge Graphs,"Yamei Tu, Rui Qiu, Han-Wei Shen",2020,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on skg: a versatile information retrieval and analysis framework for academic papers with semantic knowledge graphs providing insights for knowledge graph development and data integration.,"This 2020 paper by Yamei Tu, Rui Qiu, Han-Wei Shen explores skg: a versatile information retrieval and analysis framework for academic papers with semantic knowledge graphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1109/AIKE48582.2020.,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
turki_2013,A Decade of Scholarly Research on Open Knowledge Graphs,"Houcemeddine Turki, Abraham Toluwase Owodunni, Mohamed Ali Hadj Taieb, Fabrice Bile, Mohamed Ben Aouicha",2013,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a decade of scholarly research on open knowledge graphs providing insights for knowledge graph development and data integration.,"This 2013 paper by Houcemeddine Turki, Abraham Toluwase Owodunni, Mohamed Ali Hadj Taieb, Fabrice Bile, Mohamed Ben Aouicha explores a decade of scholarly research on open knowledge graphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1007/978-3-540-88564-1,"data-integration, knowledge-graph",A Decade of Scholarly Research on Open Knowledge Graphs,"Turki Houcemeddine, Owodunni Abraham Toluwase, Hadj Taieb Mohamed Ali, Bile Ren´e Fabrice, Aouicha Mohamed Ben, Zouhar Vil´em",2023,reference-manager,,,,,,,"Retrieval of bibliographic metadata from Scopus for publications on open knowledge graphs (2013–2022), using a specific query to filter relevant papers.",,,"What are the quantitative trends, main topics, and scholarly impacts of research on open knowledge graphs between 2013 and 2022, and how have these aspects evolved over time?","The paper analyzes the quantitative evolution of scholarly research on open knowledge graphs from 2013 to 2022 using bibliometric analysis based on Scopus data. It finds increasing importance and emerging concepts, especially since 2019, with a shift toward machine learning integration. The study highlights regional publication disparities and suggests rethinking collaboration models.","The research goal is to quantitatively analyze the evolution of open knowledge graph research (2013–2022); the approach uses bibliometric analysis; the principal finding is increasing importance and emerging concepts, with impactful work often originating from development and industry applications rather than research projects.",,1.000,exact_title
tushkanova_2019,"Knowledge Net: Model and System for Accumulation, Representation, and Use of Knowledge","Olga Tushkanova, Vladimir Samoylov",2019,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on knowledge net: model and system for accumulation, representation, and use of knowledge providing insights for knowledge graph development and data integration.","This 2019 paper by Olga Tushkanova, Vladimir Samoylov explores knowledge net: model and system for accumulation, representation, and use of knowledge. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
universit_2024,Research Trends for the Interplay between Large Language Models and Knowledge Graphs,"Soror Sahri Universit, Morteza Ezzabady Universit, Nandana Mihindukulasooriya, Hanieh Khorashadizadeh",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on research trends for the interplay between large language models and knowledge graphs providing insights for knowledge graph development and data integration.,"This 2024 paper by Soror Sahri Universit, Morteza Ezzabady Universit, Nandana Mihindukulasooriya, Hanieh Khorashadizadeh explores research trends for the interplay between large language models and knowledge graphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1007/978-3-540-76888-3,"data-integration, knowledge-graph",Research Trends for the Interplay between Large Language Models and Knowledge Graphs,"Khorashadizadeh H., Amara Fatima Zahra, Ezzabady M., Ieng Frédéric, Tiwari Sanju, Mihindukulasooriya Nandana, Groppe Jinghua, Sahri S., Benamara Farah, Groppe Sven",2024,reference-manager,,,,,,,Database-First (DB-first) approach: Combines Large Language Models (LLMs) with traditional Database Management Systems (DBMSs) to create a hybrid query execution environment.,,,"What are the emerging trends, challenges, and solutions in the interplay between Large Language Models (LLMs) and Knowledge Graphs (KGs), particularly regarding their integration for tasks such as KG question answering, multi-hop question generation, KG validation, and natural language query generation?","This paper surveys the integration of Large Language Models (LLMs) and Knowledge Graphs (KGs), focusing on how LLMs enhance KGs in tasks like text generation, ontology creation, inconsistency detection, and query generation. It also explores how KGs improve LLMs, and highlights new directions in KG question answering.","The paper's main objective is to survey the integration of LLMs and KGs, using a categorization-based approach, and its principal finding is that LLMs enhance KGs in tasks like question answering and query generation, with Freebase, Bert, and GPT-3 being most frequently used.",,1.000,exact_title
up_2024,"Digital Twins' Advancements and Applications in Healthcare, Towards Precision Medicine","up, vkatsa, panospa, lidia.strigar, gkaga, or kagadi",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","DHTs enable personalized treatment plans, disease risk prediction, and comprehensive health representations through AI-driven virtual patient replicas",Comprehensive review of digital human twins for precision medicine applications,"This paper reviews Digital Human Twins (DHTs) as virtual replicas of patients' medical characteristics, enabling personalized treatment plans and disease prediction through AI-driven comprehensive health models",How can Digital Human Twins transform healthcare and precision medicine?,"Literature review of 74 articles, categorization into DHT technologies, precision medicine applications, and challenges, analysis across multiple databases","DHTs can predict disease risks, enable personalized treatments, support surgical planning, assist drug discovery, potential to revolutionize healthcare",,"Implementation challenges, privacy concerns, need for standardization not fully addressed",Demonstrates potential for comprehensive personal health models using digital twin technology,,"Develop PKG-integrated health twins, implement privacy controls, create patient engagement tools",Agent Epsilon: Downloaded successfully - critical reference for HDM healthcare digital twin implementation,https://pmc.ncbi.nlm.nih.gov/articles/PMC11595921/,10.3390/jpm14111101,"digital-twins, disease-prediction, healthcare-ai, personalized-treatment, precision-medicine",,,,,,,,,,,,,,,,,,,
updates_2006,Continuous multimodal data supply chain and expandable clinical decision support for oncology,"Check for updates, Radiation Oncology, Yonsei Cancer Center, Medical Oncology, Internal Medicine, Cancer Research, Digital Health, Severance Hospital, Biomedical Systems Informatics, Jee Suk Chang",2006,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on continuous multimodal data supply chain and expandable clinical decision support for oncology providing insights for knowledge graph development and data integration.,"This 2006 paper by Check for updates, Radiation Oncology, Yonsei Cancer Center, Medical Oncology, Internal Medicine, Cancer Research, Digital Health, Severance Hospital, Biomedical Systems Informatics, Jee Suk Chang explores continuous multimodal data supply chain and expandable clinical decision support for oncology. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1038/s41746-025-01508-2,"data-integration, knowledge-graph",Continuous multimodal data supply chain and expandable clinical decision support for oncology,"Chang Jee Suk, Kim Hyunwook, Baek Eun Sil, Choi Jeong Eun, Lim Joon Seok, Kim Jin Sung, Shin Sang Joon",2025,reference-manager,10.1038/s41746-025-01508-2,,,,,Further evaluations in different institutional and national settings are needed to fully validate the system’s utility and generalizability.,,,"The research is partially reproducible. Data access requires application and approval via the Severance Data Portal, with strict confidentiality policies. Custom code/scripts are not publicly available but may be requested from the corresponding author, subject to IRB approval and institutional permissions. Key software versions and analysis parameters are provided.",,,"The research goal was to establish a comprehensive oncology data supply chain by integrating clinical, genomic, and imaging data; the approach involved building a persistent, flexible, and expandable infrastructure; the principal finding is that this system can accelerate clinical decision support and AI application development for risk stratification and diagnosis.",,1.000,exact_title
updates_2014,Towards a neurodevelopmental cognitive perspective of temporal processing,Check for updates,2014,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on towards a neurodevelopmental cognitive perspective of temporal processing providing insights for knowledge graph development and data integration.,"This 2014 paper by Check for updates explores towards a neurodevelopmental cognitive perspective of temporal processing. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1038/s42003-024-06641-4,"data-integration, knowledge-graph, temporal-data",Towards a neurodevelopmental cognitive perspective of temporal processing,"Buzi Giulia, Eustache Francis, Droit-Volet Sylvie, Desaunay Pierre, Hinault Thomas",2024,reference-manager,10.1038/s42003-024-06641-4,,,,,Gap in studies on time perception between nine years and adolescence.,,,,,,"The paper's main objective is to clarify the development of brain and cognitive mechanisms underlying temporal cognition across the lifespan using a lifespan approach, with the principal finding that evaluating temporal perception can aid in detecting neuropsychiatric and neurodegenerative disorders and inform new treatments.",,1.000,exact_title
uzctegui_2024,Corresponding author:,"Luis Medina Uzcátegui, Instituto de Diseño y Métodos Industriales, Facultad de Ciencias de la Ingeniería, Universidad Austral de Chile",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on corresponding author: providing insights for knowledge graph development and data integration.,"This 2024 paper by Luis Medina Uzcátegui, Instituto de Diseño y Métodos Industriales, Facultad de Ciencias de la Ingeniería, Universidad Austral de Chile explores corresponding author:. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1177/03064190231200397,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
vaikunth_2024,Knowledge Graph Modeling-Driven Large Language Model Operating System (LLM OS) for Task Automation in Process Engineering Problem-Solving,"Vijay Sri Vaikunth, Venkataramana Runkana",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on knowledge graph modeling-driven large language model operating system (llm os) for task automation in process engineering problem-solving providing insights for knowledge graph development and data integration.,"This 2024 paper by Vijay Sri Vaikunth, Venkataramana Runkana explores knowledge graph modeling-driven large language model operating system (llm os) for task automation in process engineering problem-solving. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Knowledge Graph Modeling-Driven Large Language Model Operating System (LLM OS) for Task Automation in Process Engineering Problem-Solving,"Srinivas Sakhinana Sagar, Vaikunth Vijay Sri, Runkana Venkataramana",2024,reference-manager,,,,,,,"Human-centric evaluation: Eight aspects (e.g., user satisfaction, usability, task completion) rated by humans using Likert-scale surveys, Yes/No completion, and qualitative feedback.",,,"How can a modular, AI-driven Process Engineering Operations Assistant (PEOA) framework leveraging graph retrieval-augmented generation and expert models automate and enhance complex problem-solving, error handling, and decision support in the chemical and process industry?","The paper introduces the PEOA framework for automating complex problem-solving in process engineering. Using a modular, tool-integrated approach evaluated by human-centric metrics and benchmark datasets, PEOA achieves strong performance, closely matching leading proprietary LLMs. Results highlight its adaptability, effective tool use, and potential for broader application and further enhancement.",The research goal is to automate complex process engineering tasks; the approach combines instruction-tuned small language models with Graph Retrieval-Augmented Code Generation (GRACG) and advanced knowledge graph techniques; results show the PEOA framework outperforms ablated variants and matches leading proprietary LLMs in accuracy and adaptability.,,1.000,exact_title
valle_2023,Digital twin for healthcare systems,Alexandre Vallée,2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on digital twin for healthcare systems providing insights for knowledge graph development and data integration.,"This 2023 paper by Alexandre Vallée explores digital twin for healthcare systems. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3389/fdgth.2023.1253050,"data-integration, healthcare, knowledge-graph",,,,,,,,,,,,,,,,,,,
vassiliou_2023,"iSummary: Workload-based, Personalized Summaries for Knowledge Graphs","Giannis Vassiliou, Fragkiskos Alevizakis, Nikolaos Papadakis, Haridimos Kondylakis",2023,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Introduces scalable approach for constructing personalized summaries by exploiting query logs from SPARQL endpoints, achieving superior performance in both quality and efficiency compared to baselines while requiring minimal user input",Novel scalable approach for personalized knowledge graph summarization exploiting existing query logs for user-centric content discovery,"This paper addresses the challenge of understanding and exploring large, complex knowledge graphs by proposing iSummary, a novel scalable approach for constructing personalized summaries. The research tackles the problem that existing semantic summaries are typically static, not incorporating user needs and preferences, and cannot scale effectively. iSummary exploits generic logs already available through SPARQL endpoints rather than relying on node weights or individually provided user queries. The system requires only selection of one or few nodes that users are interested in, then leverages previous user queries to identify most common connections to user-selected nodes. The approach includes theoretical guarantees on summary quality and has been tested on three real-world datasets.",How to create personalized knowledge graph summaries that scale effectively while incorporating user preferences and leveraging existing query patterns?,Scalable personalized summarization approach using SPARQL endpoint query logs; algorithm with theoretical guarantees on summary quality; evaluation on three real-world datasets; comparison against multiple baselines,Demonstrated superiority in both quality and efficiency compared to baselines; successful exploitation of query logs for personalized summarization; scalable approach suitable for large knowledge graphs,,Limited evaluation on specific knowledge graph domains; dependency on availability and quality of query logs; potential privacy concerns with query log usage,iSummary provides practical solution for personalized knowledge graph exploration that leverages existing infrastructure while maintaining scalability and quality,,Expand evaluation to more diverse knowledge graph types; investigate privacy-preserving query log analysis; develop adaptive summarization techniques,Exploits existing SPARQL endpoint infrastructure; requires minimal user input; provides theoretical guarantees on summary quality,https://arxiv.org/abs/2403.02934,10.48550/arXiv.2403.02934,"iswc-2023, knowledge-graph-summarization, personalization, sparql, workload-based-analytics",,,,,,,,,,,,,,,,,,,
vol_2019,The current issue and full text archive of this journal is available on Emerald Insight at: https://www.emerald.com/insight/0368-492X.htm,Kybernetes Vol,2019,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on the current issue and full text archive of this journal is available on emerald insight at: https://www.emerald.com/insight/0368-492x.htm providing insights for knowledge graph development and data integration.,"This 2019 paper by Kybernetes Vol explores the current issue and full text archive of this journal is available on emerald insight at: https://www.emerald.com/insight/0368-492x.htm. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1108/K-03-2019-0215,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
wan_2024,"Making knowledge graphs work for smart manufacturing: Research topics, applications and prospects","Yuwei Wan, Ying Liu, Zheyuan Chen, Chong Chen, Xinyu Li, Fu Hu, Michael Packianather",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on making knowledge graphs work for smart manufacturing: research topics, applications and prospects providing insights for knowledge graph development and data integration.","This 2024 paper by Yuwei Wan, Ying Liu, Zheyuan Chen, Chong Chen, Xinyu Li, Fu Hu, Michael Packianather explores making knowledge graphs work for smart manufacturing: research topics, applications and prospects. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.jmsy.2024.07.009,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
wang_2020,An Efficient Big Data Storage Service Architecture,"Dan Wang, Xiang Li, Peixiang Bai, Haibo Wang, Jianmin Dong",2020,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on an efficient big data storage service architecture providing insights for knowledge graph development and data integration.,"This 2020 paper by Dan Wang, Xiang Li, Peixiang Bai, Haibo Wang, Jianmin Dong explores an efficient big data storage service architecture. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
wang_2022a,KSG: Knowledge and Skill Graph,"Donglin Wang, Feng Zhao, Ziqi Zhang",2022,Yes,HIGH,"Directly addresses knowledge graph enrichment and fusion techniques using open corpus data, relevant to HDM systems requiring knowledge expansion from diverse information sources",Collaborative framework enables mutual assistance between knowledge extraction and graph fusion tasks; open corpus exploitation addresses KG incompleteness; translated relation alignment improves triple integration,Collaborative framework for refining knowledge graphs using noisy corpus triples with mutual task assistance,"This paper proposes a system to refine knowledge graphs using information harvested from additional open corpus data, addressing the challenge of building KGs from scratch by enriching existing KGs with triples from open sources. The approach formulates the task as two coupled sub-tasks: joint event extraction (JEE) and knowledge graph fusion (KGF), implemented through a Collaborative Knowledge Graph Fusion Framework. The explorer carries out JEE supervised by ground-truth annotation and existing KG, while the supervisor evaluates extracted triples and enriches the KG with highly ranked ones using a Translated Relation Alignment Scoring Mechanism.",How to refine knowledge graphs using information from open corpus while handling noisy entities and relations effectively?,Collaborative Knowledge Graph Fusion Framework with two sub-tasks: Join Event Extraction (JEE) and Knowledge Graph Fusion (KGF); explorer for supervised JEE; supervisor for triple evaluation; Translated Relation Alignment Scoring Mechanism,Proposed framework allows sub-tasks to mutually assist each other in alternating manner; improved performance in both join event extraction and knowledge graph fusion; verification of collaboration benefits,Collaborative Knowledge Graph Fusion Framework; improved performance in both JEE and KGF tasks; Translated Relation Alignment Scoring Mechanism; enhanced KG representation quality,Potential noise in extracted triples from open corpus; computational complexity of collaborative framework; evaluation limited to specific datasets,Collaborative approach can improve knowledge graph representation quality through mutual task assistance and effective noise handling,Limited exploration of noise handling in knowledge graph expansion; challenges in aligning extracted triples with existing KG schema; need for robust fusion mechanisms,Develop more sophisticated noise filtering techniques; expand evaluation to larger datasets; investigate domain-specific fusion strategies,Uses Translated Relation Alignment Scoring Mechanism for triple evaluation; demonstrates practical approach to KG enrichment from open sources; collaborative framework design applicable to other KG tasks,https://arxiv.org/abs/2206.07472,10.1145/3511808.3557623,"collaborative-learning, data-fusion, information-extraction, knowledge-graph, open-corpus",KSG: Knowledge and Skill Graph,"Zhao Feng, Zhang Ziqi, Wang Donglin",2022,reference-manager,10.1145/3511808.3557623,,"The Implementation Insights show that KSG (Knowledge and Skill Graph) enables agents to learn new skills efficiently by leveraging transferable knowledge from pre-trained models and offline datasets. Selecting pre-training models based on task similarity improves learning efficiency. Different environments and tasks enrich the KSG, supporting skill transfer and combination.",,,,"Construction of a Knowledge and Skill Graph (KSG) based on CN-DBpedia, integrating both static knowledge and dynamic behavioral skills.",,,"How can a Knowledge and Skill Graph (KSG) be constructed and utilized to enable effective skill retrieval, display, and transferable knowledge for learning new skills in agents?","The paper aims to build a Knowledge and Skill Graph (KSG) that integrates static knowledge and dynamic behavioral skills. Using data from CN-DBpedia, the authors employ entity, attribute, and relation extraction to construct KSG. Experiments show KSG supports skill retrieval, Q\&A, and aids learning new skills, highlighting its practical value.","The research goal is to enhance information retrieval by introducing the Knowledge and Skill Graph (KSG), which adds skill and environment nodes to a knowledge graph; the approach enables effective skill searching and transfer, and results show KSG supports skill retrieval and learning across different agents and environments.","The keywords or tags for this research are: Knowledge and Skill Graph, Skill Retrieval, Knowledge Graph.",1.000,exact_title
wang_2022b,Collaborative Knowledge Graph Fusion by Exploiting the Open Corpus,"Yue Wang, Yao Wan, Lu Bai, Lixin Cui, Zhuo Xu, Ming Li, Philip S. Yu, Edwin R Hancock",2022,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Collaborative framework for refining knowledge graphs using noisy corpus triples,"This 2022 paper by Yue Wang, Yao Wan, Lu Bai, Lixin Cui, Zhuo Xu, Ming Li, Philip S. Yu, Edwin R Hancock explores collaborative knowledge graph fusion by exploiting the open corpus. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,https://arxiv.org/abs/2206.07472,10.48550/arXiv.2206.07472,"data-integration, knowledge-graph",Collaborative Knowledge Graph Fusion by Exploiting the Open Corpus,"Wang Yue, Wan Yao, Bai Lu, Cui Lixin, Xu Zhuo, Li Ming, Yu Philip S., Hancock Edwin R.",2020,reference-manager,,,"The implementation uses a collaborative framework with explorer and supervisor processes. The explorer extracts triples using benchmark-based supervision, while the supervisor evaluates and enriches the knowledge graph. Experiments show improved performance and knowledge graph quality, especially with enriched triples and larger explorer hidden dimensions.",,,,"Benchmark-based Supervision JEE (BJEE): A joint model that extracts entities, event triggers, and arguments together, supervised by benchmark entity pairs sampled from a knowledge graph.",,,"How can a unified framework that combines joint event extraction with knowledge graph fusion effectively construct and enrich a high-quality, domain-oriented knowledge graph from open text corpora while addressing challenges in relation alignment, knowledge graph quality, and knowledge sharing between subtasks?","The paper aims to improve knowledge graph fusion from open text by proposing a collaborative framework with explorer and supervisor processes. Using benchmark-based supervision and contrastive learning, the method extracts and evaluates knowledge triples. Experiments show superior performance over baselines in both joint event extraction and knowledge graph embedding tasks, enhancing knowledge graph quality.","The paper's main objective is knowledge graph fusion from open corpora using a collaborative framework that combines joint event extraction and a benchmark-based supervision mechanism, with results showing superior performance over state-of-the-art baselines in both extraction and knowledge graph enrichment tasks.",,1.000,exact_title
wang_2023a,"A Survey on Temporal Knowledge Graph Completion: Taxonomy, Progress, and Prospects","Jiapu Wang, Boyue Wang, Meikang Qiu, Senior Member, Shirui Pan, Bo Xiong, Heng Liu, Linhao Luo, Tengfei Liu, Yongli Hu, Baocai Yin, Wen Gao",2023,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.","Research on a survey on temporal knowledge graph completion: taxonomy, progress, and prospects providing insights for knowledge graph development and data integration.","This 2023 paper by Jiapu Wang, Boyue Wang, Meikang Qiu, Senior Member, Shirui Pan, Bo Xiong, Heng Liu, Linhao Luo, Tengfei Liu, Yongli Hu, Baocai Yin, Wen Gao explores a survey on temporal knowledge graph completion: taxonomy, progress, and prospects. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph, temporal-data",,,,,,,,,,,,,,,,,,,
wang_2023b,Continuous Personalized Knowledge Tracing: Modeling Long-Term Learning in Online Environments,"Chengqiang Wang, Shabnam Sahebi",2023,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Proposes Continuous Personalized Knowledge Tracing (CPKT) model with personalized memory slots and user embeddings, incorporating online model training paradigm and transition-aware stochastic shared embedding achieving superior performance especially for students with longer sequences",Novel personalized knowledge tracing model designed for continuous long-term learning with online training paradigm and personalized memory mechanisms,"This paper addresses challenges in knowledge tracing by proposing Continuous Personalized Knowledge Tracing (CPKT) that models long-term learning in online environments. The research identifies that existing deep learning-based knowledge tracing models are either not personalized or not tailored for handling long sequences. CPKT incorporates two key components: personalized memory slots to maintain learner's knowledge in a lifelong manner, and personalized user embeddings that help predict individual responses, detect personalized knowledge acquisition and forgetting patterns, and interpret learner progress. The model includes transition-aware stochastic shared embedding based on learning transition matrix to regularize online model training, mimicking real-world continuous learning scenarios.",How to develop personalized knowledge tracing systems that can effectively model long-term learning while maintaining individual learner characteristics and handling continuous online learning scenarios?,Continuous Personalized Knowledge Tracing (CPKT) model with personalized memory slots and user embeddings; online model training paradigm suitable for knowledge tracing; transition-aware stochastic shared embedding with learning transition matrix; extensive experiments on four real-world datasets,Demonstrated effectiveness and superiority compared to existing methods; particularly effective for students with longer learning sequences; successful integration of personalized memory and online learning paradigms,,Limited evaluation on diverse educational domains; computational complexity for real-time deployment not fully characterized; scalability to very large student populations not demonstrated,CPKT provides effective solution for personalized knowledge tracing in continuous learning environments while maintaining individual learner characteristics and handling long-term learning dynamics,,Expand evaluation to more diverse educational contexts; optimize computational efficiency for real-time deployment; investigate advanced personalization techniques,Maintains learner knowledge in lifelong manner; detects personalized knowledge acquisition and forgetting patterns; provides interpretable analysis of learner progress,https://dl.acm.org/doi/10.1145/3583780.3614822,10.1145/3583780.3614822,"cikm-2023, continuous-learning, educational-technology, knowledge-tracing, personalized-learning",Continuous Personalized Knowledge Tracing: Modeling Long-Term Learning in Online Environments,"Wang Chunpai, Sahebi Shaghayegh",2023,reference-manager,10.1145/3583780.3614822,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
wang_2024a,Auto-tuning for HPC storage stack: an optimization perspective,"Jinqiu Wang, Lin Peng, Zhanyong Tang",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on auto-tuning for hpc storage stack: an optimization perspective providing insights for knowledge graph development and data integration.,"This 2024 paper by Jinqiu Wang, Lin Peng, Zhanyong Tang explores auto-tuning for hpc storage stack: an optimization perspective. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3502181.3531461,"data-integration, knowledge-graph",Auto-tuning for HPC storage stack: an optimization perspective,"Liu Zhangyu, Wang Jinqiu, Wu Huijun, Ma Qingzhen, Peng Lin, Tang Zhanyong",2024,reference-manager,10.1007/s42514-024-00198-8,,,,,"Users lack time or expertise to explore complex I/O systems, often leading to poor performance.",,,,,,"The research goal is to survey auto-tuning technology in HPC I/O; the approach classifies and analyzes tuning methods (heuristic, rule-based, simulation, machine learning, hybrid); the principal finding is that auto-tuning significantly improves performance with minimal human intervention and adapts to diverse systems and applications.",,1.000,exact_title
wang_2024b,"Agents in Software Engineering: Survey, Landscape, and Vision","Yanlin Wang, Wanjun Zhong, Yanxian Huang, Ensheng Shi, Min Yang, Jiachi Chen, Zibin Zheng, Hui Li, Yuchi Ma, Qianxiang Wang",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on agents in software engineering: survey, landscape, and vision providing insights for knowledge graph development and data integration.","This 2024 paper by Yanlin Wang, Wanjun Zhong, Yanxian Huang, Ensheng Shi, Min Yang, Jiachi Chen, Zibin Zheng, Hui Li, Yuchi Ma, Qianxiang Wang explores agents in software engineering: survey, landscape, and vision. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3591300,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
wang_2025,An Adaptive Framework Embedded With LLM for Knowledge Graph Construction,"Qingwang Wang, Senior Member, Chaohui Li, Yi Liu, Qiubai Zhu, Jian Song, Tao Shen, Large Language, Adaptive Construction, Knowledge Graph, Massive Multitask, Language Understanding",2025,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","LLMs provide effective way for automatic KG construction but face challenges with schema layer embedding and input length limitations; divides construction into triple extraction, relational semantic embedding, and normalization.",Framework for automatic knowledge graph construction using LLMs that eliminates need for retraining or fine-tuning internal models across different domains.,"This paper proposes ACKG-LLM framework that addresses semantic understanding and precision limitations in LLM-based knowledge graph construction by dividing the process into three subtasks: triple extraction, relational semantic information embedding, and knowledge graph normalization.",How can Large Language Models be effectively used for automatic knowledge graph construction across different domains?,"Proposed ACKG-LLM framework with three-stage approach: triple extraction, relational semantic embedding, and KG normalization; evaluated on REBEL and WiKi-NRE datasets.","Framework eliminates need for retraining/fine-tuning, shows favorable performance on benchmark datasets, enables cross-domain KG construction.",,"Abstract only - evaluation limited to specific datasets, detailed performance metrics not available from abstract.",Demonstrates practical approach to automated KG construction using LLMs with cross-domain applicability.,,"Further evaluation across more domains, optimization of semantic embedding techniques, integration with domain-specific knowledge.",Provides framework for automated KG construction that could be adapted for personal knowledge graph generation in HDM systems.,https://ieeexplore.ieee.org/document/10948338/,10.1109/TMM.2025.3557717,"automation, kg-construction, knowledge-graph, llm, schema-layer",An Adaptive Framework Embedded With LLM for Knowledge Graph Construction,"Wang Qingwang, Li Chaohui, Liu Yi, Zhu Qiubai, Song Jian, Shen Tao",2025,reference-manager,10.1109/tmm.2025.3557717,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
wen_2024,AeonG: An Efficient Built-in Temporal Support in Graph Databases,"Dong Wen, Jiamin Hou",2024,Yes,HIGH,"Breakthrough temporal graph database system achieving 5.73X storage efficiency and 2.57X query performance, directly addresses temporal modeling limitations.",Hybrid storage with anchor+delta strategy; separates current and historical versions; minimal 9.74% overhead for temporal features; built on Memgraph with MVCC support.,Efficient temporal graph database with built-in temporal support addressing,"This paper presents AeonG, a temporal graph database with built-in temporal support featuring a hybrid storage engine and anchor-based version retrieval for efficient temporal graph processing.",How to efficiently support temporal features in graph databases while minimizing storage overhead and query latency?,Developed hybrid storage engine with current/historical separation; implemented anchor+delta storage strategy; created anchor-based version retrieval; built on Memgraph with formal temporal property graph model.,Achieves 5.73X lower storage consumption and 2.57X lower temporal query latency vs state-of-the-art; only 9.74% performance degradation for temporal features; supports three temporal benchmarks.,High-performance temporal graph system with significant storage and query improvements over existing approaches.,Focus on specific graph database implementation; broader applicability to other systems not evaluated; limited discussion of distributed scenarios.,AeonG successfully addresses temporal graph challenges through innovative storage architecture and query optimization with minimal overhead.,Extend to distributed environments; integrate with streaming data sources; develop more complex temporal query operators.,Expand temporal query language; optimize for specific temporal patterns; develop tools for temporal graph analytics.,Provides architectural blueprint for implementing efficient temporal support in HDM systems with proven performance improvements.,https://www.vldb.org/pvldb/vol17/p1515-lu.pdf,10.14778/3648160.3648187,"graph-databases, mvcc, query-performance, storage-optimization, temporal-graphs",AeonG: An Efficient Built-in Temporal Support in Graph Databases,"Hou Jiamin, Zhao Zhanhao, Wang Zhouyu, Lu Wei, Jin Guodong, Wen Dong, Du Xiaoyong",2024,reference-manager,10.14778/3648160.3648187,,,,,No explicit limitations or shortcomings are stated in the provided context.,,,"The research uses experimental artifacts but does not mention releasing the source code for AeonG or the baseline implementations. There is no explicit information about public availability of source code, so reproducibility is limited.",,,"The research goal is to design AeonG, a graph database with efficient built-in temporal support; the approach uses a hybrid “anchor+delta” storage engine and a native temporal query engine; results show up to 5.73× lower storage consumption and 2.57× lower query latency compared to state-of-the-art systems.",,1.000,exact_title
wickramarachchi_2021,"Saher Mohamed, Kirollos Farah, Abdelrahman Lotfy, Kareem Rizk, Abdelrahman Saeed, Shahenda Mohamed, Ghada Khouriba, Tamer Arafa","- Wickramarachchi, R., Henson, C., Sheth, A., 2020. An Evaluation of Knowledge Graph Embeddings for Autonomous Driving Data: Experience, Practice. Technical Report. URL: https://arxiv.org/abs/2003.00344. accessed: Oct. 14, 2023.",2021,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on saher mohamed, kirollos farah, abdelrahman lotfy, kareem rizk, abdelrahman saeed, shahenda mohamed, ghada khouriba, tamer arafa providing insights for knowledge graph development and data integration.","This 2021 paper by - Wickramarachchi, R., Henson, C., Sheth, A., 2020. An Evaluation of Knowledge Graph Embeddings for Autonomous Driving Data: Experience, Practice. Technical Report. URL: https://arxiv.org/abs/2003.00344. accessed: Oct. 14, 2023. explores saher mohamed, kirollos farah, abdelrahman lotfy, kareem rizk, abdelrahman saeed, shahenda mohamed, ghada khouriba, tamer arafa. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3390/su13063191.,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
wilkins_2022,Finding Long-COVID: Temporal Topic Modeling of Electronic Health Records from the N3C and RECOVER Programs,"Kenneth J. Wilkins, Hannah E. Davis, Gina S. Assaf, Hannah Wei, Parya Zareie, Evan T. French, Johanna Loomba, Andrea Zhou, Christopher G. Chute, Richard A. Moffitt, Emily R Pfaff, Yun Jae Yoo, Peter Leese, Robert F. Chew, Melissa A. Haendel",2022,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on finding long-covid: temporal topic modeling of electronic health records from the n3c and recover programs providing insights for knowledge graph development and data integration.,"This 2022 paper by Kenneth J. Wilkins, Hannah E. Davis, Gina S. Assaf, Hannah Wei, Parya Zareie, Evan T. French, Johanna Loomba, Andrea Zhou, Christopher G. Chute, Richard A. Moffitt, Emily R Pfaff, Yun Jae Yoo, Peter Leese, Robert F. Chew, Melissa A. Haendel explores finding long-covid: temporal topic modeling of electronic health records from the n3c and recover programs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1093/jamia/ocaa196,"data-integration, healthcare, knowledge-graph, temporal-data",Finding Long-COVID: temporal topic modeling of electronic health records from the N3C and RECOVER programs,"O’Neil Shawn T., Madlock-Brown Charisse, Wilkins Kenneth J., McGrath Brenda M., Davis Hannah E., Assaf Gina S., Wei Hannah, Zareie Parya, French Evan T., Loomba Johanna, McMurry Julie A., Zhou Andrea, Chute Christopher G., Moffitt Richard A., Pfaff Emily R., Yoo Yun Jae, Leese Peter, Chew Robert F., Lieberman Michael, Haendel Melissa A.",2024,reference-manager,10.1038/s41746-024-01286-3,,,,,"LDA does not model temporal relationships between terms, so topics may mix risk factors and outcomes.",,,"Analysis code is available at https://github.com/oneilsh/lda\_pasc. No explicit mention of data availability is provided; analyses used data accessed through the NCATS N3C Data Enclave, which may have access restrictions. Thus, only the source code is openly available for reproducibility.",,,"The research goal was to analyze sex, life-stage, and wave-specific health contrasts in PASC using N3C data; the approach involved statistical modeling of 5,400 contrasts across 68 topics; results showed most effects were small, with strong effects mainly in the PASC cohort but less coherent topics.",,1.000,exact_title
wisconsinmadison_2023,DEPSRAG: Towards Agentic Reasoning and Planning for Software Dependency Management,"Mohannad Alhanahnah University of Wisconsin-Madison, USA mohannad@cs.wisc.edu",2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on depsrag: towards agentic reasoning and planning for software dependency management providing insights for knowledge graph development and data integration.,"This 2023 paper by Mohannad Alhanahnah University of Wisconsin-Madison, USA mohannad@cs.wisc.edu explores depsrag: towards agentic reasoning and planning for software dependency management. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"knowledge-graph, machine-learning, privacy, semantic-web",DEPSRAG: Towards Agentic Reasoning and Planning for Software Dependency Management,"Alhanahnah Mohannad, Boshmaf Yazan",2024,reference-manager,,,,,,,Retrieval-Augmented Generation (RAG): Uses a large language model (LLM) to answer questions by retrieving relevant data from databases and providing source references for validation.,,,"How can a multi-agent, retrieval-augmented generation system like DEPSRAG be designed and orchestrated to automate software dependency analysis, identify critical and vulnerable packages, and generate comprehensive, validated reports such as SBOMs while addressing the challenges of complex dependency structures and LLM limitations?","The paper aims to improve software supply chain security by introducing DEPSRAG, a multi-agent system for generating Software Bill of Materials (SBOM) and managing dependencies. Using orchestrated agents and retrieval-augmented generation, DEPSRAG constructs hierarchical dependency graphs, identifies risky dependencies, and recommends secure updates, exceeding regulatory SBOM requirements.","The research goal is to improve software dependency management and security; the approach uses a multi-agent Retrieval-Augmented Generation (RAG) system called DEPSRAG to analyze and recommend safe dependencies; results show DEPSRAG generates comprehensive dependency graphs, supports SBOM generation, and suggests non-vulnerable package versions.",,1.000,exact_title
words_2021,Morescient GAI for Software Engineering (Extended Version,"Additional Key Words, Marcus Kessel",2021,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on morescient gai for software engineering (extended version providing insights for knowledge graph development and data integration.,"This 2021 paper by Additional Key Words, Marcus Kessel explores morescient gai for software engineering (extended version. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3359591.3359735,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
wu_2021,A Survey on Accuracy-oriented Neural Recommendation: From Collaborative Filtering to Information-rich Recommendation,"Le Wu, Xiangnan He, Xiang Wang, Kun Zhang, Meng Wang",2021,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a survey on accuracy-oriented neural recommendation: from collaborative filtering to information-rich recommendation providing insights for knowledge graph development and data integration.,"This 2021 paper by Le Wu, Xiangnan He, Xiang Wang, Kun Zhang, Meng Wang explores a survey on accuracy-oriented neural recommendation: from collaborative filtering to information-rich recommendation. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",A Survey on Accuracy-oriented Neural Recommendation: From Collaborative Filtering to Information-rich Recommendation,"Wu Le, He Xiangnan, Wang Xiang, Zhang Kun, Wang Meng",2021,reference-manager,,,"Implementation Insights highlight that the influence of historical items depends on the target item, suggesting flexible model design. Graph-based models perform well without complex activation functions. Reproducibility and fair evaluation remain challenges, emphasizing transparent experimental settings and unified benchmarks. Adjusting model components allows adaptation to various recommendation scenarios.",,,,"Path Based Methods: Use meta-paths and paths to capture high-order connections between users and items, converting these paths into embedding vectors for recommendation.",,,"What are the key approaches, challenges, and future directions in recommendation modeling for recommender systems with a focus on accuracy, including collaborative filtering, content-enriched, and context-aware models?","This survey reviews recommender system modeling with a focus on accuracy. It categorizes and summarizes key collaborative filtering and neural models, discusses evaluation frameworks, and highlights the need for transparent, reproducible research. The paper concludes by emphasizing benchmarking, graph-based models, and future research directions for improved recommendation systems.","The research goal is to survey recommender system modeling for accuracy, using a comprehensive paper collection from top venues and keywords; the approach organizes methods by modeling type and scenario; the principal finding is a taxonomy that aids understanding and design of accurate recommendation models.",,1.000,exact_title
wu_2022,FedGNN: Federated Graph Neural Network for Privacy-Preserving Recommendation,"Chuhan Wu, Fangzhao Wu, Yang Cao, Yongfeng Huang, Xing Xie",2022,Yes,HIGH,"Addresses privacy concerns in graph-based recommendation systems using federated learning, directly applicable to HDM privacy-preserving architectures and personalized recommendation systems",Federated learning enables privacy-preserving graph-based recommendations; local differential privacy techniques protect user data; competitive performance achievable without centralized data sharing,Privacy-preserving recommendation framework using graph neural networks in federated,"This paper proposes FedGNN, a federated learning framework for privacy-preserving recommendation using graph neural networks. The approach addresses privacy concerns in centralized recommendation systems by enabling local GNN model training on user-item graphs while protecting user privacy through differential privacy techniques. The framework includes gradient aggregation on central server and privacy protection mechanisms, incorporating random item sampling for anonymity and user-item graph expansion methods to improve recommendation quality while maintaining privacy guarantees.",How to train recommendation models while protecting user privacy in decentralized environments using graph neural networks?,Federated learning with local differential privacy techniques; local GNN model training on user-item graphs; gradient aggregation on central server; privacy protection through differential privacy; user-item graph expansion method,Competitive recommendation performance while maintaining user privacy; effective privacy-preserving framework for graph-based recommendations; successful integration of federated learning with GNN-based recommendations,Privacy-preserving recommendation framework using graph neural networks; federated learning approach for decentralized recommendation; local differential privacy integration,Potential information loss due to privacy constraints; limited evaluation on large-scale datasets; computational overhead from privacy mechanisms not fully characterized,Approach can achieve competitive results with existing centralized GNN-based recommendation methods while preserving user privacy,Privacy concerns in centralized recommendation systems; need for effective privacy-preserving collaborative filtering; challenges in maintaining recommendation quality under privacy constraints,Further refinement of privacy-preserving techniques; evaluation on larger-scale datasets; optimization of privacy-utility trade-offs,Incorporates random item sampling for anonymity; uses local differential privacy for data protection; demonstrates feasibility of federated GNN-based recommendations,https://arxiv.org/abs/2102.04925,10.48550/arXiv.2102.04925,"differential-privacy, federated-learning, graph-neural-networks, privacy, recommendation-systems",FedGNN: Federated Graph Neural Network for Privacy-Preserving Recommendation,"Wu Chuhan, Wu Fangzhao, Cao Yang, Huang Yongfeng, Xie Xing",2021,reference-manager,10.475/123\_4,,"The implementation uses local differential privacy (LDP) on user gradients and adds random pseudo-item gradients to protect privacy. A privacy-preserving user-item graph expansion method exchanges encrypted neighbor embeddings, enabling high-order information use without leaking private data. Proper tuning of hyperparameters balances privacy and model performance.",,,,"Federated Learning: User data remains on local devices, and only local model updates (gradients) are shared with a central server for global model training, preserving privacy.",,,How can a federated graph neural network framework be designed to provide privacy-preserving personalized recommendations by leveraging decentralized user data while effectively modeling high-order user-item interactions?,"The paper investigates privacy-preserving recommendation methods, proposing FedGNN, which uses federated learning and graph neural networks. Experiments on six benchmark datasets show FedGNN achieves competitive or superior recommendation accuracy compared to centralized and privacy-preserving baselines, while effectively protecting user privacy through encrypted data and pseudo item sampling.","The research goal is privacy-preserving personalized recommendation; the approach is FedGNN, a federated graph neural network; the principal finding is that FedGNN achieves competitive or superior recommendation performance compared to centralized and privacy-preserving baselines while protecting user privacy.","Personalized recommendation, Graph neural network, Privacy-preserving, Federated learning",1.000,exact_title
wu_2024,Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs,"Jingpei Wu, Yan Xia",2024,Yes,HIGH,"Advances temporal reasoning capabilities for knowledge graphs with explicit timestamps, essential for HDM systems requiring temporal fact modeling and evolving personal information tracking over time.","Introduces Hyper-relational Temporal Knowledge Graph (HTKG) that couples every fact with explicit timestamps indicating temporal validity, addressing limitations in traditional KGs that lack temporal modeling capabilities for ever-evolving world knowledge.",Novel framework for temporal reasoning that extends knowledge graphs with time,"This paper addresses the limitation that traditional knowledge graphs lack explicit temporal information by proposing Hyper-relational Temporal Knowledge Graphs (HTKG) that couple every fact with timestamps explicitly indicating temporal validity. The approach recognizes that world knowledge is ever-evolving, making temporal reasoning over facts critically important for knowledge representation and reasoning systems. The research develops HTKG as a new data structure and creates benchmark datasets for evaluating temporal reasoning capabilities.",How can knowledge graphs be extended to efficiently handle temporal reasoning over facts with explicit time validity while supporting hyper-relational structures?,"Developed HTKG data structure with timestamp coupling, created Wiki-hy and YAGO-hy benchmark datasets with timestamped facts, implemented HTKG reasoning model for temporal fact processing, evaluated temporal reasoning capabilities across benchmark scenarios.","Demonstrated importance of explicit temporal modeling in knowledge graphs, showed effective representation of hyper-relational temporal facts with timestamp validity, created open-source datasets and models enabling future temporal KG research and applications.",Novel temporal knowledge graph framework with benchmarks and reasoning capabilities for time-aware fact processing with explicit timestamp modeling and hyper-relational support.,"Limited evaluation scope focusing on specific temporal reasoning tasks, need for broader assessment across diverse temporal patterns and real-world deployment scenarios, computational complexity considerations for large-scale temporal knowledge processing.",Provides important advancement in temporal knowledge representation essential for evolving personal knowledge systems that require explicit time-aware fact modeling and dynamic knowledge evolution tracking.,"Need for broader temporal reasoning evaluation across diverse domains, limited exploration of complex temporal relationship patterns, scalability assessment for large-scale temporal knowledge graphs, integration with real-world dynamic data sources.","Extend temporal reasoning to multi-hop scenarios and complex temporal patterns, develop adaptive temporal modeling for various data sources, explore integration with streaming data and real-time knowledge updates, optimize computational efficiency for large-scale deployment.","Offers architectural guidance for implementing temporal reasoning capabilities in personal knowledge systems that track evolving user information with explicit time validity, supporting dynamic knowledge evolution and historical context preservation.",https://aclanthology.org/2024.findings-emnlp.20/,10.18653/v1/D19-1522,"hyper-relational, personal-data-evolution, temporal-knowledge-graph, temporal-reasoning, time-aware-systems",Temporal Fact Reasoning over Hyper-Relational Knowledge Graphs,"Ding Zifeng, Wu Jingcheng, Wu Jingpei, Xia Yan, Xiong Bo, Tresp Volker",2024,reference-manager,,,,,,No explicit limitations or shortcomings are stated in the provided context.,,,"The research is reproducible. All experiments are implemented with PyTorch. The source code for baselines is available via provided GitHub links (e.g., https://github.com/ServiceNow/HypE). Hyperparameter search strategy, hardware details, and dataset construction are described. No explicit link for HypeTKG source code is given.",,,"The research goal is to improve hyper-relational temporal knowledge graph (HTKG) reasoning; the approach introduces HypeTKG, which leverages qualifier matching and time-invariant (TI) knowledge; results show HypeTKG achieves state-of-the-art performance, with ablation studies confirming the effectiveness of qualifier and TI knowledge integration.",,1.000,exact_title
xiang_2023,ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant,"Yifan Xiang, Zhenxi Zhang, Yixuan Weng, Shoujun Zhou, Yangfan He, Keqin Li, Twin Cities",2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on regrap-llava: reasoning enabled graph-based personalized large language and vision assistant providing insights for knowledge graph development and data integration.,"This 2023 paper by Yifan Xiang, Zhenxi Zhang, Yixuan Weng, Shoujun Zhou, Yangfan He, Keqin Li, Twin Cities explores regrap-llava: reasoning enabled graph-based personalized large language and vision assistant. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph, personal-knowledge",ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant,"Xiang Yifan, Zhang Zhenxi, Li Bin, Weng Yixuan, Zhou Shoujun, He Yangfan, Li Keqin",2025,reference-manager,,,,,,,"Construction of Knowledge Graphs (KGs): Building structured representations of objects, their attributes, and relations for personalized knowledge integration.",,,"How can integrating images, knowledge graphs, and Chain-of-Thought data enable the development and evaluation of personalized multimodal large language models capable of relational reasoning and contextual knowledge connection for personalized queries?","The paper investigates how answer length in Chain-of-Thought (CoT) QA affects model performance. Using experiments on closed-ended questions, it finds that longer CoT answers improve accuracy on difficult, multi-step reasoning tasks, but have little effect on simple tasks. The study concludes longer answers enhance reasoning for complex queries.","The research goal is to study how answer length in CoT QA pairs affects model performance; the approach refines answers by reducing reasoning steps and tests on closed-ended questions; results show longer answers improve performance on difficult tasks requiring reasoning, but have little effect on simple tasks.",,1.000,exact_title
xiao_2022,A Privacy-Preserving Subgraph-Level Federated Graph Neural Network via Differential Privacy,"Jing Xiao, Yeqing Qiu, Chenyu Huang, Jianzong Wang, Zhangcheng Huang",2022,Yes,HIGH,"Directly addresses privacy in federated graph neural networks using differential privacy at subgraph level, highly relevant to HDM privacy-preserving architectures for personal graph data",Differential privacy applied to weights and graph edges provides comprehensive privacy protection; Private Set Intersection enables graph extension while preserving privacy; federated approach addresses non-IID data challenges,Privacy-preserving federated graph neural network framework using differential,"This paper addresses federated graph neural networks for privacy-preserving applications, particularly in recommendation systems where subgraph-level federation is crucial. The research proposes DP-FedRec, a differential privacy-based federated GNN framework that leverages Private Set Intersection (PSI) to extend local graphs for each client, solving the non-IID data problem while maintaining strict privacy guarantees. The approach applies differential privacy to both weights and edges of the intersection graph to fully protect client privacy, representing a novel solution to the previously under-investigated area of DP-based federated GNNs.","How to guarantee privacy and solve non-IID data problems in federated graph neural networks simultaneously, particularly for recommendation applications?",Proposed DP-FedRec using Private Set Intersection (PSI) to extend local graphs; differential privacy applied to weights and graph edges; federated learning framework for recommendation systems; subgraph-level privacy protection,Differential privacy applied to weights and intersection graph edges; achieved privacy protection with minimal computational overhead; successful integration of PSI for graph extension,DP-FedRec framework; differential privacy integration for federated GNNs; Private Set Intersection for graph extension; privacy-preserving recommendation system,Sub-graph level approach may not generalize to all graph scenarios; computational overhead analysis needs further investigation; evaluation limited to recommendation domain,Demonstrated effective privacy preservation in federated recommendation systems while addressing non-IID data challenges through innovative PSI approach,Limited investigation of DP-based federated GNNs; challenges in balancing privacy with model utility; non-IID data problems in federated graph settings,Extend to broader graph learning applications; optimize computational efficiency; investigate adaptive privacy budget allocation,Uses differential privacy on intersection graph edges; demonstrates practical federated learning for graph data; PSI enables privacy-preserving graph expansion,https://arxiv.org/abs/2206.03492,10.48550/arXiv.2206.03492,"differential-privacy, federated-learning, graph-neural-networks, private-set-intersection, recommendation-systems",A Privacy-Preserving Subgraph-Level Federated Graph Neural Network via Differential Privacy,"Qiu Yeqing, Huang Chenyu, Wang Jianzong, Huang Zhangcheng, Xiao Jing",2022,reference-manager,,,"Implementation Insights show that adding noise (for privacy) in DP-FedRec protects data privacy without reducing data usefulness. The time to add noise increases with the number of points (nodes) in the dataset, not with the number of edges. DP-FedRec outperforms FedRec in Epinions with 12 clients.",,,,Graph Convolutional Network (GCN) under the Message Passing Neural Network (MPNN) framework: Used to extract and aggregate information from user-item graphs for prediction.,,,"How can a privacy-preserving federated graph neural network framework be designed for recommendation systems at the sub-graph level, effectively addressing both the Non-IID problem and privacy protection using differential privacy and private set intersection techniques?","The paper investigates federated learning for recommendation systems using graph neural networks (GNNs) with differential privacy (DP) to protect user data. It proposes a subgraph-level federated approach, evaluates performance on Epinions and MovieLens1M datasets, and finds that DP effectively balances privacy and data utility without compromising recommendation accuracy.","The paper's main objective is to improve recommendation systems by using federated graph neural networks with differential privacy; the key method is subgraph-level federated learning with privacy-preserving techniques, and the principal finding is enhanced prediction accuracy while protecting user privacy.","Keywords: Recommendation System, Federated Learning, Subgraph-Level Federated Learning, Graph Neural Network, Differential Privacy",1.000,exact_title
xie_2022,Enabling building digital twin: Ontology-based information management framework for multisource data integration,"X Xie, N Moretti, J Merino, J Y Chang, P Pauwels, A K Parlikad",2022,Yes,SUPER,"This paper directly addresses core aspects of heterogeneous data integration in knowledge graphs, providing critical insights for PKG architectures and temporal data management strategies that align perfectly with our research objectives.","Demonstrates techniques for integrating diverse data sources and managing heterogeneous information, essential for building comprehensive PKG systems with multi-modal data fusion capabilities.",Research on enabling building digital twin: ontology-based information management framework for multisource data integration providing insights for knowledge graph development and data integration.,"This 202 paper by X Xie, N Moretti, J Merino, J Y Chang, P Pauwels, A K Parlikad explores enabling building digital twin: ontology-based information management framework for multisource data integration. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,https://doi.org/10.1088/1755-1315/1101/9/092010,10.1088/1755-1315/1101/9/092010,"data-integration, knowledge-graph",Enabling building digital twin: Ontology-based information management framework for multi-source data integration,"Xie X, Moretti N, Merino J, Chang J Y, Pauwels P, Parlikad A K",2022,reference-manager,10.1088/1755-1315/1101/9/092010,,,,,The proposed Foundation Data Model (FDM) does not include building product or sensor observation ontologies.,,,No information available,,,The research goal is to enable effective information management for built assets by integrating heterogeneous data; the approach merges BOT and BRICK ontologies into a Foundation Data Model and compares data warehouse and mediator architectures; results show both architectures are preferable in different asset management scenarios.,No information available,0.995,fuzzy_title
xie_2022a,A federated graph neural network framework for privacy-preserving personalization,"Xing Xie, Electronic Engineering, Microsoft Research Asia",2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on a federated graph neural network framework for privacy-preserving personalization providing insights for knowledge graph development and data integration.,"This 2022 paper by Xing Xie, Electronic Engineering, Microsoft Research Asia explores a federated graph neural network framework for privacy-preserving personalization. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1038/s41467-022-30714-9,"data-integration, knowledge-graph, personal-knowledge",A federated graph neural network framework for privacy-preserving personalization,"Wu Chuhan, Wu Fangzhao, Lyu Lingjuan, Qi Tao, Huang Yongfeng, Xie Xing",2022,reference-manager,10.1038/s41467-022-30714-9,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
xie_2022b,PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling,"Haojie Xie, Yirong Chen, Xiaofen Xing, Jingkai Lin",2022,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Digital twin concept provides strong capability in integrating data from fragmented and heterogeneous sources through semantics-based model and linked data approach, enabling better-informed decision-making.",Ontology-based framework for building digital twins with multi-source data integration capabilities.,"This paper develops an ontology-based information management framework for building digital twins, addressing the challenge of integrating multi-source data through a Foundation Data Model that merges building topology and BRICK ontologies.",How to integrate multi-source data for building digital twins using an ontology-based information management framework?,"Developed Foundation Data Model (FDM), reused and merged building topology and BRICK ontologies, compared data warehouse and mediator integration architectures, conducted case study implementation.","Established standardised and modularised paradigms for discovering, fetching, and integrating data from disparate sources in building digital twin contexts.",,Access restricted by captcha system; full evaluation of framework scalability and performance not available from abstract.,Provides valuable architectural pattern for ontology-based data integration applicable to HDM systems requiring heterogeneous data fusion.,,Extend to personal digital twins; integrate real-time sensor data; develop standardized ontologies for personal data domains.,Agent Alpha: Important paper for ontology-based integration but couldn't download due to access restrictions. Architecture insights valuable for HDM design.,https://iopscience.iop.org/article/10.1088/1755-1315/1101/9/092010,10.18653/v1/P16-2096,"building-information-management, digital-twin, linked-data, multi-source-data-integration, ontology",PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling,"Xie Haojie, Chen Yirong, Xing Xiaofen, Lin Jingkai, Xu Xiangmin",2024,reference-manager,,,,,,,Psychoanalysis: Focuses on exploring unconscious thoughts and past experiences to understand current behavior.,,,No information available,"The paper examines counseling strategies, focusing on how counselors use inquiry, feedback, and therapy techniques to promote client self-reflection and problem-solving. The methodology involves analyzing counselor-client interactions. Key findings highlight the importance of openness, emotional regulation, and relationship-building. The study concludes that these approaches foster client autonomy and effective counseling outcomes.",,,1.000,exact_title
xie_2024a,Log Anomaly Detection by Adversarial Autoencoders With Graph Feature Fusion,"Yuxia Xie, Kai Yang",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",GAE-Log framework uses event graphs and knowledge graphs to model logs with adversarial training for unsupervised anomaly detection,Graph-based log anomaly detection framework using adversarial autoencoders,"This paper proposes GAE-Log, a framework that uses event graphs and knowledge graphs to model logs, employing adversarial training of autoencoders for anomaly detection while integrating temporal dynamics and contextual information",How can log anomaly detection be improved to handle the increasing scale and complexity of distributed systems?,"GAE-Log framework using event graphs and knowledge graphs, adversarial training of autoencoders, integration of temporal dynamics and contextual information","Outperforms state-of-the-art log anomaly detection methods with significant performance improvements, reduces computational complexity, enables unsupervised training",,"Specific performance metrics not detailed in abstract, evaluation limited to log data domain",Demonstrates effective use of graph-based approaches for temporal anomaly detection in complex systems,,"Extend to personal activity logs, integrate with HDM monitoring systems, develop user-friendly interfaces",Agent Epsilon: Graph-based temporal anomaly detection applicable to HDM system monitoring and user activity analysis,https://ieeexplore.ieee.org/document/10231001/,10.1109/TETCI.2023.3306406,"adversarial-learning, anomaly-detection, graph-neural-networks, log-analysis, temporal-dynamics",Log Anomaly Detection by Adversarial Autoencoders With Graph Feature Fusion,"Xie Yuxia, Yang Kai",2024,reference-manager,10.1109/tr.2023.3305376,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
xie_2024b,Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models,"Qianqian Xie, Temporal Reasoning, Chenhan Yuan",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on back to the future: towards explainable temporal reasoning with large language models providing insights for knowledge graph development and data integration.,"This 2024 paper by Qianqian Xie, Temporal Reasoning, Chenhan Yuan explores back to the future: towards explainable temporal reasoning with large language models. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3589334.3645376,"data-integration, knowledge-graph, temporal-data",Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models,"Yuan Chenhan, Xie Qianqian, Huang Jimin, Ananiadou Sophia",2024,reference-manager,10.1145/3589334.3645376,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
xie_2024c,En4S: Enabling SLOs in Serverless Storage Systems,"Minghao Xie, Chen Qian, Heiner Litz",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on en4s: enabling slos in serverless storage systems providing insights for knowledge graph development and data integration.,"This 2024 paper by Minghao Xie, Chen Qian, Heiner Litz explores en4s: enabling slos in serverless storage systems. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3698038.3698529,"data-integration, knowledge-graph",En4S: Enabling SLOs in Serverless Storage Systems,"Xie Minghao, Qian Chen, Litz Heiner",2024,reference-manager,10.1145/3698038.3698529,,"The implementation separates compute and transcoding functions to reduce lambda load times and execution limits. Performance is mainly IO-bound for analytics workloads. The scheduler outperforms ReFlex in reducing wait times, especially with varying batch sizes and LC tenant ratios, demonstrating improved efficiency and cost-effectiveness.",,,,"Deployment of baseline ephemeral storage solutions (ReFlex, Jiffy, S3) for comprehensive performance and cost comparison.",,,"How can ephemeral storage systems be designed to guarantee SLOs, scalability, and performance predictability for a large number of tenants with diverse requirements in serverless computing environments?","The paper investigates challenges in guaranteeing Service Level Objectives (SLOs) in ephemeral storage for serverless systems. It introduces En4S, a profile-based storage system, evaluated against S3 and Jiffy. En4S shows lower latency and better predictability in some scenarios, but metadata management limits its end-to-end performance.","The research goal is to address challenges in guaranteeing SLOs in ephemeral storage for multi-tenant, serverless systems; the approach is a profile-based ephemeral storage system; the principal finding is that their platform enables predictable performance by enforcing tail latency and IOPS SLOs under dynamic, high-load conditions.",,1.000,exact_title
xiong_2024,Large Language Models Can Learn Temporal Reasoning,"Siheng Xiong, Ali Payani, Ramana Kompella, Faramarz Fekri",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on large language models can learn temporal reasoning providing insights for knowledge graph development and data integration.,"This 2024 paper by Siheng Xiong, Ali Payani, Ramana Kompella, Faramarz Fekri explores large language models can learn temporal reasoning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.18653/v1/2024.findings-acl.401,"data-integration, knowledge-graph, temporal-data",Large Language Models Can Learn Temporal Reasoning,"Xiong Siheng, Payani Ali, Kompella Ramana, Fekri Faramarz",2024,reference-manager,,,,,,,"Temporal graph (TG): Uses structured, intuitive representations of temporal relationships to enhance reasoning.",,,"How can large language models be improved to perform complex temporal reasoning tasks by integrating temporal graphs, chain-of-thought reasoning, and external knowledge?","The paper proposes TG-LLM, a framework that enhances large language models' temporal reasoning by integrating temporal graphs and intermediate reasoning steps. Using Llama2-13B and ablation studies, the methodology demonstrates that explicit graph structures, chain-of-thought bootstrapping, data augmentation, and external knowledge significantly improve performance. TG-LLM outperforms existing methods.","The research goal is to improve large language models' temporal reasoning by introducing TG-LLM, a framework that translates text to temporal graphs and performs graph-based reasoning; results show TG-LLM outperforms existing methods, especially when using graph augmentation and external knowledge.",,1.000,exact_title
xu_2015,Viewpoints Future Research Directions of Software Engineering and Knowledge Engineering¤,Haiping Xu,2015,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on viewpoints future research directions of software engineering and knowledge engineering¤ providing insights for knowledge graph development and data integration.,"This 2015 paper by Haiping Xu explores viewpoints future research directions of software engineering and knowledge engineering¤. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1142/S0218194015500035,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
xu_2020,Temporal Knowledge Graph Reasoning with Historical Contrastive Learning,"Yi Xu, Junjie Ou, Hui Xu, Luoyi Fu",2020,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on temporal knowledge graph reasoning with historical contrastive learning providing insights for knowledge graph development and data integration.,"This 2020 paper by Yi Xu, Junjie Ou, Hui Xu, Luoyi Fu explores temporal knowledge graph reasoning with historical contrastive learning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph, temporal-data",Temporal Knowledge Graph Reasoning with Historical Contrastive Learning,"Xu Yi, Ou Junjie, Xu Hui, Fu Luoyi",2022,reference-manager,,,,,,,Historical contrastive learning: Involves two stages—learning contrastive representations and training a binary classifier to distinguish historical from non-historical dependencies.,,,"How can the proposed CENET (Contrastive Event Network) model improve event forecasting in temporal knowledge graphs by leveraging contrastive learning to effectively predict both repetitive and new events, considering dependencies on historical and non-historical entities?","The paper proposes CENET, a novel model for forecasting future events in temporal knowledge graphs (TKGs) using contrastive learning. By modeling both historical and non-historical dependencies and employing a copy mechanism and supervised contrastive learning, CENET achieves significant improvements in event prediction accuracy across multiple benchmark datasets.","The research goal is to improve future event forecasting on temporal knowledge graphs; the approach introduces CENET, a model using historical contrastive learning to distinguish historical and non-historical dependencies; results show CENET significantly outperforms previous methods, achieving at least 8.3% relative improvement in Hits@1 on event-based datasets.",,1.000,exact_title
xu_2023a,Adaptive Feature Fusion Networks for Origin-Destination Passenger Flow Prediction in Metro Systems,"Yuhang Xu, Yan Lyu, Guangwei Xiong, Shuyu Wang, Weiwei Wu, Helei Cui, Junzhou Luo, Adaptive Feature, Fusion Network",2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",AFFN framework captures periodic patterns of passenger flows and handles data sparsity through adaptive feature fusion and multi-task learning,Adaptive neural network framework for urban mobility prediction using multi-source data,"This paper proposes Adaptive Feature Fusion Network (AFFN) for predicting passenger flow in metro systems, using multiple knowledge-based graphs to capture spatial dependencies and analyze external factors affecting passenger flows",How can passenger flow be accurately predicted in metro systems considering complex spatial and temporal dynamics?,"Adaptive Feature Fusion Network (AFFN), multi-task AFFN for data sparsity, multiple knowledge-based graphs for spatial dependencies, external factor analysis","AFFN outperformed state-of-the-art baselines, successfully captured periodic patterns, demonstrated effectiveness in handling incompleteness and sparsity of OD matrices",,"Specific to metro systems, limited generalizability to other mobility contexts",Provides insights into predictive modeling of human movement patterns through data-driven approaches,,"Apply to personal movement prediction, integrate with HDM location tracking, develop user behavior models",Agent Epsilon: Spatial-temporal modeling applicable to HDM human behavior prediction and activity patterns,https://ieeexplore.ieee.org/document/10026633/,10.1109/TITS.2023.3237523,"feature-fusion, graph-neural-networks, passenger-flow-prediction, spatial-temporal-modeling, urban-mobility",Adaptive Feature Fusion Networks for Origin-Destination Passenger Flow Prediction in Metro Systems,"Xu Yuhang, Lyu Yan, Xiong Guangwei, Wang Shuyu, Wu Weiwei, Cui Helei, Luo Junzhou",2023,reference-manager,10.1109/tits.2023.3239101,,"The Implementation Insights highlight that AFFN and multi-task AFFN effectively predict metro passenger flows, capturing complex patterns using advanced neural networks. Although their prediction time is longer than smaller models, it remains within milliseconds, supporting real-time use. AFFN is scalable and maintains high accuracy even in complex metro systems.",,,,Direct Estimation Approaches: Use location-specific sample surveys to count passengers and collect trip information from a random sample.,,,"How can the integration of external factor-based attention modules and enhanced multi-graph convolution gated recurrent units improve the accuracy of real-time origin-destination flow prediction in metro systems, considering periodic patterns, external influences, and incomplete or sparse OD matrices?","The paper proposes an external factor-based attention module and an Enhanced Multi-Graph Convolution Gated Recurrent Unit (EMGC-GRU) to improve metro origin-destination passenger flow prediction. Using deep learning and aggregated estimation approaches, the AFFN model outperforms baselines in accuracy, demonstrating effective spatial-temporal modeling and practical implications for metro systems.","The research goal is to improve metro origin-destination flow prediction; the approach is an Adaptive Feature Fusion Network (AFFN) using spatial-temporal modeling and external factor-based attention; results show AFFN outperforms baselines, and multi-task learning with inflow/outflow prediction further boosts accuracy.",,1.000,exact_title
xu_2023b,TFSF: Topological and Feature Space Fusion with Spatio-Temporal Modeling for Crop Yield Prediction,"Shifeng Xu, Yijing Zhou, Cuiting Huang, Xiaoyang Yu, Chao Wu",2023,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",TFSF-GNN incorporates spatial knowledge through feature space similarity rather than just geographical distance for improved crop yield predictions,Graph neural network approach for agricultural prediction using spatial-temporal data,This paper proposes Topology-Feature Space Fusion Graph Neural Network (TFSF-GNN) to improve crop yield prediction by incorporating spatial relationships through feature space similarity beyond traditional geographical distance,How can spatial relationships and advanced machine learning techniques improve crop yield prediction?,"Developed TFSF-GNN using feature space similarity graphs, multiple graph convolutional networks, spatio-temporal modeling for county-level predictions",Outperformed existing network structures on county-level yield prediction tasks by capturing complex climate-geography interactions,,"Agricultural domain specific, limited transferability to personal knowledge systems",Demonstrates spatial-temporal modeling techniques but limited applicability to HDM personal data contexts,,Consider spatial-temporal modeling patterns for personal activity tracking in HDM systems,Agent Epsilon: Agricultural focus limits relevance - spatial-temporal techniques might inspire HDM location modeling,https://ieeexplore.ieee.org/document/10152724/,10.1109/JSTARS.2023.3283704,"agriculture, crop-yield-prediction, feature-fusion, graph-neural-networks, spatial-temporal-modeling",TFSF: Topological and Feature Space Fusion with Spatio-Temporal Modeling for Crop Yield Prediction,"Xu Shifeng, Zhou Yijing, Yu Xiaoyang, Huang Cuiting, Wu Chao",2023,reference-manager,10.1109/cscwd57460.2023.10152724,,"The TFSF-GNN model outperforms all baseline methods in soybean yield prediction, achieving the lowest MAE, MAPE, and RMSE across 2015-2017. Ablation studies show both topological and feature space fusion are crucial for performance. The model effectively leverages spatio-temporal data and multi-channel graph convolution for improved accuracy.",,,,"Preprocessing: Climate, soil quality, and management data are processed to form feature vectors for each county and year.",,,"How can spatio-temporal modeling using a multi-channel graph convolutional neural network (TFSF-GNN) effectively extract and fuse correlated information from climate, soil, and management data to improve crop yield prediction accuracy across different regions?","The paper aims to improve crop yield prediction by proposing the TFSF-GNN model, which fuses temporal and spatial information using multiple graph convolutional networks with attention mechanisms. Experiments on soybean data (1980–2017) show TFSF-GNN outperforms traditional and deep learning models, achieving higher accuracy and better generalization.","The research goal is crop yield prediction; the approach is the TFSF-GNN model that fuses temporal, topological, and feature space information using multi-channel graph convolution and attention; results show TFSF-GNN achieves higher accuracy and better generalization than statistical and deep learning baselines on real soybean yield data.",,1.000,exact_title
xu_2025,Big data fusion with knowledge graph: a comprehensive overview,"Huan Xu, Pengfei Zhang",2025,Yes,SUPER,"This paper directly addresses core aspects of heterogeneous data integration in knowledge graphs, providing critical insights for PKG architectures and temporal data management strategies that align perfectly with our research objectives.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on big data fusion with knowledge graph: a comprehensive overview providing insights for knowledge graph development and data integration.,"This 2025 paper by Huan Xu, Pengfei Zhang explores big data fusion with knowledge graph: a comprehensive overview. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1016/j.,"data-integration, knowledge-graph",Big data fusion with knowledge graph: a comprehensive overview,"Liu Jia, Lan Ruotian, Du Yajun, Yuan Xipeng, Xu Huan, Li Tianrui, Huang Wei, Zhang Pengfei",2025,reference-manager,10.1007/s10489-025-06549-4,,,,,,Machine learning methods are used to extract features from data and fuse them with embedded knowledge graphs at the feature level.,,,"How can knowledge graph-based data fusion methods effectively integrate multi-source heterogeneous data to address challenges such as data quality, privacy, and application-specific requirements in real-world scenarios?","This paper systematically reviews data fusion methods using knowledge graphs, categorizing them by data types: raw data fusion, raw data with knowledge graph, and knowledge graph fusion. It highlights frameworks, applications, and future directions, concluding that knowledge graphs enhance data fusion's effectiveness, especially for heterogeneous and dynamic data.",The research goal is to systematically review and categorize data fusion methods using knowledge graphs; the approach involves classifying methods by data type and analyzing frameworks and examples; the principal finding is a theoretical and practical guide for multi-source heterogeneous data fusion in intelligent systems.,,1.000,exact_title
xua_2020,AI-CTO: Knowledge graph for automated and dependable software stack solution,"Xiaoyun Xua, Jingzheng Wua, Mutian Yanga, Tianyue Luoa, Qianru Mengd, Yanjun Wua, Beijing Baidux",2020,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on ai-cto: knowledge graph for automated and dependable software stack solution providing insights for knowledge graph development and data integration.,"This 2020 paper by Xiaoyun Xua, Jingzheng Wua, Mutian Yanga, Tianyue Luoa, Qianru Mengd, Yanjun Wua, Beijing Baidux explores ai-cto: knowledge graph for automated and dependable software stack solution. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",AI-CTO: Knowledge graph for automated and dependable software stack solution,"Xu Xiaoyun, Wu Jingzheng, Yang Mutian, Luo Tianyue, Meng Qianru, Li Weiheng, Wu Yanjun",2021,reference-manager,10.3233/jifs-200899,,,,,No attributes for relations in the software knowledge graph; more information could be included in the future.,,,,,,The research goal is to automatically suggest effective software stack solutions using a knowledge graph; the approach combines graph structure and semantic information with an SVM model for prediction; results show AI-CTO outperforms baselines in recommending valuable software stacks.,,1.000,exact_title
yan_2024a,Federated Heterogeneous Graph Neural Network for Privacy-preserving Recommendation,"Bo Yan, Yang Cao, Haoyu Wang, Wenchuan Yang, Junping Du, Chuan Shi",2024,Yes,HIGH,"Addresses privacy-preserving federated learning for heterogeneous information networks in recommendation systems, directly relevant to HDM privacy architectures requiring distributed personal data processing while maintaining data ownership and privacy.",Achieves 34% improvement in Hit Rate@10 and 42% improvement in NDCG@10 through FedHGNN framework that partitions HINs into private client-side and shared server-side networks while applying differential privacy to protect user interactions and high-order patterns.,Privacy-preserving federated learning framework for heterogeneous information,This paper addresses privacy challenges in recommender systems using heterogeneous information networks (HINs) by proposing a federated learning approach where HINs are partitioned into private (client-side) and shared (server-side) networks. The FedHGNN framework enables collaborative training of recommendation models using distributed HINs while protecting user privacy through differential privacy techniques and semantic-preserving user interaction publishing methods that maintain the broken semantic connections in distributed networks.,How can federated learning be applied to heterogeneous information networks for recommendation systems while maintaining strong privacy guarantees and preserving semantic relationships across distributed data?,"Developed FedHGNN framework with HIN partitioning strategy, implemented semantic-preserving user interaction publishing method, designed HGNN model with node- and semantic-level aggregations, applied differential privacy techniques for user pattern protection, evaluated under reasonable privacy budgets.","Demonstrated 34% improvement in Hit Rate@10 and 42% improvement in NDCG@10 compared to baseline methods, achieved effective privacy protection through differential privacy mechanisms, successfully recovered broken semantic connections in distributed network environments while maintaining recommendation quality.",Federated heterogeneous graph neural network framework with significant performance improvements and strong privacy guarantees for distributed recommendation systems.,"Limited evaluation to specific recommendation datasets, requires further validation across diverse heterogeneous network types, computational complexity considerations for large-scale federated deployment, privacy-utility trade-off optimization needs refinement.",Provides novel approach to privacy-preserving recommendation systems by leveraging federated learning and graph neural network techniques while maintaining semantic relationships and user privacy in distributed environments.,"Need for broader evaluation across diverse application domains and heterogeneous network types, optimization of privacy-utility trade-offs, scalability assessment for large-scale federated deployments, integration with real-world recommendation systems.","Extend framework to additional recommendation domains and heterogeneous network types, optimize computational efficiency for large-scale federated scenarios, develop adaptive privacy mechanisms, investigate integration with existing commercial recommendation platforms.","Offers practical framework for implementing privacy-preserving personal recommendation systems in distributed HDM architectures with focus on heterogeneous data integration, user privacy protection, and semantic relationship preservation across federated environments.",https://arxiv.org/abs/2310.11730,arXiv:2310.11730,"differential-privacy, federated-learning, graph-neural-networks, heterogeneous-information-networks, privacy-preserving-recommendation",Federated Heterogeneous Graph Neural Network for Privacy-preserving Recommendation,"Yan Bo, Cao Yang, Wang Haoyu, Yang Wenchuan, Du Junping, Shi Chuan",2024,reference-manager,10.1145/3589334.3645693,,,,,,"Two-stage perturbation mechanism: First perturbs user-related shared HINs using EM (Expectation-Maximization) for selection, then perturbs user-item interactions within selected shared HINs to preserve semantics and privacy.",,,How can we recover broken meta-path semantics for HIN-based federated recommendation (FedRec) while rigorously protecting user privacy through formal privacy definitions and a semantic-preserving user interaction publishing mechanism?,"The paper proposes FedHGNN, a Federated Heterogeneous Graph Neural Network for privacy-preserving recommendations on HINs. It introduces a two-stage perturbation mechanism to protect user privacy while recovering semantic information. Experiments show FedHGNN outperforms baselines, achieving strong recommendation accuracy and rigorous privacy guarantees.","The research goal is privacy-preserving recommendation on distributed HINs; the approach introduces FedHGNN, combining a two-stage perturbation mechanism for semantic-preserving user interaction publishing with a heterogeneous GNN; results show FedHGNN achieves strong recommendation performance while providing rigorous privacy guarantees.",,1.000,exact_title
yan_2024b,Prior knowledge-guided multilevel graph neural network for tumor risk prediction and interpretation via multi-omics data integration,"Hongxi Yan, Dawei Weng, Dongguo Li, Yu Gu, Wenji Ma, Qingjie Liu",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Hierarchical GNN design enables effective multi-level feature extraction; Prior knowledge integration improves prediction accuracy; Pathway-level aggregation enhances interpretability,Multilevel graph neural network leveraging prior knowledge for enhanced tumor risk prediction through multi-omics integration,"This paper addresses critical challenges in multi-omics data integration for cancer survival prediction, including limited sample sizes, high dimensionality, and heterogeneous data modalities. The authors propose a hierarchical graph neural network that sequentially leverages multi-omics data, gene regulatory networks, and pathway information. The method constructs guidance graphs to establish associations within and between omics data, using GNN to extract gene features based on gene interactions. A learnable linear layer aggregates gene-level features into pathway-level features, enhancing both accuracy and interpretability. The approach employs GNN-Explainer and IGscore algorithms for non-linear identification of key factors at gene and pathway levels.",How can prior knowledge such as gene regulatory networks and pathway information be effectively integrated with multi-omics data to improve tumor risk prediction accuracy and interpretability?,Developed Multilevel-GNN with hierarchical design; Constructed guidance graphs for omics data associations; Implemented learnable linear layer for pathway-level aggregation; Applied GNN-Explainer and IGscore for interpretation,"Achieved better accuracy compared with existing methods; Identified key genes (SEC61G, CYP27B1) and pathways associated with tumor pathogenesis; Enhanced model interpretability at gene and pathway levels",,Not explicitly detailed in the available information,Successfully integrates prior biological knowledge with deep learning for improved cancer survival prediction,,Extend to other cancer types; Integrate additional omics modalities; Develop more advanced interpretation algorithms,Demonstrates effective integration of domain knowledge with graph neural networks; Hierarchical design enables multi-level feature extraction; Interpretability mechanisms crucial for biomedical applications,https://academic.oup.com/bib/article/doi/10.1093/bib/bbae184/7658016,10.1093/bib/bbae184,"cancer-prediction, graph-neural-networks, interpretability, multi-omics, prior-knowledge",Prior knowledge-guided multilevel graph neural network for tumor risk prediction and interpretation via multi-omics data integration,"Yan Hongxi, Weng Dawei, Li Dongguo, Gu Yu, Ma Wenji, Liu Qingjie",2024,reference-manager,10.1093/bib/bbae184,,The implementation insights show that pathway aggregation and graph neural network modules improve prediction accuracy and stability over standard neural networks and other dimensionality reduction methods. The model performs well across various time divisions and clinical data. The explanation methods effectively identify gene pathways strongly linked to patient risk.,,,,Ablation experiments were conducted to assess the effectiveness of different model components and dimensionality reduction methods.,,,"How can a Multilevel Graph Neural Network that integrates multi-omics data, gene regulatory networks, and pathway information improve prediction performance and interpretability in cancer research compared to existing methods?","The study aims to improve cancer risk prediction using multi-omics data by introducing a pathway aggregation module with a graph neural network. Through ablation studies and comparisons with other methods, the proposed approach achieved superior AUC and stability. Key genes and pathways identified correlate strongly with patient risk, supporting the model’s interpretability.","The research goal is tumor risk prediction and interpretation using multi-omics data; the approach integrates prior knowledge-guided multilevel graph neural networks, and the principal finding is that this method outperforms others in AUC and identifies key genes and pathways strongly correlated with patient risk.",,1.000,exact_title
yang_2022,Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling,"Linyao Yang, Hongyang Chen, Senior Member, Zhao Li, Xiao Ding, Xindong Wu",2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on give us the facts: enhancing large language models with knowledge graphs for fact-aware language modeling providing insights for knowledge graph development and data integration.,"This 2022 paper by Linyao Yang, Hongyang Chen, Senior Member, Zhao Li, Xiao Ding, Xindong Wu explores give us the facts: enhancing large language models with knowledge graphs for fact-aware language modeling. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Give Us the Facts: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling,"Yang Linyao, Chen Hongyang, Li Zhao, Ding Xiao, Wu Xindong",2021,reference-manager,,,,,,,"Data augmentation: Refines training data during pretraining, emphasizing informative words to improve factual knowledge in language models.",,,"How can integrating knowledge graphs (KGs) with pre-trained language models (PLMs) and large language models (LLMs) enhance semantic representation, factual knowledge modeling, and reduce issues such as hallucination and inconsistency in tasks like sentiment analysis, knowledge graph completion, and question answering?","The paper systematically reviews methods for enhancing large language models (LLMs) with knowledge graphs (KGs), focusing on knowledge graph enhanced large language models (KGLLMs). It categorizes and compares approaches, discusses challenges like hallucination and inconsistency, and concludes that KG integration improves factual accuracy and reasoning in LLMs.","The paper's main objective is to review and categorize methods for enhancing large language models (LLMs) with knowledge graphs (KGs), using a systematic approach, and concludes that integrating KGs into LLMs (KGLLMs) improves factual knowledge modeling; keywords: research goal, systematic review, knowledge graph enhancement, LLMs, results.",,1.000,exact_title
yang_2024a,Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education,"Rui Yang, Boming Yang, Sixun Ouyang, Tianwei She, Aosong Feng, Yuang Jiang, Freddy Lecue, Jinghui Lu, Irene Li",2024,Yes,MEDIUM,"Focuses on knowledge graph construction using LLMs, relevant to PKG architectures for educational content but limited scope to NLP education domain",LLMs can provide global perspective for knowledge graph construction; zero-shot KG construction achievable with proper frameworks; educational domain demonstrates practical applicability,LLM-powered framework for creating knowledge graphs with global triplet fusion,"This paper proposes Graphusion, a zero-shot knowledge graph construction approach using large language models with global triplet fusion capabilities. The framework addresses limitations in existing KG construction approaches by leveraging LLMs to provide comprehensive knowledge integration without requiring domain-specific training. The approach surpasses supervised baselines by 10% in link prediction accuracy and introduces TutorQA benchmark with 1,200 QA pairs for evaluation in the NLP education domain.",How can large language models facilitate zero-shot knowledge graph construction with global perspective and improved accuracy?,Zero-shot knowledge graph construction framework; global triplet fusion using LLMs; TutorQA benchmark development; evaluation on concept entity extraction and relation recognition,Surpasses supervised baselines by 10% in link prediction accuracy; achieves high scores in concept entity extraction and relation recognition; demonstrates effective zero-shot KG construction,"Introduced TutorQA benchmark with 1,200 QA pairs; zero-shot KG construction framework; improved link prediction performance; global triplet fusion methodology",Focused specifically on NLP educational domain; limited evaluation beyond education context; scalability to other domains not demonstrated,Demonstrates potential of LLMs in automated knowledge graph creation with global perspective and improved accuracy over traditional methods,Limited global perspective in existing KG construction approaches; need for domain-agnostic KG construction methods; lack of comprehensive educational KG benchmarks,Expand framework to other domain-specific knowledge graphs; develop domain-agnostic construction methods; create larger-scale educational benchmarks,Achieves high scores in concept entity extraction and relation recognition; zero-shot approach reduces training requirements; global triplet fusion improves KG completeness,https://arxiv.org/abs/2407.10794,10.48550/arXiv.2407.10794,"educational-technology, knowledge-graph, llm, nlp, zero-shot-learning",Graphusion: Leveraging Large Language Models for Scientific Knowledge Graph Fusion and Construction in NLP Education,"Yang Rui, Yang Boming, Ouyang Sixun, She Tianwei, Feng Aosong, Jiang Yuang, Lecue Freddy, Lu Jinghui, Li Irene",2024,reference-manager,,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
yang_2024b,SSTKG: Simple Spatio-Temporal Knowledge Graph for Intepretable and Versatile Dynamic Information Embedding,Ruiyi Yang,2024,Yes,HIGH,"Addresses spatio-temporal knowledge graph embedding for dynamic information systems, highly relevant to HDM applications requiring location-aware temporal modeling and versatile personal data representation across space and time.","Introduces novel 3-step embedding method for integrating spatial and temporal data into knowledge graphs, addressing limitations in current static approaches and enabling dynamic information representation for improved prediction and recommendation accuracy.",Simple spatio-temporal knowledge graph framework that enables interpretable,"This paper addresses the limitation that current knowledge graph methods predominantly rely on static data, neglecting the dynamic nature and hidden spatio-temporal attributes of real-world scenarios, which often results in suboptimal predictions and recommendations. The proposed SSTKG framework provides a comprehensive approach to understanding underlying patterns and trends in dynamic knowledge graphs by integrating spatial and temporal dimensions through a novel 3-step embedding methodology.",How can spatio-temporal knowledge graphs be designed to capture dynamic information patterns while maintaining interpretability and versatility for various prediction and recommendation applications?,"Developed Simple Spatio-Temporal Knowledge Graph (SSTKG) framework with novel 3-step embedding method, integrated spatial and temporal data representation, evaluated across multiple domains including retail sales forecasting and traffic volume prediction, addressed scalability and semantic understanding challenges.","Enhanced accuracy of predictions and relevance of recommendations through dynamic spatio-temporal modeling, demonstrated effectiveness across retail sales forecasting and traffic volume prediction scenarios, provided comprehensive framework for understanding patterns and trends in dynamic knowledge graphs.",Spatio-temporal knowledge graph framework with improved prediction accuracy and recommendation relevance through dynamic information embedding and interpretable pattern recognition.,"Current methods predominantly rely on static data limiting dynamic modeling capabilities, existing spatio-temporal inference methods face scalability issues, evaluation limited to specific application domains requiring broader validation.",Paves the way for more effective utilization of spatio-temporal data in knowledge graphs with potential impacts across a wide range of sectors requiring dynamic information modeling and temporal-spatial pattern recognition.,"Need for broader evaluation across diverse application domains, scalability assessment for large-scale spatio-temporal data processing, integration with real-time data streams, enhanced interpretability mechanisms for complex spatio-temporal relationships.","Expand framework to additional application domains beyond retail and traffic, develop real-time processing capabilities for streaming spatio-temporal data, enhance interpretability features for complex pattern explanation, optimize computational efficiency for large-scale deployment.","Provides architectural framework for implementing spatio-temporal knowledge systems in personal data management contexts, enabling location-aware temporal modeling and dynamic pattern recognition for comprehensive personal information representation across space and time.",https://arxiv.org/abs/2402.12132,arXiv:2402.12132,"dynamic-information-embedding, location-aware-modeling, spatio-temporal-knowledge-graphs, temporal-spatial-patterns",SSTKG: Simple Spatio-Temporal Knowledge Graph for Intepretable and Versatile Dynamic Information Embedding,"Yang Ruiyi, Salim Flora D., Xue Hao",2024,reference-manager,10.1145/3589334.3645441,,,,,,"Construction of Simple Spatio-Temporal Knowledge Graph (SSTKG): Entities and their spatio-temporal relationships are modeled using embeddings and an “influence” metric, focusing on flexible, interpretable representations.",,,"How can a Simple Spatio-Temporal Knowledge Graph (SSTKG) framework be designed to efficiently and interpretably model dynamic spatio-temporal relationships among entities, enabling accurate prediction and knowledge graph completion across diverse real-world datasets?","The paper proposes the Simple Spatio-Temporal Knowledge Graph (SSTKG) framework to improve recommendation and prediction tasks by modeling both spatial and temporal relations using three types of embeddings and """"influence."""" Experiments on real-world datasets show SSTKG outperforms baseline models and offers strong interpretability. Future work aims to refine and enhance SSTKG.","The research goal is to develop a Simple Spatio-Temporal Knowledge Graph (SSTKG) framework using embeddings and """"influence"""" to model entity relations; the approach integrates spatial-temporal data for prediction tasks, and results show SSTKG outperforms baseline models in accuracy and interpretability on real-world datasets.",,1.000,exact_title
yang_2025,Graphusion: A RAG Framework for Scientific Knowledge Graph Construction with a Global Perspective,"Rui Yang, Fan Gao, Moritz Blum, Freddy Lecue, Boming Yang, Aosong Feng, Tianwei She, Jinghui Lu, Xinjie Zhao, Sixun Ouyang, Yuang Jiang, Irene Li",2025,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on graphusion: a rag framework for scientific knowledge graph construction with a global perspective providing insights for knowledge graph development and data integration.,"This 2025 paper by Rui Yang, Fan Gao, Moritz Blum, Freddy Lecue, Boming Yang, Aosong Feng, Tianwei She, Jinghui Lu, Xinjie Zhao, Sixun Ouyang, Yuang Jiang, Irene Li explores graphusion: a rag framework for scientific knowledge graph construction with a global perspective. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.18653/v1/P19-1470,"data-integration, knowledge-graph",Graphusion: A RAG Framework for Scientific Knowledge Graph Construction with a Global Perspective,"Yang Rui, Yang Boming, Zhao Xinjie, Gao Fan, Feng Aosong, Ouyang Sixun, Blum Moritz, She Tianwei, Jiang Yuang, Lecue Freddy, Lu Jinghui, Li Irene",2025,reference-manager,10.1145/3701716.3717821,,"Implementation Insights are as follows: The Graphusion pipeline, which constructs knowledge graphs (KGs), outperforms baselines like GPT-4o and GraphRAG across multiple tasks, especially in tasks requiring global understanding. It generates more relevant and convincing answers, introduces expanded entities, and generalizes well to new domains like Japanese medical data.",,,,Entity extraction: Both GraphRAG and Graphusion extract entities from text to build a knowledge graph.,,,"What is the primary relationship between learning {entity\_1} and understanding {entity\_2} in the domain of {domain}, and is knowledge of {entity\_1} a necessary prerequisite for comprehending {entity\_2}?","The paper investigates improving knowledge graph construction in natural language processing using the Graphusion method. Through comparative experiments and expert evaluations, Graphusion outperforms baselines like GPT-4o and GraphRAG in accuracy, semantic alignment, and expert-rated criteria, especially in complex educational tasks. The study concludes Graphusion enhances factuality and persuasiveness.","The paper's main objective is to improve knowledge graph construction in NLP by introducing the Graphusion framework, which fuses local and global knowledge graphs; the key method is knowledge fusion, and the principal finding is that Graphusion outperforms baselines in accuracy, similarity, hit rate, and expert evaluation across multiple tasks.","Basic NLP Foundations, Text Readability Metrics, Corpora and Datasets, Machine Learning, Word distributions, Attention models, RoBERTa, ELMo, Transformer, Reading comprehension, GraphRAG, Knowledge Fusion, Seed Extraction, KG Aggregation, Local KG Construction, Generation, Retrieval-Augmented Generation, Chain of Thought Prompting, Semantic parsing, Relation extraction.",1.000,exact_title
yao_2024,FEDRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement,"Dezhong Yao, Tongtong Liu, Qi Cao, Hai Jin",2024,Yes,HIGH,"Directly addresses privacy-preserving federated learning for recommendation systems using knowledge graphs, highly relevant to HDM privacy architectures and personal knowledge graph applications.","Uses Local Differential Privacy (LDP) and pseudo-labeling to enable federated learning with knowledge graph enhancement while preventing global sharing of user-item interactions, achieving 4% accuracy improvement over baselines.",Privacy-preserving federated recommendation framework that leverages knowledge,"This paper proposes FedRKG, a privacy-preserving federated recommendation framework that integrates knowledge graphs to enhance recommendation quality while protecting user privacy. The framework uses Local Differential Privacy (LDP) and pseudo-labeling techniques to prevent the global sharing of user-item interaction graphs while still enabling effective recommendation learning through publicly available item knowledge. The approach constructs a global knowledge graph on the server side and employs relation-aware Graph Neural Networks (GNNs) to capture higher-order user-item interactions.",How can federated learning and knowledge graphs be combined to create privacy-preserving recommendation systems that maintain high accuracy while protecting user data?,"Federated learning framework with local differential privacy, relation-aware GNN model, experiments on three real-world datasets, comparison with centralized and federated baselines.","Achieved 4% average accuracy improvement over federated learning baselines while maintaining competitive performance with centralized algorithms, demonstrated effective privacy preservation through LDP and pseudo-labeling techniques.",Privacy-preserving federated recommendation framework with knowledge graph enhancement that balances accuracy and privacy protection.,"Relies on publicly available item information for knowledge graph construction, potential computational overhead from privacy mechanisms, limited evaluation to specific recommendation datasets.",Successfully demonstrates that federated learning with knowledge graph enhancement can achieve strong recommendation performance while preserving user privacy through differential privacy mechanisms.,"Need for more sophisticated privacy preservation techniques, limited exploration of knowledge graph relationship diversity, scalability evaluation with larger datasets.","Explore advanced privacy preservation methods, expand knowledge graph relationship types, evaluate scalability with larger user bases, investigate integration with additional data modalities.","Provides practical framework for implementing privacy-preserving recommendation systems in HDM architectures, demonstrates feasibility of federated knowledge graph approaches for personal data protection.",https://arxiv.org/abs/2401.11089,10.1007/978-981-99-9896-8_6,"federated-learning, hdm-privacy, knowledge-graph, local-differential-privacy, privacy-preservation, recommendation-systems",FEDRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement,"Yao Dezhong, Liu Tongtong, Cao Qi, Jin Hai",2024,reference-manager,,,,,,,"Federated Learning (FL): A privacy-preserving approach where each client trains on local user-item interaction data, and only model updates are shared with the server.",,,How can a federated learning framework leveraging knowledge graphs be designed to provide accurate and privacy-preserving recommendations across diverse client devices without relying on sensitive user data or social network information?,"The paper proposes FEDRKG, a federated learning framework using graph neural networks (GNN) and knowledge graphs (KG) for privacy-preserving recommendations. By leveraging public item data and privacy mechanisms like local differential privacy (LDP), FEDRKG outperforms state-of-the-art federated methods and matches centralized models while protecting user data.","The research goal is to develop a privacy-preserving recommendation system; the approach introduces FEDRKG, a federated learning framework using graph neural networks and knowledge graphs; results show FEDRKG outperforms state-of-the-art federated methods and is competitive with centralized algorithms while protecting user privacy.",,1.000,exact_title
yc_2024,A Brief Survey on Deep Learning-Based Temporal Knowledge Graph Completion,"yc, j.n",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Deep learning methods achieve \""state-of-the-art performance\"" in temporal knowledge graph completion. GNN-based methods achieved \""highest Hits@1 values (up to 66.7% in static filtered setting)\"".",Comprehensive analysis of deep learning approaches to temporal knowledge graph completion with performance metrics.,"This survey examines deep learning-based methods for temporal knowledge graph completion, analyzing various approaches including LSTM, CNN, GNN, and attention mechanisms for temporal modeling.",How can deep learning methods improve temporal knowledge graph completion performance?,"Survey of deep learning methods including LSTM, CNN, GNN, and attention mechanisms; performance analysis across different approaches.",GNN-based methods achieved highest Hits@1 values up to 66.7%; identification of temporal embedding techniques; analysis of temporal consistency constraints.,,Most methods show Hits@1 values below 61.2%; significant room for improvement in temporal knowledge graph completion.,Establishes current state-of-the-art in deep learning-based temporal knowledge graph completion with clear performance benchmarks.,,"Focus on few-shot learning, unified completion methods, and interpretable temporal knowledge graph completion.",Provides technical guidance for implementing deep learning-based temporal knowledge graph completion systems.,https://www.mdpi.com/2076-3417/14/19/8871,10.3390/app14198871,"deep-learning, graph-neural-networks, knowledge-graph-completion, temporal-knowledge-graph, temporal-modeling",A Brief Survey on Deep Learning-Based Temporal Knowledge Graph Completion,"Jia Ningning, Yao Cuiyou",2024,reference-manager,10.3390/app14198871,,"Implementation Insights highlight that current deep learning-based TKGC (Temporal Knowledge Graph Completion) methods have significant room for improvement, with the highest Hits@1 at 61.2%. CNN-based methods show promise but need fairer comparisons. Large language models underperform, and integrating temporal information remains challenging. Further research and verification are needed.",,,,"Attention-based methods: Use attention mechanisms to model the importance of entities and relations in temporal knowledge graphs, capturing features with time and graph structure information.",,,"What are the main categories, challenges, and future research directions of deep learning-based temporal knowledge graph completion (TKGC) methods?","This paper reviews deep learning-based temporal knowledge graph completion (TKGC) methods, categorizing them into eight types. It highlights recent advances, identifies key challenges like few-shot TKGC and interpretability, and suggests future research directions. The study emphasizes the need for unified methods and improved interpretability in TKGC.","The research goal is to review deep learning-based temporal knowledge graph completion (TKGC) methods, the approach is a comprehensive survey categorizing methods into eight core techniques, and the principal finding is that while progress exists, significant room for improvement and several future research directions remain.",,1.000,exact_title
yu_2016,Knowledge-enhanced Multi-perspective Video Representation Learning for Scene Recognition,"Xuzheng Yu, Chen Jiang, Wei Zhang, Tian Gan, Linlin Chao, Jianan Zhao, Yuan Cheng, Qingpei Guo, Wei Chu",2016,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on knowledge-enhanced multi-perspective video representation learning for scene recognition providing insights for knowledge graph development and data integration.,"This 2016 paper by Xuzheng Yu, Chen Jiang, Wei Zhang, Tian Gan, Linlin Chao, Jianan Zhao, Yuan Cheng, Qingpei Guo, Wei Chu explores knowledge-enhanced multi-perspective video representation learning for scene recognition. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph",Knowledge-enhanced Multi-perspective Video Representation Learning for Scene Recognition,"Yu Xuzheng, Jiang Chen, Zhang Wei, Gan Tian, Chao Linlin, Zhao Jianan, Cheng Yuan, Guo Qingpei, Chu Wei",2024,reference-manager,,,,,,Difficulty distinguishing useful from useless information due to diversity and discreteness of multi-perspective data.,,,,"How can a two-stream framework that integrates temporal and knowledge-enhanced non-temporal information, along with knowledge-enhanced feature fusion and self-distillation, improve the effectiveness and efficiency of video scene recognition?",,The research goal is to improve video scene recognition by effectively fusing multi-perspective information using knowledge enhancement; the approach introduces a knowledge-enhanced model balancing efficiency and performance; results show the proposed model outperforms baselines on the Koubei dataset in F1 score (0.735) and RP@90% (0.561).,,1.000,exact_title
yu_2024,"Ontology-Driven Architecture for Managing Environmental, Social, and Governance Metrics","Mingqin Yu, Fethi A. Rabhi, Madhushi Bandara",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on ontology-driven architecture for managing environmental, social, and governance metrics providing insights for knowledge graph development and data integration.","This 2024 paper by Mingqin Yu, Fethi A. Rabhi, Madhushi Bandara explores ontology-driven architecture for managing environmental, social, and governance metrics. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3390/electronics13091719,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
yue_2023,MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI,"Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, Wenhu Chen",2023,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on mmmu: a massive multi-discipline multimodal understanding and reasoning benchmark for expert agi providing insights for knowledge graph development and data integration.,"This 2023 paper by Xiang Yue, Yuansheng Ni, Kai Zhang, Tianyu Zheng, Ruoqi Liu, Ge Zhang, Samuel Stevens, Dongfu Jiang, Weiming Ren, Yuxuan Sun, Cong Wei, Botao Yu, Ruibin Yuan, Renliang Sun, Ming Yin, Boyuan Zheng, Zhenzhu Yang, Yibo Liu, Wenhao Huang, Huan Sun, Yu Su, Wenhu Chen explores mmmu: a massive multi-discipline multimodal understanding and reasoning benchmark for expert agi. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI,"Yue Xiang, Ni Yuansheng, Zhang Kai, Zheng Tianyu, Liu Ruoqi, Zhang Ge, Stevens Samuel, Jiang Dongfu, Ren Weiming, Sun Yuxuan, Wei Cong, Yu Botao, Yuan Ruibin, Sun Renliang, Yin Ming, Zheng Boyuan, Yang Zhenzhu, Liu Yibo, Huang Wenhao, Sun Huan, Su Yu",2024,reference-manager,,,"Implementation Insights highlight the importance of standardized data annotation and quality assurance, effective empirical evaluation pipelines, and user-friendly annotation interfaces. OCR and captioning enhancements did not significantly improve text-only model performance, emphasizing the need for models that integrate both textual and visual information for complex multimodal tasks.",,,,"Data Collection: The benchmark was collected in three stages, starting with reviewing common university materials.",,,"What processes and protocols are most effective for collecting, annotating, and validating a large-scale, high-quality multimodal question dataset across diverse academic subjects?","The paper introduces a large-scale, multi-discipline, multimodal benchmark for expert-level AGI. The main objective is to evaluate models' understanding and reasoning across diverse subjects using annotated questions, including those with multiple images. The methodology involves rigorous data collection, annotation, and validation. Results highlight subject distribution and model evaluation. The benchmark advances multimodal AGI assessment.","The research goal is to create a massive multi-discipline multimodal benchmark (MMMU) for expert AGI; the approach involves collecting, annotating, and validating diverse questions with images across subjects; the principal finding is a comprehensive dataset enabling robust evaluation of multimodal understanding and reasoning models.",,1.000,exact_title
yutongchen_2024,CTINexus: Automatic Cyber Threat Intelligence Knowledge Graph Construction Using Large Language Models,"Virginia Tech yutongchen, Virginia Tech obajabe, Virginia Tech saimon.tsega, UC Berkeley dawnson, Virginia Tech pengga",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Introduces CTINexus framework with automatic prompt construction, hierarchical entity alignment, and long-distance relation prediction using optimized in-context learning, achieving significant outperformance over existing methods in constructing accurate and complete knowledge graphs.",Novel framework for automatic cyber threat intelligence knowledge graph construction using large language models without extensive data or parameter tuning requirements.,"This paper addresses current cyber threat intelligence (CTI) knowledge extraction methods that lack flexibility and generalizability, often producing inaccurate and incomplete knowledge extraction. CTINexus introduces a novel framework using large language models with three core techniques: automatic prompt construction with optimal demonstration retrieval, hierarchical entity alignment to canonicalize and remove redundancy, and long-distance relation prediction to complete knowledge graphs requiring no extensive data or parameter tuning.",How can large language models be effectively used to construct accurate and complete cyber threat intelligence knowledge graphs without requiring extensive data annotation or parameter tuning?,"Developed CTINexus framework with automatic prompt construction using optimal demonstration retrieval, implemented hierarchical entity alignment for canonicalization, designed long-distance relation prediction for knowledge graph completion, evaluated on 150 real-world CTI reports from 10 platforms.","CTINexus significantly outperforms existing methods in constructing accurate and complete cyber security knowledge graphs, demonstrates adaptability to various ontologies with minimal annotated examples, provides efficient and adaptable solution for dynamic threat landscape analysis.",,"Evaluation limited to cyber threat intelligence domain, requires validation across broader knowledge domains, computational efficiency considerations for large-scale deployment not fully characterized in available summary.",Provides transformative potential for CTI analysis through efficient and adaptable automated knowledge graph construction using advanced large language model techniques without extensive training requirements.,,"Expand framework to additional knowledge domains beyond cybersecurity, optimize computational efficiency for large-scale deployment, integrate with existing knowledge management platforms, investigate cross-domain applicability.",Offers practical implementation framework for automated knowledge graph construction from unstructured text using LLMs with focus on entity resolution and relation prediction essential for HDM knowledge extraction applications.,https://arxiv.org/abs/2410.21060,arXiv:2410.21060,"cyber-threat-intelligence, entity-alignment, knowledge-graph-construction, llm, relation-prediction",CTINEXUS: Automatic Cyber Threat Intelligence Knowledge Graph Construction Using Large Language Models,"Cheng Yutong, Bajaber Osama, Tsegai Saimon Amanuel, Song Dawn, Gao Peng",2025,reference-manager,,,"CTINEXUS achieves efficient, adaptive knowledge extraction with minimal data and tuning. Using two prompt examples balances effectiveness and efficiency. Sorting examples by ascending similarity (kNN-ascend) improves results. GPT-4 outperforms other models. For entity merging, a 0.6 threshold and text-embedding-3-large yield optimal precision and recall.",,,,"Annotation by three PhD students with expertise in threat intelligence, using independent annotation and arbitration to ensure quality and reduce bias.",,,"How does CTINEXUS improve the efficiency and accuracy of cybersecurity knowledge graph construction compared to existing CTI knowledge extraction methods, particularly in entity alignment and relation prediction?","The paper introduces CTINEXUS, a system for constructing cybersecurity knowledge graphs. Using a three-phase methodology—triplet extraction, hierarchical entity alignment, and long-distance relation prediction—CTINEXUS outperforms state-of-the-art methods in triplet extraction. Rigorous annotation and evaluation show substantial agreement and improved performance, supporting more accurate cybersecurity knowledge extraction.","The research goal is to improve cyber threat intelligence (CTI) knowledge extraction; the approach is CTINEXUS, which uses multi-phase triplet extraction and entity alignment; results show CTINEXUS outperforms state-of-the-art baselines in constructing accurate cybersecurity knowledge graphs.",,1.000,exact_title
yxyan_2025,Pseudo-Knowledge Graph: Meta-Path Guided Retrieval and In-Graph Text for RAG-Equipped LLM,"China yxyan, China yang, China wh, China ma, China wangta, China glu",2025,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Develops Pseudo-Knowledge Graph framework that integrates Meta-path Retrieval, In-graph Text, and Vector Retrieval to enhance RAG systems by preserving natural language and leveraging various retrieval techniques for richer knowledge representation.","Novel PKG framework for LLM enhancement that addresses RAG limitations in high-volume, low-information-density databases through multi-modal retrieval and improved relational awareness.","This paper proposes a Pseudo-Knowledge Graph (PKG) framework that enhances Retrieval-Augmented Generation for Large Language Models by addressing limitations in traditional RAG systems when dealing with high-volume, low-information-density databases. The approach integrates meta-path guided retrieval, in-graph text preservation, and vector retrieval to improve relational awareness and overcome fragmented answer generation. The framework preserves natural language text while leveraging various retrieval techniques for richer knowledge representation.",How can knowledge graphs enhance Large Language Model retrieval capabilities while addressing fragmentation and relational awareness limitations in traditional RAG systems?,"Developed PKG framework integrating Meta-path Retrieval, In-graph Text, and Vector Retrieval; evaluated on Open Compass and MultiHop-RAG benchmarks; focused on managing large volumes of data and complex relationships.","Demonstrates effectiveness in managing large volumes of data and complex relationships, improves relational awareness in information retrieval, overcomes fragmented answer generation in traditional RAG systems.",,"Detailed implementation specifics, code availability, and comprehensive technical depth not provided in abstract; requires further technical validation.",Successfully addresses RAG limitations through novel PKG framework that preserves natural language while enhancing retrieval capabilities for complex knowledge relationships.,,"Expand technical implementation details, develop comprehensive evaluation framework, integrate with established PKG methodologies.","Provides framework for intelligent query interfaces in HDM systems, particularly relevant for personalized knowledge access and LLM-based conversational interfaces.",https://arxiv.org/abs/2503.00309,arXiv:2503.00309,"knowledge-graph, llm-enhancement, meta-path-retrieval, personal-knowledge-graph, retrieval-augmented-generation",Pseudo-Knowledge Graph: Meta-Path Guided Retrieval and In-Graph Text for RAG-Equipped LLM,"Yang Yuxin, Wu Haoyang, Wang Tao, Yang Jia, Ma Hao, Luo Guojie",2025,reference-manager,,,"The Implementation Insights highlight that combining traditional NLP extraction, LLM-based extraction, and embedding in-graph text chunks in the PKG Builder significantly improves performance. Iterative extraction and verification ensure data completeness and accuracy. Integrating multiple retrieval methods enhances LLM reasoning, scalability, and domain adaptability. No new insights beyond these findings are uncovered.",,,,"Regular Expression Retrieval: Finds precise pattern-based matches, such as exact researcher names or keywords.",,,"How can integrating meta-path retrieval with large language models improve the accuracy, coherence, and comprehensiveness of answers in complex multi-hop research queries within heterogeneous knowledge graphs?","The paper introduces a meta-path retrieval method for efficient information extraction from a PKG (Property Knowledge Graph). By pre-constructing meta-paths and using a lightweight, context-aware model, the approach enables rapid, multi-hop exploration of complex relationships. Experiments show improved accuracy, coherence, and comprehensiveness over traditional retrieval methods.","The paper’s main objective is to improve multi-hop retrieval in knowledge graphs; its key method combines pre-constructed meta-paths with a lightweight, context-aware model for efficient meta-path retrieval; principal finding: this approach significantly enhances retrieval efficiency and enables deeper, more insightful relational analysis across domains.",,1.000,exact_title
zafeiropoulos_2024,Evaluating Ontology-Based PD Monitoring and Alerting in Personal Health Knowledge Graphs and Graph Neural Networks,"Nikolaos Zafeiropoulos, Pavlos Bitilis, George E. Tsekouras, Konstantinos Kotis",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Explores user-centric knowledge modeling and personalization strategies that can inform the design of personal knowledge graph systems focused on individual data management.,Research on evaluating ontology-based pd monitoring and alerting in personal health knowledge graphs and graph neural networks providing insights for knowledge graph development and data integration.,"This 2024 paper by Nikolaos Zafeiropoulos, Pavlos Bitilis, George E. Tsekouras, Konstantinos Kotis explores evaluating ontology-based pd monitoring and alerting in personal health knowledge graphs and graph neural networks. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3390/info15020100,"data-integration, healthcare, knowledge-graph, personal-knowledge",Evaluating Ontology-Based PD Monitoring and Alerting in Personal Health Knowledge Graphs and Graph Neural Networks,"Zafeiropoulos Nikolaos, Bitilis Pavlos, Tsekouras George E., Kotis Konstantinos",2024,reference-manager,10.3390/info15020100,,,,,Sustaining relevance of Wear4PDmove amid evolving technologies and healthcare practices.,,,,"How can the Wear4PDmove ontology semantically integrate heterogeneous health data to support advanced reasoning, event recognition, and personalized decision-making for Parkinson’s disease monitoring and care?","The paper aims to improve Parkinson’s Disease (PD) monitoring and alerting by integrating wearable sensor data, advanced semantic analysis, and Graph Neural Networks (GNNs). Using the Wear4PDmove ontology and a Patient Health Knowledge Graph (PHKG), the study demonstrates enhanced, patient-centric PD care and offers insights for future research.","The research goal is to enhance PD monitoring and care using advanced semantic data analysis and wearable technology; the approach integrates the Wear4PDmove ontology, PHKG, and PHGNNs for nuanced movement data analysis; results show improved patient-centric monitoring, interoperability, and insights for personalized healthcare.","Tags: Parkinson’s Disease, Knowledge Graph, Ontology, Semantic Web, Wearables, Machine Learning, Graph Neural Network, RDF, OWL, Sensor Data, Linked Data, Neuroinformatics, Explainable AI, Data Integration, Semantic Interoperability, Drug Repurposing, Feature Selection, MRI, Personal Healthcare Record.",1.000,exact_title
zha_2024,Data-centric Artificial Intelligence: A Survey,"Daochen Zha, Zaid Pervaiz Bhat, Kwei-Herng Lai, Fan Yang, Zhimeng Jiang, Shaochen Zhong, Xia Hu",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Shift from model design to data quality enhancement represents fundamental paradigm change; systematic data engineering crucial for AI success; data-centric approach addresses three key goals: training data development, inference data development, and data maintenance",First comprehensive survey providing global view of data lifecycle tasks and systematic data engineering for AI systems,"This survey addresses the emerging concept of data-centric AI, where attention has shifted from advancing model design to enhancing data quality and quantity. The paper discusses the necessity of data-centric AI, followed by a holistic view of three general data-centric goals and representative methods. The authors provide the first comprehensive survey offering a global view of tasks across various stages of the data lifecycle, aiming to help readers grasp the broad picture of systematic data engineering for building AI systems.",How can we systematically engineer data for building AI systems across the entire data lifecycle to improve AI performance and reliability?,"Holistic review of data-centric AI across three goals: training data development, inference data development, and data maintenance; systematic analysis of data lifecycle tasks; comprehensive methodology review for data quality enhancement",Shift from model design to data quality enhancement represents fundamental paradigm change; systematic data engineering crucial for AI success; first comprehensive framework for understanding data-centric AI approaches,,Emerging field with evolving methodologies; standardization of data-centric approaches still developing; evaluation metrics for data quality improvements need refinement,"Systematic data engineering is crucial for AI success, with data quality being more important than model architecture refinements in many applications",,Develop standardized data-centric methodologies; create comprehensive evaluation frameworks; explore domain-specific data engineering approaches,Emphasizes systematic data engineering over model development; provides framework for data lifecycle management; offers practical guidance for data quality improvement,https://arxiv.org/abs/2303.10158,10.48550/arXiv.2303.10158,"ai-systems, data-centric-ai, data-engineering, data-quality, machine-learning",Data-centric Artificial Intelligence: A Survey,"Zha Daochen, Bhat Zaid Pervaiz, Lai Kwei-Herng, Yang Fan, Jiang Zhimeng, Zhong Shaochen, Hu Xia",2025,reference-manager,10.1145/3711118,,"Implementation Insights highlight diverse methods for inference data development, including data slicing, algorithmic recourse, adversarial samples, and prompt engineering. Automation levels vary from minimum collaboration to fully automated, learning-based, or programmatic approaches. New insight: Evaluation increasingly focuses on granular, data-centric tasks beyond traditional accuracy metrics.",,,,Programmatic automation: Uses rule-based or statistical programs for tasks like imputing missing values or finding duplicates.,,,"What are the necessary tasks, roles of automation and human participation, and current progress in developing, maintaining, and evaluating data to advance data-centric AI?","This paper surveys data-centric AI, aiming to define key concepts, tasks, and challenges. It reviews efficient data collection, integration, visualization, and quality assessment methods, emphasizing automation and human participation. The study organizes literature by goals, analyzes benchmarks, and highlights future research opportunities in data-centric AI.","The research goal is to enhance data-centric AI by addressing data reduction and maintenance; the approach reviews automation and collaboration methods for tasks like data cleaning, feature/sample size reduction, and quality improvement; the principal finding is that both automation and human participation are essential for effective, efficient, and interpretable data management.",,1.000,exact_title
zhang_2019,Enhancing Sequential Recommendation with Graph Contrastive Learning,"Yixin Zhang, Yong Liu, Yonghui Xu, Hao Xiong, Chenyi Lei, Wei He, Lizhen Cui, Chunyan Miao",2019,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on enhancing sequential recommendation with graph contrastive learning providing insights for knowledge graph development and data integration.,"This 2019 paper by Yixin Zhang, Yong Liu, Yonghui Xu, Hao Xiong, Chenyi Lei, Wei He, Lizhen Cui, Chunyan Miao explores enhancing sequential recommendation with graph contrastive learning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph",Enhancing Sequential Recommendation with Graph Contrastive Learning,"Zhang Yixin, Liu Yong, Xu Yonghui, Xiong Hao, Lei Chenyi, He Weiliang, Li-Cui, Miao C.",2022,reference-manager,,"GCL4SR, a new recommendation model, uses a global transition graph and subgraph sampling to improve sequence representation.",,,,,,,,,,"The research goal is to improve sequential recommendation; the approach, GCL4SR, uses subgraphs from all users’ sequences to provide both local and global context; results show GCL4SR consistently outperforms state-of-the-art methods on multiple datasets and metrics.",,1.000,exact_title
zhang_2021a,Dynamic Graph Neural Networks for Sequential Recommendation,"Mengqi Zhang, Shu Wu, Xueli Yu, Qiang Liu, Liang Wang",2021,Yes,HIGH,"Addresses sequential recommendation through dynamic graph modeling, providing techniques for HDM systems to track and predict user behavior evolution and preference changes over time",DGSR framework models collaborative signals between user sequences through dynamic graphs; converts next-item prediction to link prediction in temporal graphs; demonstrates effectiveness on three public benchmarks with superior performance,Dynamic graph neural network approach for sequential recommendation modeling,"This paper proposes Dynamic Graph Neural Network for Sequential Recommendation (DGSR) to address limitations in existing sequential recommendation methods that only model individual user sequences. DGSR connects different user sequences through dynamic graph structures, exploring interactive user and item behaviors with temporal and order information. The approach models collaborative signals among different user sequences within a unified framework, converting next-item prediction into link prediction between user and item nodes in dynamic graphs. Experimental validation on three public benchmarks demonstrates performance improvements over state-of-the-art methods.",How to model collaborative signals between different user sequences in sequential recommendation rather than analyzing individual sequences in isolation?,Dynamic graph structure connecting user sequences; temporal and order information integration; conversion of next-item prediction to link prediction; unified framework for modeling collaborative signals,Superior performance on three public benchmarks compared to state-of-the-art methods; effective modeling of collaborative signals between user sequences; successful conversion of recommendation to link prediction problem,DGSR framework for sequential recommendation; dynamic graph modeling of user interactions; collaborative signal integration across user sequences; link prediction approach for recommendations,Evaluation limited to three public datasets; computational complexity of dynamic graph construction not fully analyzed; scalability to large-scale recommendation systems unclear,Dynamic graph modeling significantly improves sequential recommendation by capturing collaborative signals between user sequences rather than modeling individual preferences in isolation,Limited exploration of collaborative signals in sequential recommendation; existing methods focus on individual user sequences; need for unified frameworks handling multiple user interactions,Investigate larger-scale dataset performance; optimize dynamic graph construction efficiency; explore real-time recommendation applications,Converts recommendation to link prediction in dynamic graphs; models collaborative signals between user sequences; provides unified framework for temporal user behavior modeling,https://arxiv.org/abs/2104.07368,10.48550/arXiv.2104.07368,"collaborative-filtering, dynamic-graphs, graph-neural-networks, sequential-recommendation, user-modeling",Dynamic Graph Neural Networks for Sequential Recommendation,"Zhang Mengqi, Wu Shu, Yu Xueli, Liu Qiang, Wang Liang",2015,reference-manager,,,"The implementation uses DGSR with DGL, embedding size 50, sequence length 50, Adam optimizer (lr=0.01), batch size 50, λ=1e-4, sub-graph order m=4, and 2-3 DAN layers. Larger sub-graphs and higher embedding sizes improve performance, but gains stabilize. DGSR outperforms baselines by leveraging dynamic graph structures.",,,,Dynamic Graph Neural Networks: The proposed DGSR framework uses dynamic graph neural networks to model user-item interactions over time for sequential recommendation.,,,"How does the proposed DGSR model, incorporating dynamic graph recommendation networks, perform compared to state-of-the-art sequential recommendation methods, and what are the effects of its key components and hyper-parameters on recommendation accuracy?","The paper investigates DGSR, a dynamic graph-based sequential recommendation model. Using three Amazon datasets, it compares DGSR to state-of-the-art methods. DGSR outperforms baselines, especially in sparse datasets, by explicitly modeling cross-sequence information. The study also analyzes hyper-parameter effects, confirming DGSR’s robustness and superior performance.","The research goal is to improve sequential recommendation by modeling both long-term and short-term user-item interactions using a dynamic graph recommendation network (DGSR); the approach combines dynamic graph neural layers with recurrent or attention modules, and results show DGSR outperforms state-of-the-art methods on three real-world datasets.",,1.000,exact_title
zhang_2021b,Paterns for Representing Knowledge Graphs to Communicate Situational Knowledge of Service Robots,"Shengchen Zhang, Yi Dai, Zixuan Wang, Lyumanshan Ye, Chaoran Chen, Xiaohua Sun",2021,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on paterns for representing knowledge graphs to communicate situational knowledge of service robots providing insights for knowledge graph development and data integration.,"This 2021 paper by Shengchen Zhang, Yi Dai, Zixuan Wang, Lyumanshan Ye, Chaoran Chen, Xiaohua Sun explores paterns for representing knowledge graphs to communicate situational knowledge of service robots. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3411764.3445767,"data-integration, knowledge-graph",Patterns for Representing Knowledge Graphs to Communicate Situational Knowledge of Service Robots,"Zhang Shengchen, Wang Zixuan, Chen Chaoran, Dai Yi, Ye Lyumanshan, Sun Xiaohua",2021,reference-manager,10.1145/3411764.3445767,,"The implementation insights show that the pattern library supports effective interface design for communicating situational knowledge, but users found some information confusing and hard to find. New insights include the need for hierarchical patterns, classification trees to reduce overload, and exploring multimodal (voice, gesture) interactions for better human-robot knowledge exchange.",,,,Participants arranged hexagonal knowledge cards on a canvas to visually communicate situational knowledge in HRI scenarios.,,,"How can patterns for presenting situational robotic knowledge be discovered and formalized to improve the communication of semantic, procedural, and episodic knowledge between humans and robots through graphical interfaces?","The paper investigates how to represent and communicate situational knowledge in Human-Robot Interaction (HRI) through graphical interfaces. Using a qualitative study with scenario comics and card arrangement tasks, the authors identify patterns for presenting semantic, procedural, and episodic knowledge. The findings inform interface design to improve knowledge exchange in HRI.","The research goal is to identify effective patterns for representing situational robotic knowledge graphs; using a qualitative, visual grounded theory approach with university students arranging knowledge cards, the study found distinct low- and high-level patterns for communicating semantic, procedural, and episodic knowledge in human-robot interaction.",,0.994,fuzzy_title
zhang_2022,Research Article# Building a Knowledge Base of Bridge Maintenance Using Knowledge Graph,Yang Zhang,2022,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on research article# building a knowledge base of bridge maintenance using knowledge graph providing insights for knowledge graph development and data integration.,"This 2022 paper by Yang Zhang explores research article# building a knowledge base of bridge maintenance using knowledge graph. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",Building a Knowledge Base of Bridge Maintenance Using Knowledge Graph,"Zhang Yang, Liu Jia, Hou Kepeng",2023,reference-manager,10.1155/2023/6047489,,,,,Data sparsity in the relational database is shown as a limitation.,,,All data generated or analyzed during this study are included in the published article. No information about the availability of source code for the project is provided.,How can a comprehensive bridge maintenance knowledge graph (BMKG) be constructed using a hybrid ontology-based approach to effectively manage heterogeneous and discrete knowledge in the bridge maintenance domain?,,"The research goal is to build a bridge maintenance knowledge base using a hybrid knowledge graph method; the approach combines ontology for organization and a graph database for storage, and the principal finding is that this method improves efficiency, generality, and quality in managing bridge maintenance knowledge.",,0.900,fuzzy_title
zhang_2023,Describe and query semantic building digital twin data in temporal Knowledge Graphs,"Yingying Zhang, Jakob Beetz",2023,Yes,SUPER,"This paper directly addresses core aspects of heterogeneous data integration in knowledge graphs, providing critical insights for PKG architectures and temporal data management strategies that align perfectly with our research objectives.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on describe and query semantic building digital twin data in temporal knowledge graphs providing insights for knowledge graph development and data integration.,"This 2023 paper by Yingying Zhang, Jakob Beetz explores describe and query semantic building digital twin data in temporal knowledge graphs. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph, temporal-data",,,,,,,,,,,,,,,,,,,
zhang_2024,A framework towards digital twins for type 2 diabetes,"Yue Zhang, Guangrong Qin, Boris Aguilar, Noa Rappaport, James T. Yurkovich, Lance Pflieger, Sui Huang, Leroy Hood, Ilya Shmulevich",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a framework towards digital twins for type 2 diabetes providing insights for knowledge graph development and data integration.,"This 2024 paper by Yue Zhang, Guangrong Qin, Boris Aguilar, Noa Rappaport, James T. Yurkovich, Lance Pflieger, Sui Huang, Leroy Hood, Ilya Shmulevich explores a framework towards digital twins for type 2 diabetes. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.3389/fdgth.2024.1336050,"data-integration, knowledge-graph",A framework towards digital twins for type 2 diabetes,"Zhang Yue, Qin Guangrong, Aguilar Boris, Rappaport Noa, Yurkovich James T., Pflieger Lance, Huang Sui, Hood Leroy, Shmulevich Ilya",2024,reference-manager,10.3389/fdgth.2024.1336050,,,,,,"Data filtering and cleaning: Included subjects with complete demographic, clinical, proteomic, and metabolomic data for at least two time points; excluded features and subjects with high missingness.",,,"How can the integration of multiomic data, clinical features, and knowledge graph-based modeling improve the prediction and interpretation of clinical outcomes in type 2 diabetes over 6 months to 1 year?",,"The research goal was to develop a digital twin framework for type 2 diabetes using machine learning, multiomic data, knowledge graphs, and mechanistic models; the approach integrated these methods to predict disease progression, and the principal finding was the identification of both known and novel disease components for precision medicine.",,1.000,exact_title
zhanga_2024,A Comprehensive Survey on Automatic Text Summarization with Exploration of LLM-Based Methods,"Yang Zhanga, Hanlei Jina, Dan Menga, Jun Wang1a, Jinghua Tana",2024,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a comprehensive survey on automatic text summarization with exploration of llm-based methods providing insights for knowledge graph development and data integration.,"This 2024 paper by Yang Zhanga, Hanlei Jina, Dan Menga, Jun Wang1a, Jinghua Tana explores a comprehensive survey on automatic text summarization with exploration of llm-based methods. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1108/eb026526,"data-integration, knowledge-graph",A Comprehensive Survey on Automatic Text Summarization with Exploration of LLM-Based Methods,"Zhang Yang, Jin Hanlei, Meng Dan, Wang Jun, Tan Jinghua",2025,reference-manager,,,"Implementation Insights highlight the development of automated frameworks for fact-checking summaries, implicit-based text exploration systems for healthcare, and models integrating clinical terms for improved summarization. The paper also introduces an automated retrieval algorithm for collecting ATS research, adaptable to other domains, and emphasizes LLM-based summarization advancements.",,,,Extractive Methods: Select important sentences or phrases directly from the original text using unsupervised (statistical ranking) or supervised (machine learning/deep learning classification) techniques.,,,"What are the latest advancements, challenges, and methodologies in Automated Text Summarization (ATS), including dataset collection, categorization, evaluation metrics, and the impact of Large Language Model (LLM)-based approaches across various domains such as news, scientific papers, novels, and blogs?","The paper reviews Automatic Text Summarization (ATS), focusing on extractive, abstractive, and hybrid methods. It examines statistical, clustering, and graph-based techniques, highlighting their strengths and weaknesses. The main objective is to improve information retrieval efficiency. The study concludes that method choice depends on resource needs and application context.","The research goal is to provide a comprehensive review of Automated Text Summarization (ATS), the key method is an automated paper retrieval algorithm combining keyword search and LLM-based prompting, and the principal finding is that recent LLM-based methods have significantly advanced ATS flexibility and performance.",,1.000,exact_title
zhao_2022,Skefl: Single-Key Homomorphic Encryption for Secure Federated Learning,Dongfang Zhao,2022,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on skefl: single-key homomorphic encryption for secure federated learning providing insights for knowledge graph development and data integration.,"This 2022 paper by Dongfang Zhao explores skefl: single-key homomorphic encryption for secure federated learning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph",,,,,,,,,,,,,,,,,,,
zhao_2023,A SysML-centric integration framework for helicopter fuel system development,"H Zhao, W K Wu, X M Hu, Y Q Guo, C Zhang, G X Hao",2023,Yes,LOW,"While demonstrating model-based integration frameworks, focuses on aerospace engineering rather than knowledge graphs or HDM systems",SysML provides standardized approach for complex system integration; Model patterns enable consistent component representation; Tool integration critical for complex systems,Presents SysML-based framework for integrating tools and data in helicopter,"The paper describes a SysML-centric integration framework specifically designed for helicopter fuel system development. The framework introduces ""A SysML Model Pattern"" to represent standard component definitions from IEC-81346, providing a standardized approach for tool integration and data management in aerospace engineering. Developed by researchers from KTH Royal Institute of Technology and Linköping University, the work demonstrates practical application of model-based systems engineering (MBSE) principles. The case study validates the framework's effectiveness in managing complex aerospace systems through standardized modeling approaches.",How to create an effective integration framework for complex helicopter fuel system development using SysML,Model-based systems engineering approach; SysML Model Pattern implementation; Case study validation with helicopter fuel system,SysML Model Patterns effectively represent IEC-81346 standard components; Framework enables successful tool integration in aerospace applications,SysML-centric integration framework; Model patterns for standard components; Demonstrated tool integration approach,Not available from search results,SysML provides effective central integration framework for complex aerospace systems,Not specified in available information,Not specified in available information,Model and data management approach based on SysML enables practical tool integration; Standard component definitions crucial for consistency,Available through IEEE Xplore,10.1109/AERO55745.2023.10115875,"aerospace, integration-framework, mbse, sysml, systems-engineering",A SysML-centric integration framework for helicopter fuel system development,"Zhao H, Wu W K, Hu X M, Guo Y Q, Zhang C, Hao G X",2023,reference-manager,10.1088/1742-6596/2472/1/012040,,,,,,"SysML-centric integration framework: Integrates SysML modeling tools with simulation and analysis tools for system development, supporting concept design through verification and validation.",,,"How can a SysML-centric integration framework, utilizing FMI-based co-simulation, improve the conceptual design, verification, and validation of helicopter fuel systems to meet complex stakeholder requirements and regulatory standards?","The paper aims to develop a SysML-centric integration framework for helicopter fuel system conceptual design. Using FMI-based co-simulation, it integrates simulation models (e.g., from AMESim) into SysML tools to verify performance. Results show improved fidelity, reusability, and efficiency, supporting complex system analysis and traceability.","The research goal is to develop a SysML-centric integration framework for helicopter fuel system development; the key method uses an FMI-based co-simulation approach to link SysML models with simulation tools; the principal finding is improved model fidelity, reusability, and efficiency in system analysis and verification.",,1.000,exact_title
zhao_2024,AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data,"Xinjie Zhao, Moritz Blum, Rui Yang, Boming Yang, Tony Wang, Xin Li, Huitao Li, Yanran Fu, Rongrong Wang, Juntao Zhang, Irene Li, Weill Cornell Medicine",2024,Yes,HIGH,"Addresses LLM-KG integration for private data processing through multi-agent knowledge management platform, directly relevant to HDM systems requiring sophisticated LLM integration with personal knowledge graphs and dynamic knowledge extraction capabilities","Achieves 95.12% accuracy in task classification and 90.45% success rate in task execution through multi-agent architecture for interpreting user intents and real-time knowledge graph interaction, addressing LLM hallucination and limited reasoning challenges","Multi-agent knowledge management platform enabling dynamic knowledge extraction,","This paper introduces AGENTiGraph, a multi-agent knowledge management platform that addresses challenges with Large Language Models such as hallucination and limited reasoning by enabling dynamic knowledge extraction, integration, and visualization. The platform uses a multi-agent architecture for interpreting user intents and facilitating real-time knowledge graph interaction, making it adaptable to evolving user requirements. The research demonstrates applications in specialized domains including legislation and healthcare, showing significant performance improvements over existing zero-shot baselines.",How can multi-agent knowledge management platforms address LLM limitations in hallucination and reasoning while enabling dynamic knowledge extraction and integration for private data applications?,"Multi-agent architecture for user intent interpretation; real-time knowledge graph interaction system; experimental evaluation on 3,500 test cases; performance comparison with state-of-the-art zero-shot baselines; domain-specific applications in legislation and healthcare",Significantly outperformed state-of-the-art zero-shot baselines; achieved 95.12% accuracy in task classification; attained 90.45% success rate in task execution; demonstrated versatility across complex domain-specific tasks,Multi-agent knowledge management platform; dynamic knowledge extraction and integration system; real-time knowledge graph interaction framework; specialized domain knowledge graph construction capability,"Limited evaluation to specific domains (legislation, healthcare); computational complexity considerations for real-time knowledge graph interaction not fully characterized; scalability assessment for large-scale private data scenarios",Successfully demonstrates superior performance in knowledge graph interactions with versatile platform capabilities for complex domain-specific tasks and potential for specialized knowledge graph construction,Limited reasoning capabilities in traditional LLMs; challenges with hallucination in knowledge-intensive applications; need for dynamic knowledge integration in evolving user requirements,Expand evaluation to additional specialized domains; investigate scalability for large-scale private data processing; develop advanced multi-agent coordination mechanisms for complex knowledge tasks,Provides practical framework for implementing sophisticated LLM-KG integration in private data environments; demonstrates significant performance improvements in knowledge-intensive applications essential for HDM chatbot and assistant capabilities,https://arxiv.org/abs/2410.11531,arXiv:2410.11531,"interactive-platforms, knowledge-management, llm-kg-integration, multi-agent-systems, private-data-processing",AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data,"Zhao Xinjie, Blum Moritz, Yang Rui, Yang Boming, Carpintero Luis Márquez, Pina-Navarro Mónica, Wang Tony, Li Xin, Li Huitao, Fu Yanran, Wang Rongrong, Zhang Juntao, Li Irene",2024,reference-manager,,,,,,,,,,What are the key concepts I should explore to fully understand the applications of transfer learning in NLP?,,,,1.000,exact_title
zhong_2022,A Comprehensive Survey on Automatic Knowledge Graph Construction,"Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, Xindong Wu",2022,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a comprehensive survey on automatic knowledge graph construction providing insights for knowledge graph development and data integration.,"This 2022 paper by Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, Xindong Wu explores a comprehensive survey on automatic knowledge graph construction. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
zhong_2024,From data to insights: the application and challenges of knowledge graphs in intelligent audit,"Zhong, H., Yang, D., Shi, S., Wei, L., Wang, Y.",2024,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.","Knowledge graphs enable rich semantic relationship modeling, multi-hop reasoning can extract complex knowledge connections, neural network-based inference offers advanced knowledge representation, multi-source knowledge graph reasoning crucial for complex information processing.","Knowledge graphs transform complex data into interconnected, semantically meaningful networks for intelligent information processing with focus on improving data correlation and risk identification through semantic understanding.","The paper explores knowledge graph technologies in intelligent auditing, highlighting their potential to transform data integration and analysis. By constructing rich entity relationship networks, knowledge graphs provide deep semantic understanding, improving information processing accuracy and efficiency. The research emphasizes key technologies like data extraction, knowledge fusion, and reasoning techniques, addressing challenges in data collection, knowledge graph maintenance, and handling data incompleteness while demonstrating neural network-based reasoning advantages for complex information processing scenarios.",How can knowledge graph technologies enhance intelligent auditing processes and data analysis through semantic relationship modeling and advanced reasoning capabilities?,"Comprehensive literature review, analysis of knowledge graph extraction techniques, exploration of reasoning and completion methods, examination of neural network-based inference approaches for intelligent information processing.","Knowledge graphs significantly improve data correlation and risk identification, neural network-based reasoning offers advantages in knowledge representation, multi-source knowledge graph reasoning crucial for complex information processing scenarios.",,"Data collection challenges, complexity of knowledge graph maintenance, potential data incompleteness and uncertainty, scalability issues for large-scale knowledge graph deployment.","Knowledge graphs present transformative potential for intelligent information processing, particularly in complex domains requiring advanced semantic understanding and multi-hop reasoning capabilities.",,"Integrate knowledge graphs with machine learning, expand application domains, enhance knowledge sharing mechanisms, develop automated construction techniques.","Provides framework for implementing knowledge graph-based intelligent information processing systems applicable to HDM domains requiring complex data correlation, semantic understanding, and automated knowledge extraction capabilities.",https://journalofcloudcomputing.springeropen.com/articles/10.1186/s13677-024-00674-0,10.1186/s13677-024-00674-0,"data-integration, intelligent-audit, knowledge-graph, neural-network-reasoning, semantic-modeling",From data to insights: the application and challenges of knowledge graphs in intelligent audit,"Zhong Hao, Yang Dong, Shi Shengdong, Wei Lai, Wang Yanyan",2024,reference-manager,10.1186/s13677-024-00674-0,,Implementation Insights Summary:,,,,,,,,,,,1.000,exact_title
zhou_2018,Intelligent Bug Fixing with Software Bug Knowledge Graph,Cheng Zhou,2018,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on intelligent bug fixing with software bug knowledge graph providing insights for knowledge graph development and data integration.,"This 2018 paper by Cheng Zhou explores intelligent bug fixing with software bug knowledge graph. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3236024.3275428,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
zhou_2024a,Electronic Health Record–Oriented Knowledge Graph System for Collaborative Clinical Decision Support Using Multicenter Fragmented Medical Data: Design and Application Study,"Tianshu Zhou, Ping Zhang, Jianghua Chen, Jingsong Li",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Achieves 97.5% agreement rate in privacy negotiations with 83.3% user satisfaction through strategic scaffolding, context-aware suggestions, and crowdsourced preference models, completing negotiations in average 3.27 minutes.",Interactive privacy negotiation system for shared IoT devices that enables multi-user privacy configuration through strategic scaffolding and context-aware suggestions.,"This paper presents ThingPoll, an interactive system that helps users negotiate privacy configurations for IoT devices in shared settings. The system addresses privacy concerns arising when multiple stakeholders share IoT devices by strategically scaffolding the negotiation process through eliciting privacy preferences, providing helpful contexts, and suggesting feasible configuration options. The approach bootstraps a preference model from a custom crowdsourced privacy preferences dataset and identifies successful negotiation patterns from observational studies.",How can interactive systems effectively facilitate privacy negotiations for IoT devices in shared settings while ensuring user satisfaction and efficient agreement processes?,"Observational study with 12 participants for negotiation pattern analysis, user study with 30 participants evaluating privacy settings for 4 devices, crowdsourced privacy preference dataset development, comparative analysis with baseline approaches.","Achieved 97.5% agreement rate in negotiation scenarios, average negotiation time of 3.27 minutes, 83.3% user satisfaction compared to baseline approaches, identified successful negotiation patterns from observational data.",,"Limited to specific research context, potential scalability challenges with larger numbers of users or devices, evaluation focused on controlled laboratory settings rather than real-world deployments.",Demonstrates that interactive negotiation systems can effectively facilitate privacy configuration in shared IoT environments with high user satisfaction and agreement rates.,,"Expand privacy negotiation frameworks to more complex multi-user scenarios, evaluate real-world deployment effectiveness, integrate with commercial IoT platforms, develop adaptive negotiation strategies.","Provides practical framework for implementing privacy-preserving device integration in HDM systems, particularly relevant for multi-user environments and shared personal data scenarios requiring collaborative privacy management.",https://dl.acm.org/doi/10.1145/3613904.3642897,10.2196/54263,"hdm-device-integration, interactive-negotiation, iot-privacy, multi-user-privacy, privacy-configuration, shared-devices",Electronic Health Record–Oriented Knowledge Graph System for Collaborative Clinical Decision Support Using Multicenter Fragmented Medical Data: Design and Application Study,"Shang Yong, Tian Yu, Lyu Kewei, Zhou Tianshu, Zhang Ping, Chen Jianghua, Li Jingsong",2024,reference-manager,10.2196/54263,,,,,,Deployment of the system across three tertiary hospitals to integrate and analyze multicenter EHR data for CKD detection.,,,How can a multicenter collaborative reasoning framework securely integrate and analyze fragmented electronic health record data from multiple hospitals to improve the early detection of overlooked chronic kidney disease?,"The paper investigates a multicenter collaborative reasoning framework for clinical decision support (CDS) using distributed EHR knowledge graphs. It employs secure, privacy-preserving sharing of intermediate reasoning results across hospitals. The system integrates findings to generate precise, explainable CDS responses, enhancing decision-making while maintaining data security and efficiency.","The research goal was to enable secure, collaborative clinical decision support (CDS) using fragmented multicenter EHR data; the approach used an EHR-oriented knowledge graph system with encrypted, blockchain-synchronized intermediate results; the principal finding was effective, privacy-preserving CDS generation without sharing original data, benefiting early chronic disease detection.",,1.000,exact_title
zhou_2024b,Bring Privacy To The Table: Interactive Negotiation for Privacy Settings of Shared Sensing Devices (ThingPoll),"Haozhe Zhou, Mayank Goel, Yuvraj Agarwal",2024,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Achieves 97.5% agreement rate in privacy negotiations with 83.3% user satisfaction through strategic scaffolding, context-aware suggestions, and crowdsourced preference models, completing negotiations in average 3.27 minutes.",Interactive privacy negotiation system for shared IoT devices that enables multi-user privacy configuration through strategic scaffolding and context-aware suggestions.,"This paper presents ThingPoll, an interactive system that helps users negotiate privacy configurations for IoT devices in shared settings. The system addresses privacy concerns arising when multiple stakeholders share IoT devices by strategically scaffolding the negotiation process through eliciting privacy preferences, providing helpful contexts, and suggesting feasible configuration options. The approach bootstraps a preference model from a custom crowdsourced privacy preferences dataset and identifies successful negotiation patterns from observational studies.",How can interactive systems effectively facilitate privacy negotiations for IoT devices in shared settings while ensuring user satisfaction and efficient agreement processes?,"Observational study with 12 participants for negotiation pattern analysis, user study with 30 participants evaluating privacy settings for 4 devices, crowdsourced privacy preference dataset development, comparative analysis with baseline approaches.","Achieved 97.5% agreement rate in negotiation scenarios, average negotiation time of 3.27 minutes, 83.3% user satisfaction compared to baseline approaches, identified successful negotiation patterns from observational data.",,"Limited to specific research context, potential scalability challenges with larger numbers of users or devices, evaluation focused on controlled laboratory settings rather than real-world deployments.",Demonstrates that interactive negotiation systems can effectively facilitate privacy configuration in shared IoT environments with high user satisfaction and agreement rates.,,"Expand privacy negotiation frameworks to more complex multi-user scenarios, evaluate real-world deployment effectiveness, integrate with commercial IoT platforms, develop adaptive negotiation strategies.","Provides practical framework for implementing privacy-preserving device integration in HDM systems, particularly relevant for multi-user environments and shared personal data scenarios requiring collaborative privacy management.",https://dl.acm.org/doi/10.1145/3613904.3642897,10.1145/3613904.3642897,"hdm-device-integration, interactive-negotiation, iot-privacy, multi-user-privacy, privacy-configuration, shared-devices",Bring Privacy To The Table: Interactive Negotiation for Privacy Settings of Shared Sensing Devices,"Zhou Haozhe, Goel Mayank, Agarwal Yuvraj",2024,reference-manager,10.1145/3613904.3642897,,,,,,"Iterative design process: The study used repeated cycles of designing, building, and evaluating the negotiation system, ThingPoll.",,,"How can a negotiation system like ThingPoll be designed and evaluated to effectively mediate privacy and functionality preferences among smart home users, compared to non-negotiation approaches such as Veto Vote and Majority Vote?","The paper investigates ThingPoll, a negotiation system for privacy settings in shared smart homes. Using simulated scenarios and a two-phase user study with 30 participants, it evaluates user workload, experiences, and willingness to adopt such apps. Findings suggest ThingPoll is practical, though results are exploratory due to sample size limitations.","The research goal was to design and evaluate ThingPoll, an IoT privacy negotiation system; using an iterative approach with formative and summative studies, the principal finding highlights the need for cooperative, efficient, and fair privacy negotiations between smart home visitors and homeowners.",,0.900,fuzzy_title
zhou_2025,Group verifiable secure aggregate federated learning based on secret sharing,"Sufang Zhou, Lin Wang, Liangyi Chen, Yifeng Wang, KeYuan",2025,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on group verifiable secure aggregate federated learning based on secret sharing providing insights for knowledge graph development and data integration.,"This 2025 paper by Sufang Zhou, Lin Wang, Liangyi Chen, Yifeng Wang, KeYuan explores group verifiable secure aggregate federated learning based on secret sharing. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1145/3065386,"data-integration, educational-technology, knowledge-graph",Group verifiable secure aggregate federated learning based on secret sharing,"Zhou Sufang, Wang Lin, Chen Liangyi, Wang Yifeng, Yuan Ke",2025,reference-manager,10.1038/s41598-025-94478-0,,,,,"Assumes synchronized updates; real-world network latency may cause asynchronous updates, leading to instability or suboptimal model convergence.",,,,,,"The research goal is to enhance secure aggregation in federated learning; the approach introduces the GVSA protocol using lightweight validation and secret sharing; results show GVSA improves security and efficiency over existing methods, though large-scale deployment still faces efficiency and security challenges.",No information available,1.000,exact_title
zhu_2019,A Short Survey: Exploring Knowledge Graph-based Neural-Symbolic System from Application Perspective,"Shenzhe Zhu, Toronto Toronto",2019,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on a short survey: exploring knowledge graph-based neural-symbolic system from application perspective providing insights for knowledge graph development and data integration.,"This 2019 paper by Shenzhe Zhu, Toronto Toronto explores a short survey: exploring knowledge graph-based neural-symbolic system from application perspective. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, knowledge-graph",,,,,,,,,,,,,,,,,,,
zhu_2022,"FedMIA: An Effective Membership Inference Attack Exploiting ""All for One"" Principle in Federated Learning","Gongxi Zhu, Donghao Li, Hanlin Gu, Yuan Yao, Lixin Fan, Yuxing Han",2022,Yes,LOW,"This paper has limited direct relevance to heterogeneous data integration in PKG architectures, though it may provide general background on knowledge representation or data management concepts.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,"Research on fedmia: an effective membership inference attack exploiting ""all for one"" principle in federated learning providing insights for knowledge graph development and data integration.","This 2022 paper by Gongxi Zhu, Donghao Li, Hanlin Gu, Yuan Yao, Lixin Fan, Yuxing Han explores fedmia: an effective membership inference attack exploiting ""all for one"" principle in federated learning. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, educational-technology, knowledge-graph",FedMIA: An Effective Membership Inference Attack Exploiting 'All for One' Principle in Federated Learning,"Zhu Gongxi, Li Donghao, Gu Hanlin, Yao Yuan, Fan Lixin, Han Yuxing",2025,reference-manager,,,,,,,Developed and evaluated FedMIA-I (using model loss measurement) and FedMIA-II (using Grad-Cosine measurement) for membership inference attacks.,,,"How effective is the proposed FedMIA membership inference attack in federated learning settings, and how robust is it against various defense methods and configurations?","The paper introduces FedMIA, a novel Membership Inference Attack (MIA) method for federated learning. Using a one-tailed likelihood-ratio hypothesis test and leveraging cross-client updates, FedMIA outperforms six baseline MIAs and remains effective against common defenses. The study highlights the urgent need for new privacy defenses in federated learning.","The research goal is to assess federated learning's vulnerability to membership inference; the approach introduces FedMIA, leveraging non-target client updates and a likelihood-ratio test; results show FedMIA is highly effective across settings and robust to common defenses, exposing urgent needs for new privacy protections.",,1.000,exact_title
zhu_2025,A Temporal Knowledge Graph Generation Dataset Supervised Distantly by Large Language Models,"Jun Zhu, Yan Fu, Junlin Zhou, Duanbing Chen",2025,Yes,HIGH,"This work provides significant contributions to knowledge graph construction and data integration methodologies, offering valuable approaches that can be adapted for heterogeneous data fusion in PKG systems.","Provides approaches for temporal data modeling and time-based analysis in knowledge systems, contributing to temporal-first architecture design patterns for PKG implementations.",Research on a temporal knowledge graph generation dataset supervised distantly by large language models providing insights for knowledge graph development and data integration.,"This 2025 paper by Jun Zhu, Yan Fu, Junlin Zhou, Duanbing Chen explores a temporal knowledge graph generation dataset supervised distantly by large language models. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,10.1007/978-3-642-15939-8,"data-integration, knowledge-graph, temporal-data",A Temporal Knowledge Graph Generation Dataset Supervised Distantly by Large Language Models,"Zhu Jun, Fu Yan, Zhou Junlin, Chen Duanbing",2025,reference-manager,10.1038/s41597-025-05062-0,,,,,,Construction of temporal quadruples by combining triplets using discovered relation patterns through statistics and human annotation.,,,"How can document-level temporal relation extraction be systematically achieved to construct temporal knowledge graphs by associating temporal information with entity relations, and what methods and datasets enable effective extraction and reasoning of such temporal relations from documents?","The paper aims to automate temporal relation extraction from documents using a large language model (LLM)-based framework. By redefining relations and constructing the Tem-DocRED dataset, the study demonstrates that LLMs outperform rule-based and traditional methods in temporal reasoning, though with higher training complexity. The approach enables richer temporal knowledge graphs.","The paper's main objective is to extract document-level temporal relations using LLMs; it introduces a novel dataset (Tem-DocRED) and a seq-to-seq framework for generating time-aware quadruples, concluding that LLMs enable more effective temporal knowledge graph construction than traditional methods.","Keywords or tags for this research include: temporal knowledge graph (TKG), TKG reasoning, TKG question answering, DocTRE, Re-DocRED, Tem-DocRED, relation extraction, large language models (LLMs), entity annotations, event participation, administrative entity, dataset construction, and relation definitions.",1.000,exact_title
zuo_2023,KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis,Kaiwen Zuo,2023,Yes,MEDIUM,"While not directly focused on heterogeneous data integration, this paper offers supporting concepts and techniques relevant to knowledge graph development and data management that may inform PKG system design.",Contributes to the broader understanding of knowledge graph technologies and data management practices relevant to PKG system development.,Research on kg4diagnosis: a hierarchical multi-agent llm framework with knowledge graph enhancement for medical diagnosis providing insights for knowledge graph development and data integration.,"This 2023 paper by Kaiwen Zuo explores kg4diagnosis: a hierarchical multi-agent llm framework with knowledge graph enhancement for medical diagnosis. The work contributes to the field of knowledge graphs and data management, offering perspectives relevant to heterogeneous data integration challenges in modern information systems.",,,,,,,,,,,,"data-integration, healthcare, knowledge-graph",KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis,"Zuo Kaiwen, Jiang Yirui, Mo Fan, Liò Pietro",2025,reference-manager,,,,,,,Context-based data chunking and segmentation: Medical documents are divided into contextually relevant chunks using segmentation rules.,,,"How can a hierarchical multi-agent framework integrating LLMs and automated knowledge graph construction improve the accuracy, scalability, and reliability of clinical decision-making in medical diagnosis and treatment using unstructured and multimodal medical data?","KG4Diagnosis introduces a hierarchical multi-agent framework for automated medical knowledge graph construction and diagnostic reasoning. Using BioBERT, LLMs, and medical ontologies, the system segments medical texts, extracts entities/relations, and builds validated knowledge graphs. Results show improved accuracy in diagnosis and treatment recommendations, enhancing clinical decision-making.","KG4Diagnosis aims to enhance clinical decision-making by integrating a hierarchical multi-agent framework with automated medical knowledge graph construction, using advanced semantic extraction techniques, and demonstrates improved diagnostic accuracy and reduced hallucination compared to traditional approaches.",,1.000,exact_title
