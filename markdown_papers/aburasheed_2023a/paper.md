---
cite_key: "aburasheed_2023a"
title: "Building Contextual Knowledge Graphs for Personalized Learning Recommendations Using Text Mining and Semantic Graph Completion"
authors: "Hasan Abu-Rasheed, Mareike Dornhöfer, Christian Weber, Gábor Kismihók, Ulrike Buchmann, Madjid Fathi"
year: 2023
doi: "10.48550/arXiv.2401.13609"
url: "https://arxiv.org/html/2401.13609v1"
relevancy: "High"
tldr: "Framework for transforming hierarchical learning data models into knowledge graphs with enhanced contextual representation through text mining pipeline and semantic relation extraction for personalized learning recommendations."
insights: "Achieves 79% semantic similarity matching with expert-created links while significantly improving graph connectivity metrics including 109% increase in average degree centrality and 861% increase in betweenness centrality through automated semantic relation extraction."
summary: "This paper addresses the challenge of representing learning objects (LOs) within their context to advance learners from basic to higher-order learning objectives. By transforming hierarchical data models into knowledge graph (KG) models, the research enables more personalized and contextual learning recommendations. The approach uses a custom text mining pipeline (TMP) with semantic relation extraction using language detection, text cleaning, title and description embeddings, and cosine similarity algorithms to construct knowledge graphs with enhanced semantic relations."
research_question: "How can hierarchical learning data models be transformed into knowledge graphs that better represent learning object contexts for improved personalized recommendation systems?"
methodology: "Custom text mining pipeline (TMP) development, semantic relation extraction using language detection and text cleaning, title and description embeddings with cosine similarity algorithms, knowledge graph construction with semantic relations, comparative evaluation against expert-created links."
key_findings: "79% of semantic similarity scores were equal or higher than expert-created links, increased average degree centrality from 1.079 to 2.262 (109% improvement), betweenness centrality increased from 1.57 to 15.1 (861% improvement), reduced weakly connected components from 63 to 35."
limitations: "Dependency on volume and quality of learning object's textual metadata, potential repetitive content across multilingual resources, computational complexity with large-scale datasets."
conclusion: "Successfully demonstrated that semantic relation extraction can significantly enhance learning object connectivity and contextual representation, enabling more nuanced learning path recommendations through improved graph structure."
future_work: "Increase text mining pipeline robustness, expand similarity descriptions and domain-specific context integration, explore integration with additional educational data modalities."
implementation_insights: "Provides practical framework for educational knowledge graph construction with focus on automated semantic relation extraction and contextual enhancement applicable to personal learning recommendation systems."
tags:
  - "Educational Knowledge Graphs"
  - "Text Mining"
  - "Semantic Graph Completion"
  - "Learning Recommendations"
  - "Contextual KG"
---

# **Building Contextual Knowledge Graphs for Personalized Learning Recommendations using Text Mining and Semantic Graph Completion**

Hasan Abu-Rasheed*<sup>1</sup>*,\* , Mareike Dornhöfer*<sup>1</sup>* , Christian Weber*<sup>1</sup>* , Gábor Kismihók*<sup>2</sup>* , Ulrike Buchmann*<sup>1</sup>* and Madjid Fathi*<sup>1</sup>*

*<sup>1</sup>University of Siegen, Siegen, Germany <sup>2</sup>Leibniz University Hannover, Hannover, Germany*

#### **Abstract**

Modelling learning objects (LO) within their context enables the learner to advance from a basic, remembering-level, learning objective to a higher-order one, i.e., a level with an application- and analysis objective. While hierarchical data models are commonly used in digital learning platforms, using graph-based models enables representing the context of LOs in those platforms. This leads to a foundation for personalized recommendations of learning paths. In this paper, the transformation of hierarchical data models into knowledge graph (KG) models of LOs using text mining is introduced and evaluated. We utilize custom text mining pipelines to mine semantic relations between elements of an expert-curated hierarchical model. We evaluate the KG structure and relation extraction using graph quality-control metrics and the comparison of algorithmic semantic-similarities to expert-defined ones. The results show that the relations in the KG are semantically comparable to those defined by domain experts, and that the proposed KG improves representing and linking the contexts of LOs through increasing graph communities and betweenness centrality

#### **Keywords**

Knowledge graphs, Graph-based database models, Learning context, Personalized learning, Text mining

# **1. Introduction**

The rapid progress of digitalization in education increased the reachability of learners to online, open educational recourses (OER), e.g., through massive open online courses (MOOCs). While this provides more learning opportunities, an approach of one-size-fits-all on online learning platforms may not work for the wide spectrum of learners, their learning goals, and learning contexts. Personalized learning is proven as an essential requirement for better educational development and learning performance. Moreover, personalization becomes more essential in situations like self-learning, on-the-job training, or vocational education and training (VET), where initial training that learners get, e.g., in formal education, is no longer adequate to the job requirements [\[1,](#page-4-0) [2\]](#page-4-1). This is due to learning taking place within a context, where not only multiple learning objectives may overlap based on the job's requirements, but also the learner's background and current state of knowledge might differ considerably. Modern digital learning platforms need to be more contextualized and personalized environments to realize an educational setting that is meaningful to learners, related to their domain, and tailored towards their preferences and needs, to enhance their capacity-development [\[1,](#page-4-0) [2\]](#page-4-1). To account for the learning context, personalization approaches, such as recommender systems (RS), have been developed as context-aware algorithms. Their efficiency, however, is also bound to the contextual information of learning materials that are being recommended, not only to the learner profiles. A personalized, context-aware recommendation is offered when RS algorithms can match a learner's context to a context of learning objects (LO) and materials. Digital learning platforms still often organize learning content into groups of materials that

\*Corresponding author.

© 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).

deploy a hierarchical nature, e.g., as curricula, which are organized into courses, lectures, topics, and finally materials. While this organization is suited to represent the details of a learning objective, it offers no strategy for learning individualization, or model a cross-domain contextualization, which may indicate a learning recommendation, e.g., of courses from different curricula that are required in one application area or one learning context. To consider this context, data models need to be designed in a flexible and semantically enhanced way, which can be realized as a knowledge graph (KG) structure [\[3\]](#page-4-2). Unlike hierarchical data structures, KG structures offer the potential to consider relations among LOs. Transferring a hierarchical data model into a KG is possible by identifying relations between elements, based on their semantic relatedness and independent of hierarchical limitations. This identification can be done by text mining methods. In KGs, LOs are defined as nodes, and the relations among them are defined as edges. Relations in the KG define one or more types of relevancies between LOs, thus creating a contextual semantic relation based on e.g., the domain of the LOs or their textual similarity. In this paper, we extract information about the shared context of LOs by analyzing their textual semantics. Contextual information is then integrated into the KG as additional relations. Groups of contextually related LOs in the KG may be utilized by a RS, to generate contextual recommendations [\[4,](#page-4-3) [5\]](#page-4-4). We construct the KG utilizing the relations of a hierarchical data model and the semantic relations between LOs, representing the context of those objects in the graph. Semantic relations are extracted with a customized text mining pipeline (TMP), which is designed to analyze and capture the similarities between LOs based on their textual descriptions. A language-dependent similarity algorithm is utilized to mine the semantic similarities between the two description languages of the input data, namely English and German. Our contributions in this paper are: 1) Designing a semantic approach for transferring hierarchical data models in digital learning platforms to graph models. 2) Developing an approach for capturing and modelling the context of LOs to realize semantic KG completion based

*IEEE International Conference on Advanced Learning Technologies (ICALT23)*

<sup>\$</sup> [hasan.abu.rasheed@uni-siegen.de](mailto:hasan.abu.rasheed@uni-siegen.de) (H. Abu-Rasheed)

[0000-0002-2921-4809](https://orcid.org/0000-0002-2921-4809) (H. Abu-Rasheed)

on a semantic TMP. With the later contribution, present hierarchical structures for LOs can be transformed into contextualizing KGs. In the following sections, an overview of the research background is discussed before we describe the KG construction and semantic relation extraction (RE) among LOs. Then, the evaluation process and results are presented before concluding the paper.

# **2. Background**

Historically, learning is founded in "didactic- and lecturebased methods" which oftentimes are focused only on memorizing content instead of supporting "learning transfer" and engendering "problem-solving" [\[6\]](#page-4-5). Wilcke, Bloem and de Boer identified a lack of general data models allowing the representation of more than one domain simultaneously and are thus unsuitable to incorporate heterogeneous data, therefore proposing KGs as a default data model [\[3\]](#page-4-2). KGs have been utilized in technology-enhanced learning (TEL) [\[7,](#page-4-6) [8,](#page-4-7) [9\]](#page-4-8) in recent years. However, the role of the data model in representing the context of LOs in TEL is still less visited in literature, in comparison to e.g. user profiling. Here, we define the context based on situative and subject-oriented learning theories [\[2\]](#page-4-1), where context is defined as the situation in which learning happens. This includes the learner's situation (location, previous knowledge, etc.) and the LO's situation (type, length, implementation scenario, etc.). Context is described by factors that can relate two or more LOs to each other if they serve the same learning situation [\[8,](#page-4-7) [10\]](#page-4-9). Ontologies and KGs have been identified as effective methods for embedding LO context into knowledge representation [\[7,](#page-4-6) [11\]](#page-4-10). Furthermore, research shows that the embedding approaches of contextual information in the KG model and algorithms enable capturing the complex relations that learners follow to solve problems [\[6,](#page-4-5) [12,](#page-4-11) [13\]](#page-4-12). Several approaches have been followed to construct graph models from LOs [\[14\]](#page-4-13). Based on a job-skill hierarchy, authors in [\[15,](#page-4-14) [16\]](#page-4-15) utilize the job titles as textual content to create relations between job representations in the KG. To link jobs and their corresponding skills, Dave et al. [\[17\]](#page-4-16) create three graphs, connecting jobs and skills, using the textual content and existing hierarchical levels. Similarly, de Groot et al. [\[18\]](#page-4-17) create a text-based skill matching, with the support of the ESCO framework. The previous approaches, however, do not explicitly address the role of LOs' context in the KG and do not go far enough to mine further semantic and contextualizing relations between LOs.

# **3. Contextual Knowledge Graph Construction**

We develop a KG as a contextual model that represents the semantic relations among LOs. We adopt the taxonomical structure of the digital learning system in [\[19\]](#page-4-18), eDoer. This 5-level taxonomy is sufficiently simple and semantically distinctive for the construction of a solid graph data model. Its levels are 1) Journey: which represents a learning goal, 2) Course: a container that represents one aspect of the learning goal, 3) Topic: a concrete knowledge element of a course, 4) Educational Package: a group of related and ordered OERs, and 5) Educational Content: a concrete OER that can be studied. Semantic relations in the KG connect LOs within one or more taxonomical levels. Hereafter, we

use the term LO to represent all levels except the Journey. The resulting KG enables modelling the context of a LO through its connections to other objects, which appear in the same learning scenario.

### **3.1. Text Mining for Semantic Relation Extraction**

When creating new Journeys and their content, contentcreators provide detailed textual descriptions of each object. These descriptions offer the potential to mine semantic similarities between the objects [\[5\]](#page-4-4). Capturing textual semantics requires text-mining algorithms to consider word meanings and sentence structures. We designed a customized TPM, shown in Fig.1, to maximize the use of LO's textual metadata. The TMP handles objects' titles (short texts) and descriptions (long texts), written in two languages (English and German). To detect the language, we use a pre-trained model for language detection [\[20\]](#page-5-0), with a precision of 99% over 53 languages. A text-cleaning step then removes special characters and strings that can affect the text similarity algorithm. The structure of the sentences is kept intact, since text similarities are calculated on a semantic level, not as a bag-of-words (BOW). Titles and descriptions follow two processing paths in the TMP, due to the higher volume of description texts, which may include multiple topics. Such topics provide information about potential relevancies to other LOs. Therefore, the next step for titles is creating title embeddings, while descriptions have an additional step of extracting the integrated topics before the embeddings are created for each extracted topic. To generate title embeddings that are accurate in English and German, we use the Sentence-BERT model [\[21\]](#page-5-1) and the Spacy library [\[22\]](#page-5-2) for natural language processing (NLP) in Python. Title embeddings are used to calculate semantic textual similarities between titles using a cosine similarity algorithm [\[6\]](#page-4-5). Titles with different languages have embeddings created in different corpus spaces. Therefore, we translate German titles before calculating the cosine similarity. The translation is done automatically using DeepL API translation service [\[23\]](#page-5-3). After extracting the main topics from the description using the KeyBERT model [\[24\]](#page-5-4), text embeddings are created. To compare two descriptions, an intersection matrix is created to determine which topic-pairs from the two topic sets are compared. The final similarity average is then calculated across all topics of both LOs. The resulting scores from titles and descriptions are used to determine if a semantic relation is created between the two LOs, based on similarity thresholds, which are defined experimentally and then fine-tuned through expert validation.

### **3.2. Knowledge Graph Construction**

The structure of our KG includes the original hierarchical model and extends it with semantic relations calculated by the TMP, see Fig.2. We preserve the hierarchical relations since they are created by the content creators, and we add the "has\_semantic\_relation\_to" type to them. In the KG, node types represent taxonomy levels. The new relation type creates direct and indirect connections between learning goals (Journeys) and the LOs. For example, although the Journey "Dementia in elderly care" is not directly connected with the Journey "Communication in elderly care", several indirect paths were semantically found through connected

![](_page_2_Figure_0.jpeg)
<!-- Image Description: This flowchart illustrates a knowledge graph (KG) relation creation process.  It details steps including language detection, text cleaning, topic extraction, title and description embedding generation, and a bilingual check using a translator API.  Title-title similarity scores and an averaging algorithm calculate average description similarity.  A topic comparison matrix, shown as a matrix  $[T_{ij}]$, quantifies topic similarity between titles.  The overall purpose is to build KG relations based on title and description similarity. -->

**Figure 1:** Text mining pipeline (TMP) and semantic similarity calculation for title and description properties of the learning objects.

![](_page_2_Figure_2.jpeg)
<!-- Image Description: The image displays the transformation of a hierarchical model into a graph model.  The left side shows a hierarchical representation of topics ("Journey," "Course," "Topic") related to dementia and communication in elderly care.  The right side shows a graph model, connecting these topics with various relationships ("has_course," "has_topic," "has_semantic_relation_to").  The transformation illustrates a shift from structured to interconnected data representation for knowledge analysis. -->

**Figure 2:** First three levels of the KG structure, representing the role of semantic relations in creating the KG from the hierarchical one.

Courses and Topics that appear in a similar learning context. This context appears in Fig.2 in the form of a densely connected partial network of Topics (area A), whose textual descriptions revealed that they serve the same scenario. As discussed in [\[4\]](#page-4-3), such a network can enable a learner to achieve a higher knowledge level that enables comprehension, inferencing, and problem-solving. This is accomplished by learning LOs within their context, in contrast to learning isolated LOs that may only enable remembering.

# **4. Evaluation and Results**

The evaluation of KG's quality utilizes a wide range of metrics, which may have different indications in different domains. In TEL and VET, it is important to consider the metrics, whose indications can reflect the role of the KG in the learning process. KG evaluation should also address the quality of the extracted relations, as a foundation for evaluating the quality of the KG structure. Therefore, our evaluation strategy is implemented quantitatively and qualitatively. Qualitative evaluation is conducted with domain experts to validate the relation-extraction process and results, as well as the KG's role in contextualizing the learning recommendations. Quantitative evaluation is designed two-fold: The first part evaluates the quality of extracted relations in the KG. It focuses on the TMP and evaluates its ability to connect LOs semantically in comparison to expert-created links. The second part considers network metrics [\[25\]](#page-5-5) and quality-control methods, as surveyed in [\[26\]](#page-5-6), where those are classified in the domain of linked open data (LOD) into six dimensions: representation, accessibility, intrinsic, dataset dynamicity, contextual, and trust. To select the metrics that are relevant and meaningful in the scope of this research, we utilize [\[6,](#page-4-5) [27,](#page-5-7) [13\]](#page-4-12). They show that effective evaluation of KG's ability to represent learning context and the learner's mental model can be accomplished through metrics that correspond to contextual dimension (relevancy and completeness) and intrinsic dimension (interlinking, density, average degree). We build on those findings and use the metrics of *average degree centrality*, *clustering coefficient*, *weakly connected components*, and *betweenness centrality*.

### **4.1. Evaluation Dataset**

For the evaluation, we use a dataset of expert-curated OERs. The data set is provided by Tavakoli et al. [\[19\]](#page-4-18). Expertcurated content provides a high level of credibility to the baseline model, which is essential for a fair evaluation. After data exploratory analysis (DEA), we filter out LOs that do not have educational content associated with them and remove the duplicated and isolated ones. The resulting hierarchical model we use for creating the KG features 122 Journeys, 432 Courses, 767 Topics, 2565 Educational packages, and 7358 OERs.

### **4.2. Evaluation of the Semantic Relation Extraction**

The goal of semantic relation extraction is to connect LOs that appear in the same or a similar learning context. This goal aligns with the best practices of content creators, who connect an LO to another one if both are needed in the same learning situation. We utilize this logic to evaluate the semantic similarity scores that our TMP calculates among Courses and Topics. We first calculate the average of text cosine similarity scores among the LOs in each Journey (i): , by comparing each LO to all other LOs in Journey i. Then, we compare the similarity score of each semantic relation , , to the average similarity of the journeys i,j that it connects , = <sup>+</sup> 2 .

If the TMP is able to extract semantic relations with similarity scores that are comparable to the expert-curated relations, we assume that the new semantic relation is meaningful. We define comparability here as being within the same range of both Journeys' similarity . This means that , >= , . Fig.3 shows the scores of a random sample of 240 semantic relations in the KG, alongside the semantic similarity of each Journey-pair they connect. From the results, we can conclude: 1) the similarity scores calculated within each Journey range between 86% and around 90%. This confirms the basic assumption that expert-curated LOs in Journeys are semantically similar. 2) 79% of our semantic similarity scores are either equal or higher than score averages calculated within Journeys, while the remaining 21% is slightly below the average. This indicates that the semantic relations between different Journeys are as meaningful as the relations that experts created within each Journey.

### **4.3. KG Evaluation Metrics**

From the wide range of graph quality metrics, our selection is based on the meaning of each metric in the scope of TEL and VET. Selected metrics reflect certain aspects of our KG, when interpreted from a pedagogical point of view in TEL and VET. The comparison here is conducted between the hierarchical structure and the proposed KG, in the light of

![](_page_3_Figure_0.jpeg)
<!-- Image Description: This line graph displays semantic similarity scores for source and target branches, and their inter-branch similarity, across various semantic relations (identified by ID).  The x-axis represents the semantic relation ID, while the y-axis shows the similarity score. Three lines depict the average source branch similarity, average target branch similarity, and the overall semantic similarity between branches.  The graph likely illustrates the performance or consistency of a semantic relation model. -->

**Figure 3:** Semantic-relation textual-similarity scores (Purple), compared to the Journeys (Blue and Orange) connected by those relations through the TMP.

the value-added that KG structure offers based on the interpretation of each graph quality metric. In the following, we elaborate on the selected metrics and their domain interpretation. Table 1 shows our KG results in comparison to the original hierarchical model.

#### **4.3.1. Average Degree Centrality (ADC)**

Degree centrality (DC) measures a node's popularity in a graph [\[28\]](#page-5-8). It evaluates the connectedness of a node through its incoming and outgoing relations. In an educational usecase, ADC reflects LO's connectedness to other objects that take place in the learning scenario. The reason is that LOs are either connected by experts, or through a semantic relation. While DC in a hierarchical model represents the LO's relation to other LOs from the same Journey, the increase of that object's DC in the graph model shows that new relations have been found to other Journeys, meaning that the LO may appear in more learning contexts. After calculating the DC for all graph nodes, the average (ADC) is determined, which has doubled for our KG.

#### **4.3.2. Clustering Coefficient (CC)**

CC reflects how strongly a node belongs to a community in a graph. Communities are clusters of nodes that are densely inter-connected. A community is considered more modular if it is easy to separate from other communities. Communities of LOs in our KG represent their context. Therefore, the higher the community count is, the more contexts are represented. Modularity, on the other hand, reflects the potential to separate a learning context from another. Therefore, a lower modularity score is preferred, since it means that learning contexts are well connected to each other. Evaluation results show that our KG increased the detected communities, due to the semantic relations, and decreased graph modularity.

#### **4.3.3. Weakly Connected Components (WCC)**

WCC detects sets of nodes in the graph that are loosely connected to other graph parts. Therefore, a high WCC score reflects poor connectedness of LO groups in the data model. Using Monge and Elkan's algorithm [\[29\]](#page-5-9), we find an effective reduction of the loosely connected node groups in our KG.

#### **4.3.4. Betweenness Centrality (BC)**

BC describes the impact of a node on the flow of information within that graph. It is especially relevant to VET and TEL, since LOs with high BC work as bridges that link individual

learning goals to each other, to solve a more complex problem [\[4\]](#page-4-3). Using Brandes and Pich's algorithm [\[30\]](#page-5-10), our results show that the KG has an average BC value of 15.1, which is about 10 times the BC score of the original hierarchical model.

### **4.4. Qualitative expert-evaluation**

We also evaluated our KG construction and contextualization approach with domain experts in two focus groups. The groups included experts in VET and researcher-training programs. A total of nine experts participated and answered three questions on 1) The role of connecting learning goals in learning contexts, 2) KGs as contextual data models in their domain, and 3) Using LO's textual description to mine contextual relations. All participants emphasized the need for connecting individual learning goals for solving reallife, job-related problems. Six participants pointed out that highly connected nodes in the graph can represent transferrable skills among different domains. Three experts found a direct use of connecting multi-lingual LOs in their daily work. They also pointed out that a recommendation of multi-lingual content should avoid repetition of the same content written in different languages. Experts also agreed that textual content and description of LOs are important sources for contextual information. They indicated that content creators should roughly understand the way algorithms extract semantic relations, so that they can enrich the descriptions of their LO content with useful contextual information, allowing better connectivity in the KG. The pedagogical experts also addressed the dynamic change of the learner's context, and the development of the learning domain, which requires a continuous update of the KG.

# **5. Conclusion**

In this paper, we introduced a semantic approach for KG completion to enhance the contextual representation of LOs for personalized learning systems. A concept and a textmining pipeline for relation extraction are proposed, to transfer hierarchical data models into graph ones, thus enhancing the structural and contextual quality of the data model. Our findings from the TMP and KG evaluation suggest that the KG was able to enhance LOs connectivity on a semantic level. Increased connectivity allowed the KG to represent a context around an LO, through its relations to other similar LOs, which appear in the same or similar learning contexts. Proposed TMP can be used with different hierarchical structures of LOs, such as those generated from other digital learning platforms, since it utilizes the commonly used title- and description properties of LOs. A limitation here is the dependency of our TMP on the volume and quality of LO's textual metadata. The multilingualism of the proposed solution corresponded to a real-world challenge in VET, but it also raised the concern about repetitive content in a KG-based RS. Although our solution is not responsible for the decision-making process in that scenario, it can still be further developed to expand the similarity description, reflecting potential identical content in multiple languages. Further steps of this research aim to increase the robustness of TMP against textual data sparsity and enrich LOs contextualization with additional domain-specific features.

**Table 1**

KG Quality Evaluation Against Hierarchical Model. Preferred Value-Trends in VET and TEL Use-Case are Explained

| Evaluation Metric                                 | Hierarchical data model | KG    | Preferred value trends |
|---------------------------------------------------|-------------------------|-------|------------------------|
| Average Degree Centrality                         | 1.079                   | 2.262 | increasing             |
| Clustering Coefficient (Number of communities)    | 253                     | 541   | increasing             |
| Clustering Coefficient (Average modularity score) | 0.779                   | 0.636 | decreasing             |
| Weakly Connected Components                       | 63                      | 35    | decreasing             |
| Betweenness Centrality                            | 1.57                    | 15.1  | increasing             |

# **References**

- <span id="page-4-0"></span>[1] U. Buchmann, Subjektbildung und Qualifikation. Ein Beitrag zur Entwicklung berufsbildungswissenschaftlicher Qualifikationsforschung, 2nd ed., Frankfurt a.M., 2011.
- <span id="page-4-1"></span>[2] U. Buchmann, Vocational-scientific education in qualification design – conditional factors for quality assurance and development of qualifications across educational sectors, in: V. Rein, J. Wildt (Eds.), Professionalscientific education: discourses, perspectives, implications and options for science and practice, Verlag Barbara Budrich, Opladen Berlin Toronto, 2022, pp. 341–371.
- <span id="page-4-2"></span>[3] X. Wilcke, P. Bloem, V. de Boer, The knowledge graph as the default data model for learning on heterogeneous knowledge, DS 1 (2017) 39–57. URL: [https://content.iospress.com/articles/](https://content.iospress.com/articles/data-science/ds007) [data-science/ds007.](https://content.iospress.com/articles/data-science/ds007) doi:[10.3233/DS-170007](http://dx.doi.org/10.3233/DS-170007).
- <span id="page-4-3"></span>[4] D. L. Trumpower, M. Filiz, G. S. Sarwar, Assessment for learning using digital knowledge maps, in: D. Ifenthaler, R. Hanewald (Eds.), Digital Knowledge Maps in Education, Springer New York, New York, NY, 2014, pp. 221–237. doi:[10.1007/978-1-4614-3178-7\\_12](http://dx.doi.org/10.1007/978-1-4614-3178-7_12).
- <span id="page-4-4"></span>[5] H. Abu Rasheed, C. Weber, J. Zenkert, P. Czerner, R. Krumm, M. Fathi, A text extraction-based smart knowledge graph composition for integrating lessons learned during the microchip design, in: K. Arai, S. Kapoor, R. Bhatia (Eds.), Intelligent Systems and Applications, Springer International Publishing, Cham, 2021, pp. 594–610.
- <span id="page-4-5"></span>[6] P. J. Giabbanelli, A. A. Tawfik, V. K. Gupta, Learning analytics to support teachers' assessment of problem solving: A novel application for machine learning and graph algorithms, in: D. Ifenthaler, D.-K. Mah, J. Y.- K. Yau (Eds.), Utilizing Learning Analytics to Support Study Success, Springer International Publishing, 2019, pp. 175–199. doi:[10.1007/978-3-319-64792-0\\_](http://dx.doi.org/10.1007/978-3-319-64792-0_11) [11](http://dx.doi.org/10.1007/978-3-319-64792-0_11).
- <span id="page-4-6"></span>[7] E. Ilkou, H. Abu-Rasheed, M. Tavakoli, S. Hakimov, G. Kismihók, S. Auer, W. Nejdl, Educor: An educational and career-oriented recommendation ontology, in: The Semantic Web – ISWC 2021: 20th International Semantic Web Conference, ISWC 2021, Virtual Event, October 24–28, 2021, Proceedings, Springer-Verlag, Berlin, Heidelberg, 2021, p. 546–562. doi:[10.1007/](http://dx.doi.org/10.1007/978-3-030-88361-4_32) [978-3-030-88361-4\\_32](http://dx.doi.org/10.1007/978-3-030-88361-4_32).
- <span id="page-4-7"></span>[8] K. Verbert, et al., Context-aware recommender systems for learning: A survey and future challenges, IEEE Trans. Learning Technol. 5 (2012) 318–335. doi:[10.1109/TLT.2012.11](http://dx.doi.org/10.1109/TLT.2012.11).
- <span id="page-4-8"></span>[9] A. Visvizi, L. Daniela, Technology-enhanced learning and the pursuit of sustainability, Sustainability 11 (2019) 4022. doi:[10.3390/su11154022](http://dx.doi.org/10.3390/su11154022).

- <span id="page-4-9"></span>[10] Y. M. Hemmler, D. Ifenthaler, Indicators of the learning context for supporting personalized and adaptive learning environments, in: 2022 International Conference on Advanced Learning Technologies (ICALT), IEEE, Bucharest, Romania, 2022, pp. 61–65. doi:[10.](http://dx.doi.org/10.1109/ICALT55010.2022.00026) [1109/ICALT55010.2022.00026](http://dx.doi.org/10.1109/ICALT55010.2022.00026).
- <span id="page-4-10"></span>[11] J. Berri, R. Benlamri, Y. Atif, Ontology-based framework for context-aware mobile learning, in: Proceeding of the 2006 international conference on Communications and mobile computing - IWCMC '06, ACM Press, Vancouver, British Columbia, Canada, 2006, p. 1307. doi:[10.1145/1143549.1143811](http://dx.doi.org/10.1145/1143549.1143811).
- <span id="page-4-11"></span>[12] P. J. Giabbanelli, A. A. Tawfik, B. Wang, Designing the next generation of map assessment systems: Open questions and opportunities to automatically assess a student's knowledge as a map, Journal of Research on Technology in Education (2022). doi:[10.](http://dx.doi.org/10.1080/15391523.2022.2119449) [1080/15391523.2022.2119449](http://dx.doi.org/10.1080/15391523.2022.2119449).
- <span id="page-4-12"></span>[13] M. K. Kim, K. S. McCarthy, Using graph centrality as a global index to assess students' mental model structure development during summary writing, Education Tech Research Dev 69 (2021) 971–1002. doi:[10.1007/](http://dx.doi.org/10.1007/s11423-021-09942-1) [s11423-021-09942-1](http://dx.doi.org/10.1007/s11423-021-09942-1).
- <span id="page-4-13"></span>[14] Y. Fettach, M. Ghogho, B. Benatallah, Knowledge graphs in education and employability: A survey on applications and techniques, IEEE Access 10 (2022) 80174–80183. doi:[10.1109/ACCESS.2022.](http://dx.doi.org/10.1109/ACCESS.2022.3194063) [3194063](http://dx.doi.org/10.1109/ACCESS.2022.3194063).
- <span id="page-4-14"></span>[15] J.-J. Decorte, J. V. Hautte, T. Demeester, C. Develder, Jobbert: Understanding job titles through skills, in: arXiv, 2021. doi:[10.48550/arXiv.2109.09605](http://dx.doi.org/10.48550/arXiv.2109.09605).
- <span id="page-4-15"></span>[16] H. Luo, S. Ma, A. J. B. Selvaraj, Y. Sun, Learning job representation using directed graph embedding, in: Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data, ACM, Anchorage Alaska, 2019, pp. 1–5. doi:[10.1145/3326937.3341263](http://dx.doi.org/10.1145/3326937.3341263).
- <span id="page-4-16"></span>[17] V. S. Dave, B. Zhang, M. A. Hasan, K. AlJadda, M. Korayem, A combined representation learning approach for better job and skill recommendation, in: Proceedings of the 27th ACM International Conference on Information and Knowledge Management, ACM, Torino Italy, 2018, pp. 1997–2005. doi:[10.1145/3269206.](http://dx.doi.org/10.1145/3269206.3272023) [3272023](http://dx.doi.org/10.1145/3269206.3272023).
- <span id="page-4-17"></span>[18] M. de Groot, J. Schutte, D. Graus, Job posting-enriched knowledge graph for skills-based matching, arXiv (2021). doi:[10.48550/arXiv.2109.02554](http://dx.doi.org/10.48550/arXiv.2109.02554).
- <span id="page-4-18"></span>[19] M. Tavakoli, A. Faraji, M. Molavi, S. T. Mol, G. Kismihók, Hybrid human-ai curriculum development for personalised informal learning environments, in: LAK22: 12th International Learning Analytics and Knowledge Conference, Association for Computing Machinery, New York, NY, USA, 2022, pp. 563–569. doi:[10.1145/3506860.3506917](http://dx.doi.org/10.1145/3506860.3506917).

- <span id="page-5-0"></span>[20] S. Nakatani, Language detection library for java, 2010. URL: [http://code.google.com/p/language-detection/,](http://code.google.com/p/language-detection/) accessed: Feb. 02, 2023.
- <span id="page-5-1"></span>[21] N. Reimers, I. Gurevych, Sentence-bert: Sentence embeddings using siamese bert-networks, arXiv (2019). doi:[10.48550/arXiv.1908.10084](http://dx.doi.org/10.48550/arXiv.1908.10084).
- <span id="page-5-2"></span>[22] Library architecture · spacy api documentation, 2023. URL: [https://spacy.io/api,](https://spacy.io/api) accessed Feb. 03, 2023.
- <span id="page-5-3"></span>[23] Deepl api, 2023. URL: [https://www.deepl.com/en/](https://www.deepl.com/en/docs-api) [docs-api,](https://www.deepl.com/en/docs-api) accessed Feb. 03, 2023.
- <span id="page-5-4"></span>[24] M. Grootendorst, Maartengr/keybert: Bibtex, 2021. doi:[10.5281/zenodo.4461265](http://dx.doi.org/10.5281/zenodo.4461265).
- <span id="page-5-5"></span>[25] C. Guéret, P. Groth, C. Stadler, J. Lehmann, Assessing linked data mappings using network measures, in: E. Simperl, et al. (Eds.), The Semantic Web: Research and Applications, Springer Berlin Heidelberg, 2012, pp. 87–102. doi:[10.1007/978-3-642-30284-8\\_13](http://dx.doi.org/10.1007/978-3-642-30284-8_13).
- <span id="page-5-6"></span>[26] A. Zaveri, et al., Quality assessment for linked data: A survey: A systematic literature review and conceptual framework, SW 7 (2016) 63–93. URL: [https://content.iospress.com/articles/](https://content.iospress.com/articles/semantic-web/sw175) [semantic-web/sw175.](https://content.iospress.com/articles/semantic-web/sw175) doi:[10.3233/SW-150175](http://dx.doi.org/10.3233/SW-150175).
- <span id="page-5-7"></span>[27] H. S. Shin, A. Jeong, Modeling the relationship between students' prior knowledge, causal reasoning processes, and quality of causal maps, Computers & Education 163 (2021) 104113. doi:[https://doi.org/](http://dx.doi.org/https://doi.org/10.1016/j.compedu.2020.104113) [10.1016/j.compedu.2020.104113](http://dx.doi.org/https://doi.org/10.1016/j.compedu.2020.104113).
- <span id="page-5-8"></span>[28] L. C. Freeman, Centrality in social networks: Conceptual clarification, Social Networks 1 (1978) 215–239. doi:[10.1016/0378-8733\(78\)90021-7](http://dx.doi.org/10.1016/0378-8733(78)90021-7).
- <span id="page-5-9"></span>[29] A. E. Monge, C. Elkan, An efficient domainindependent algorithm for detecting approximately duplicate database records, in: Workshop on Research Issues on Data Mining and Knowledge Discovery, DMKD 1997 in cooperation with ACM SIG-MOD'97, Tucson, Arizona, USA, 1997.
- <span id="page-5-10"></span>[30] U. Brandes, C. Pich, Centrality estimation in large networks, International Journal of Bifurcation Chaos 17 (2007) 2303–2318. doi:[10.1142/](http://dx.doi.org/10.1142/S0218127407018403) [S0218127407018403](http://dx.doi.org/10.1142/S0218127407018403).