<!-- cite_key: sowiski2020 -->

# Overview of Current Challenges in Multi-Architecture Software Engineering and a Vision for the Future

Piotr Sowiński 1 ,2[0000 −0002 −2543 <sup>−</sup>9461], Ignacio Lacalle3[0000 −0002 −6002 −4050] , Rafael Vaño3[0000 −0003 −2372 <sup>−</sup>6253], Carlos E. Palau3[0000 −0002 −3795 <sup>−</sup>5404], Maria Ganzha 1 ,2[0000 −0001 −7714 <sup>−</sup>4844], and Marcin Paprzycki2[0000 −0002 −8069 −2152]

<sup>1</sup> Faculty of Mathematics and Information Science, Warsaw University of Technology, ul. Koszykowa 75, 00-662 Warsaw, Poland

<sup>2</sup> Systems Research Institute, Polish Academy of Sciences, ul. Newelska 6, 01-447 Warsaw, Poland

{piotr.sowinski,maria.ganzha,marcin.paprzycki}@ibspan.waw.pl <sup>3</sup> Communications Department, Universitat Politècnica de València, 46022 Valencia, Spain

{iglaub,ravagar2}@upv.es, cpalau@dcom.upv.es

Abstract. The landscape of computing technologies is changing rapidly, straining existing software engineering practices and tools. The growing need to produce and maintain increasingly complex multi-architecture applications makes it crucial to effectively accelerate and automate software engineering processes. At the same time, artificial intelligence (AI) tools are expected to work hand-in-hand with human developers. Therefore, it becomes critical to model the software accurately, so that the AI and humans can share a common understanding of the problem. In this contribution, firstly, an in-depth overview of these interconnected challenges faced by modern software engineering is presented. Secondly, to tackle them, a novel architecture based on the emerging WebAssembly technology and the latest advancements in neuro-symbolic AI, autonomy, and knowledge graphs is proposed. The presented system architecture is based on the concept of dynamic, knowledge graph-based WebAssembly Twins, which model the software throughout all stages of its lifecycle. The resulting systems are to possess advanced autonomous capabilities, with full transparency and controllability by the end user. The concept takes a leap beyond the current software engineering approaches, addressing some of the most urgent issues in the field. Finally, the efforts towards realizing the proposed approach as well as future research directions are summarized.

Keywords: Software engineering · Overview · WebAssembly · Multiarchitecture software · Autonomy · Software engineering automation · Knowledge graphs.

# 1 Introduction

The modern landscape of hardware and software platforms is changing rapidly. In CPU architectures, the existing technologies are expanding their ranges of applications (e.g., ARM processors shifting to the servers), while entirely new platforms, such as RISC-V [\[24\]](#page-17-0), emerge. This requires the existing software to be adapted to the new instruction sets, which can be a costly and lengthy process. At the same time, computational workloads are increasingly deployed across the entire computing continuum [\[23\]](#page-17-1), introducing even more hardware diversity. Software engineers are faced with the seemingly impossible task of producing applications that are required to run on multiple highly heterogeneous platforms, spanning from the large Cloud clusters to the tiny IoT devices. The software must also evolve rapidly, to keep up with consumer demands, technological changes, and to maintain competitiveness in the global market. In this context, the current specific challenges for software vendors include migrating Cloud applications to the Edge [\[69\]](#page-20-0), and using the emerging, quickly evolving hardware (e.g., specialized machine learning accelerators [\[3,](#page-16-0)[50\]](#page-19-0)) to its full potential.

Much of the recent innovation in software engineering (SE) has been focused on increasing the degree of automation in all stages of the software lifecycle – from the Continuous Integration / Continuous Delivery (CI/CD) pipelines [\[61\]](#page-19-1) to the artificial intelligence (AI) based coding assistants, and documentation generation tools [\[28\]](#page-17-2). However, the current automation tools are, generally, disconnected from each other. They lack autonomy in making decisions, and are usually regarded (and designed) as corrective patches that aim only to heal a specific issue, thus lacking a holistic view of the software lifecycle and the variety of existing interdependencies. Effectively, the whole SE process still hinges on the developer being able to grasp the full complexity of the software, and initiating all required actions. Considering that, introducing autonomy to the SE tools could present a deep transformative change in how it is possible to tackle complex problems, such as resource use optimization of multi-architecture software, or adapting applications to the dynamically changing environment.

Independently, there is also a clear need to improve software modeling capabilities, moving beyond the isolated models that address only a narrow slice of the software lifecycle. Integrated, yet highly modular and dynamic models are needed. They must be comprehensible to both humans and computers, forming a much-needed bridge of mutual understanding, allowing both sides to operate with the same concepts (i.e., AI alignment). Such holistic models could become the basis of future software engineering automation tools that could carry out complex tasks autonomously, while remaining completely transparent, explainable, and controllable.

Guiding example. Throughout the text, to better illustrate the presented concepts, we will be referring to a guiding example, based on a real use case from the Smart Safety of Workers pilot in the ASSIST-IoT Horizon 2020 project [\[15\]](#page-17-3). This scenario is meant to be challenging from the software engineering standpoint, highlighting areas in need of improvement.

In the considered scenario, a software module that can detect falls of construction workers in near-real time is to be developed. The module uses acceleration measurements collected from IoT devices worn by the employees. It must work on a very wide variety of hardware platforms, depending on the client and the existing computing infrastructure. Here, it is assumed that different construction companies may have different (e.g. legacy, present or future) hardware and software platforms. This includes highly heterogeneous IoT and Edge devices (used for lower latency and better privacy), as well as Cloud clusters, e.g., in the case of clients who do not have enough computing capacity on the Edge. Moreover, it is assumed that the used hardware can change quickly (even every few months) due to the shifts in the device availability, client preferences, technological advances, and older devices breaking quickly in the harsh environment. The hardware platforms may have different processor architectures (including x86, ARM, RISC-V), computing capabilities (from hundreds of kilobytes to terabytes of system memory), machine learning accelerators, and networking (Ultra-Wide Band, Wi-Fi, Bluetooth, ZigBee...). The worker safety application must be able to evolve very quickly to, among others, adapt to client demands and/or newlyintroduced machine learning models, and to keep up with the competition. For example, new integrations with clients' systems are expected to be one of the most common requests. The clients also want to understand the system's design and evolution, to make sure it reflects their requirements in terms of, among others, use case requirements (e.g., workplace safety standards), cybersecurity, or worker privacy.

Summary of contributions. In this work, we consider the intersection of the following three relevant challenges in modern software engineering: (i) developing multi-architecture applications, (ii) accelerating and automating the SE processes, and (iii) software modeling. For each, a deep dive into the current technological obstacles and opportunities is presented. We believe that these challenges are interconnected and thus propose a joint solution – an architecture of a general system accelerating software engineering tasks for multi-architecture applications using WebAssembly. The presented system concept targets all stages of the software lifecycle – from planning, through coding, testing, up to deployment and operation. It leverages the latest achievements in AI, autonomy, and knowledge representation to potentially pose a paradigm shift in software engineering and change how next-generation software is developed.

# <span id="page-2-0"></span>2 Background

In what follows, we present an analysis of the main challenges and latest developments in the three considered areas: multi-architecture applications, software engineering process acceleration and automation, and software modeling.

## <span id="page-3-0"></span>2.1 Multi-Architecture Applications

Multiple challenges in building software for multi-architecture systems reflect the complexity and the heterogeneity of modern distributed computing environments, primarily in the computing continuum [\[34,](#page-18-0)[62\]](#page-19-2). The used platforms span from the large compute clusters (e.g., in the Cloud), to the resource-constrained IoT sensors and actuators. This being the case, the developers must be aware of all possible CPU Instruction Set Architectures (ISAs) present in the devices, and have dedicated tooling for each. The hardware platforms also differ greatly in terms of supported compute accelerators, storage, and networking capabilities. Meanwhile, the need to make the applications more dynamic and resilient is undeniable – software providers must cope with high availability requirements, rapidly changing customer demands, diverse hardware, and supply chain risks. For example, in the event of a chip shortage, the ability to effortlessly switch to a different ISA, for which processors are more widely available, would be of tremendous value to the businesses. Although it is possible to tackle these issues partially with the current tools (as described in what follows), it is generally a difficult task, requiring expertise not only in coding, but also in compilers, distributed deployments, self-adaptation, and more, which increases the costs.

Currently, partial solutions to these problems exist, and are in active use in the industry. Containers are perhaps the most popular [\[69,](#page-20-0)[9\]](#page-16-1), providing a semiisolated runtime environment and some degree of portability. However, their multi-architecture capabilities rely on building the container image separately for each ISA, which requires all dependencies to also be available for that instruction set. In the past, container developers usually prepared only images for x86 or x86-64 processors. Through concerted effort, the industry in the recent years managed to make ARM-based container images also widespread [\[29\]](#page-17-4). However, the limitations of this approach become visible with the emerging RISC-V architecture [\[14\]](#page-17-5). If RISC-V is to see wide adoption, every software vendor will have to again adapt their software to the new ISA. This recurring adaptation process slows down the take-up of new hardware platforms, and substantially increases the costs of multi-architecture application development. As an alternative to the containers, one may consider programming languages that compile to a portable bytecode, which can be then executed on any supported hardware platform. Such is the case with the Java Virtual Machine (JVM), or .NET. However, both of these frameworks support only a limited number of languages which were specifically designed or ported to compile to the bytecode (e.g., Java for the JVM, C# for .NET).

When considering the guiding example, the presented technologies offer no satisfactory solutions. The company developing the worker fall detection application would most likely choose to maintain a few versions of the software in parallel. For example, for the larger Cloud and Edge devices, multi-architecture containers would be used, with each ISA being supported separately. For IoT devices, the application would have to be recompiled into a binary format specific to a given platform, making the process more expensive. Additional consideration would have to be given to the machine learning accelerators, available on each platform, as they often require specialized libraries or runtimes to be used, further increasing the amount of the needed binary distributions. For the clients requiring additional integrations, separate distributions including additional code would also be needed.

One of the most promising recent developments in this area is WebAssembly (Wasm) [\[58\]](#page-19-3) – an emerging technology for building multi-architecture executables. Although it was initially designed to boost the performance of browserbased applications, it is increasingly being used in general-purpose systems [\[69\]](#page-20-0). Its advantage over previous approaches (e.g., the Java Virtual Machine) lies in: (i) a very diverse set of supported programming languages, (ii) a much lighter and modular design, (iii) support for a wider variety of hardware platforms (including the smallest IoT devices [\[56\]](#page-19-4)), and (iv) the involvement of many large and competing technological stakeholders from the start, instead of a single, dominating entity. Specifically, some of the most significant members of the Bytecode Alliance (the nonprofit organization maintaining parts of the Wasm ecosystem) include Intel, Amazon, ARM, Cisco, Microsoft, Mozilla, Red Hat, and Siemens[4](#page-4-0) . With a much smaller footprint and better security than containers [\[69,](#page-20-0)[41\]](#page-18-1), Wasm appears to be the execution model of the future computing continuum applications [\[42](#page-18-2)[,62\]](#page-19-2). Its key advantage is the ability to run a WebAssembly binary on almost any platform in the computing continuum.

Although Wasm is a relatively new technology, its ecosystem is developing rapidly. Among key initiatives in this space is the WebAssembly System Interface (WASI)[5](#page-4-1) , which seeks to provide a portable and secure system interface [\[66\]](#page-20-1), including functionalities such as sockets, filesystem access, and the HTTP protocol. The WASI initiative is currently evaluating proposals for even more ambitious features, such as uniform interfaces for machine learning acceleration, GPU access, SQL databases, and key-value stores. In this sense, WASI may grow beyond what was traditionally thought of as a "system interface" (e.g., POSIX [\[37\]](#page-18-3)), by providing a universal interface for a wide variety of common functionalities that may be used across the computing continuum. At the time of writing (October 2024), the latest release of WASI is 0.2.2, released on October 4, 2024. The next feature version (0.3) is expected to include the introduction of asynchronous APIs.

The Wasm Component Model[6](#page-4-2) is a recent architectural proposal, aiming to enable component composability in WebAssembly binaries. With the Component Model it is possible to seamlessly link together modules written in a variety of languages, which are normally not easily interoperable – for example C++, C#, Go, JavaScript, Python, and Rust. The proposal includes a universal binary interface language (Wasm Interface Type, WIT) in which contracts between components are defined. This is an ambitious project, as each of these languages has a completely different and unrelated type system. This is in contrast to, for example, the Java Virtual Machine, in which all languages share the same basic

<span id="page-4-0"></span><sup>4</sup> <https://bytecodealliance.org/>

<span id="page-4-1"></span><sup>5</sup> <https://wasi.dev/>

<span id="page-4-2"></span><sup>6</sup> <https://component-model.bytecodealliance.org/introduction.html>

JVM constructs and types. Concurrently with the Wasm Component Model, a registry protocol for Wasm components is being developed: warg[7](#page-5-0) . The warg protocol envisions a federated network of Wasm registries which will engage in, for example, collaborative vulnerability tracking.

Finally, wasmCloud[8](#page-5-1) should be mentioned, as an orchestration framework for WebAssembly applications, explicitly targeting heterogeneous deployments and Cloud-Edge scenarios. It builds on top of the component model and WASI, to make application deployment as seamless as possible. Additionally, wasmCloud provides a mesh network (called "lattice") based on NATS[9](#page-5-2) to enable communication between components.

Despite these recent advances, it should be stressed that at this time, the WebAssembly ecosystem has not yet fully matured. The aforementioned projects are all working towards a new common technological baseline that is expected to crystallize in the next few years. Developers migrating to Wasm are encountering practical issues in their code that take time to resolve [\[72\]](#page-20-2). WebAssembly is also still lacking in overarching software engineering methodologies and tooling, to create a robust, complete software lifecycle. Such methodologies and tools are needed, given the radical change in the underlying technologies and assumptions, which question the applicability of past approaches.

In the guiding example, it can be stipulated that the company would use Wasm to build a universal module that can work on any platform. Interfacing with the network and the machine learning accelerators would be done via WASI. Client-specific code would be implemented and composed with the Wasm Component Model. The complete deployment would be then orchestrated via wasmCloud. However, WebAssembly by itself does not solve all challenges. Additionally, a new SE methodology and toolset would be needed to adapt the company's processes. Let us look into these issues in more detail in the following subsections.

## 2 Software Engineering Process Acceleration and Automation

Accelerating software development and maintenance has been the focus of software engineering for decades [\[54,](#page-19-5)[47\]](#page-18-4). Although much was achieved in terms of methodologies, tools, and industry practices, the constantly increasing complexity of software processes still requires more innovation. Inefficient processes can be found across the entire software lifecycle, with frequent miscommunication, lack of traceability, and monolithic changes that are hard to manage. For example, in requirements analysis, miscommunication between the stakeholders and the technical teams is common. In the code writing phase, the teams often lack precise information on what to implement and what the user really needs. Meanwhile, in code maintenance, it is hard to avoid regressions due to partial or poorly understood bug fixes, or cascading dependencies that make on-the-fly modifications very challenging (if not impossible) to automate.

<span id="page-5-0"></span><sup>7</sup> <https://warg.io/>

<span id="page-5-1"></span><sup>8</sup> <https://wasmcloud.com/>

<span id="page-5-2"></span><sup>9</sup> <https://nats.io/>

Effectively automating processes in software development and maintenance is crucial to ensuring timeliness, high quality, and consistency of the software product. Automation can reduce costs and greatly accelerate software development [\[61\]](#page-19-1). However, the automation capabilities of the state-of-the-art tools are still limited, and do not always deliver on the expectations [\[19,](#page-17-6)[75\]](#page-20-3). As a result, many processes still rely on the developers to carry out the critical work manually. Although maintaining control of the processes is crucial due to (among others) security and quality assurance concerns, this does not preclude extending automation to making autonomous decisions. Controllable, transparent, and explainable autonomy of software workflows would enable one to realize use cases that were previously very hard or even impossible to implement reliably. This includes program self-repair, run-time self-adaptation, and more, taking over the decision-making burden from the developer. Micro-managing the complexity of modern software appears to be no longer possible to be realized by hand. In the long term, continuing improvements in resource efficiency, security, and privacy may only be achievable with better automation.

In this context, the last two years have seen perhaps the most abrupt paradigm shift in software engineering to date. The emergence of Large Language Models (LLMs) opened up new possibilities for automation, such as coding assistants (e.g., GitHub Copilot [\[13\]](#page-17-7)), documentation generation (e.g., Scribe, DocuWriter), testing, and more [\[28\]](#page-17-2). However, LLMs have obvious issues with transparency and reliability [\[4](#page-16-2)[,73\]](#page-20-4), which has serious practical implications for SE [\[60\]](#page-19-6). For example, language models for code generation were demonstrated to be prone to misusing APIs and introducing new vulnerabilities to the applications [\[44\]](#page-18-5). LLMs are also still largely disconnected from the SE methodologies and from other existing tools. Modern software processes are already very complex, with a multiplicity of tools that assist developers during each stage of the development lifecycle. Introducing AI into the mix in an ad hoc manner further complicates the situation. This poses the question of whether further optimizations in software processes should instead be sought in a more holistic and systematic manner.

Although process automation is widespread in modern software engineering, the capabilities that are delivered by state-of-the-art tools remain limited. Numerous DevOps and DevSecOps [\[39\]](#page-18-6) platforms are commercially available (e.g., GitLab, GitHub), along with many CI/CD automation tools, either integrated into such platforms or external (e.g., Jenkins, CircleCI, Travis). However, these tools must be set up manually, thus requiring deep expertise in CI/CD tooling [\[55\]](#page-19-7). Furthermore, such tools have no or very limited autonomous capabilities – usually they operate on a set of fixed triggers, also set up manually. On the other hand, with the recent surge in the popularity of LLMs, AI-based coding assistants (e.g., GitHub Copilot) offer to automate some tasks, such as code writing, commit message management, or writing task descriptions. However, these tools also require explicit prompting from the user and take no action on their own – they do help accelerate certain activities, but possess no autonomous decision-making capabilities. While early work was recently done in building

autonomous coding agents [\[71\]](#page-20-5), they rely heavily on black-box, unaccountable LLMs, and very little is known about their effectiveness in practice. However, it is important to note that as of today (October 2024), research concerning relations between LMMs and SE is one of the hottest research areas.

In the guiding example, the fall detection application will get more complex over time, making it increasingly difficult to maintain. For each new platform, introducing additional CI/CD configuration will be required. It would also be very challenging (or impossible) to automate adaptations to changing client requirements, or to automate security vulnerability patching (which is one of the most important forms of necessary software maintenance).

## 3 Software Modeling

The increasing complexity and dynamicity of modern software pose a major challenge for software vendors. Nowadays, applications are composed of hundreds of software modules and libraries. As such, modeling the intricate web of implemented features, requirements, code, and dependencies is a slow and laborious task. At the same time, the application as a whole must evolve rapidly, to make sure that the ever-shifting demands of the stakeholders are met, and to stay relevant in the very competitive market. Not being able to efficiently manage this growing complexity can lead to wasted resources (e.g., developer time, electricity), security issues, bloated applications, or delays in integrating software components. Conversely, an accurate, representative model of the application and its requirements could drastically accelerate development and maintenance, and serve as a reliable ground truth for both the developers and the automated tools.

The increasing complexity of software projects, and the need to consider the entire lifecycle of an application strain the existing Model-Driven Engineering approaches [\[6\]](#page-16-3). Current solutions must be made more dynamic, scalable, and enable intelligent automated completion in the model specification and creation. Although UML is the industry standard in software modeling, using it for communication with stakeholders and among team members is time-consuming and prone to misunderstandings [\[18\]](#page-17-8). BPMN is more business- and process-oriented, with some overlap with UML. However, in practice, modeling errors are common in BPMN models [\[36\]](#page-18-7). Moreover, it is considered overcomplicated and hard to understand by some users [\[57\]](#page-19-8). Moving on to the code, design-by-contract programming formally specifies the behavior of software components [\[43\]](#page-18-8). However, this is usually only applicable within a single programming language, and is disconnected from other types of software-related models. Although there are some solutions for model-driven code generation [\[67\]](#page-20-6) and other AI-based tasks, especially using LLMs [\[8\]](#page-16-4), the range of their capabilities is very narrow, and it is not clear how to integrate them with each other, and with the existing SE processes. Moreover, the aforementioned modeling approaches only consider a part of the software lifecycle (e.g., requirements, code, dependencies) and can hardly be extended to the other application areas.

The problem of having many disconnected solutions to software modeling could be addressed with an approach that is modular, expressive, and freely extensible from the start, such as ontologies and knowledge graphs [\[25,](#page-17-9)[27\]](#page-17-10). Modern ontology languages like OWL [\[70\]](#page-20-7) use the Semantic Web as their technological backbone, which gives them the ability to interlink knowledge across the Internet [\[5\]](#page-16-5). Indeed, several ontologies for software engineering applications were already proposed. For example, the Software Build System Ontology (SBSON) [\[17\]](#page-17-11) allows for modeling dependencies, releases, and software packages. On the other hand, the TwoUse Toolkit [\[48\]](#page-18-9) translates UML class diagrams into ontologies. The Software Description Ontology [\[22\]](#page-17-12) provides terms for describing software, especially applications developed for scientific purposes. Unfortunately, none of these approaches resolves the software modeling issue completely and holistically. However, they are not required to do so. They only need to cover well the part of the software lifecycle relevant to them. It is possible to later reuse multiple pertinent ontologies in concert, to obtain a holistic solution tailored to a given software engineering use case. This, however, is still an unexplored area of research.

The ontology-based approach allows one to interlink knowledge not only within one domain (software engineering), but also beyond it, opening new possibilities. Depending on the use case, it could be for example beneficial to interlink the software model with a description of research artifacts (e.g., benchmark results) as provided by the Information Research Artifact Ontology [\[45\]](#page-18-10). When considering the deployment of distributed sensor networks and similar systems, one may use standard ontologies such as Web of Things TD [\[33\]](#page-18-11), SOSA/SSN [\[51\]](#page-19-9), or SAREF [\[21\]](#page-17-13). Finally, especially relevant in requirements modeling and communicating with the stakeholders, accurately representing the specific application domain is often crucial. Ontologies can also help with that, as they were successfully applied across a wide range of use cases, from biomedicine [\[32\]](#page-18-12) to building information modeling [\[46\]](#page-18-13) and popular music [\[74\]](#page-20-8). This Semantic Webbased approach breaks with the usual assumptions of what a software model is and, essentially, puts no boundaries or limits on what can be modeled in a uniform manner. This, however, requires a lot of work to be put into adhering to the Linked Data best practices and the FAIR principles (findability, accessibility, interoperability, reusability) [\[53\]](#page-19-10). Otherwise, practical issues in reusing ontologies may create too much friction for adopters and make the proposed vision of an ecosystem for knowledge graph-based software modeling rather unattractive.

In the guiding example, the company would most likely use UML (or BMPN, or a similar tool) to communicate with the clients. However, maintaining the models for each client and each software variant would be very time-consuming, and the clients may not be familiar with the selected modeling tools. Alternatively, the company could employ knowledge graphs to represent the use case logic and requirements, however, translating this knowledge into the actual software is an open research subject. The knowledge graph would also have to be constructed and then actively maintained, which in practice can turn out to be a serious problem, involving long-term resource commitment [\[77](#page-20-9)[,78\]](#page-20-10). Therefore,

for this approach to succeed, the process of knowledge elicitation and formalization, as well as management of knowledge evolution would have to be at least partially automated. This, again, is an area of active research.

# 3 Proposed System Architecture

Taking into account what has been discussed thus far, let us introduce an architecture for a system that would tackle the indicated challenges of software modeling and SE process automation for multi-architecture software. The proposed concept offers a comprehensive view of the entire software engineering lifecycle, and can plug in seamlessly into the existing tools and processes, such as those discussed in Section [2.](#page-2-0) The general architecture is described in what follows, with a visual overview presented in Figure [1.](#page-9-0) Further details about each component (WebAssembly Twin, Autonomy Core, and Modular Pluggable Connectors) are presented in subsequent sections.

![](_page_9_Figure_4.jpeg)

<span id="page-9-0"></span>Fig. 1. Overview of the proposed system architecture.

The technological and conceptual backbone of the proposed architecture is the WebAssembly Twin (WT), a dynamic, knowledge graph-enabled model of the WebAssembly software. The WT is intended to serve as a closely tied, bidirectionally synchronized "twin" of the WebAssembly modules and applications. Not only does the WT model reflect the actual, existing software, but also any change in the model induces corresponding changes in the software – essentially, providing a powerful Model-Driven Engineering abstraction. The WT is inherently modular, with modules corresponding to the different versions of the software and to the different modeling domains. The WT uses dynamic knowledge graphs [\[52\]](#page-19-11) with event-driven reads and writes, flowing through a highperformance event bus. Access to the WebAssembly Twin is provided via an open, universal API that is used by the Autonomy Core (AC) and the Modular Pluggable Connectors (MPCs). The WebAssembly Twin is further discussed in Section [3.1.](#page-10-0)

Modular Pluggable Connectors are non-autonomous automation tools – executing specific commands, to carry out some work in the software (via the existing tools, processes, and platforms) or in the WT. An MPC can, for example, present a chat interface to the user, to aid them with requirement specification that will be stored in the WT. A different MPC could generate code on behalf of the AC, using specifications from the WT. MPCs are modular – they are composed of smaller modules to foster reusability of the automation components (e.g., shared interface code). They communicate with the user via an Integrated Development Environment (IDE) plugin, integrating seamlessly with tools that are already familiar to the developer. Modular Pluggable Connectors are further discussed in Section [3.2.](#page-12-0)

The Autonomy Core moves one step further in terms of automation capabilities. It can, on its own, assess the situation, plan a series of actions, and carry out the plan, modifying the software and/or the WebAssembly Twin. The AC uses MPCs as its working tools (as a developer would use, e.g., an IDE), while the WT becomes its modeling medium/knowledge base. The decisions in the AC are taken by a mix of neuro-inspired and symbolic AI algorithms – exploiting the best characteristics of both, in the form of a neuro-symbolic fusion. While machine learning (including neural network models) brings immense intuitive and heuristic capabilities, symbolic reasoning grounds the decisions in the formal knowledge from the WT and guarantees transparency, explainability, and control of the solution. The AC is fully transparent with its decision-making, while its autonomy level is fully controllable by the developer. Human supervision or interaction with the AC is performed via dedicated user interfaces, embedded in the IDE plugin, to make it easily accessible for the developers. The Autonomy Core is further discussed in Section [3.3.](#page-13-0)

The shared principle of all these components is their openness and modularity, as the only sustainable path to adoption of such a system is through being open and extensible from the start. This is the same philosophy that is used in, among others, the WebAssembly ecosystem, as discussed in Section [2.1.](#page-3-0) Let us now discuss each of the three conceptual components of the proposed architecture in more detail.

## <span id="page-10-0"></span>3.1 WebAssembly Twin

The WebAssembly Twin (Figure [2\)](#page-11-0) takes a leap beyond the state of the art in software modeling, by aiming to be thoroughly dynamic, modular, and cover any software-related modeling needs. The WT's content is highly structured and carries semantic meaning, using knowledge graphs [\[27\]](#page-17-10) as the modeling medium. The meta-knowledge basis for the WT is provided by a set of abstract metamodels, schemas, and ontologies. Where possible, the meta-model will reuse existing, especially standardized ontologies (e.g., from ETSI or W3C), to foster interoperability. Due to its inherent extensibility and the vast collection of already published ontologies, the Resource Description Framework (RDF) [\[12\]](#page-16-6)

ecosystem appears to be most appropriate to be used as the knowledge graph model. In RDF, ontologies are most commonly expressed in the Web Ontology Language (OWL) [\[70\]](#page-20-7), allowing one to define expressive reasoning rules. Constraints (useful for, for instance, validation) can be written down in the Shapes Constraint Language (SHACL) [\[31\]](#page-18-14). RDF, OWL, and SHACL are standardized by the W3C and there are many independent implementations of these standards. This should help in facilitating the adoption of the proposed concept.

![](_page_11_Figure_2.jpeg)

<span id="page-11-0"></span>Fig. 2. Architecture of the WebAssembly Twin.

This approach opens the way to expressing knowledge about software in a structured manner – its design requirements, code, tests, interfaces, software contracts, resource use characteristics, security vulnerabilities, and more, on multiple levels of integration. Owing to the intrinsic modularity and flexibility of knowledge graphs, the WT could be easily extended by third parties to cover new use cases, and fuse knowledge across all stages of the software lifecycle. Here, note that the WT cannot be merely a static knowledge graph. It must be a highly dynamic, event-driven system with an internal streaming event bus for carrying commands and knowledge fragments in near-real time. This is needed because the knowledge about the software will be evolving over time. For example, new requirements or target platforms may arise, refactors in the code may be made, and runtime errors may be registered in the deployments. Reacting to and propagating these events quickly is crucial to ensuring that the WebAssembly Twin really does deliver the expected value, instead of being a slow and superfluous add-on to the SE process. In the WT, the event bus writes to and reads from the internal dynamic knowledge graphs and allows for rapid propagation of commands and information to/from WT clients. With a dynamically changing, modular structure, the WT is able to handle a wide variety of challenging scenarios that require fusing complex knowledge across domains.

Dynamicity and complexity are a major technical challenge, with performance being often a serious obstacle in adopting knowledge-rich systems. This should be addressed through the judicious use of state-of-the-art technology, such as low-latency messaging (e.g., NATS[10](#page-12-1), Eclipse Zenoh[11](#page-12-2)), high-performance semantic streaming (e.g., the Jelly protocol[12](#page-12-3) [\[65\]](#page-19-12)), and knowledge graph federation. Access to the WT is to be provided via a straightforward open application programming interface (API), enabling third parties to easily implement services that use the WT (e.g., Modular Pluggable Connectors). The WT should be considered a companion to its corresponding WebAssembly module/component. Thus, it should be at least partially distributed with the built application, for example through the currently-developed warg registry protocol[13](#page-12-4). These semantic descriptions of software modules could be used by downstream developers, who could then more easily build their own WebAssembly Twins by composing them from already available WTs.

An initial assessment of ontologies that could potentially be used as part of the WT meta-model, points to: SBSON (dependency management) [\[17\]](#page-17-11), ontologies developed in the MOST project (Software Engineering) [\[48\]](#page-18-9), the Software Description Ontology [\[22\]](#page-17-12), or ontologies developed in the Software Process Deployment and Evaluation Framework project [\[59\]](#page-19-13). Not only strictly softwarerelated ontologies are relevant here, though. Ontologies dedicated to, for example, tracking energy use, environmental footprint, work management, and more could be integrated into the WebAssembly Twin, depending on the specific use cases. In the guiding example, for example, it would be useful to include an ontology of workplace safety such as OSHDO-Core [\[35\]](#page-18-15), to represent regulatory and client requirements. Moreover, as noted earlier, standardized ontologies related to IoT and sensor networks, such as SOSA/SSN [\[51\]](#page-19-9) or SAREF [\[21\]](#page-17-13) are likely to be used.

### <span id="page-12-0"></span>3.2 Modular Pluggable Connectors

Current software engineering practices involve the use of many diverse tools and processes, such as IDEs, CI/CD systems, code repositories, design tools, and methodologies (DevOps/DevSecOps). These solutions are of tremendous, proven value and must be exploited effectively in the proposed approach. This is done with the Modular Pluggable Connectors – a set of composable functionality blocks. MPCs, built upon a shared open specification and API, flexibly cover the needs of modifying and reading the WT, interfacing with the aforementioned existing SE tools, and interacting with the user (see Figure [3](#page-13-1) for more specific examples).

The modular structure of MPCs simplifies their implementation – for example, the code to interact with the WT API can be shared between many connectors, while a pre-trained AI module can be reused for many different tasks.

<span id="page-12-1"></span><sup>10</sup> <https://nats.io/>

<span id="page-12-2"></span><sup>11</sup> <https://zenoh.io/>

<span id="page-12-3"></span><sup>12</sup> <https://w3id.org/jelly>

<span id="page-12-4"></span><sup>13</sup> <https://warg.io/>

![](_page_13_Figure_1.jpeg)

<span id="page-13-1"></span>Fig. 3. Example Modular Pluggable Connectors.

specification This flexibility enables one to use any kind of AI applicable to a given problem and maximize reuse of existing AI solutions, easing the adoption. This may include: self-supervised generative models [\[28\]](#page-17-2) (e.g., for code and test generation), multimodal deep neural networks [49] (e.g., for interacting with users and reading graphical media such as hand-drawn diagrams), graph neural networks (for WT comprehension, e.g., ULTRA [20]), time series analysis and prediction models (for example, for anomaly detection in monitoring data [\[38\]](#page-18-16)), and symbolic reasoning [10] for inferring new knowledge based on what is already stored in the WebAssembly Twin. The MPCs are expected to form an open ecosystem of modules developed by multiple industry and research actors.

In the guiding scenario, the software company would ideally be able to reuse many MPCs published openly by other actors. Additionally, they could relatively easily prepare their own MPCs for integrations with the tools already being used by the development teams. This would allow the company to retain most of its original tools and processes, lowering the cost of adopting the new technology. Use case-specific modules could also be prepared, for example an interface that would explain the software's algorithm using occupational health and safety terminology, by exploiting the cross-domain knowledge stored in the WebAssembly Twin.

#### <span id="page-13-0"></span>3.3 Autonomy Core

Finally, the leap forward in automation capabilities is provided by the Autonomy Core (AC) (Figure 4) – a general autonomy enabler, capable of planning and executing complex WebAssembly software workflows on its own. The vision behind the AC is to realize complex, self-adaptive use cases – for example: (i) responding to a spike of runtime errors and fixing the bug autonomously, while also adding tests to prevent the problem from re-occurring; (ii) detecting a security vulnerability in the dependency chain and resolving the issue by updating

![](_page_14_Figure_1.jpeg)

the affected module; (iii) identifying a possible resource optimization (e.g., more efficient library, unnecessary code) and introducing it in practice.

<span id="page-14-0"></span>Fig. 4. Architecture of the Autonomy Core.

The Autonomy Core extends the framework of monitor-analyze-plan-execute with knowledge (MAPE-K) [\[30\]](#page-18-17), adapted to fit in the proposed architecture. The WebAssembly Twin serves as the source of knowledge, with the AC also being able to modify the WT in a feedback loop, enabling iterative processes (i.e. iterative self-adaptation). Knowledge graphs were previously proposed as an ideal base for future autonomous systems due to their unique characteristics [\[7\]](#page-16-8). Using the semantics imbued in the WT, the AC is able to "understand" the content of the WT, and generalize it to entirely new concepts (e.g., new use cases, or modeling domains) – this can be achieved with symbolic reasoning. On the other hand, machine learning methods excel at less rigorous cognitive processes, such as reasoning by analogy. The AC will effectively leverage both, using the emerging neuro-symbolic techniques that aim to bring together the best characteristics of both types of AI [\[26,](#page-17-15)[40,](#page-18-18)[76\]](#page-20-11).

Maintaining control and accountability of the autonomous processes is crucial, with failures in the AC having the potential for serious social, environmental, and economic consequences. Therefore, a systematic, risk-based system for determining autonomy levels must be employed, considering the potential for errors, and their possible implications. Based on this, the system will use one of the following modes: human-in-the-loop, human-on-the-loop (observing), and full autonomy. In this context, using reinforcement learning with human feedback [\[1\]](#page-16-9) should be investigated to let the AC dynamically learn from interacting with the user. Transparency and explainability are similarly crucial. Therefore, the AC must be end-to-end transparent and interpretable, with its explanations being based on the well-defined terms in the WT (the symbolic part of the neurosymbolic hybrid). The WT thus establishes a "bridge of understanding" between

the user and the AC, providing a set of concepts understandable by both the human and the machine, with the explanation being profiled to suit the nature of the process and the involved stakeholders. This concept of using knowledge graphs to help with machine learning explainability has already been explored in recent studies [\[68\]](#page-20-12).

In the guiding scenario, an autonomous workflow could be used to automatically adapt the software to API changes in the customers' systems. Once such a change was detected, the AC would propose a modification to the integration code and submit it for human review. Alternatively, the AC could monitor the performance of the application in deployment and seek to identify hardware platforms on which the software performs poorly. Subsequently, it could issue improvement recommendations to the development team, along with potential code that could address the issue. The AC could simulate the outcome of different changes to the code and automatically discard modifications that would not improve the performance.

# 4 Conclusion and Future Work

The proposed system architecture aims to tackle several interconnected and very relevant challenges in modern software engineering. By analyzing the current issues concerning multi-architecture development, SE process acceleration, and software modeling, it becomes clear that there is a lot of room for novel methodological concepts and technical innovations. Specifically, the proposed architecture is intended to greatly accelerate software engineering processes, throughout the entire software lifecycle of multi-architecture, continuum-native applications. This is achieved through the proposed combination of dynamic, knowledge-based software models (WebAssembly Twin); flexible and powerful, yet transparent and controllable autonomy (Autonomy Core); and modularized automation components (Modular Pluggable Connectors). The ideas presented here are illustrated in a realistic guiding scenario, originating from the ASSIST-IoT project.

Realizing the proposed architecture in practice would require further technical and research work, some of which is already happening, as outlined in Section [2.](#page-2-0) The WebAssembly ecosystem is advancing rapidly, with the Component Model, WASI, wasmCloud, and the warg protocol expected to be the biggest drivers of technical progress in the area. The WebAssembly Twin assumes using knowledge graphs in a very demanding scenario, with a lot of dynamic changes and a very complex graph structure. This certainly requires further research in dynamic knowledge graphs [\[52\]](#page-19-11), high-performance streaming knowledge graph systems (stream protocols, reasoners, query engines), and interface standardization to connect these solutions together (e.g., the recent RDF Stream Taxonomy proposal [\[63\]](#page-19-15)). Establishing a sustainable ecosystem of interoperable ontologies for these knowledge graphs is also challenging (cf. issues with reusing ontologies in practice [\[64\]](#page-19-16)). However, the Semantic Web community has made great progress in implementing the FAIR practices in the recent years [\[11,](#page-16-10)[22,](#page-17-12)[53\]](#page-19-10), making the outlook rather optimistic. The realization of Modular Pluggable Connectors hinges mainly on defining an open, shared API, and the ability of the community to sustain an ecosystem of interdependent, pluggable modules. Perhaps the most challenging from the research standpoint is the Autonomy Core, which integrates tightly with the WT. Further studies are needed to establish the precise technological and methodological base for such a system, building on the decades of research in autonomous systems. Recently, much work was done in connecting neuro-symbolic AI with knowledge graphs [\[16\]](#page-17-16) and dynamic knowledge graphs [\[2\]](#page-16-11). Nonetheless, many technical challenges remain to be solved in this field.

Acknowledgments. This study was partially funded by the European Commission, under the Horizon Europe project aerOS, grant number 101069732.

Disclosure of Interests. The authors have no competing interests to declare that are relevant to the content of this article.

# References

- <span id="page-16-9"></span>1. Abel, D., Salvatier, J., Stuhlmüller, A., Evans, O.: Agent-agnostic human-in-theloop reinforcement learning. arXiv preprint arXiv:1701.04079 (2017)
- <span id="page-16-11"></span>2. Alam, M., Gesese, G.A., Paris, P.H.: Neurosymbolic methods for dynamic knowledge graphs. arXiv preprint arXiv:2409.04572 (2024)
- <span id="page-16-0"></span>3. Alam, S., Yakopcic, C., Wu, Q., Barnell, M., Khan, S., Taha, T.M.: Survey of deep learning accelerators for edge and emerging computing. Electronics 13(15), 2988 (2024)
- <span id="page-16-2"></span>4. Bender, E.M., Gebru, T., McMillan-Major, A., Shmitchell, S.: On the dangers of stochastic parrots: Can language models be too big? In: Proceedings of the 2021 ACM conference on fairness, accountability, and transparency. pp. 610–623 (2021)
- <span id="page-16-5"></span>5. Bizer, C., Heath, T., Berners-Lee, T.: Linked Data: Principles and state of the art. In: World wide web conference. vol. 1, p. 40. Citeseer (2008)
- <span id="page-16-3"></span>6. Bucchiarone, A., Cabot, J., Paige, R.F., Pierantonio, A.: Grand challenges in model-driven engineering: an analysis of the state of the research. Software and Systems Modeling 19, 5–13 (2020)
- <span id="page-16-8"></span>7. Calbimonte, J.P., Ciortea, A., Kampik, T., Mayer, S., Payne, T.R., Tamma, V., Zimmermann, A.: Autonomy in the age of knowledge graphs: vision and challenges. Transactions on Graph Data & Knowledge 1(1), 22p (2023)
- <span id="page-16-4"></span>8. Cámara, J., Troya, J., Burgueño, L., Vallecillo, A.: On the assessment of generative AI in modeling tasks: an experience report with ChatGPT and UML. Software and Systems Modeling 22(3), 781–793 (2023)
- <span id="page-16-1"></span>9. Casalicchio, E.: Container orchestration: A survey. Systems Modeling: Methodologies and Tools pp. 221–235 (2019)
- <span id="page-16-7"></span>10. Chen, X., Jia, S., Xiang, Y.: A review: Knowledge reasoning over knowledge graph. Expert systems with applications 141, 112948 (2020)
- <span id="page-16-10"></span>11. Cox, S.J., Gonzalez-Beltran, A.N., Magagna, B., Marinescu, M.C.: Ten simple rules for making a vocabulary fair. PLoS computational biology 17(6), e1009041 (2021)
- <span id="page-16-6"></span>12. Cyganiak, R., Wood, D., Lanthaler, M.: RDF 1.1 concepts and abstract syntax. W3C recommendation, W3C (Feb 2014), [https://www.w3.org/TR/2014/](https://www.w3.org/TR/2014/REC-rdf11-concepts-20140225/) [REC-rdf11-concepts-20140225/](https://www.w3.org/TR/2014/REC-rdf11-concepts-20140225/), Accessed on 17 April 2024

- 18 P. Sowiński et al.
- <span id="page-17-7"></span>13. Dakhel, A.M., Majdinasab, V., Nikanjam, A., Khomh, F., Desmarais, M.C., Jiang, Z.M.J.: GitHub Copilot AI pair programmer: Asset or liability? Journal of Systems and Software 203, 111734 (2023)
- <span id="page-17-5"></span>14. Dakić, V., Mršić, L., Kunić, Z., Ðambić, G.: Evaluating ARM and RISC-V architectures for high-performance computing with Docker and Kubernetes. Electronics 13(17), 3494 (2024)
- <span id="page-17-3"></span>15. Danilenka, A., Sowiński, P., Rachwał, K., Bogacka, K., Dąbrowska, A., Kobus, M., Baszczyński, K., Okrasa, M., Olczak, W., Dymarski, P., et al.: Real-time AI-driven fall detection method for occupational health and safety. Electronics 12(20), 4257 (2023)
- <span id="page-17-16"></span>16. DeLong, L.N., Mir, R.F., Fleuriot, J.D.: Neurosymbolic AI for reasoning over knowledge graphs: A survey. IEEE Transactions on Neural Networks and Learning Systems (2024)
- <span id="page-17-11"></span>17. Eghan, E.E.: Dependency Management 2.0–A Semantic Web Enabled Approach. Ph.D. thesis, Concordia University (2019)
- <span id="page-17-8"></span>18. Fernández-Sáez, A.M., Chaudron, M.R., Genero, M.: An industrial case study on the use of UML in software maintenance and its perceived benefits and hurdles. Empirical Software Engineering 23(6), 3281–3345 (2018)
- <span id="page-17-6"></span>19. Fitzgerald, B., Stol, K.J.: Continuous software engineering and beyond: trends and challenges. In: Proceedings of the 1st International Workshop on rapid continuous software engineering. pp. 1–9 (2014)
- <span id="page-17-14"></span>20. Galkin, M., Yuan, X., Mostafa, H., Tang, J., Zhu, Z.: Towards foundation models for knowledge graph reasoning. arXiv preprint arXiv:2310.04562 (2023)
- <span id="page-17-13"></span>21. García-Castro, R., Lefrançois, M., Poveda-Villalón, M., Daniele, L.: The ETSI SAREF ontology for smart applications: a long path of development and evolution. Energy Smart Appliances: Applications, Methodologies, and Challenges pp. 183– 215 (2023)
- <span id="page-17-12"></span>22. Garijo, D., Ratnakar, V., Gil, Y., Khider, D.: The software description ontology (2021), <https://w3id.org/okn/o/sd/1.9.0>
- <span id="page-17-1"></span>23. Gkonis, P., Giannopoulos, A., Trakadas, P., Masip-Bruin, X., D'Andria, F.: A survey on IoT-edge-cloud continuum systems: status, challenges, use cases, and open issues. Future Internet 15(12), 383 (2023)
- <span id="page-17-0"></span>24. Greengard, S.: Will RISC-V revolutionize computing? Communications of the ACM 63(5), 30–32 (2020)
- <span id="page-17-9"></span>25. Grimm, S., Abecker, A., Völker, J., Studer, R.: Ontologies and the Semantic Web. In: Domingue, J., Fensel, D., Hendler, J.A. (eds.) Handbook of Semantic Web Technologies, pp. 507–579. Springer Berlin Heidelberg, Berlin, Heidelberg (2011). [https://doi.org/10.1007/978-3-540-92913-0\\_13](https://doi.org/10.1007/978-3-540-92913-0_13), [https://doi.org/10.1007/](https://doi.org/10.1007/978-3-540-92913-0_13) [978-3-540-92913-0\\_13](https://doi.org/10.1007/978-3-540-92913-0_13)
- <span id="page-17-15"></span>26. Hitzler, P., Sarker, M.K.: Neuro-symbolic artificial intelligence: The state of the art. IOS press (2022)
- <span id="page-17-10"></span>27. Hogan, A., Blomqvist, E., Cochez, M., d'Amato, C., Melo, G.D., Gutierrez, C., Kirrane, S., Gayo, J.E.L., Navigli, R., Neumaier, S., et al.: Knowledge graphs. ACM Computing Surveys (Csur) 54(4), 1–37 (2021)
- <span id="page-17-2"></span>28. Hou, X., Zhao, Y., Liu, Y., Yang, Z., Wang, K., Li, L., Luo, X., Lo, D., Grundy, J., Wang, H.: Large language models for software engineering: A systematic literature review. arXiv preprint arXiv:2308.10620 (2023)
- <span id="page-17-4"></span>29. Kaiser, S., Haq, M.S., Tosun, A.Ş., Korkmaz, T.: Container technologies for ARM architecture: A comprehensive survey of the state-of-the-art. IEEE Access 10, 84853–84881 (2022)

- <span id="page-18-17"></span>30. Kephart, J.O., Chess, D.M.: The vision of autonomic computing. Computer 36(1), 41–50 (2003)
- <span id="page-18-14"></span>31. Knublauch, H., Kontokostas, D.: Shapes constraint language (SHACL). W3C recommendation, W3C (Jul 2017), [https://www.w3.org/TR/2017/](https://www.w3.org/TR/2017/REC-shacl-20170720/) [REC-shacl-20170720/](https://www.w3.org/TR/2017/REC-shacl-20170720/)
- <span id="page-18-12"></span>32. Konopka, B.M.: Biomedical ontologies—a review. Biocybernetics and Biomedical Engineering 35(2), 75–86 (2015)
- <span id="page-18-11"></span>33. Korkan, E., Käbisch, S., McCool, M.: Web of Things (WoT) Thing Description 1.1. W3C recommendation, W3C (Dec 2023), https://www.w3.org/TR/2023/RECwot-thing-description11-20231205/
- <span id="page-18-0"></span>34. Kumar, R., Baughman, M., Chard, R., Li, Z., Babuji, Y., Foster, I., Chard, K.: Coding the computing continuum: Fluid function execution in heterogeneous computing environments. In: 2021 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW). pp. 66–75. IEEE (2021)
- <span id="page-18-15"></span>35. Ławrynowicz, A., Ławniczak, I.: Towards a core ontology of occupational safety and health. In: Ontology Engineering: 12th International Experiences and Directions Workshop on OWL, OWLED 2015, co-located with ISWC 2015, Bethlehem, PA, USA, October 9-10, 2015, Revised Selected Papers 12. pp. 134–142. Springer (2016)
- <span id="page-18-7"></span>36. Leopold, H., Mendling, J., Günther, O.: Learning from quality issues of BPMN models from industry. IEEE software 33(4), 26–33 (2015)
- <span id="page-18-3"></span>37. Lewine, D.: POSIX programmers guide. " O'Reilly Media, Inc." (1991)
- <span id="page-18-16"></span>38. Liu, M., Cen, L., Ruta, D.: Gradient boosting models for cybersecurity threat detection with aggregated time series features. In: 2023 18th Conference on Computer Science and Intelligence Systems (FedCSIS). pp. 1311–1315. IEEE (2023)
- <span id="page-18-6"></span>39. Lopez, O., Blasi, J., Uriarte, M., Lacalle, I., Galiana, G., Palau, C.E., Garro, E., Ganzha, M., Paprzycki, M., Lewandowski, P., et al.: DevSecOps methodology for NG-IoT ecosystem development lifecycle. Journal of Computer Science and Cybernetics 37(3), 321–337 (2021)
- <span id="page-18-18"></span>40. Lu, Z., Afridi, I., Kang, H.J., Ruchkin, I., Zheng, X.: Surveying neuro-symbolic approaches for reliable artificial intelligence of things. Journal of Reliable Intelligent Environments pp. 1–23 (2024)
- <span id="page-18-1"></span>41. Ménétrey, J., Pasin, M., Felber, P., Schiavoni, V.: Twine: An embedded trusted runtime for WebAssembly. In: 2021 IEEE 37th International Conference on Data Engineering (ICDE). pp. 205–216. IEEE (2021)
- <span id="page-18-2"></span>42. Ménétrey, J., Pasin, M., Felber, P., Schiavoni, V.: WebAssembly as a common layer for the cloud-edge continuum. In: Proceedings of the 2nd Workshop on Flexible Resource and Application Management on the Edge. pp. 3–8 (2022)
- <span id="page-18-8"></span>43. Meyer, B.: Applying "design by contract". Computer 25(10), 40–51 (1992)
- <span id="page-18-5"></span>44. Mousavi, Z., Islam, C., Moore, K., Abuadbba, A., Babar, M.A.: An investigation into misuse of Java security apis by large language models. In: Proceedings of the 19th ACM Asia Conference on Computer and Communications Security. pp. 1299–1315 (2024)
- <span id="page-18-10"></span>45. Nguyen, V.B., Svátek, V.: Ontology for informatics research artifacts. In: European Semantic Web Conference. pp. 126–130. Springer (2021)
- <span id="page-18-13"></span>46. Niknam, M., Karshenas, S.: A shared ontology approach to semantic representation of BIM data. Automation in Construction 80, 22–36 (2017)
- <span id="page-18-4"></span>47. Osterweil, L.J., Ghezzi, C., Kramer, J., Wolf, A.L.: Determining the impact of software engineering research on practice. Computer 41(3), 39–49 (2008)
- <span id="page-18-9"></span>48. Parreiras, F.S.: Semantic Web and model-driven engineering. John Wiley & Sons (2012)

- 20 P. Sowiński et al.
- <span id="page-19-14"></span>49. Pawłowski, M., Wróblewska, A., Sysko-Romańczuk, S.: Effective techniques for multimodal data fusion: A comparative analysis. Sensors 23(5), 2381 (2023)
- <span id="page-19-0"></span>50. Peccerillo, B., Mannino, M., Mondelli, A., Bartolini, S.: A survey on hardware accelerators: Taxonomy, trends, challenges, and perspectives. Journal of Systems Architecture 129, 102561 (2022)
- <span id="page-19-9"></span>51. Phuoc, D.L., Haller, A., Janowicz, K., Cox, S., Lefrançois, M., Taylor, K.: Semantic sensor network ontology. W3C recommendation, W3C (Oct 2017), https://www.w3.org/TR/2017/REC-vocab-ssn-20171019/
- <span id="page-19-11"></span>52. Polleres, A., Pernisch, R., Bonifati, A., Dell'Aglio, D., Dobriy, D., Dumbrava, S., Etcheverry, L., Ferranti, N., Hose, K., Jiménez-Ruiz, E., et al.: How does knowledge evolve in open knowledge graphs? Transactions on Graph Data and Knowledge 1(1), 11–1 (2023)
- <span id="page-19-10"></span>53. Poveda-Villalón, M., Espinoza-Arias, P., Garijo, D., Corcho, O.: Coming to terms with FAIR ontologies. In: International Conference on Knowledge Engineering and Knowledge Management. pp. 255–270. Springer (2020)
- <span id="page-19-5"></span>54. Raccoon, L.: Fifty years of progress in software engineering. ACM SIGSOFT Software Engineering Notes 22(1), 88–104 (1997)
- <span id="page-19-7"></span>55. Rajapakse, R.N., Zahedi, M., Babar, M.A., Shen, H.: Challenges and solutions when adopting DevSecOps: A systematic review. Information and software technology 141, 106700 (2022)
- <span id="page-19-4"></span>56. Ray, P.P.: An overview of WebAssembly for IoT: Background, tools, state-of-theart, challenges, and future directions. Future Internet 15(8), 275 (2023)
- <span id="page-19-8"></span>57. Recker, J.: Opportunities and constraints: the current struggle with BPMN. Business Process Management Journal 16(1), 181–201 (2010)
- <span id="page-19-3"></span>58. Rossberg, A.: Webassembly core specification. W3C working draft, W3C (Sep 2024), <https://www.w3.org/TR/2024/WD-wasm-core-2-20240911/>
- <span id="page-19-13"></span>59. Ruiz-Rube, I., Dodero, J.M., Colomo-Palacios, R.: A framework for software process deployment and evaluation. Information and Software Technology 59, 205–221 (2015)
- <span id="page-19-6"></span>60. Sallou, J., Durieux, T., Panichella, A.: Breaking the silence: the threats of using LLMs in software engineering. In: Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results. pp. 102–106 (2024)
- <span id="page-19-1"></span>61. Soares, E., Sizilio, G., Santos, J., Da Costa, D.A., Kulesza, U.: The effects of continuous integration on software development: a systematic literature review. Empirical Software Engineering 27(3), 78 (2022)
- <span id="page-19-2"></span>62. Sowiński, P., Lacalle, I., Vaño, R., Palau, C.E.: Autonomous choreography of WebAssembly workloads in the federated cloud-edge-IoT continuum. In: 2023 IEEE 12th International Conference on Cloud Networking (CloudNet). pp. 454–459. IEEE (2023)
- <span id="page-19-15"></span>63. Sowiński, P., Szmeja, P., Ganzha, M., Paprzycki, M.: RDF stream taxonomy: Systematizing RDF stream types in research and practice. Electronics 13(13), 2558 (2024)
- <span id="page-19-16"></span>64. Sowiński, P., Wasielewska-Michniewska, K., Ganzha, M., Paprzycki, M., Bădică, C.: Ontology reuse: The real test of ontological design. In: New Trends in Intelligent Software Methodologies, Tools and Techniques, pp. 631–645. IOS Press (2022)
- <span id="page-19-12"></span>65. Sowiński, P., Wasielewska-Michniewska, K., Ganzha, M., Paprzycki, M., et al.: Efficient RDF streaming for the edge-cloud continuum. In: 2022 IEEE 8th World Forum on Internet of Things (WF-IoT). pp. 1–8. IEEE (2022)

- <span id="page-20-1"></span>66. Spies, B., Mock, M.: An evaluation of WebAssembly in non-web environments. In: 2021 XLVII Latin American Computing Conference (CLEI). pp. 1–10. IEEE (2021)
- <span id="page-20-6"></span>67. Sunitha, E., Samuel, P.: Automatic code generation from UML state chart diagrams. IEEE Access 7, 8591–8608 (2019)
- <span id="page-20-12"></span>68. Tiddi, I., Schlobach, S.: Knowledge graphs as tools for explainable machine learning: A survey. Artificial Intelligence 302, 103627 (2022)
- <span id="page-20-0"></span>69. Vaño, R., Lacalle, I., Sowiński, P., S-Julián, R., Palau, C.E.: Cloud-native workload orchestration at the edge: A deployment review and future directions. Sensors 23(4), 2215 (2023)
- <span id="page-20-7"></span>70. W3C OWL Working Group: OWL 2 web ontology language document overview (second edition). W3C recommendation, W3C (Dec 2012), [https://www.w3.org/](https://www.w3.org/TR/2012/REC-owl2-overview-20121211/) [TR/2012/REC-owl2-overview-20121211/](https://www.w3.org/TR/2012/REC-owl2-overview-20121211/)
- <span id="page-20-5"></span>71. Wang, L., Ma, C., Feng, X., Zhang, Z., Yang, H., Zhang, J., Chen, Z., Tang, J., Chen, X., Lin, Y., et al.: A survey on large language model based autonomous agents. Frontiers of Computer Science 18(6), 186345 (2024)
- <span id="page-20-2"></span>72. Waseem, M., Das, T., Ahmad, A., Liang, P., Mikkonen, T.: Issues and their causes in WebAssembly applications: An empirical study. In: Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering. pp. 170–180 (2024)
- <span id="page-20-4"></span>73. Weidinger, L., Uesato, J., Rauh, M., Griffin, C., Huang, P.S., Mellor, J., Glaese, A., Cheng, M., Balle, B., Kasirzadeh, A., et al.: Taxonomy of risks posed by language models. In: Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency. pp. 214–229 (2022)
- <span id="page-20-8"></span>74. Weigl, D.M., Crawford, T., Gkiokas, A., Goebl, W., Emilia, G., Guti, N., Liem, C.C., Santos, P.: Fair interconnection and enrichment of public-domain music resources on the web. Empirical Musicology Review 16(1), 16–33 (2021)
- <span id="page-20-3"></span>75. Wiklund, K., Eldh, S., Sundmark, D., Lundqvist, K.: Impediments for software test automation: A systematic literature review. Software Testing, Verification and Reliability 27(8), e1639 (2017)
- <span id="page-20-11"></span>76. Yu, D., Yang, B., Liu, D., Wang, H., Pan, S.: A survey on neural-symbolic learning systems. Neural Networks (2023)
- <span id="page-20-9"></span>77. Zablith, F., Antoniou, G., d'Aquin, M., Flouris, G., Kondylakis, H., Motta, E., Plexousakis, D., Sabou, M.: Ontology evolution: a process-centric survey. The knowledge engineering review 30(1), 45–75 (2015)
- <span id="page-20-10"></span>78. Zhong, L., Wu, J., Li, Q., Peng, H., Wu, X.: A comprehensive survey on automatic knowledge graph construction. ACM Computing Surveys 56(4), 1–62 (2023)
